# åœ¨ Google Cloud Dataproc ä¸­ä½¿ç”¨ Apache Sqoop ç§»åŠ¨æ•°æ®

> åŸæ–‡ï¼š<https://medium.com/google-cloud/moving-data-with-apache-sqoop-in-google-cloud-dataproc-4056b8fa2600?source=collection_archive---------0----------------------->

![](img/434b648d1035f5cbc50f8a70dcc83d3a.png)

æœ‰å…³ç³»æ•°æ®åº“å—ï¼Ÿâ€”æƒ³ç”¨ [Apache Sqoop](https://sqoop.apache.org/) æŠŠè¿™ä¸ªæ•°æ®åº“å¯¼å‡ºåˆ°[äº‘å­˜å‚¨](https://cloud.google.com/storage/)ã€ [BigQuery](https://cloud.google.com/bigquery/) ï¼Œæˆ–è€… [Apache Hive](https://hive.apache.org/) ï¼Ÿâ€”æƒ³é€šè¿‡ [Cloud Dataproc](https://cloud.google.com/dataproc/) æ¥å®Œæˆè¿™ä¸€åˆ‡ï¼Œè¿™æ ·æ‚¨å°±åªéœ€ä¸ºæ‚¨ä½¿ç”¨çš„ä¸œè¥¿ä»˜è´¹äº†ï¼Ÿ

å¸Œæœ›ä½ å›ç­”**æ˜¯**å› ä¸ºè¿™å°±æ˜¯è¿™ç¯‡æ–‡ç« çš„å†…å®¹ï¼

Cloud Dataproc éå¸¸æ£’ï¼Œå› ä¸ºå®ƒå¯ä»¥å¿«é€Ÿåˆ›å»ºä¸€ä¸ª Hadoop é›†ç¾¤ï¼Œç„¶åæ‚¨å¯ä»¥ä½¿ç”¨å®ƒæ¥è¿è¡Œæ‚¨çš„ Hadoop ä½œä¸š(ç‰¹åˆ«æ˜¯æœ¬æ–‡ä¸­çš„ Sqoop ä½œä¸š)ï¼Œç„¶åä¸€æ—¦æ‚¨çš„ä½œä¸šå®Œæˆï¼Œæ‚¨å°±å¯ä»¥ç«‹å³åˆ é™¤é›†ç¾¤ã€‚è¿™æ˜¯åˆ©ç”¨ Dataproc çŸ­æš‚çš„æŒ‰ä½¿ç”¨ä»˜è´¹æ¨¡å‹å‰Šå‡æˆæœ¬çš„ä¸€ä¸ªå¾ˆå¥½çš„ä¾‹å­ï¼Œå› ä¸ºç°åœ¨æ‚¨å¯ä»¥å¿«é€Ÿåˆ›å»º/åˆ é™¤ hadoop é›†ç¾¤ï¼Œå†ä¹Ÿä¸ä¼šè®©é›†ç¾¤é—²ç½®äº†ï¼

è¿™é‡Œæ˜¯å…³äºä½¿ç”¨ Sqoop çš„å¿«é€Ÿç‹¬å®¶æ–°é—»(çœ‹æˆ‘åœ¨é‚£é‡Œåšäº†ä»€ä¹ˆğŸ˜)ç§»åŠ¨æ•°æ®:

*   Sqoop å°†æ•°æ®ä»å…³ç³»æ•°æ®åº“ç³»ç»Ÿæˆ–å¤§å‹æœºå¯¼å…¥ HDFS (Hadoop åˆ†å¸ƒå¼æ–‡ä»¶ç³»ç»Ÿ)ã€‚
*   åœ¨ Dataproc Hadoop é›†ç¾¤ä¸Šè¿è¡Œ Sqoop å¯ä»¥è®©æ‚¨è®¿é—®å†…ç½®çš„äº‘å­˜å‚¨è¿æ¥å™¨ï¼Œè¯¥è¿æ¥å™¨å…è®¸æ‚¨ä½¿ç”¨äº‘å­˜å‚¨ gs:// file å‰ç¼€ï¼Œè€Œä¸æ˜¯ Hadoop hdfs:// file å‰ç¼€ã€‚
*   å‰é¢ä¸¤ç‚¹æ„å‘³ç€ä½ å¯ä»¥ä½¿ç”¨ Sqoop å°†æ•°æ®ç›´æ¥å¯¼å…¥äº‘å­˜å‚¨ï¼Œå®Œå…¨è·³è¿‡ HDFSï¼
*   ä¸€æ—¦ä½ çš„æ•°æ®åœ¨äº‘å­˜å‚¨ä¸­ï¼Œä½ å¯ä»¥ç®€å•åœ°ä½¿ç”¨ Cloud SDK [bq å‘½ä»¤è¡Œå·¥å…·](https://cloud.google.com/bigquery/docs/bq-command-line-tool)å°†æ•°æ®[åŠ è½½åˆ° BigQuery ä¸­ã€‚**æˆ–è€…ï¼Œæ‚¨å¯ä»¥é€šè¿‡å°†***Hive . metastore . warehouse . dir***æŒ‡å‘ä¸€ä¸ª**](https://cloud.google.com/bigquery/docs/loading-data-cloud-storage-avro#bigquery-import-gcs-file-cli)[**GCS bucket**](https://cloud.google.com/storage/docs/creating-buckets)**ï¼Œè®© Sqoop å°†æ•°æ®ç›´æ¥å¯¼å…¥åˆ°æ‚¨çš„ Dataproc é›†ç¾¤çš„ Hive ä»“åº“ä¸­ï¼Œè¯¥ä»“åº“å¯ä»¥åŸºäºäº‘å­˜å‚¨ï¼Œè€Œä¸æ˜¯ HDFSã€‚**

æ‚¨å¯ä»¥ä½¿ç”¨ä¸¤ç§ä¸åŒçš„æ–¹æ³•å‘é›†ç¾¤æäº¤ Dataproc ä½œä¸š:

## **æ–¹æ³•ä¸€ã€‚)æ‰‹åŠ¨ Dataproc ä»»åŠ¡æäº¤**

*   [åˆ›å»º Dataproc é›†ç¾¤](https://cloud.google.com/dataproc/docs/guides/create-cluster)
*   [æäº¤ Dataproc ä½œä¸š](https://cloud.google.com/dataproc/docs/guides/submit-job)
*   [å½“ä½œä¸šå®Œæˆæ—¶åˆ é™¤ Dataproc é›†ç¾¤](https://cloud.google.com/dataproc/docs/guides/manage-cluster#deleting_a_cluster)

## **æ–¹æ³•äºŒã€‚)ä½¿ç”¨å·¥ä½œæµæ¨¡æ¿è‡ªåŠ¨æäº¤ Dataproc ä»»åŠ¡**

*   åˆ›å»ºä¸€ä¸ª[å·¥ä½œæµæ¨¡æ¿](https://cloud.google.com/dataproc/docs/concepts/workflows/overview)ï¼Œè¯¥æ¨¡æ¿è‡ªåŠ¨æ‰§è¡Œä¹‹å‰çš„ 3 ä¸ªæ‰‹åŠ¨æ­¥éª¤(åˆ›å»ºã€æäº¤ã€åˆ é™¤)ã€‚

ä½¿ç”¨æ‰‹åŠ¨ä½œä¸šæäº¤æ–¹æ³•æ›´å®¹æ˜“æ’é™¤ä½œä¸šé”™è¯¯ï¼Œå› ä¸ºæ‚¨å¯ä»¥æ§åˆ¶ä½•æ—¶åˆ é™¤é›†ç¾¤ã€‚ä¸€æ—¦æ‚¨å‡†å¤‡å¥½åœ¨ç”Ÿäº§ä¸­è¿è¡Œä½œä¸šï¼Œä½¿ç”¨å·¥ä½œæµæ¨¡æ¿çš„è‡ªåŠ¨åŒ–æ–¹æ³•æ˜¯ç†æƒ³çš„ï¼Œå› ä¸ºå®ƒè´Ÿè´£é›†ç¾¤åˆ›å»ºã€ä½œä¸šæäº¤å’Œåˆ é™¤ã€‚è¿™ä¸¤ç§æ–¹æ³•å®é™…ä¸Šéå¸¸ç±»ä¼¼äºè®¾ç½®ï¼Œä¸‹é¢ä¼šæœ‰æ›´è¯¦ç»†çš„ä»‹ç»ã€‚

# **ç­‰ç­‰ï¼åœ¨ä½ é˜…è¯»ä¹‹å‰â€¦**

ä¸‹é¢çš„ä¾‹å­æ¼”ç¤ºäº†ä½¿ç”¨ Sqoop è¿æ¥åˆ° MySQL æ•°æ®åº“ã€‚æ‚¨å¯ä»¥é€šè¿‡åœ¨çº¿[quick start for Cloud SQL for MySQL](https://cloud.google.com/sql/docs/mysql/quickstart)åœ¨ GCP å¿«é€Ÿè½»æ¾åœ°åˆ›å»ºè‡ªå·±çš„æµ‹è¯• MySQL æ•°æ®åº“ã€‚å¦‚æœæ‚¨å®Œæˆäº†å¿«é€Ÿå…¥é—¨ï¼Œä¸è¦å¿˜è®°ä½¿ç”¨[äº‘ SQL ä»£ç†åˆå§‹åŒ–æ“ä½œ](https://github.com/GoogleCloudPlatform/dataproc-initialization-actions/tree/master/cloud-sql-proxy)åˆ›å»º Dataproc é›†ç¾¤ï¼Œä»¥ä¾¿æ‚¨å¯ä»¥è½»æ¾è¿æ¥åˆ° MySQL æ•°æ®åº“ã€‚æœ€åï¼Œé€šè¿‡åœ¨å®Œæˆåæ¸…ç†æ•°æ®åº“æ¥é¿å…äº§ç”Ÿè´¹ç”¨ã€‚

# æ‰‹åŠ¨æäº¤ Dataproc ä½œä¸šçš„ 3 ä¸ªæ­¥éª¤

**1ã€‚åˆ›å»ºä¸€ä¸ª Dataproc é›†ç¾¤**

gcloud å·¥å…·çš„ [Dataproc é›†ç¾¤åˆ›å»ºå‘½ä»¤](https://cloud.google.com/dataproc/docs/guides/create-cluster)å°†é»˜è®¤åˆ›å»ºä¸€ä¸ªä¸»èŠ‚ç‚¹è™šæ‹Ÿæœº(è™šæ‹Ÿæœº)å’Œä¸¤ä¸ªå·¥ä½œèŠ‚ç‚¹è™šæ‹Ÿæœºã€‚æ‰€æœ‰ 3 ä¸ªèŠ‚ç‚¹è™šæ‹Ÿæœºéƒ½æ˜¯ n1 å‹æ ‡å‡† 4 æœºå™¨ã€‚ä¸ºç®€å•èµ·è§ï¼Œä¸‹é¢çš„ç¤ºä¾‹å‘½ä»¤ä½¿ç”¨äº†æœ€å°‘çš„å¿…è¦æ ‡å¿—ã€‚**æ³¨æ„:ä½¿ç”¨æœ€åä¸€ä¸ª** `--properties` **æ ‡å¿—æ˜¯ä¸ºäº†ç”¨äº‘å­˜å‚¨ä½ç½®** `gs://<GCS_BUCKET>/hive-warehouse` **è¦†ç›–é»˜è®¤çš„é›†ç¾¤ä¸Šçš„ Hive ä»“åº“ç›®å½•(hdfs:///user/hive/warehouse)ã€‚é€šè¿‡å°†è¿™ä¸ª Hive ä»“åº“ç›®å½•** `hive.metastore.warehouse.dir` **æŒ‡å‘äº‘å­˜å‚¨ï¼Œå¯ä»¥æŒä¹…åŒ–æ‰€æœ‰ Hive æ•°æ®(å³ä½¿åˆ é™¤äº† Dataproc é›†ç¾¤)ã€‚**

*   *å¦‚æœæ‚¨æ­£åœ¨è¿æ¥åˆ°æœ¬åœ°æ‰˜ç®¡çš„ MySQL æ•°æ®åº“ï¼Œå› æ­¤ä¸éœ€è¦* [*äº‘ SQL ä»£ç†*](https://cloud.google.com/sql/docs/mysql/sql-proxy) *ï¼Œè¯·ä½¿ç”¨ä¸‹é¢çš„å‘½ä»¤åˆ›å»ºæ‚¨çš„é›†ç¾¤ã€‚ç¡®ä¿å°†é›†ç¾¤åˆ†é…ç»™åœ¨æ‚¨çš„ GCP ç¯å¢ƒå’Œæœ¬åœ°ç¯å¢ƒä¹‹é—´å…±äº«çš„* [*VPC ç½‘ç»œ*](https://cloud.google.com/vpc/) *ã€‚*

```
gcloud dataproc clusters create <**CLUSTER_NAME**> --zone=<**ZONE**> --network=<**VPC_NETWORK**> --properties=hive:hive.metastore.warehouse.dir=gs://<**GCS_BUCKET**>/hive-warehouse
```

*   *å¦‚æœæ‚¨ä½¿ç”¨* [*äº‘ SQL ä»£ç†*](https://cloud.google.com/sql/docs/mysql/sql-proxy) *è¿æ¥åˆ°äº‘ SQL-MySQL æ•°æ®åº“ï¼Œè¯·ä½¿ç”¨ä¸‹é¢çš„å‘½ä»¤åˆ›å»ºæ‚¨çš„é›†ç¾¤ã€‚* ***æ³¨æ„:ç”±äºé»˜è®¤çš„ MySQL ç«¯å£ 3306 å·²ç»è¢« Dataproc çš„é»˜è®¤ Hive å…ƒæ•°æ® MySQL æœåŠ¡å™¨å ç”¨ï¼Œæ‰€ä»¥éœ€è¦ä¸º<ç«¯å£>é€‰æ‹©ä¸€ä¸ª 3306 ä»¥å¤–çš„å€¼(å¦‚ 3307)ã€‚***

```
gcloud dataproc clusters create <**CLUSTER_NAME**> --zone=<**ZONE**> --scopes=default,sql-admin --initialization-actions=gs://dataproc-initialization-actions/cloud-sql-proxy/cloud-sql-proxy.sh --properties=hive:hive.metastore.warehouse.dir=gs://<**GCS_BUCKET**>/hive-warehouse --metadata=enable-cloud-sql-hive-metastore=false --metadata=additional-cloud-sql-instances=<**PROJECT_ID**>:<**REGION**>:<[**SQL_INSTANCE_NAME**](https://cloud.google.com/sql/docs/mysql/instance-info)>=tcp:<**PORT**> 
```

**2ã€‚æäº¤ä¸€ä¸ªè¿è¡Œ** [**Sqoop å¯¼å…¥å·¥å…·**](https://sqoop.apache.org/docs/1.4.7/SqoopUserGuide.html#_literal_sqoop_import_literal) çš„ dataproc hadoop ä½œä¸š

*   *å¦‚æœæ‚¨å¸Œæœ› Sqoop å°†æ‚¨çš„æ•°æ®åº“è¡¨ä½œä¸º Avro æ–‡ä»¶å¯¼å…¥äº‘å­˜å‚¨ï¼Œè¯·æäº¤ä¸‹é¢çš„ä½œä¸šå‘½ä»¤ï¼Œç„¶åæ‚¨å°†ä½¿ç”¨ bq å·¥å…·* [*åŠ è½½åˆ° BigQuery*](https://cloud.google.com/bigquery/docs/loading-data-cloud-storage-avro#bigquery-import-gcs-file-cli) *ä¸­ã€‚*

```
gcloud dataproc jobs submit hadoop --cluster=<**CLUSTER_NAME**> --class=org.apache.sqoop.Sqoop --jars=gs://<**GCS_BUCKET**>/sqoop-1.4.7-hadoop260.jar,gs://<**GCS_BUCKET**>/avro-tools-1.8.2.jar,file:///usr/share/java/mysql-connector-java-5.1.42.jar -- import -Dmapreduce.job.user.classpath.first=true --connect=jdbc:mysql://<**HOSTNAME**>:<**PORT**>/<**DATABASE_NAME**> --username=<**DATABASE_USERNAME**> --password-file=gs://<**GCS_BUCKET**>/passwordFile.txt --target-dir=gs://<**GCS_BUCKET**>/mysql_output --table=<**TABLE**> --as-avrodatafile
```

*   *å¦‚æœæ‚¨æƒ³è®© Sqoop å°†æ‚¨çš„æ•°æ®åº“è¡¨å¯¼å…¥åˆ°ä¸€ä¸ª Hive è¡¨ä¸­ï¼Œæäº¤ä¸‹é¢çš„ job å‘½ä»¤ã€‚* ***æ³¨æ„:ä¸‹é¢çš„å‘½ä»¤å’Œä¸Šé¢çš„ä¸€æ ·ï¼Œåªæ˜¯åœ¨*** `â€” -jars=` ***å‚æ•°ä¸­å¤šåŠ äº†ä¸€ä¸ª jar*** `file:///usr/lib/hive/lib/hive-exec.jar` ***ï¼Œç”¨*** `--hive-import`æ›¿æ¢äº† `--as-avrodatafile` ***ï¼Œå¹¶å»æ‰äº†`--target-dir`æ ‡å¿—ã€‚***

```
gcloud dataproc jobs submit hadoop --cluster=<**CLUSTER_NAME**> --class=org.apache.sqoop.Sqoop --jars=gs://<**GCS_BUCKET**>/sqoop-1.4.7-hadoop260.jar,gs://<**GCS_BUCKET**>/avro-tools-1.8.2.jar,file:///usr/share/java/mysql-connector-java-5.1.42.jar,file:///usr/lib/hive/lib/hive-exec.jar -- import -Dmapreduce.job.user.classpath.first=true --connect=jdbc:mysql://<**HOSTNAME**>:<**PORT**>/<**DATABASE_NAME**> --username=<**DATABASE_USERNAME**> --password-file=gs://<**GCS_BUCKET**>/passwordFile.txt --table=<**TABLE**> --hive-import
```

**3ã€‚ä¸€æ—¦ Dataproc ä»»åŠ¡å®Œæˆï¼Œåˆ é™¤é›†ç¾¤**

```
gcloud dataproc clusters delete <**CLUSTER_NAME**>
```

# ä»”ç»†çœ‹çœ‹æ­¥éª¤ 2

![](img/99212497900f4f1356d44fd03aa47e8b.png)

è¿‘è·ç¦»è§‚å¯Ÿ

`gcloud dataproc jobs submit hadoop`â†è¯¥å‘½ä»¤çš„ç¬¬ä¸€éƒ¨åˆ†æ˜¯è°ƒç”¨ [gcloud å·¥å…·](https://cloud.google.com/sdk/gcloud/reference)çš„åœ°æ–¹ã€‚gcloud å·¥å…·æœ‰å¾ˆå¤šåŠŸèƒ½ï¼Œæ‰€ä»¥æ›´å…·ä½“åœ°è¯´ï¼Œæ‚¨è°ƒç”¨çš„æ˜¯ [hadoop](https://cloud.google.com/sdk/gcloud/reference/dataproc/jobs/submit/hadoop) ä½œä¸šæäº¤å‘½ä»¤ã€‚è¯¥å‘½ä»¤åµŒå¥—åœ¨ gcloud å·¥å…·ä¸­çš„å‡ å±‚å‘½ä»¤ç»„ä¸‹: [dataproc ç»„](https://cloud.google.com/sdk/gcloud/reference/beta/dataproc)->-[ä½œä¸šç»„](https://cloud.google.com/sdk/gcloud/reference/dataproc/jobs)->-[æäº¤ç»„](https://cloud.google.com/sdk/gcloud/reference/dataproc/jobs/submit) - > [hadoop å‘½ä»¤](https://cloud.google.com/sdk/gcloud/reference/dataproc/jobs/submit/hadoop)ã€‚

`--cluster` â†è¿™ä¸ª gcloud æ ‡å¿—æŒ‡å®šå°†ä½œä¸šæäº¤åˆ°å“ªä¸ª dataproc é›†ç¾¤ã€‚

`--class` â†è¿™ä¸ª gcloud æ ‡å¿—æŒ‡å®šäº†æ‚¨å¸Œæœ› Dataproc ä½œä¸šè¿è¡Œçš„ä¸»ç±»(org.apache.sqoop.Sqoop)ã€‚åœ¨å¹•åï¼ŒDataproc è°ƒç”¨ Hadoop å·¥å…·å¹¶è¿è¡Œè¿™ä¸ªä¸»ç±»ï¼Œå°±åƒ [Sqoop å‘½ä»¤è¡Œå·¥å…·](https://github.com/apache/sqoop/blob/11c83f68386add243762929ecf7f6f25a99efbf4/bin/sqoop#L101)ä¸€æ ·ã€‚**æ³¨æ„:ç¡®ä¿åœ¨** `--jars` **æ ‡å¿—ä¸­åŒ…å«ä¸»ç±»çš„ jar æ–‡ä»¶çš„è·¯å¾„(ä¾‹å¦‚** `--jars=gs://<GCS_BUCKET>/sqoop-1.4.7-hadoop260.jar` **)ã€‚**

`--jars`â†è¿™ä¸ª gcloud æ ‡å¿—æŒ‡å®šäº†ä¸€ä¸ªé€—å·åˆ†éš”çš„ jar æ–‡ä»¶åˆ—è¡¨**è·¯å¾„**(è·¯å¾„åº”è¯¥æŒ‡å‘ GCS æˆ– Dataproc é›†ç¾¤ä¸­çš„æ–‡ä»¶)ã€‚è¿™äº› jar æ–‡ä»¶è¢«æä¾›ç»™ Dataproc é›†ç¾¤ä¸­çš„ MapReduce å’Œ driver ç±»è·¯å¾„ã€‚è¦åœ¨ Dataproc ä¸­è¿è¡Œ Sqoopï¼Œæ‚¨éœ€è¦æä¾›ä»¥ä¸‹ jar æ–‡ä»¶:

*   æœ€æ–°çš„ Sqoop ç‰ˆæœ¬([Sqoop-1 . 4 . 7-Hadoop 260 . jar](http://central.maven.org/maven2/org/apache/sqoop/sqoop/1.4.7/sqoop-1.4.7-hadoop260.jar))([Maven ç«™ç‚¹](https://mvnrepository.com/artifact/org.apache.sqoop/sqoop)æŸ¥çœ‹æœ€æ–°ç‰ˆæœ¬)
*   JDBC é©±åŠ¨ç¨‹åºéœ€è¦è¿æ¥åˆ°æ‚¨çš„æ•°æ®åº“ã€‚å¯¹äº MySQL é©±åŠ¨ç¨‹åºï¼Œåªéœ€å°†æ–‡ä»¶è·¯å¾„æ·»åŠ åˆ°å­˜åœ¨äº Dataproc é›†ç¾¤ä¸­çš„ MySQL é©±åŠ¨ç¨‹åº(file:///usr/share/Java/MySQL-connector-Java-5 . 1 . 42 . jar)ã€‚å¦‚æœæ‚¨è¿æ¥åˆ°å¦ä¸€ä¸ªæ•°æ®åº“ï¼Œä¾‹å¦‚ DB2ï¼Œé‚£ä¹ˆåŒ…æ‹¬è¯¥æ•°æ®åº“æ‰€å¿…éœ€çš„ DB2 JDBC é©±åŠ¨ç¨‹åºã€‚
*   ä»¥æŒ‡å®šçš„è¾“å‡ºæ ¼å¼åºåˆ—åŒ–æ•°æ®æ‰€éœ€çš„ä»»ä½• jar æ–‡ä»¶ã€‚åœ¨æœ¬ä¾‹ä¸­ï¼Œæ‚¨å°†å¯¼å…¥çš„ MySQL æ•°æ®å­˜å‚¨ä¸º Avro æ–‡ä»¶ï¼Œå› æ­¤æ‚¨åŒ…æ‹¬äº† Avro jar([Avro-tools-1 . 8 . 2 . jar](https://repo1.maven.org/maven2/org/apache/avro/avro-tools/1.8.2/avro-tools-1.8.2.jar))([Maven ç«™ç‚¹](https://mvnrepository.com/artifact/org.apache.avro/avro-tools)ä»¥æ£€æŸ¥æœ€æ–°ç‰ˆæœ¬)ã€‚**æ³¨æ„:Sqoop å·¥å…·æœ¬èº«è¦æ±‚ Avro ç‰ˆæœ¬è‡³å°‘ä¸º 1.8.0 æ‰èƒ½æ­£å¸¸è¿è¡Œï¼Œå› æ­¤å³ä½¿æ‚¨ä¸æ‰“ç®—ä»¥ Avro æ ¼å¼å­˜å‚¨æ•°æ®ï¼ŒAvro jar ä¹Ÿæ˜¯å¿…è¦çš„ã€‚**
*   (å¯é€‰)å·²ç»å­˜åœ¨äº Dataproc ä¸­çš„é…ç½®å•å…ƒé©±åŠ¨ç¨‹åº(file:///usr/lib/Hive/lib/Hive-exec . jar)ã€‚**æ³¨æ„:åªæœ‰å½“æ‚¨ä½¿ç”¨ Sqoop å°†æ•°æ®ç›´æ¥å¯¼å…¥ Dataproc çš„ Hive ä»“åº“æ—¶ï¼Œæ‰éœ€è¦è¿™ä¸ª Hive jarã€‚**

`-- import`â†å•ä¸ª`--` gcloud å‚æ•°å°†å·¦è¾¹çš„ gcloud ç‰¹å®šæ ‡å¿—å’Œå³è¾¹çš„ hadoop ä½œä¸šå‚æ•°åˆ†å¼€ã€‚æ—¢ç„¶æ‚¨å°† Sqoop ä¸»ç±»ä¼ é€’ç»™äº† hadoop å·¥å…·(é€šè¿‡`--class`æ ‡å¿—)ï¼Œé‚£ä¹ˆæ‚¨è¿˜å¿…é¡»æŒ‡å®šæ‚¨å¸Œæœ›ä¸»ç±»è¿è¡Œçš„ Sqoop å·¥å…·(åœ¨æœ¬ä¾‹ä¸­ä¸º`import`)ã€‚åœ¨`import`ä¹‹åï¼Œæ‚¨ä¸º [Sqoop å¯¼å…¥å·¥å…·](https://sqoop.apache.org/docs/1.4.7/SqoopUserGuide.html#_literal_sqoop_import_literal)æŒ‡å®šæ‰€æœ‰å‚æ•°ã€‚

`-Dmapreduce.job.user.classpath.first=true`â†è¿™ä¸ª Hadoop å‚æ•°å¯¹äºæŒ‡ç¤º Hadoop ä¼˜å…ˆä½¿ç”¨ç”¨æˆ·æä¾›çš„ jar(é€šè¿‡`--jars`æ ‡å¿—ä¼ é€’)è€Œä¸æ˜¯é›†ç¾¤ä¸­åŒ…å«çš„é»˜è®¤ jar æ˜¯å¿…è¦çš„ã€‚Sqoop éœ€è¦ Avro çš„ 1.8.0 ç‰ˆæœ¬ï¼Œè€Œ Avro çš„æœ¬åœ° Dataproc ç‰ˆæœ¬åœ¨æ’°å†™æœ¬æ–‡æ—¶æ˜¯ 1.7.7ã€‚å°†è¿™ä¸ªå‚æ•°è®¾ç½®ä¸º`true`å°†ä¼šç»™ Sqoop ä½ åœ¨`--jars`åˆ—è¡¨ä¸­ä¼ é€’çš„ Avro jar çš„æ­£ç¡®ç‰ˆæœ¬ã€‚

`-â€”connect=`â†è¿™ä¸ª Sqoop å‚æ•°æŒ‡å®šäº† JDBC è¿æ¥å­—ç¬¦ä¸²: *jdbc:mysql:// <ä¸»æœºå> : <ç«¯å£> / <æ•°æ®åº“å>ã€‚* **æ³¨æ„:å¦‚æœæ‚¨ä½¿ç”¨äº‘ SQL ä»£ç†è¿æ¥åˆ°æ‚¨çš„æ•°æ®åº“ï¼Œè¯·ç¡®ä¿ä¸»æœºåè®¾ç½®ä¸ºâ€œlocalhost â€,å¹¶ä¸”æ‚¨ä½¿ç”¨çš„ç«¯å£ä¸æ‚¨åˆ›å»º Dataproc é›†ç¾¤**æ—¶ä½¿ç”¨çš„ä»£ç†ç«¯å£ç›¸åŒ(ä¾‹å¦‚ï¼Œç¡®ä¿é›†ç¾¤åˆ›å»ºå‚æ•°`--metadata=additional-cloud-sql-instances=<PROJECT_ID>:<REGION>:<[SQL_INSTANCE_NAME](https://cloud.google.com/sql/docs/mysql/instance-info)>=tcp:<**PORT**>`å’Œæ‚¨çš„ Sqoop è¿æ¥å‚æ•°`--connect=jdbc:mysql://<HOSTNAME>:<**PORT**>/<DATABASE_NAME>`å…±äº«åŒä¸€ä¸ªç«¯å£)ã€‚

`--username=`â†è¿™ä¸ª Sqoop å‚æ•°æŒ‡å®šåœ¨å‘å…³ç³»æ•°æ®åº“è¿›è¡Œèº«ä»½éªŒè¯æ—¶ä½¿ç”¨çš„ç”¨æˆ·åã€‚

`--password-file=`â†è¿™ä¸ª Sqoop å‚æ•°æŒ‡å®šäº† GCS (Google Cloud Storage)ä¸­çš„ä¸€ä¸ªæ–‡ä»¶çš„è·¯å¾„ï¼Œè¯¥æ–‡ä»¶åŒ…å«æ‚¨çš„æ•°æ®åº“çš„å¯†ç ã€‚**è­¦å‘Š:ä¸è¦ä½¿ç”¨** `--password` **é€‰é¡¹è€Œä¸æ˜¯** `--password-file` **é€‰é¡¹ï¼Œå› ä¸ºè¿™å°†ä½¿æ‚¨çš„å¯†ç æš´éœ²åœ¨æ—¥å¿—ä¸­ã€‚**

`--target-dir=`â†ä¼ ç»Ÿä¸Šï¼Œå½“åœ¨ Hadoop ä¸­è¿è¡Œ Sqoop æ—¶ï¼Œæ‚¨ä¼šå°†è¿™ä¸ª Sqoop å‚æ•°è®¾ç½®ä¸º HDFS (hdfs://)ç›®å½•è·¯å¾„ï¼Œä½†æ˜¯ç”±äºæ‚¨ä½¿ç”¨çš„æ˜¯ Dataprocï¼Œæ‚¨å¯ä»¥åˆ©ç”¨å†…ç½®çš„ GCS è¿æ¥å™¨ï¼Œå°†å…¶è®¾ç½®ä¸º GCS (gs://)ç›®å½•è·¯å¾„ã€‚è¿™æ„å‘³ç€ Sqoop ä¼šå°†å¯¼å…¥çš„æ•°æ®å­˜å‚¨åœ¨æ‚¨æŒ‡å®šçš„ GCS ä½ç½®ï¼Œå®Œå…¨è·³è¿‡ HDFSã€‚

`--table=`â†è¿™ä¸ª Sqoop å‚æ•°æŒ‡å®šäº†è¦å¯¼å…¥çš„æ•°æ®åº“è¡¨ã€‚

`--as-avrodatafile`â†æŒ‡å®šæ­¤ Sqoop æ ‡å¿—ï¼Œä»¥ Avro æ–‡ä»¶æ ¼å¼å­˜å‚¨æ‰€æœ‰å¯¼å…¥çš„æ•°æ®ã€‚Avro æ ¼å¼çš„ä¼˜ç‚¹æ˜¯æ—¢èƒ½ä»¥äºŒè¿›åˆ¶æ ¼å¼å‹ç¼©æ•°æ®ï¼Œåˆèƒ½å°†è¡¨æ¨¡å¼å­˜å‚¨åœ¨åŒä¸€ä¸ªæ–‡ä»¶ä¸­ã€‚

`--hive-import` â†æŒ‡å®šè¿™ä¸ª Sqoop æ ‡å¿—ï¼Œå°†æ‰€æœ‰å¯¼å…¥çš„æ•°æ®å­˜å‚¨åˆ°ä¸€ä¸ª Hive è¡¨ä¸­ã€‚**æ³¨æ„:å½“æ‚¨ä½¿ç”¨** `--hive-import` **æ ‡å¿—æ—¶ï¼Œè¯·ç¡®ä¿æ‚¨çš„ Dataproc é›†ç¾¤æ˜¯ä½¿ç”¨** `--properties=hive:hive.metastore.warehouse.dir=gs://<GCS_BUCKET>/hive-warehouse` **æ ‡å¿—åˆ›å»ºçš„ï¼Œè¿™æ ·æ‚¨å°±å¯ä»¥åœ¨ GCS ä¸­æŒä¹…åŒ–æ‚¨çš„é…ç½®å•å…ƒæ•°æ®ã€‚**

# ä½¿ç”¨å·¥ä½œæµæ¨¡æ¿è‡ªåŠ¨æäº¤ Dataproc ä»»åŠ¡çš„ 4 ä¸ªæ­¥éª¤

**1ã€‚åˆ›å»ºå·¥ä½œæµç¨‹**

*   *åˆ›å»ºå·¥ä½œæµæ¨¡æ¿æœ¬èº«ä¸ä¼šåˆ›å»ºäº‘ Dataproc é›†ç¾¤ï¼Œä¹Ÿä¸ä¼šåˆ›å»ºå’Œæäº¤ä½œä¸šã€‚æ¨¡æ¿åªæ˜¯ä¸€ç»„æŒ‡ä»¤ã€‚åªæœ‰å½“å·¥ä½œæµæ¨¡æ¿è¢«* ***å®ä¾‹åŒ–*** *æ—¶ï¼Œé›†ç¾¤å’Œä½œä¸šæ‰ä¼šè¢«åˆ›å»ºå’Œæ‰§è¡Œ(å‚è§æ­¥éª¤ 4)ã€‚*

```
gcloud beta dataproc workflow-templates create <**TEMPLATE_ID**>
```

**2ã€‚æ·»åŠ å·¥ä½œæµé›†ç¾¤åˆ›å»ºå±æ€§**

*   *ä¸ºäº†ç®€å•èµ·è§ï¼Œè®¸å¤šé›†ç¾¤å±æ€§è¢«æ•…æ„çœç•¥äº†*

```
gcloud beta dataproc workflow-templates set-managed-cluster <**TEMPLATE_ID**> --zone=<**ZONE**> --cluster-name=<**CLUSTER_NAME**>
```

**3ã€‚å°†ä½œä¸šæ·»åŠ åˆ°æ‚¨çš„å·¥ä½œæµä¸­ï¼Œä»¥ä¾¿åœ¨é›†ç¾¤ä¸Šè¿è¡Œ**

*   *å¦‚æœæ‚¨å¸Œæœ› Sqoop å°†æ‚¨çš„æ•°æ®åº“è¡¨ä½œä¸º Avro æ–‡ä»¶å¯¼å…¥åˆ°äº‘å­˜å‚¨ä¸­ï¼Œè¯·å°†ä¸‹é¢çš„ä½œä¸šæ·»åŠ åˆ°æ‚¨çš„å·¥ä½œæµä¸­ï¼Œç„¶åæ‚¨å°†ä½¿ç”¨ bq å·¥å…·* [*åŠ è½½åˆ° BigQuery*](https://cloud.google.com/bigquery/docs/loading-data-cloud-storage-avro#bigquery-import-gcs-file-cli) *ä¸­ã€‚*

```
gcloud beta dataproc workflow-templates add-job hadoop --step-id=<**STEP_ID**> --workflow-template=<**TEMPLATE_ID**> --class=org.apache.sqoop.Sqoop --jars=gs://<**GCS_BUCKET**>/sqoop-1.4.7-hadoop260.jar,gs://<**GCS_BUCKET**>/avro-tools-1.8.2.jar,file:///usr/share/java/mysql-connector-java-5.1.42.jar -- import -Dmapreduce.job.user.classpath.first=true --connect=jdbc:mysql://<**HOSTNAME**>:<**PORT**>/<**DATABASE_NAME**> --username=sqoop --password-file=gs://<**GCS_BUCKET**>/passwordFile.txt --target-dir=gs://<**GCS_BUCKET**>/mysql_output --table=<**TABLE**> --as-avrodatafile
```

*   *å¦‚æœæ‚¨å¸Œæœ› Sqoop å°†æ‚¨çš„æ•°æ®åº“è¡¨å¯¼å…¥åˆ°é…ç½®å•å…ƒè¡¨ä¸­ï¼Œè¯·å°†ä¸‹é¢çš„ä½œä¸šæ·»åŠ åˆ°æ‚¨çš„å·¥ä½œæµä¸­ã€‚* ***æ³¨æ„:ä¸‹é¢çš„å‘½ä»¤åœ¨*** `â€” -jars=` ***å‚æ•°ä¸­å¢åŠ äº†ä¸€ä¸ª jar*** `file:///usr/lib/hive/lib/hive-exec.jar` ***å¹¶æŠŠ*** `--as-avrodatafile` ***æ›¿æ¢ä¸º*** `--hive-import`

```
gcloud beta dataproc workflow-templates add-job hadoop --step-id=<**STEP_ID**> --workflow-template=<**TEMPLATE_ID**> --class=org.apache.sqoop.Sqoop --jars=gs://<**GCS_BUCKET**>/sqoop-1.4.7-hadoop260.jar,gs://<**GCS_BUCKET**>/avro-tools-1.8.2.jar,file:///usr/share/java/mysql-connector-java-5.1.42.jar,file:///usr/lib/hive/lib/hive-exec.jar -- import -Dmapreduce.job.user.classpath.first=true --connect=jdbc:mysql://<**HOSTNAME**>:<**PORT**>/<**DATABASE_NAME**> --username=<**DATABASE_USERNAME**> --password-file=gs://<**GCS_BUCKET**>/passwordFile.txt --table=<**TABLE**> --hive-import
```

**4ã€‚å®ä¾‹åŒ–/è¿è¡Œå·¥ä½œæµ**

*   *æ”¯æŒæ¨¡æ¿çš„å¤šä¸ª(åŒæ—¶)å®ä¾‹åŒ–ã€‚*

```
gcloud beta dataproc workflow-templates instantiate <**TEMPLATE_ID**>
```

# å°†æ‚¨çš„ Sqoop-Import æ•°æ®åŠ è½½åˆ° BigQuery ä¸­

![](img/fa5c033c1ace48d3ee39de60e96a93c3.png)

å¦‚æœæ‚¨ä½¿ç”¨ Sqoop å°†æ•°æ®åº“è¡¨å¯¼å…¥äº‘å­˜å‚¨ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨ [bq å‘½ä»¤è¡Œå·¥å…·](https://cloud.google.com/bigquery/docs/bq-command-line-tool)ç®€å•åœ°[å°†å…¶åŠ è½½åˆ° BigQuery](https://cloud.google.com/bigquery/docs/loading-data-cloud-storage-avro#bigquery-import-gcs-file-cli) :

```
bq load --source_format=AVRO <**YOUR_DATASET**>.<**YOUR_TABLE**> gs://<**GCS_BUCKET**>/mysql_output/*.avro
```

# ä½¿ç”¨ Dataproc é…ç½®å•å…ƒä½œä¸šæŸ¥è¯¢é…ç½®å•å…ƒè¡¨

![](img/527512cbec5210217f66bb2d0f190a3f.png)

å¦‚æœæ‚¨ä½¿ç”¨ Sqoop å°†æ‚¨çš„æ•°æ®åº“è¡¨å¯¼å…¥åˆ° Dataproc ä¸­çš„ Hiveï¼Œé‚£ä¹ˆæ‚¨å¯ä»¥é€šè¿‡å‘ Dataproc é›†ç¾¤æäº¤ä¸€ä¸ª [Hive ä½œä¸š](https://cloud.google.com/sdk/gcloud/reference/dataproc/jobs/submit/hive),åœ¨æ‚¨çš„ Hive ä»“åº“ä¸Šè¿è¡Œ SQL [æŸ¥è¯¢](https://cwiki.apache.org/confluence/display/Hive/GettingStarted#GettingStarted-SQLOperations):

```
gcloud dataproc jobs submit hive --cluster=<**CLUSTER_NAME**> -e="SELECT * FROM <**TABLE**>"
```

**æ³¨æ„:ç¡®ä¿åœ¨ Dataproc é›†ç¾¤ä¸Šè¿è¡Œè¿™äº›é…ç½®å•å…ƒä½œä¸šï¼Œè¯¥é›†ç¾¤çš„é»˜è®¤é…ç½®å•å…ƒä»“åº“ç›®å½•æŒ‡å‘åŒ…å«æ‚¨çš„ Sqoop å¯¼å‡ºæ•°æ®çš„åŒä¸€ä¸ª GCS bucket(ä¾‹å¦‚ï¼Œæ‚¨çš„é›†ç¾¤åº”è¯¥ä½¿ç”¨** `--properties=hive:hive.metastore.warehouse.dir=gs://<**GCS_BUCKET**>/hive-warehouse` **åˆ›å»º)ã€‚**

## å¸Œæœ›è¿™ä»½æŒ‡å—èƒ½ä¸ºä½ æä¾›è®¸å¤šæœ‰ä»·å€¼çš„æ•°æ®ï¼