<html>
<head>
<title>Streaming Dialogflow on your Desktop/Device/Raspberry Pi</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">桌面/设备/Raspberry Pi上的流媒体对话流</h1>
<blockquote>原文：<a href="https://medium.com/google-cloud/streaming-dialogflow-on-your-desktop-device-raspberry-pi-fe95b70b33a1?source=collection_archive---------0-----------------------#2020-02-06">https://medium.com/google-cloud/streaming-dialogflow-on-your-desktop-device-raspberry-pi-fe95b70b33a1?source=collection_archive---------0-----------------------#2020-02-06</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><figure class="hh hi ez fb hj hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es hg"><img src="../Images/2cfd8034797d8e8cf9c58f8f23a3e848.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JyR1iXGc9MjcDaUZX5vXQQ.png"/></div></div></figure><div class=""/><p id="bc52" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><em class="jo">把你的本地电脑变成一个由Dialogflow驱动的听、说的语音用户界面。</em></p><p id="79e0" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">如果你以前使用过<a class="ae jp" href="https://dialogflow.com/" rel="noopener ugc nofollow" target="_blank"> Dialogflow </a> (DF)，你就会知道这是一种构建智能对话界面的快捷方式。Dialogflow <a class="ae jp" href="https://cloud.google.com/dialogflow/docs/agents-overview" rel="noopener ugc nofollow" target="_blank">代理</a>可以是Facebook Messenger或Slack chatbot、Google Assistant或Alexa应用程序，甚至是自动化客户服务代理背后的大脑。</p><p id="b3a4" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">Dialogflow自带了一些支持的集成，使得在Slack/脸书/Alexa/etc上部署一个DF应用变得轻而易举。</p><figure class="jr js jt ju fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es jq"><img src="../Images/122006483d219b5e47f4cf92b0367d32.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*YVtn2tKT7oj5tbE4"/></div></div><figcaption class="jv jw et er es jx jy bd b be z dx translated">一些内置的Dialogflow集成。</figcaption></figure><p id="d993" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">但有时，您并不想将代理集成到现有平台中，而是想在自己的设备上运行它。也许你正在构建一个自助信息亭，想直接从你的localMac/PC/Raspberry Pi与Dialogflow对话。</p><p id="8ded" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在本文中，我将向您展示如何做到这一点，方法是连接Node.js中的Dialogflow代理，从您计算机的麦克风流入音频，并通过您的扬声器流出DialogFlow代理的响应。(如果您不使用Node，请在这里查看Python代码示例<a class="ae jp" href="https://gist.github.com/dalequark/aa0385de55b97fe1e2950b6e1ead063c" rel="noopener ugc nofollow" target="_blank"/>。)您需要的只是一个现有的DF代理。同时，如果你想直接跳到代码，你可以在这里找到它<a class="ae jp" href="https://gist.github.com/dalequark/4648c110b02963a049da2bfa637493fb" rel="noopener ugc nofollow" target="_blank">。</a></p><p id="6714" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们开始吧👉</p><h1 id="cde6" class="jz ka ht bd kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw bi translated">将Dialogflow配置为说话</h1><p id="4e43" class="pw-post-body-paragraph iq ir ht is b it kx iv iw ix ky iz ja jb kz jd je jf la jh ji jj lb jl jm jn hb bi translated">首先，登录到<a class="ae jp" href="https://dialogflow.cloud.google.com/#/login" rel="noopener ugc nofollow" target="_blank"> Dialogflow控制台</a>并导航到您想要流化的项目。就我而言，我正在从事一个名为<code class="du lc ld le lf b">SimpleAlarm</code>的项目。</p><p id="0497" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">点按屏幕左上角的齿轮图标。</p><figure class="jr js jt ju fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es lg"><img src="../Images/99072f2b08d4dcf1c662a566f654e279.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*V83_TX7XOAN29GEd"/></div></div></figure><p id="8fab" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在这里，在General选项卡下，记下您的项目id(我的是<code class="du lc ld le lf b">simplealarm-spoitm</code>)。保存该值以备后用。</p><figure class="jr js jt ju fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es lh"><img src="../Images/b4cc31d6f29f5e7a088f753594b5560c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*ekLqDFUtYm-5Vtbs"/></div></div></figure><p id="3ecd" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">接下来，导航到“语音”选项卡，向下滚动并单击“启用自动文本到语音”旁边的滑块启用此选项会导致Dialogflow在其响应中返回音频数据，这些数据可以直接通过扬声器播放。</p><figure class="jr js jt ju fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es lh"><img src="../Images/5a7974ba87975ff140ea6859eb2c259c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*K9wxEMtTvgJNKQXD"/></div></div></figure><p id="3201" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">如果您向下滚动到此处，您还可以看到用于更改代理声音的各种选项。在默认设置为“自动”的“语音”下，您可以选择男声和女声以及<a class="ae jp" href="https://cloud.google.com/text-to-speech/docs/wavenet" rel="noopener ugc nofollow" target="_blank"> WaveNet </a>语音，它们听起来比标准语音更像人类。</p><figure class="jr js jt ju fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es lh"><img src="../Images/c758044d485214e8e85c56b69278f879.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*lrkveaoz-XyJuA-K"/></div></div></figure><p id="0431" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">点击保存，我们就可以开始了。</p><h2 id="f274" class="li ka ht bd kb lj lk ll kf lm ln lo kj jb lp lq kn jf lr ls kr jj lt lu kv lv bi translated">证明</h2><p id="0ebb" class="pw-post-body-paragraph iq ir ht is b it kx iv iw ix ky iz ja jb kz jd je jf la jh ji jj lb jl jm jn hb bi translated">因为我们希望从本地计算机与Node.js中的Dialogflow代理进行交互，所以我们需要设置身份验证。在整个Google Cloud中，认证是通过<a class="ae jp" href="https://cloud.google.com/iam/docs/service-accounts" rel="noopener ugc nofollow" target="_blank">服务账户</a>来处理的，我们现在就来设置。</p><p id="6486" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">首先，导航到GCP <a class="ae jp" href="https://console.cloud.google.com/" rel="noopener ugc nofollow" target="_blank">控制台</a>(现在是一个很好的时机，你需要有一个谷歌云帐户和登录)。导航到项目id与您的Dialogflow代理的项目id相对应的GCP项目(还记得我们在上一步中注意到的吗？).</p><p id="fb87" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在左侧栏中，转到IAM &amp; admin -&gt;服务帐户。</p><figure class="jr js jt ju fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es lw"><img src="../Images/6abff91d2ce7f8b5b87d55d8e7a4c948.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Gum8JTFKUor5B6LQ"/></div></div></figure><p id="fc65" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">点击屏幕顶部的“+创建服务帐户”。</p><figure class="jr js jt ju fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es lh"><img src="../Images/8b0c1dcddbc54500700d812c09e75aa5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*MiGa1RdTFg1I1HOW"/></div></div></figure><p id="60ce" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">创建一个新的服务帐户，用某个名称描述它的使用位置(在本例中，在我们的desktop/raspi/etc上)。</p><figure class="jr js jt ju fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es lx"><img src="../Images/b654e56ad89adfba0aa578452afbce4f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*GrEupndLjdJkV466"/></div></div></figure><p id="998b" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">单击创建。在下一页，您可以为您的帐户授予权限。现在，我们需要的只是“Dialogflow API Client”权限。</p><figure class="jr js jt ju fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es lh"><img src="../Images/19c5d582031312fe1e65ba74e9207115.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Gu7457P4_q5rZJrM"/></div></div></figure><p id="e19f" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">最后，在最后一个屏幕上，您会看到一个按钮，上面写着“+ CREATE KEY”单击该按钮。</p><figure class="jr js jt ju fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es ly"><img src="../Images/ddc51dc3fc24cb00bc9bb11e845661da.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*EUBZhE66Bkl5q4dT"/></div></div></figure><p id="b3fe" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">接下来，选择“JSON”作为键类型，并选择Create。</p><figure class="jr js jt ju fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es lz"><img src="../Images/0e64e819d357cabf16405ad84afb15fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*CDPruQgB7yFr9Usz"/></div></div></figure><p id="6270" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这会将一个<code class="du lc ld le lf b">json</code>凭证文件下载到您的计算机上。任何拥有此文件的人都可以访问您的Dialogflow代理，所以请保密，不要将其签入任何GitHub repos！</p><p id="a960" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">同时，为该项目创建一个新文件夹(即<code class="du lc ld le lf b">dialogflow_streaming_agent</code>)，并将凭证<code class="du lc ld le lf b">json</code>文件移动到该文件夹中。</p><h1 id="5226" class="jz ka ht bd kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw bi translated">编写Node.js Dialogflow流代码</h1><h2 id="6417" class="li ka ht bd kb lj lk ll kf lm ln lo kj jb lp lq kn jf lr ls kr jj lt lu kv lv bi translated">属国</h2><p id="4a1f" class="pw-post-body-paragraph iq ir ht is b it kx iv iw ix ky iz ja jb kz jd je jf la jh ji jj lb jl jm jn hb bi translated">要开始，您需要下载一些依赖项。对于这个项目，我使用包<a class="ae jp" href="https://www.npmjs.com/package/node-record-lpcm16" rel="noopener ugc nofollow" target="_blank"> node-record-lpcm16 </a>来记录来自我的麦克风的音频，使用包<a class="ae jp" href="https://github.com/TooTallNate/node-speaker" rel="noopener ugc nofollow" target="_blank"> node-speaker </a>通过我的扬声器播放来自Dialogflow的音频响应。你可以使用其他的扬声器和麦克风库，但我发现它们在我的MacBook和Pi上都能正常工作。</p><p id="1615" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">要安装<code class="du lc ld le lf b">node-record-lpcm16</code>，你可能需要先安装一些依赖项，比如<code class="du lc ld le lf b">sox</code>。在这里看文档<a class="ae jp" href="https://github.com/gillesdemey/node-record-lpcm16" rel="noopener ugc nofollow" target="_blank">，但是在Mac上，你可能会想做这样的事情:</a></p><pre class="jr js jt ju fd ma lf mb mc aw md bi"><span id="6038" class="li ka ht lf b fi me mf l mg mh">brew install sox<br/>npm install node-record-lpcm16</span></pre><p id="dd17" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在Linux上:</p><pre class="jr js jt ju fd ma lf mb mc aw md bi"><span id="c727" class="li ka ht lf b fi me mf l mg mh">sudo apt-get install sox libsox-fmt-all<br/>npm install node-record-lpcm16</span></pre><p id="6a3f" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">要安装<code class="du lc ld le lf b">node-speaker</code>:</p><pre class="jr js jt ju fd ma lf mb mc aw md bi"><span id="fa0c" class="li ka ht lf b fi me mf l mg mh">npm install speaker</span></pre><p id="bee8" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">或者在Linux上:</p><pre class="jr js jt ju fd ma lf mb mc aw md bi"><span id="dc95" class="li ka ht lf b fi me mf l mg mh">sudo apt-get install libasound2-dev<br/>npm install speaker</span></pre><p id="6cfc" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在我的Mac上，我注意到我在使用这个库的时候总是出现错误<code class="du lc ld le lf b">Illegal Instruction: 4</code>。解决方案是安装带有该标志的<code class="du lc ld le lf b">speaker</code>:</p><pre class="jr js jt ju fd ma lf mb mc aw md bi"><span id="4399" class="li ka ht lf b fi me mf l mg mh">npm install speaker --mpg123-backend=openal</span></pre><p id="cd86" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">最后:</p><pre class="jr js jt ju fd ma lf mb mc aw md bi"><span id="e935" class="li ka ht lf b fi me mf l mg mh">npm install pump dotenv dialogflow-v2</span></pre><h2 id="a5a8" class="li ka ht bd kb lj lk ll kf lm ln lo kj jb lp lq kn jf lr ls kr jj lt lu kv lv bi translated">了解Dialogflow流接口</h2><p id="6158" class="pw-post-body-paragraph iq ir ht is b it kx iv iw ix ky iz ja jb kz jd je jf la jh ji jj lb jl jm jn hb bi translated"><strong class="is hu">对话流流配置</strong></p><p id="d6f0" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">如果您浏览Dialogflow文档，您会看到有一个名为<a class="ae jp" href="https://cloud.google.com/dialogflow/docs/detect-intent-stream#detect-intent-stream-nodejs" rel="noopener ugc nofollow" target="_blank">Detect Intent with Audio Stream Input</a>的示例代码页。这个片段向您展示了如何在<em class="jo">文件</em>之间传输音频。但是在这篇文章中，我们不是从文件中提取音频，而是直接从麦克风中收集音频，并通过扬声器直接播放。我将一步一步地向您介绍如何做到这一点，但是完整的代码示例在这里是<a class="ae jp" href="https://gist.github.com/dalequark/4648c110b02963a049da2bfa637493fb" rel="noopener ugc nofollow" target="_blank"/>。</p><p id="86a0" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">要开始使用Dialogflow流接口，请导入库并创建新的客户端:</p><pre class="jr js jt ju fd ma lf mb mc aw md bi"><span id="88a3" class="li ka ht lf b fi me mf l mg mh">const dialogflow = require('dialogflow');</span><span id="6482" class="li ka ht lf b fi mi mf l mg mh">const sessionClient = new dialogflow.SessionsClient();</span></pre><p id="0970" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在这个流设置中，我们将从麦克风收集音频，并不断将其发送到<code class="du lc ld le lf b">sessionClient</code>。但是在我们发送音频之前，我们需要发送给Dialogflow的第一个数据包是一个配置对象。我将这一步打包成一个函数，我称之为<code class="du lc ld le lf b">makeInitialStreamRequestArgs</code>:</p><pre class="jr js jt ju fd ma lf mb mc aw md bi"><span id="d689" class="li ka ht lf b fi me mf l mg mh">function makeInitialStreamRequestArgs(projectId, sessionId) {<br/>    // Initial request for Dialogflow setup<br/>        <br/>    const sessionPath = sessionClient.sessionPath(projectId, sessionId);<br/>        <br/>    return {            <br/>        session: sessionPath,            <br/>        queryInput: {                <br/>            audioConfig: {                    <br/>                audioEncoding: "LINEAR16",<br/>                sampleRateHertz: 16000,<br/>                languageCode: "en-US",<br/>            },                <br/>            singleUtterance: true,            <br/>         },            <br/>         outputAudioConfig: {                <br/>             audioEncoding: `OUTPUT_AUDIO_ENCODING_LINEAR_16`,<br/>             sampleRateHertz: 16000,            <br/>         },        <br/>    };    <br/>}</span></pre><p id="a8bf" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">先说这些配置参数。</p><p id="e856" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">首先，<code class="du lc ld le lf b">makeInitialStreamRequestArgs</code>需要两个参数，<code class="du lc ld le lf b">projectId</code>和<code class="du lc ld le lf b">sessionId</code>。<code class="du lc ld le lf b">projectId</code>是您的GCP项目ID，它是我们从上面的Dialogflow控制台收集的(在我的例子中，它是<code class="du lc ld le lf b">simplealarm-spoitm</code>)。另一方面，<code class="du lc ld le lf b">sessionId</code>是您，即调用者，为每个用户<em class="jo">会话</em>创建的id。您将在每次调用Dialogflow时发送此sessionId，以表明您正在继续正在进行的对话。</p><p id="985f" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这两个参数<code class="du lc ld le lf b">projectId</code>和<code class="du lc ld le lf b">sessionId</code>一起用于创建一个<code class="du lc ld le lf b">sessionPath</code>变量，该变量与初始配置一起发送。</p><p id="8ad4" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">您会注意到上面的代码中有一个名为<code class="du lc ld le lf b">queryInput</code>的<code class="du lc ld le lf b">json</code>字段，它告诉Dialogflow预期的输入音频数据类型。我们设置<code class="du lc ld le lf b">audioEncoding: "LINEAR16"</code>来表示我们正在以“16位线性脉码调制(PCM)编码”从麦克风发送音频。该字段也可以是<code class="du lc ld le lf b">"MP3"</code>、<code class="du lc ld le lf b">"FLAC"</code>，或者这里所列<a class="ae jp" href="https://cloud.google.com/speech-to-text/docs/encoding" rel="noopener ugc nofollow" target="_blank">的几种其他编码类型。对于来自麦克风的原始数据，您通常会希望使用<code class="du lc ld le lf b">"LINEAR16"</code>。<code class="du lc ld le lf b">sampleRateHertz: 16000</code>表示我们将发送以1600赫兹采样的Dialogflow音频。在Linux上，您可以使用以下命令确定麦克风的采样速率:</a></p><pre class="jr js jt ju fd ma lf mb mc aw md bi"><span id="41fa" class="li ka ht lf b fi me mf l mg mh">arecord --list-devices</span></pre><p id="9a00" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">然而，我发现在这里使用一个交替的采样率不会破坏任何东西🤞。</p><p id="8f61" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在<code class="du lc ld le lf b">queryInput</code>中，我们将设置字段<code class="du lc ld le lf b">singleUtterance: true</code>。来自<a class="ae jp" href="https://cloud.google.com/dialogflow/docs/detect-intent-stream" rel="noopener ugc nofollow" target="_blank">文档</a>:</p><ul class=""><li id="eb2c" class="mj mk ht is b it iu ix iy jb ml jf mm jj mn jn mo mp mq mr bi translated">如果<code class="du lc ld le lf b">false</code>(默认)，语音识别不会停止，直到客户端关闭流。</li><li id="cf69" class="mj mk ht is b it ms ix mt jb mu jf mv jj mw jn mo mp mq mr bi translated">如果是<code class="du lc ld le lf b">true</code>，Dialogflow将检测输入音频中的单个话语。当Dialogflow检测到音频的声音已经停止或暂停时，它会停止语音识别并向您的客户端发送一个带有识别结果<code class="du lc ld le lf b">END_OF_SINGLE_UTTERANCE</code>的<code class="du lc ld le lf b">StreamingDetectIntentResponse</code>。在收到<code class="du lc ld le lf b">END_OF_SINGLE_UTTERANCE</code>后，任何发送到Dialogflow的音频都会被Dialogflow忽略。</li></ul><p id="d1b3" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">将该字段设置为<code class="du lc ld le lf b">true</code>方便地意味着Dialogflow将自动检测用户何时停止讲话，允许它处理何时停止监听并开始讲话的逻辑。</p><p id="c344" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">最后，<code class="du lc ld le lf b">outputAudioConfig</code>告诉Dialogflow我们想要接收什么类型的音频，然后我们将通过扬声器播放。</p><p id="a6fe" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hu">将Dialogflow连接到麦克风</strong></p><p id="ddd7" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">为了开始收集音频和检测意图，让我们创建一个新函数<code class="du lc ld le lf b">getAudio(sessionId)</code>，它将处理创建一个Dialogflow流、创建一个麦克风流、设置配置和检测意图。<code class="du lc ld le lf b">getAudio</code>将返回一个<a class="ae jp" href="https://developers.google.com/web/fundamentals/primers/promises" rel="noopener ugc nofollow" target="_blank"> Javascript Promise </a>，当它收到来自Dialogflow的音频响应时，这个Promise 将被解析。</p><p id="adb2" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">首先，创建一个新的Dialogflow意图检测流，如下所示:</p><pre class="jr js jt ju fd ma lf mb mc aw md bi"><span id="45bf" class="li ka ht lf b fi me mf l mg mh">function getAudio(sessionId, projectId) {</span><span id="696c" class="li ka ht lf b fi mi mf l mg mh">    const detectStream = this.sessionClient.streamingDetectIntent()            .on('error', console.error);</span></pre><p id="dfeb" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">接下来，我们将使用上一步中编写的函数发送Dialogflow配置包:</p><pre class="jr js jt ju fd ma lf mb mc aw md bi"><span id="a6d0" class="li ka ht lf b fi me mf l mg mh">detectStream.write(makeInitialStreamRequestArgs(projectId, sessionId));</span></pre><p id="80ea" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在我们将开始从麦克风收集音频，并将其传输到<code class="du lc ld le lf b">detectStream</code>对象。</p><p id="03a3" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">为了创建麦克风流，我们将使用之前安装的库<code class="du lc ld le lf b">node-record-lpcm16</code>创建一个新的<code class="du lc ld le lf b">record</code>对象:</p><pre class="jr js jt ju fd ma lf mb mc aw md bi"><span id="b226" class="li ka ht lf b fi me mf l mg mh">const recording = record.record({<br/>    sampleRateHertz: 16000,                <br/>    threshold: 0,                <br/>    verbose: false,                <br/>    recordProgram: 'arecord', // Try also "arecord" or "sox"<br/>    silence: '10.0',            <br/>});            <br/>const recordingStream = recording.stream().on('error', console.error);</span></pre><p id="63ff" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">您应该将<code class="du lc ld le lf b">recordProgram</code>设置为您电脑上安装的任何音频录制软件。我的MacBook上用的是<code class="du lc ld le lf b">sox</code>，Linux/Raspberry Pi上用的是<code class="du lc ld le lf b">arecord</code>。</p><p id="06fb" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">为了将记录流(<code class="du lc ld le lf b">recordingStream</code>)连接到Dialogflow流(<code class="du lc ld le lf b">detectStream</code>)，我使用了一个名为<a class="ae jp" href="https://www.npmjs.com/package/pump" rel="noopener ugc nofollow" target="_blank"> pump </a>的小型Javascript库。这让我们对来自<code class="du lc ld le lf b">recordingStream</code>的数据做一个小的转换，所以它是<code class="du lc ld le lf b">detectStream</code>期望的格式。</p><pre class="jr js jt ju fd ma lf mb mc aw md bi"><span id="6e11" class="li ka ht lf b fi me mf l mg mh">const pumpStream = pump(recordingStream,            <br/>    // Format the audio stream into the request format.<br/>    new Transform({objectMode: true,<br/>    transform: (obj, _, next) =&gt; {<br/>        next(null, { inputAudio: obj });<br/>    },}),            <br/>    detectStream);</span></pre><p id="1345" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hu">流式音频和检测意图</strong></p><p id="99fb" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在我们正在将音频数据传输到云端，Dialogflow可以监听——当它检测到用户结束讲话时——尝试匹配用户的<a class="ae jp" href="https://cloud.google.com/dialogflow/docs/intents-overview" rel="noopener ugc nofollow" target="_blank">意图</a>并返回响应。</p><p id="1784" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">让我们来看看:</p><figure class="jr js jt ju fd hk"><div class="bz dy l di"><div class="mx my l"/></div><figcaption class="jv jw et er es jx jy bd b be z dx translated">将麦克风数据流式传输到Dialogflow并监听Dialogflow的响应</figcaption></figure><p id="87b6" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这里<a class="ae jp" href="http://baby-name-gen.firebaseapp.com" rel="noopener ugc nofollow" target="_blank">发生了很多事情</a>，我们来分解一下。</p><p id="14fc" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><code class="du lc ld le lf b">detectStream.on('data'</code>是监听Dialogflow发出的<code class="du lc ld le lf b">data</code>事件的处理程序。Dialogflow发出<code class="du lc ld le lf b">data</code>事件来传达<a class="ae jp" href="https://cloud.google.com/dialogflow/docs/reference/rpc/google.cloud.dialogflow.v2#google.cloud.dialogflow.v2.StreamingDetectIntentResponse" rel="noopener ugc nofollow" target="_blank">丢失的不同类型的信息</a>:</p><pre class="jr js jt ju fd ma lf mb mc aw md bi"><span id="679d" class="li ka ht lf b fi me mf l mg mh">{ responseId: '',<br/>  recognitionResult: null,<br/>  queryResult:<br/>   { fulfillmentMessages: [],<br/>     outputContexts: [],<br/>     queryText: '',<br/>     speechRecognitionConfidence: 0,<br/>     action: '',<br/>     parameters: null,<br/>     allRequiredParamsPresent: false,<br/>     fulfillmentText: '',<br/>     webhookSource: '',<br/>     webhookPayload: null,<br/>     intent: null,<br/>     intentDetectionConfidence: 0,<br/>     diagnosticInfo: null,<br/>     languageCode: 'en-US',<br/>     sentimentAnalysisResult: null },<br/>  webhookStatus: null,<br/>  outputAudio: &lt;Buffer &gt;,<br/>  outputAudioConfig: null }</span></pre><p id="96a4" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">例如，当用户说话时，Dialogflow将触发一个设置了参数<code class="du lc ld le lf b">data.recognitionResult</code>的<code class="du lc ld le lf b">data</code>事件，该事件包含它认为用户所说内容的实时副本。例如，如果我对着麦克风说，“今天天气如何？”Dialogflow可能会发出几个带有<code class="du lc ld le lf b">recognitionResult.transcript</code>的<code class="du lc ld le lf b">data</code>事件，分别包含:</p><pre class="jr js jt ju fd ma lf mb mc aw md bi"><span id="150a" class="li ka ht lf b fi me mf l mg mh">“What’s”<br/>“What’s the”<br/>“What’s the heather” // NOTE: heather changed later to "weather"<br/>“What’s the weather today?”</span></pre><p id="973f" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">请注意，有时(如上例所示)，当用户说出更多单词并提供更多上下文时，转写可能会发生变化。</p><p id="7e75" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">当用户停止讲话时，Dialogflow将发出一个数据包，其中字段<code class="du lc ld le lf b">data.recognitionResult.isFinal</code>设置为<code class="du lc ld le lf b">true</code>。此时，你会<strong class="is hu">需要</strong>关闭<strong class="is hu">麦克风:</strong></p><pre class="jr js jt ju fd ma lf mb mc aw md bi"><span id="4d3b" class="li ka ht lf b fi me mf l mg mh">if (data.recognitionResult.isFinal) {           <br/>   console.log("Result Is Final");                    <br/>   recording.stop();                    <br/>}</span></pre><p id="8741" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">当用户停止说话时，Dialogflow将开始将用户所说的内容与意图进行匹配。然后它将发出一个数据事件，字段<code class="du lc ld le lf b">data.queryResult</code>被填充。<code class="du lc ld le lf b">data.queryResult.fulfillmentText</code>将包含Dialogflow回复的文本版本(即“今天天气多云”)。<code class="du lc ld le lf b">queryResult</code>还包含<a class="ae jp" href="https://cloud.google.com/dialogflow/docs/reference/rpc/google.cloud.dialogflow.v2#queryresult" rel="noopener ugc nofollow" target="_blank">其他有用的字段</a>，如<code class="du lc ld le lf b">queryResult.intent.displayName</code>(匹配意向的名称)和用于匹配参数的<code class="du lc ld le lf b">queryResult.parameters</code>。</p><p id="3f99" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">最后，Dialogflow发出的最后一个<code class="du lc ld le lf b">data</code>事件将包含一个音频响应<code class="du lc ld le lf b">data.outputAudio</code>。此时，在上面的代码中，我们关闭泵(<code class="du lc ld le lf b">pumpStream.end</code>)并解析承诺，返回音频和<code class="du lc ld le lf b">queryResult</code>:</p><pre class="jr js jt ju fd ma lf mb mc aw md bi"><span id="e071" class="li ka ht lf b fi me mf l mg mh">resolve({“audio” : data.outputAudio, “queryResult” : queryResult});</span></pre><p id="3fa8" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">顺便说一下，如果不清楚这些是如何组合在一起的，请查看<a class="ae jp" href="https://gist.github.com/dalequark/4648c110b02963a049da2bfa637493fb" rel="noopener ugc nofollow" target="_blank">完整的代码示例</a>(到目前为止，我们一直在谈论<code class="du lc ld le lf b">getAudio</code>函数)。</p><p id="64ac" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">恭喜你！您已经设置了使用Dialogflow进行流式传输的最难部分。</p><p id="5580" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hu">通过扬声器播放Dialogflow的音频响应</strong></p><p id="1df9" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在用户向我们的代理发出请求并且我们收到它的音频响应后，我们将需要使用<code class="du lc ld le lf b">node-speaker</code>库通过我们计算机的扬声器播放该响应。我们将在一个名为<code class="du lc ld le lf b">playAudio</code>的函数中完成:</p><pre class="jr js jt ju fd ma lf mb mc aw md bi"><span id="addd" class="li ka ht lf b fi me mf l mg mh">playAudio(audioBuffer) {        <br/>    return new Promise(resolve =&gt; {            <br/>        // Setup the speaker for playing audio            <br/>        const speaker = new Speaker({                <br/>            channels: 1,                <br/>            bitDepth: 16,                <br/>            sampleRate: 16000,            <br/>        });                        <br/>        speaker.on("close", () =&gt; {                <br/>            resolve();            <br/>        });                <br/>        // Setup the audio stream, feed the audio buffer in   <br/>        const audioStream = new PassThrough();<br/>        audioStream.pipe(speaker);<br/>        audioStream.end(audioBuffer);        <br/>    })    <br/>}</span></pre><p id="08c5" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">因为通过扬声器播放音频是一个异步操作，<code class="du lc ld le lf b">playAudio</code>返回一个承诺，当<code class="du lc ld le lf b">audioBuffer</code>完成播放时，这个承诺就解决了。这里，在<code class="du lc ld le lf b">Speaker</code>的配置中，<code class="du lc ld le lf b">sampleRate</code>应该与我们在配置Dialogflow流时在<code class="du lc ld le lf b">outputAudioConfig</code>中传递的值相同(在本例中是16000)。</p><p id="2fb9" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在你有了一个通过扬声器播放音频的功能！</p><p id="8657" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hu">将所有这些放在一起</strong></p><p id="e8b6" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在我们已经编写了获取和播放音频的代码，让我们将它们编织成一个“听-播放-听-播放-听…”的循环。换句话说，我们将设计一个新的功能，听用户说话，等待他们停止说话，说出一个响应，然后再次开始听，就像一个真正的(有礼貌的)人一样。</p><p id="6fb3" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">写一个新函数，<code class="du lc ld le lf b">stream</code>，像这样:</p><pre class="jr js jt ju fd ma lf mb mc aw md bi"><span id="b8fe" class="li ka ht lf b fi me mf l mg mh">async function stream() {<br/>   console.log('Listening, press Ctrl+C to stop.');   <br/>   // Create a new id for this session    <br/>   const sessionId = uuidv1();        <br/>       <br/>   while (true) {        <br/>       const res = await getAudio(sessionId, YOUR_PROJECT_ID);     <br/>       if (res["queryResult"]) {<br/>           console.log("Got query result ", res["queryResult"]);      <br/>       }        <br/>       if (res["audio"]) {<br/>           await stream.playAudio(res["audio"]);        <br/>       }<br/>}}</span></pre><p id="6225" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这个异步函数<code class="du lc ld le lf b">stream</code>通过生成一个随机的会话id来创建一个新的会话。然后，它创建一个循环，从麦克风收集数据，侦听来自Dialogflow的音频响应，并通过扬声器播放它。它在一个<code class="du lc ld le lf b">while(true)</code>循环中这样做，即永远这样做。</p><p id="e632" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在，如果在Javascript文件的末尾调用<code class="du lc ld le lf b">stream()</code>，就可以开始了！当然，你也可以下载并运行<a class="ae jp" href="https://gist.github.com/dalequark/4648c110b02963a049da2bfa637493fb" rel="noopener ugc nofollow" target="_blank">我的代码</a>。(抱歉，它与这些内联样本不完全一致，但它们非常接近)。</p><h1 id="6cfa" class="jz ka ht bd kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw bi translated">你完了！</h1><p id="d4ce" class="pw-post-body-paragraph iq ir ht is b it kx iv iw ix ky iz ja jb kz jd je jf la jh ji jj lb jl jm jn hb bi translated">调高音量，开始聊天。你刚刚建立了你的第一个会说会听的数字伴侣，它永远不会厌倦听你说话。告诉你的朋友不客气。</p></div></div>    
</body>
</html>