# Composer/ç”¨æˆ·å®šä¹‰çš„ä¼ æ„Ÿå™¨å®ç°ä¸­çš„ BigQuery ä¼ æ„Ÿå™¨

> åŸæ–‡ï¼š<https://medium.com/google-cloud/bigquery-sensor-in-composer-b526c9a91c26?source=collection_archive---------1----------------------->

æƒ³è¦åœ¨æºæ•°æ®åº“åˆ·æ–°å’Œç›®æ ‡æ•°æ®åº“åŠ è½½ä½œä¸šä¹‹é—´åˆ›å»ºä¾èµ–å…³ç³»å—ï¼Ÿ

æƒ³è®© OLAP åŠ è½½ä½œä¸šä¸€ç›´ç­‰åˆ°æº OLTP ç³»ç»Ÿæ›´æ–°å—ï¼Ÿç»§ç»­ä¸‹å»ï¼Œçœ‹çœ‹è¿™ä¸ªæ•™ç¨‹ã€‚

![](img/c5cb799fbd750f21b4681c55f5726d21.png)

**å‡†å¤‡:**å¯é‡ç”¨æ€§ã€åšå®¢ã€ç¤¾åŒºè´¡çŒ®

**å‡è®¾**

æœ¬æ•™ç¨‹å‡è®¾æ‚¨ç†Ÿæ‚‰:

*   Composerï¼ŒBigQueryï¼ŒPython

# ç¤ºä¾‹ä½¿ç”¨æ¡ˆä¾‹:

åªæœ‰åœ¨æŒ‡å®šçš„æ—¶é—´èŒƒå›´(å¯ä¿®æ”¹)å†…æ›´æ–°æºè¡¨æ—¶ï¼Œæ‰åº”è¯¥æ‰§è¡Œä¸€äº›ä¸‹æ¸¸ä»»åŠ¡ã€‚

æºé¡¹ç›®é™åˆ¶äº†å…ƒæ•°æ®æŸ¥çœ‹å™¨æƒé™ï¼Œå®ƒå¯ä»¥é€šè¿‡ API è°ƒç”¨ï¼Œä½†æ˜¯å®ƒä»¬é™åˆ¶äº†é€šè¿‡ Information_schema æŸ¥è¯¢å…ƒæ•°æ®ã€‚

è®®ç¨‹æ˜¯é€šè¿‡ bigquery API æ£€æŸ¥è¡¨çš„ lastmodifiedtimeï¼Œå¦‚æœè¡¨æ²¡æœ‰åœ¨æŒ‡å®šçš„èŒƒå›´å†…æ›´æ–°ï¼Œåˆ™é‡æ–°è°ƒåº¦ DAGã€‚

poke æ–¹æ³•å°†åœ¨ä¸Šè¿°æ—¶é—´é—´éš”åé‡è¯•ï¼Œå¹¶åœ¨æºè¡¨æ›´æ–°æ—¶è‡ªåŠ¨æ‰§è¡Œä¸‹ä¸€ä¸ªä»»åŠ¡ã€‚

ä¸éœ€è¦äººå·¥å¹²é¢„ã€‚

ä¸éœ€è¦åœ¨å›ºå®šçš„æ—¶é—´é—´éš”å®‰æ’ DAG æ¥æ£€æŸ¥è¿™ä¸€ç‚¹ã€‚

**åœºæ™¯:**æœ‰ä¸€ä¸ª OLTP æºè¡¨â€˜OLTP _ customerâ€™ã€‚æœ‰ä¸€ä¸ª OLAP ç›®æ ‡è¡¨ dim_customerã€‚åªæœ‰å½“æºè¡¨åœ¨è¿™ä¸€å°æ—¶å†…è¢«ä¿®æ”¹æ—¶ï¼Œä¸‹ä¸€ä¸ªä»æºè¡¨åŠ è½½ç»´åº¦è¡¨çš„ä»»åŠ¡æ‰ä¼šæ‰§è¡Œã€‚åœ¨ä¿®æ”¹æºè¡¨ä¹‹å‰ï¼Œä»»åŠ¡å°†ç»§ç»­è¢«é‡æ–°è°ƒåº¦ã€‚

å¤©ç©ºé¢œè‰²è¡¨ç¤ºé‡æ–°è®¡åˆ’çš„çŠ¶æ€ã€‚æ¯å½“æ›´æ–°æºè¡¨æ—¶ï¼ŒDAG éƒ½ä¼šè‡ªåŠ¨å¼€å§‹è¿è¡Œä»¥ä¸‹ä»»åŠ¡å¹¶å®Œæˆè¯¥è¿‡ç¨‹

# **è§£å†³æ–¹æ¡ˆ:**

## ä»‹ç»

æ°”æµä¼ æ„Ÿå™¨å…è®¸æ‚¨æ£€æŸ¥æ˜¯å¦æ»¡è¶³å®Œæˆæ ‡å‡†ã€‚

Bigquery Sensor å¯ä»¥ä½œä¸ºæ°”æµæ’ä»¶åˆ›å»ºï¼Œå¹¶å¯ä»¥ä½œä¸º python æ¨¡å—å¯¼å…¥åˆ°æ°”æµ DAG ä¸­ã€‚

è¯¥è§£å†³æ–¹æ¡ˆåŸºäºä¸€ä¸ªåŸºäº BigQuery å®¢æˆ·ç«¯çš„ç”¨æˆ·è‡ªå®šä¹‰ä¼ æ„Ÿå™¨ã€‚

Airflow æœ‰ä¸€ä¸ªç®€å•çš„å†…ç½®æ’ä»¶ç®¡ç†å™¨ï¼Œå¯ä»¥é€šè¿‡ç®€å•åœ°å°†æ–‡ä»¶æ”¾å…¥$AIRFLOW_HOME/plugins æ–‡ä»¶å¤¹ä¸­ï¼Œå°†å¤–éƒ¨åŠŸèƒ½é›†æˆåˆ°å…¶æ ¸å¿ƒä¸­ã€‚

æ’ä»¶æ–‡ä»¶å¤¹ä¸­çš„ python æ¨¡å—è¢«å¯¼å…¥ï¼Œå®å’Œ web è§†å›¾è¢«é›†æˆåˆ° Airflow çš„ä¸»é›†åˆä¸­ï¼Œå¯ä¾›ä½¿ç”¨ã€‚

## å»ºç­‘/è®¾è®¡:

**æ­¥éª¤ 1:** å½“æºè¡¨åœ¨æœ€åä¸€ä¸ªå°æ—¶æ²¡æœ‰è¢«ä¿®æ”¹æ—¶ã€‚DAG å·²å¯åŠ¨ï¼Œå®ƒæ£€æŸ¥åˆ°æºè¡¨æœªæ›´æ–°ï¼Œå› æ­¤å®ƒé‡æ–°è®¡åˆ’äº† DAGã€‚ä»»åŠ¡ IsModifiedSource æ˜¯å¤©ç©ºé¢œè‰²ï¼Œè¿™æ„å‘³ç€å®ƒå¤„äºé‡æ–°è®¡åˆ’çŠ¶æ€ã€‚

![](img/901824d1bac13b506dd3b5ade6a68bc1.png)

**ç¬¬äºŒæ­¥:**ä¿®æ”¹æºè¡¨ã€‚æ’å…¥ä¸€æ¡è®°å½•

![](img/a11ff58f54b2a7f8035bf9ee1be91522.png)

**æ­¥éª¤ 3:** é‡æ–°è°ƒåº¦çš„ä»»åŠ¡â€œIsSourceModifiedâ€å¼€å§‹è¿è¡Œï¼Œä¼ æ„Ÿå™¨è„šæœ¬åœ¨æ¯ä¸ª poke_interval ä¹‹åæ£€æŸ¥è¡¨ä¿®æ”¹æ—¶é—´ï¼Œåªè¦ä¸å½“å‰å°æ—¶ç›¸åŒ¹é…ï¼Œå°±æ‰§è¡Œè¯¥ä»»åŠ¡

![](img/d07dbb74f0b27c8068468c67240d0ac6.png)

**æ­¥éª¤ 4:**DAG å®Œæˆï¼Œç»´åº¦è¡¨ä» oltp æºè¡¨åŠ è½½

![](img/6b0a50d3c605347aaca062ef35d6063d.png)

## ä½¿ç”¨æ°”æµä¼ æ„Ÿå™¨çš„å¥½å¤„:

ä¼ æ„Ÿå™¨æ˜¯ä¸€ä¸ªæ“ä½œå‘˜**åœ¨ä¸€æ®µæ—¶é—´é—´éš”å†…è¯„ä¼°æ˜¯å¦ç¬¦åˆæ ‡å‡†/æ¡ä»¶ã€‚**å¦‚æœæ˜¯ï¼Œåˆ™æˆåŠŸï¼Œå¦åˆ™é‡è¯•ï¼Œç›´åˆ°è¶…æ—¶ã€‚

æ°”æµä¼šå¸¦æ¥ä¸åŒçš„ä¼ æ„Ÿå™¨ï¼Œä»¥ä¸‹æ˜¯æœ€å¸¸ç”¨çš„ä¸€äº›ä¼ æ„Ÿå™¨:

*   *æ–‡ä»¶ä¼ æ„Ÿå™¨*:ç­‰å¾…æ–‡ä»¶æˆ–æ–‡ä»¶å¤¹è¿›å…¥æ–‡ä»¶ç³»ç»Ÿã€‚
*   *s3key sensor*:ç­‰å¾…ä¸€æŠŠé’¥åŒ™å‡ºç°åœ¨ S3 æ¡¶é‡Œã€‚
*   SqlSensor :é‡å¤è¿è¡Œä¸€æ¡ sql è¯­å¥ï¼Œç›´åˆ°æ»¡è¶³ä¸€ä¸ªæ ‡å‡†ã€‚
*   HivePartitionSensor :ç­‰å¾…ä¸€ä¸ªåˆ†åŒºå‡ºç°åœ¨ Hive ä¸­ã€‚
*   *ExternalTaskSensor*:ç­‰å¾…ä¸åŒ DAG æˆ–ä¸åŒ DAG ä¸­çš„ä»»åŠ¡åœ¨ç‰¹å®šæ‰§è¡Œæ—¥æœŸå®Œæˆã€‚(æŒºæœ‰ç”¨çš„é‚£ä¸ªğŸ¤“)
*   *datetime sensor*:ç­‰å¾…æŒ‡å®šçš„æ—¥æœŸæ—¶é—´(ç”¨äºä¸ºæ‚¨çš„ Dag æ·»åŠ ä¸€äº›å»¶è¿Ÿ)

## æ ¹æ®ä¸šåŠ¡é€»è¾‘åˆ›å»ºç”¨æˆ·å®šä¹‰ä¼ æ„Ÿå™¨ï¼Œå³ BigQuery ä¼ æ„Ÿå™¨:

æˆ‘ä»¬è¿˜å¯ä»¥æ ¹æ®æˆ‘ä»¬çš„ä¸šåŠ¡é€»è¾‘åˆ›å»ºå®šåˆ¶çš„ä¼ æ„Ÿå™¨ã€‚

è¯¥èµ„äº§åŸºäºç”¨æˆ·å®šä¹‰çš„ä¼ æ„Ÿå™¨ï¼Œè¯¥ä¼ æ„Ÿå™¨åŸºäº BigQuery å®¢æˆ·ç«¯è¡¨ ModifiedTimeã€‚æˆ‘ä»¬å¯ä»¥åœ¨å¤šä¸ª Dag ä¸­é‡ç”¨åŒä¸€ä¸ªä¼ æ„Ÿå™¨æ¥æ£€æŸ¥è¿™äº›å…ˆå†³æ¡ä»¶ã€‚æ­¤å¤–ï¼Œé€šè¿‡ä½¿ç”¨è¯¥è„šæœ¬ä½œä¸ºæ¨¡æ¿ï¼Œæˆ‘ä»¬å¯ä»¥è½»æ¾åˆ›å»ºå…·æœ‰ä¸åŒä¸šåŠ¡é€»è¾‘çš„ä¸åŒ BigQuery ä¼ æ„Ÿå™¨ã€‚

*   è¿™ä¸ªä¾‹å­åŒ…æ‹¬å¦‚ä½•ä» BigQuery API è®¿é—®å…ƒæ•°æ®ä¿¡æ¯
*   è¯¥ç¤ºä¾‹è¿˜åŒ…æ‹¬ä½¿ç”¨ Google Secret Manager æ¥ä¿æŠ¤æœåŠ¡å¸æˆ·å‡­è¯ã€‚

## è„šæœ¬:

**1)bigquerytablemodified sensor . py**

![](img/8afb5561de01c251124511b8e630945b.png)

```
"""This module contains a Google Bigquery SQL sensor."""
from typing import Optional, Sequence, Union
from airflow.hooks import BaseHook
from airflow.sensors import BaseSensorOperator
from airflow.exceptions import AirflowException
import datetime
from google.cloud import bigquery
from google.oauth2 import service_account
from google.cloud import secretmanager
import pendulum
import logging
import json
class BigQueryTableModifiedSensor(BaseSensorOperator):
"""
Checks for the True or False output in Google Bigquery Query Job output.
:param sql: The query to return True or False as Final output
:type sql: str
:param use_legacy_sql: Option to run legacy SQL
:type use_legacy_sql: Boolean
:param bigquery_conn_id: The connection ID to use when connecting to
Google BigQuery.
:type bigquery_conn_id: str
"""
template_fields = (
'sql',
'use_legacy_sql',
'bigquery_conn_id',
'full_table_identifier',
'secret_manager_project_name',
'secret_name'
)
ui_color = '#f0eee2'
# accept table identifiers from main DAG
def __init__(self,*,bigquery_conn_id: str = 'google_cloud_default',
use_legacy_sql: bool = False,sql: str = None,full_table_identifier,secret_manager_project_name,secret_name,**kwargs) -> None:
super().__init__(**kwargs)
self.bigquery_conn_id = bigquery_conn_id
self.sql = None
self.use_legacy_sql = use_legacy_sql
self.full_table_identifier=full_table_identifier
self.secret_manager_project_name=secret_manager_project_name
self.secret_name=secret_name
def access_secret_version(self,project_id, secret_id, version_id):
# Create the Secret Manager client.
client = secretmanager.SecretManagerServiceClient()
# Build the resource name of the secret version.
name = f"projects/{project_id}/secrets/{secret_id}/versions/{version_id}"
logging.info(name)
logging.info("inside get_table_modified before accessing")
# Access the secret version.
response = client.access_secret_version(name)
payload = response.payload.data.decode("UTF-8")
#logging.info(payload)
return payload
def poke(self,context: dict) -> bool:
full_table_identifier=self.full_table_identifier
secret_manager_project_name=self.secret_manager_project_name
secret_name=self.secret_name
key_content=self.access_secret_version(secret_manager_project_name,
secret_name,"1")
service_account_info = json.loads(key_content,strict=False)
logging.info("returned from gsm function")
logging.info(service_account_info)
credentials=
service_account.Credentials.from_service_account_info(service_account_info)
client = bigquery.Client(credentials=credentials,project=credentials.project_id)
table = client.get_table(full_table_identifier)
logging.info(table.modified)
logging.info(table.modified.date())
logging.info(table.modified.hour)
if table.modified.hour == datetime.datetime.now().hour:
logging.info("IsModifiedThisHour TRUE")
else:
logging.info("IsModifiedThisHour False")
return table.modified.hour == datetime.datetime.now().hour
```

**2)æ ·æœ¬ DAG ä½¿ç”¨æ°”æµæ’ä»¶ä½œä¸ºç”¨æˆ·å®šä¹‰çš„ä¼ æ„Ÿå™¨**

![](img/cb3b6b4d17ec242a6a0d4a20ab744814.png)

```
from sensors.BigQueryTableModifiedSensor import BigQueryTableModifiedSensor
import os
import json
import datetime
import airflow
from airflow import DAG
from airflow import models
from airflow.models import Variable
from airflow.operators import DummyOperator
from airflow.operators import BashOperator
from airflow.contrib.operators import bigquery_to_bigquery
from airflow.contrib.operators import bigquery_to_gcs
from airflow.contrib.operators import gcs_to_bq
from airflow.contrib.operators import bigquery_operator
from airflow.providers.google.cloud.operators.bigquery import BigQueryExecuteQueryOperator
import datetime
from google.cloud import bigquery
from google.oauth2 import service_account
from google.cloud import secretmanager
import pendulum
import logging
import re
from airflow.contrib.operators.bigquery_operator import BigQueryOperator
from airflow.providers.google.cloud.operators.bigquery import BigQueryInsertJobOperator
from airflow.contrib.operators.gcs_list_operator import GoogleCloudStorageListOperator
from airflow.contrib.operators.gcs_to_gcs import GoogleCloudStorageToGoogleCloudStorageOperator
from google.cloud import storage
from airflow.providers.google.cloud.operators.bigquery import BigQueryExecuteQueryOperator
from airflow.operators import DummyOperator
from airflow.operators.python_operator import PythonOperator
logger = logging.getLogger("airflow.task")
local_tz = pendulum.timezone("Europe/Amsterdam")
secret_manager_project_name=Variable.get('secret_manager_project')
secret_name=Variable.get('secret_name')
project_name=Variable.get('project_name')
dataset_name=Variable.get('dataset_name')
source_table_name=Variable.get('source_table_name')
full_table_identifier=project_name+'.'+dataset_name+'.'+source_table_name
target_table_name=Variable.get('target_table_name')
#Default args for the DAG execution
default_args = {
'email_on_failure': True,
'email_on_retry': False
}
#DAG initialization
#DAG initialization
with airflow.DAG(
'load_oltp_table_to_dimension_table',
start_date=datetime.datetime(2021, 1, 1),
schedule_interval=None) as dag:
logging.info("inside DAG")
start = DummyOperator(
task_id='start',
dag=dag)
finish = DummyOperator(
task_id='finish',
dag=dag)
check_precondition = BigQueryTableModifiedSensor(
task_id ='IsSourceModified',
bigquery_conn_id = 'bigquery_default',
use_legacy_sql = False,
sql = None,
full_table_identifier=full_table_identifier,
secret_manager_project_name=secret_manager_project_name,
secret_name=secret_name,
poke_interval = 60,
timeout = 3600,
mode = 'reschedule',
dag=dag
)
run_new_job = BigQueryOperator(
task_id='RunLoadJobWhenSourceModified',
sql='insert into `'+project_name+'.'+dataset_name+'.'+target_table_name+'` select generate_uuid(),c.customer_id,c.customer_name,c.customer_city,current_timestamp(),null,"Yes" from `'+project_name+'.'+dataset_name+'.'+source_table_name+'` c;',
use_legacy_sql=False,
bigquery_conn_id='bigquery_default',
dag=dag)
start>>check_precondition>>run_new_job>>finish
```

# ä¼ æ„Ÿå™¨è„šæœ¬çš„è§£é‡Š:

æ‰€æœ‰ä¼ æ„Ÿå™¨éƒ½ç»§æ‰¿è‡ª BaseSensorOperatorï¼Œå¹¶å…·æœ‰ä»¥ä¸‹å‚æ•°:

*   æ¨¡å¼:ä¼ æ„Ÿå™¨å¦‚ä½•å·¥ä½œã€‚æœ‰ä¸¤ç§æ¨¡å¼:
*   æˆ³:è¿™æ˜¯é»˜è®¤æ¨¡å¼ã€‚ä½¿ç”¨ poke æ—¶ï¼Œä¼ æ„Ÿå™¨ä¼šåœ¨æ•´ä¸ªæ‰§è¡Œæ—¶é—´å†…å ç”¨ä¸€ä¸ªå·¥ä½œæ’æ§½ï¼Œå¹¶åœ¨ä¸¤æ¬¡ poke ä¹‹é—´ä¼‘çœ ã€‚
*   é‡æ–°å®‰æ’:å¦‚æœä¸ç¬¦åˆæ ‡å‡†ï¼Œä¼ æ„Ÿå™¨å°†é‡Šæ”¾å…¶å·¥ä½œæ’æ§½ï¼Œå¹¶é‡æ–°å®‰æ’ä¸‹æ¬¡æ£€æŸ¥æ—¶é—´ã€‚
*   poke_interval:ä½¿ç”¨ poke æ¨¡å¼æ—¶ï¼Œè¿™æ˜¯ä¼ æ„Ÿå™¨åœ¨å†æ¬¡æ£€æŸ¥æ¡ä»¶ä¹‹å‰ç­‰å¾…çš„æ—¶é—´(ç§’)ã€‚é»˜è®¤å€¼ä¸º 30 ç§’ã€‚
*   è¶…æ—¶:ä¼ æ„Ÿå™¨æ£€æŸ¥çŠ¶å†µçš„æœ€é•¿æ—¶é—´(ç§’)ã€‚å¦‚æœè¾¾åˆ°è¯¥æ—¶é—´æ—¶è¿˜æ²¡æœ‰æ»¡è¶³æ¡ä»¶ï¼Œåˆ™ä»»åŠ¡å¤±è´¥ã€‚

æ ¹æ®ç»™å®šçš„ä¸šåŠ¡é€»è¾‘ï¼Œå¯ä»¥åœ¨ä¼ æ„Ÿå™¨ç±»çš„ __init__ æ–¹æ³•ä¸­ä¼ é€’å¯å˜æ•°é‡çš„å‚æ•°ã€‚

ç„¶åï¼Œå¯ä»¥ä»ä»»ä½• DAG è°ƒç”¨ä¼ æ„Ÿå™¨æ¥æ£€æŸ¥æ˜¯å¦æ»¡è¶³å‰ææ¡ä»¶ã€‚

```
check_precondition = BigQueryTableModifiedSensor(
task_id ='IsSourceModified',
bigquery_conn_id = 'bigquery_default',
use_legacy_sql = False,
sql = None,
full_table_identifier=full_table_identifier,
secret_manager_project_name=secret_manager_project_name,
secret_name=secret_name, - - - Only needed if you use Google Secret Manager
poke_interval = 60,
timeout = 3600,
mode = 'reschedule',
dag=dag
)
```

# å¦‚ä½•åœ¨ DAG ä¸­ä½¿ç”¨ BigQuery ä¼ æ„Ÿå™¨è„šæœ¬

ä½¿ç”¨ç¬¬ä¸€ä¸ªè„šæœ¬ bigquerytablemodifiedssensor . py åˆ›å»ºä¼ æ„Ÿå™¨ã€‚

æ ¹æ®ä¸šåŠ¡é€»è¾‘ä¿®æ”¹è„šæœ¬ã€‚

å°†è„šæœ¬æ–‡ä»¶æ”¾åœ¨æ°”æµç¯å¢ƒçš„ä»¥ä¸‹è·¯å¾„ä¸­

æ°”æµ-ç¯å¢ƒ-æ¡¶/æ’ä»¶/ä¼ æ„Ÿå™¨/bigquerytablemodified sensor**ã€‚** py

![](img/57e6ca5a28932deb936a4c8d46d21c08.png)

å°† BigQueryTableModifiedSensor æ¨¡å—å¯¼å…¥åˆ°æ‚¨æƒ³è¦ä½¿ç”¨å®ƒçš„ DAG ä¸­ã€‚