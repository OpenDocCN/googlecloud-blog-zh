<html>
<head>
<title>Fast export large database tables — using GCP Serverless Dataproc</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">快速导出大型数据库表—使用GCP无服务器Dataproc</h1>
<blockquote>原文：<a href="https://medium.com/google-cloud/fast-export-large-database-tables-using-gcp-serverless-dataproc-spark-bb32b1260268?source=collection_archive---------3-----------------------#2022-05-26">https://medium.com/google-cloud/fast-export-large-database-tables-using-gcp-serverless-dataproc-spark-bb32b1260268?source=collection_archive---------3-----------------------#2022-05-26</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="a41a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">从MySQL(任何JDBC)导入大表到Cloud Spanner(或者GCS，BigQuery)</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/4e4a1bfb622ddbbb1cef2fdfe55a489a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*zg60riCuBk9HSgGc"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">Spark导出大型表格</figcaption></figure><h1 id="a0fc" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">介绍</h1><p id="f984" class="pw-post-body-paragraph if ig hi ih b ii kr ik il im ks io ip iq kt is it iu ku iw ix iy kv ja jb jc hb bi translated">您是否希望快速导出/导入数百GBs-TB的大型表？</p><p id="c7a0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">多线程并行导入导出数据的方法？</p><p id="5df0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">倾向于保留导出数据的模式？</p><p id="c52a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">使用强大、成熟、开源和强化的机制？</p><p id="271e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">A.使用GCP无服务器Dataproc的<a class="ae kw" href="https://github.com/GoogleCloudPlatform/dataproc-templates/tree/main/java/src/main/java/com/google/cloud/dataproc/templates/jdbc#2-jdbc-to-gcs" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj"> JDBCToGCS </strong> </a>模板可以帮助您以快速、高效和多线程的方式导出表格。</p><p id="c57a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">B.使用<a class="ae kw" href="https://github.com/GoogleCloudPlatform/dataproc-templates/blob/main/java/src/main/java/com/google/cloud/dataproc/templates/gcs/README.md" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj"> GCSToSpanner </strong> </a>模板将数据从GCS导入到云Spanner。</p><h1 id="7101" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated"><strong class="ak">主要优势</strong></h1><ol class=""><li id="e14c" class="kx ky hi ih b ii kr im ks iq kz iu la iy lb jc lc ld le lf bi translated">Dataproc Serverless是完全管理的、无服务器的和自动伸缩的。</li><li id="91af" class="kx ky hi ih b ii lg im lh iq li iu lj iy lk jc lc ld le lf bi translated">这两个模板都是开源的，完全可定制，并可用于简单的工作。</li><li id="eaad" class="kx ky hi ih b ii lg im lh iq li iu lj iy lk jc lc ld le lf bi translated">Spark为MySQL、Postgresql、DB2、Derby、H2、SQL Server、Oracle、Postgresql和Teradata数据库内置了jdbc方言。</li><li id="01be" class="kx ky hi ih b ii lg im lh iq li iu lj iy lk jc lc ld le lf bi translated">一旦作业结束，短暂gcp资源就会被释放。</li><li id="3fad" class="kx ky hi ih b ii lg im lh iq li iu lj iy lk jc lc ld le lf bi translated">您可以以<strong class="ih hj"> avro、parquet、csv和orc </strong>格式导出数据。</li><li id="c3c3" class="kx ky hi ih b ii lg im lh iq li iu lj iy lk jc lc ld le lf bi translated">允许表分区，使用它可以并行读取数据块。</li><li id="de4d" class="kx ky hi ih b ii lg im lh iq li iu lj iy lk jc lc ld le lf bi translated">GCSToSpanner模板可以并行读取多个文件(每次每个线程一个文件)，并以极快的速度将大量数据加载到Cloud Spanner中。</li></ol><h1 id="3246" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">简单用法</h1><p id="3b8a" class="pw-post-body-paragraph if ig hi ih b ii kr ik il im ks io ip iq kt is it iu ku iw ix iy kv ja jb jc hb bi translated">这种用法适用于小桌子(&lt;1 GB in size) as it will not be multi-threaded.</p><ol class=""><li id="f76c" class="kx ky hi ih b ii ij im in iq ll iu lm iy ln jc lc ld le lf bi translated">Ensure you have enabled the subnet with Private Google Access, if you are going to use “default” VPC Network generated by GCP. Still you will need to enable private access as below. (<a class="ae kw" href="https://cloud.google.com/dataproc-serverless/docs/concepts/network" rel="noopener ugc nofollow" target="_blank">参见此处</a>了解详情)</li></ol><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lo"><img src="../Images/3b1552393115c07b39e070abf1da4389.png" data-original-src="https://miro.medium.com/v2/resize:fit:570/format:webp/0*2OKjt1b9tkrYIcYp.png"/></div></figure><pre class="je jf jg jh fd lp lq lr ls aw lt bi"><span id="ae8e" class="lu ju hi lq b fi lv lw l lx ly">gcloud compute networks subnets update default --region=us-central1 --enable-private-ip-google-access</span></pre><p id="f018" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">2.[首选]出于一致性目的，暂停对源数据库的写入。这可以通过创建读取复制副本并暂停其上的复制来实现。或者，您可以克隆活动实例。</p><p id="49ae" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">3.确保可以从VPC网络访问您的源数据库。<br/> <strong class="ih hj">注意</strong>:当与VPC网络对等时，可以使用私有IP访问云SQL实例。</p><p id="6b05" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">4.为jar文件创建一个GCS存储桶和暂存位置。<br/>还要下载相应源数据库的JDBC驱动程序jar，并上传到GCS桶中。</p><p id="a9ee" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">5.在预装了<a class="ae kw" href="https://cloud.google.com/shell/docs/how-cloud-shell-works" rel="noopener ugc nofollow" target="_blank">各种工具</a>的云壳中克隆git repo。或者使用任何预装了JDK 8+、Maven3+和Git的机器。</p><pre class="je jf jg jh fd lp lq lr ls aw lt bi"><span id="3764" class="lu ju hi lq b fi lv lw l lx ly">git clone <a class="ae kw" href="https://github.com/GoogleCloudPlatform/dataproc-templates.git" rel="noopener ugc nofollow" target="_blank">https://github.com/GoogleCloudPlatform/dataproc-templates.git</a><br/>cd dataproc-templates/java</span></pre><p id="7d58" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">6.获取身份验证凭据(以提交作业)。</p><pre class="je jf jg jh fd lp lq lr ls aw lt bi"><span id="f198" class="lu ju hi lq b fi lv lw l lx ly">gcloud auth application-default login</span></pre><p id="c46e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">7.执行模板，更多细节参见<a class="ae kw" href="https://github.com/GoogleCloudPlatform/dataproc-templates/tree/main/java/src/main/java/com/google/cloud/dataproc/templates/jdbc#2-jdbc-to-gcs" rel="noopener ugc nofollow" target="_blank"> JDBCToGCS </a>文档。<br/>替换特定于环境的值(gcp项目、区域、jdbc url、驱动程序jar的路径等)。<br/>例如:</p><pre class="je jf jg jh fd lp lq lr ls aw lt bi"><span id="84ce" class="lu ju hi lq b fi lv lw l lx ly">export GCP_PROJECT=my-gcp-proj \<br/>export REGION=us-central1  \<br/>export SUBNET=projects/my-gcp-proj/regions/us-central1/subnetworks/default   \<br/>export GCS_STAGING_LOCATION=gs://my-gcp-proj/mysql-export/staging \<br/>export JARS=gs://my-gcp-proj/mysql-export/mysql-connector-java-8.0.17.jar<br/><br/>bin/start.sh \<br/>-- --template JDBCTOGCS \<br/>--templateProperty 'jdbctogcs.jdbc.url=jdbc:mysql://192.168.16.3:3306/MyCloudSQLDB?user=root&amp;password=root' \<br/>--templateProperty jdbctogcs.jdbc.driver.class.name=com.mysql.cj.jdbc.Driver \<br/>--templateProperty jdbctogcs.output.location=gs://my-gcp-proj/mysql-export/export/table1_export \<br/>--templateProperty jdbctogcs.output.format=parquet \<br/>--templateProperty jdbctogcs.write.mode=<!-- -->Overwrite<!-- --> \<br/>--templateProperty 'jdbctogcs.sql=SELECT * FROM MyDB.employee'</span></pre><p id="80f2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">注意</strong>:如果尚未启用，它会要求您启用Dataproc Api。</p><p id="3517" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">8.使用<a class="ae kw" href="https://github.com/GoogleCloudPlatform/dataproc-templates/blob/main/java/src/main/java/com/google/cloud/dataproc/templates/gcs/README.md#2-gcs-to-spanner" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj"> GCSToSpanner </strong> </a>模板将数据导入云扳手。每个执行者/工作者一次加载一个文件，因此拥有多个文件是并行性的关键。下面的配置使用通配符" table1_export/ <strong class="ih hj">部分*。</strong>拼花地板"其中可以放有一个或多个文件。<br/>例如:</p><pre class="je jf jg jh fd lp lq lr ls aw lt bi"><span id="6a3a" class="lu ju hi lq b fi lv lw l lx ly">export GCP_PROJECT=my-gcp-proj \<br/>export REGION=us-central1  \<br/>export SUBNET=projects/my-gcp-proj/regions/us-central1/subnetworks/default   \<br/>export GCS_STAGING_LOCATION=gs://my-gcp-proj/mysql-export/staging</span><span id="c2fd" class="lu ju hi lq b fi lz lw l lx ly">bin/start.sh \<br/>-- --template GCSTOSPANNER \<br/>--templateProperty project.id=my-gcp-proj \<br/>--templateProperty gcs.spanner.input.format=parquet \<br/>--templateProperty gcs.spanner.input.location<!-- -->=gs://my-gcp-proj/mysql-export/export/table1_export<!-- -->/part*.parquet \<br/>--templateProperty gcs.spanner.output.instance=spanner-inst \<br/>--templateProperty gcs.spanner.output.database=spanner-db \<br/>--templateProperty gcs.spanner.output.table=employee \<br/>--templateProperty gcs.spanner.output.saveMode=Overwrite \<br/>--templateProperty gcs.spanner.output.primaryKey=id</span></pre><h1 id="8b89" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">高级用法(多线程导出/导入)</h1><p id="694f" class="pw-post-body-paragraph if ig hi ih b ii kr ik il im ks io ip iq kt is it iu ku iw ix iy kv ja jb jc hb bi translated">假设您在mysql数据库中有一个Employee表模式，如下所示:</p><pre class="je jf jg jh fd lp lq lr ls aw lt bi"><span id="1a43" class="lu ju hi lq b fi lv lw l lx ly">CREATE TABLE `employee` (<br/>  `id` bigint(20) unsigned NOT NULL,<br/>  `name` varchar(100) NOT NULL,<br/>  `email` varchar(100) NOT NULL,<br/>  `current_salary` int unsigned DEFAULT NULL,<br/>  `account_id` bigint(20) unsigned NOT NULL,<br/>  `department` varchar(100) DEFAULT NULL,<br/>  `created_at` datetime NOT NULL,<br/>  `updated_at` datetime NOT NULL,<br/>  PRIMARY KEY (`id`)<br/>) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_bin;</span></pre><p id="ff17" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">假设最大雇员id为1亿(用于upperBound参数)。</p><p id="1abd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">按照上一节所述执行步骤1-4。<br/>通过指定分区属性来更改步骤5。</p><p id="27d1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">执行spark作业和分区参数，示例如下:</p><pre class="je jf jg jh fd lp lq lr ls aw lt bi"><span id="a18d" class="lu ju hi lq b fi lv lw l lx ly">export GCP_PROJECT=my-gcp-proj \<br/>export REGION=us-central1  \<br/>export SUBNET=projects/my-gcp-proj/regions/us-central1/subnetworks/default   \<br/>export GCS_STAGING_LOCATION=gs://my-gcp-proj/mysql-export/staging \<br/>export JARS=gs://my-gcp-proj/mysql-export/mysql-connector-java-8.0.17.jar<br/><br/>bin/start.sh \<br/>-- --template JDBCTOGCS \<br/>--templateProperty 'jdbctogcs.jdbc.url=jdbc:mysql://192.168.16.3:3306/MyCloudSQLDB?user=root&amp;password=root' \<br/>--templateProperty jdbctogcs.jdbc.driver.class.name=com.mysql.cj.jdbc.Driver \<br/>--templateProperty jdbctogcs.output.location=gs://my-gcp-proj/mysql-export/export/table1_export \<br/>--templateProperty jdbctogcs.output.format=parquet \<br/>--templateProperty jdbctogcs.write.mode=OVERWRITE \<br/>--templateProperty <!-- -->'jdbctogcs.sql=select * FROM employee' \<br/><strong class="lq hj">--templateProperty jdbctogcs.sql.partitionColumn=id \<br/>--templateProperty jdbctogcs.sql.lowerBound=0 \<br/>--templateProperty jdbctogcs.sql.upperBound=100000000 \<br/>--templateProperty jdbctogcs.sql.numPartitions=400</strong></span></pre><p id="6b42" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">继续步骤6，与简单用法相同。</p><h1 id="b52b" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">逮到你了。</h1><ol class=""><li id="9e20" class="kx ky hi ih b ii kr im ks iq kz iu la iy lb jc lc ld le lf bi translated"><strong class="ih hj">决定#分区</strong></li></ol><p id="e55e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Spark SQL执行查询并将整个结果集加载到内存中。因此，每个分区应该只获取足够小的数据，以便保存在内存中。对于Dataproc Serverless，默认情况下每个worker获得8 GB内存。因此，获取500K行，每行大小为1KB，导致500MB的内存使用量，这可能是正常的。</p><p id="cd6b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">拥有更多的分区和更多的执行器可以通过增加并行性来进一步提高速度。<br/>您可以使用以下配置指定执行者:</p><pre class="je jf jg jh fd lp lq lr ls aw lt bi"><span id="9fe9" class="lu ju hi lq b fi lv lw l lx ly">export SPARK_PROPERTIES=spark.executor.instances=50,spark.dynamicAllocation.maxExecutors=200</span></pre><p id="e7b0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">2.<strong class="ih hj">处理“无符号bigint”数据类型</strong></p><p id="cdcf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在上面的例子中，一些列是无符号的bigint，比如“id”，“account id”。DBA通常会创建无符号bigint列。然而，默认情况下，<a class="ae kw" href="https://github.com/apache/spark/blob/master/sql/core/src/main/scala/org/apache/spark/sql/execution/datasources/jdbc/JdbcUtils.scala#L180" rel="noopener ugc nofollow" target="_blank">Spark SQL</a>在读取“无符号bigint”时会将其转换为“十进制”数据类型。因此，当在gcs上编写parquet文件时，生成的模式将相应地包含“decimal(20，0)”数据类型。</p><p id="f30d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">当将数据作为数字数据类型导入Spanner时，这通常是不可取的，因为它会自动进行推断。</p><p id="6822" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果这些列中的数据低于有符号限制，那么简单的转换就可以解决这个问题。强制转换的一个副作用是，现有的索引将不起作用，并使sql查询非常慢。为了减轻is，我们还应该将当前列添加为，然后在其上进行分区。稍后当数据导入到Cloud Spanner时，删除这个额外的列。</p><p id="c937" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">例如:</p><pre class="je jf jg jh fd lp lq lr ls aw lt bi"><span id="3998" class="lu ju hi lq b fi lv lw l lx ly">export GCP_PROJECT=my-gcp-proj \<br/>export REGION=us-central1  \<br/>export SUBNET=projects/my-gcp-proj/regions/us-central1/subnetworks/default   \<br/>export GCS_STAGING_LOCATION=gs://my-gcp-proj/mysql-export/staging \<br/>export JARS=gs://my-gcp-proj/mysql-export/mysql-connector-java-8.0.17.jar<br/><br/>bin/start.sh \<br/>-- --template JDBCTOGCS \<br/>--templateProperty 'jdbctogcs.jdbc.url=jdbc:mysql://192.168.16.3:3306/MyCloudSQLDB?user=root&amp;password=root' \<br/>--templateProperty jdbctogcs.jdbc.driver.class.name=com.mysql.cj.jdbc.Driver \<br/>--templateProperty jdbctogcs.output.location=gs://my-gcp-proj/mysql-export/export/table1_export \<br/>--templateProperty jdbctogcs.output.format=parquet \<br/>--templateProperty jdbctogcs.write.mode=OVERWRITE \<br/>--templateProperty <strong class="lq hj">'jdbctogcs.sql=select CAST(id as SIGNED) id, name, email, current_salary, CAST(account_id as SIGNED) account_id, department, created_at, updated_at, id as tbl_id FROM employee'</strong> \<br/>--templateProperty jdbctogcs.sql.partitionColumn=tbl_id \<br/>--templateProperty jdbctogcs.sql.lowerBound=0 \<br/>--templateProperty jdbctogcs.sql.upperBound=100000000 \<br/>--templateProperty jdbctogcs.sql.numPartitions=400</span></pre><p id="63a6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">3.<strong class="ih hj">插入批量大小<br/> </strong>您可以通过如下指定“GCS . spanner . output . batchinsertsize”属性来微调GCSToSpanner作业的插入批量大小。请注意，Cloud Spanner限制每个写请求20，000个突变(截至今天)。</p><p id="4a8c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">例如:</p><pre class="je jf jg jh fd lp lq lr ls aw lt bi"><span id="db96" class="lu ju hi lq b fi lv lw l lx ly">export GCP_PROJECT=my-gcp-proj \<br/>export REGION=us-central1  \<br/>export SUBNET=projects/my-gcp-proj/regions/us-central1/subnetworks/default   \<br/>export GCS_STAGING_LOCATION=gs://my-gcp-proj/mysql-export/staging</span><span id="b365" class="lu ju hi lq b fi lz lw l lx ly">bin/start.sh \<br/>-- --template GCSTOSPANNER \<br/>--templateProperty project.id=my-gcp-proj \<br/>--templateProperty gcs.spanner.input.format=parquet \<br/>--templateProperty gcs.spanner.input.location<!-- -->=gs://my-gcp-proj/mysql-export/export/table1_export<!-- -->/part*.parquet \<br/>--templateProperty gcs.spanner.output.instance=spanner-inst \<br/>--templateProperty gcs.spanner.output.database=spanner-db \<br/>--templateProperty gcs.spanner.output.table=employee \<br/>--templateProperty gcs.spanner.output.saveMode=Overwrite \<br/>--templateProperty gcs.spanner.output.primaryKey=id \<br/><strong class="lq hj">--templateProperty gcs.spanner.output.batchInsertSize=2000</strong></span></pre><p id="3296" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">4.<strong class="ih hj">无锁读取</strong> <br/>你可以选择指示mysql (source db)进行未提交读取，让select更快。然而，脏读在许多情况下可能是不可接受，所以不是理想的方法。更好的方法是使用静态克隆。</p><p id="4b8b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">5.<strong class="ih hj">表导入的顺序<br/> </strong>理想情况下，您不应该在目标数据库上创建约束、索引、外键引用。因此，进口订单应该不会引起任何问题。否则，您将需要在导入表数据时手动处理关系。</p><h1 id="1723" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">替代目标</h1><ol class=""><li id="c0db" class="kx ky hi ih b ii kr im ks iq kz iu la iy lb jc lc ld le lf bi translated"><strong class="ih hj"> BigQuery <br/> </strong>由于数据库表已经导出到GCS中，您可以使用<a class="ae kw" href="https://github.com/GoogleCloudPlatform/dataproc-templates/blob/main/java/src/main/java/com/google/cloud/dataproc/templates/gcs/README.md" rel="noopener ugc nofollow" target="_blank"><strong class="ih hj">gcstobiqquery</strong></a>模板将数据摄取到BigQuery中。</li><li id="752d" class="kx ky hi ih b ii lg im lh iq li iu lj iy lk jc lc ld le lf bi translated"><strong class="ih hj">另一个数据库</strong> <br/> Spark JDBC原生支持以下数据库MySQL / MariaDB、Postgresql、DB2、Oracle。使用<a class="ae kw" href="https://github.com/GoogleCloudPlatform/dataproc-templates/blob/main/java/src/main/java/com/google/cloud/dataproc/templates/gcs/README.md#3-gcs-to-jdbc" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj"> GCSToJDBC </strong> </a>模板(<a class="ae kw" rel="noopener" href="/google-cloud/importing-data-from-gcs-to-databases-via-jdbc-using-dataproc-serverless-7ed75eab93ba"> blogpost </a>)您可以将数据摄取到其中任何一个模板中。</li></ol></div></div>    
</body>
</html>