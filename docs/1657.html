<html>
<head>
<title>Getting Started with Kerberized Dataproc Clusters with Cross-Realm Trust</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">跨领域信任的Kerberized化Dataproc集群入门</h1>
<blockquote>原文：<a href="https://medium.com/google-cloud/getting-started-with-kerberized-dataproc-clusters-with-cross-realm-trust-222d991660dd?source=collection_archive---------0-----------------------#2020-11-12">https://medium.com/google-cloud/getting-started-with-kerberized-dataproc-clusters-with-cross-realm-trust-222d991660dd?source=collection_archive---------0-----------------------#2020-11-12</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="ecc0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在本文中，我们将介绍使用Kerberos建立多个Dataproc集群的架构和部署，这些集群使用跨领域信任进行互操作。本文中部署的terraform模块和脚本在github repo<a class="ae jd" href="https://github.com/GoogleCloudPlatform/professional-services/tree/main/examples/kerberized_data_lake" rel="noopener ugc nofollow" target="_blank"><em class="je">Kerberos化_data_lake </em> </a>中提供。</p><h1 id="fd0f" class="jf jg hi bd jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc bi translated">概观</h1><p id="6c7c" class="pw-post-body-paragraph if ig hi ih b ii kd ik il im ke io ip iq kf is it iu kg iw ix iy kh ja jb jc hb bi translated">下面的架构是用Kerberos部署Dataproc的几种方法之一。在这个架构中，我们利用<a class="ae jd" href="https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/security#kerberos-config" rel="noopener ugc nofollow" target="_blank"> Dataproc的安全配置</a>来创建集群上的KDC，并管理集群的服务主体和keytabs，这是对Hadoop集群进行Kerberos化所需要的。</p><figure class="kj kk kl km fd kn er es paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="er es ki"><img src="../Images/08ce64a7b04ce0b11232dbab6b755b92.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EFhycGg--TotunoA2fgpZg.png"/></div></div></figure><p id="5ecf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">使用这种架构，Dataproc集群必须建立信任，以确保经过身份验证的用户可以在分析集群上运行作业，并访问中央配置单元metastore。跨Kerberos领域配置的单向信任允许经过身份验证的用户无缝访问所需的Hadoop服务。跨领域信任的三个关键组件包括:</p><h2 id="bf9b" class="ku jg hi bd jh kv kw kx jl ky kz la jp iq lb lc jt iu ld le jx iy lf lg kb lh bi translated">企业目录服务(Active Directory、麻省理工学院KDC分校、FreeIPA)</h2><ul class=""><li id="4844" class="li lj hi ih b ii kd im ke iq lk iu ll iy lm jc ln lo lp lq bi translated">带有KDC的单一主Dataproc集群，用于管理用户和团队的账户</li></ul><h2 id="f4a8" class="ku jg hi bd jh kv kw kx jl ky kz la jp iq lb lc jt iu ld le jx iy lf lg kb lh bi translated">分析Dataproc集群</h2><ul class=""><li id="5673" class="li lj hi ih b ii kd im ke iq lk iu ll iy lm jc ln lo lp lq bi translated">供用户执行Spark、MapReduce、Hive/Beeline、Presto等的集群。</li><li id="838f" class="li lj hi ih b ii lr im ls iq lt iu lu iy lv jc ln lo lp lq bi translated">与公司域的单向信任以验证最终用户</li></ul><h2 id="3fc8" class="ku jg hi bd jh kv kw kx jl ky kz la jp iq lb lc jt iu ld le jx iy lf lg kb lh bi translated">配置单元Metastore Dataproc群集</h2><ul class=""><li id="935c" class="li lj hi ih b ii kd im ke iq lk iu ll iy lm jc ln lo lp lq bi translated">数据库和表的中央metastore</li><li id="c4ac" class="li lj hi ih b ii lr im ls iq lt iu lu iy lv jc ln lo lp lq bi translated">与公司域的单向信任，以验证最终用户对metastore的访问</li><li id="5e53" class="li lj hi ih b ii lr im ls iq lt iu lu iy lv jc ln lo lp lq bi translated">与analytics clusters域的单向信任，以验证用于<a class="ae jd" href="https://cwiki.apache.org/confluence/display/Hive/Setting+Up+HiveServer2#SettingUpHiveServer2-Impersonation" rel="noopener ugc nofollow" target="_blank"> HiveServer2模拟</a>的HiveServer2服务主体</li></ul><h1 id="4833" class="jf jg hi bd jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc bi translated"><strong class="ak">部署</strong></h1><p id="d70b" class="pw-post-body-paragraph if ig hi ih b ii kd ik il im ke io ip iq kf is it iu kg iw ix iy kh ja jb jc hb bi translated"><a class="ae jd" href="https://github.com/GoogleCloudPlatform/professional-services/tree/main/examples/kerberized_data_lake" rel="noopener ugc nofollow" target="_blank"><strong class="ih hj">Kerberos化_data_lake </strong> git仓库</a>使用terragrunt/terraform为上述Kerberos架构提供部署。该部署需要多个GCP产品，包括Dataproc、云KMS、云存储、VPC，并且可以部署在沙盒环境中，以审查所使用的所有组件和服务。</p><p id="841a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">作为先决条件，Dataproc集群配置有<strong class="ih hj">无外部IP <em class="je"> s </em> </strong>，并要求子网启用<a class="ae jd" href="https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/network#create_a_cloud_dataproc_cluster_with_internal_ip_address_only" rel="noopener ugc nofollow" target="_blank">私有Google访问</a>。</p><ol class=""><li id="2427" class="li lj hi ih b ii ij im in iq lw iu lx iy ly jc lz lo lp lq bi translated"><strong class="ih hj">设置环境变量(根据需要修改)</strong>:</li></ol><pre class="kj kk kl km fd ma mb mc md aw me bi"><span id="e091" class="ku jg hi mb b fi mf mg l mh mi">export PROJECT=$(gcloud info --format='value(config.project)')<br/>export ZONE=$(gcloud info --format='value(config.properties.compute.zone)')<br/>export REGION=${ZONE%-*}<br/>export DATALAKE_ADMIN=$(gcloud config list --format='value(core.account)')<br/>export DATAPROC_SUBNET=default</span></pre><p id="7958" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 2。创建地形变量文件:</strong></p><pre class="kj kk kl km fd ma mb mc md aw me bi"><span id="7f0f" class="ku jg hi mb b fi mf mg l mh mi">cat &gt; kerb_datalake.tfvars &lt;&lt; EOL<br/>project="${PROJECT}"<br/>region="${REGION}"<br/>zone="${ZONE}"<br/>data_lake_super_admin="${DATALAKE_ADMIN}"<br/>dataproc_subnet="${DATAPROC_SUBNET}"<br/>users=["bob", "alice"]<br/>tenants=["core-data"]<br/>EOL</span></pre><p id="24ee" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">配置注释</strong>:</p><ul class=""><li id="8cac" class="li lj hi ih b ii ij im in iq lw iu lx iy ly jc ln lo lp lq bi translated"><code class="du mj mk ml mb b">project</code>、<code class="du mj mk ml mb b">region</code>、<code class="du mj mk ml mb b">zone</code>——指部署的项目、地区、地带</li><li id="7d1c" class="li lj hi ih b ii lr im ls iq lt iu lu iy lv jc ln lo lp lq bi translated"><code class="du mj mk ml mb b">data_lake_super_admin</code> -正在部署的资源(KMS密钥、GCS存储桶等)的IAM管理员。)</li><li id="d119" class="li lj hi ih b ii lr im ls iq lt iu lu iy lv jc ln lo lp lq bi translated"><code class="du mj mk ml mb b">datataproc_subnet</code>-data proc集群的子网</li></ul><p id="1f57" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 3。查看kerb_data_lake.tfvars并<em class="je">运行部署</em> : </strong></p><pre class="kj kk kl km fd ma mb mc md aw me bi"><span id="7fe0" class="ku jg hi mb b fi mf mg l mh mi">terraform workspace new ${PROJECT}<br/>terraform init<br/>terraform apply -var-file kerb_datalake.tfvars</span></pre><h1 id="f3d8" class="jf jg hi bd jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc bi translated"><strong class="ak">设置详情</strong></h1><p id="a4d9" class="pw-post-body-paragraph if ig hi ih b ii kd ik il im ke io ip iq kf is it iu kg iw ix iy kh ja jb jc hb bi translated">在这个例子中，我们使用一个麻省理工学院的KDC来实现公司域，在这里我们在一个KDC中管理用户主体。为了验证部署，我们创建三个用户:<em class="je">alice@FOO.COM</em>、<em class="je">bob@FOO.COM</em>，以及一个不需要人工交互的应用服务帐户<em class="je">core-data-svc@FOO.COM</em>(即密码提示)进行身份验证。</p><p id="e5d2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">有三个集群拥有自己的Kerberos领域，因为每个集群都部署了自己的KDC。FOO.COM代表企业领域，而其他人则专门负责数据湖。值得注意的是，当我们为所有服务创建Dataproc集群时，例如独立的中央KDC，我们只配置集群来支持特定的服务，而不是作为传统的数据处理集群。下面是对三个集群及其各自的Kerberos领域的描述:</p><pre class="kj kk kl km fd ma mb mc md aw me bi"><span id="55bb" class="ku jg hi mb b fi mf mg l mh mi"><strong class="mb hj">cluster :       kdc-cluster </strong><br/>realm   :       FOO.COM<br/>desc    :       corporate directory service / domain controller where user/service accounts are created</span><span id="bcc0" class="ku jg hi mb b fi mm mg l mh mi"><strong class="mb hj">cluster :       metastore-cluster</strong><br/>realm   :       HIVE-METASTORE.FOO.COM<br/>desc    :       master only nodes that host the hive metastore catalog and provided default hive connection for all analytics clusters</span><span id="939f" class="ku jg hi mb b fi mm mg l mh mi"><strong class="mb hj">cluster :       analytics-cluster</strong><br/>realm   :       ANALYTICS.FOO.COM<br/>desc    :       multi-tenant cluster(s) for data processing, users kinit alice@FOO.COM and are authenticated to access resources and execute jobs</span></pre><h2 id="2ff5" class="ku jg hi bd jh kv kw kx jl ky kz la jp iq lb lc jt iu ld le jx iy lf lg kb lh bi translated"><strong class="ak">KDCs的秘密</strong></h2><p id="c8b8" class="pw-post-body-paragraph if ig hi ih b ii kd ik il im ke io ip iq kf is it iu kg iw ix iy kh ja jb jc hb bi translated">Dataproc Kerberos部署需要集群上KDC的秘密和信任的额外秘密:</p><p id="8ddf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">1)</strong>KDC根主体的加密秘密<br/> <strong class="ih hj"> 2) </strong>用于建立对远程KDC的信任的加密秘密</p><p id="731a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Terraform在本地生成并加密随机生成的秘密，并将它们推送到集群可访问的特定GCS秘密桶。创建集群时，设置将使用加密密钥的GCS URI，流入内容，使用KMS密钥解密，并设置必要的配置，而不在集群上存储密钥。</p><h2 id="b511" class="ku jg hi bd jh kv kw kx jl ky kz la jp iq lb lc jt iu ld le jx iy lf lg kb lh bi translated"><strong class="ak">Kerberos主体的秘密</strong></h2><p id="719b" class="pw-post-body-paragraph if ig hi ih b ii kd ik il im ke io ip iq kf is it iu kg iw ix iy kh ja jb jc hb bi translated">除了设置集群上KDC的秘密之外，我们还为<em class="je">alice@FOO.COM</em>、<em class="je">bob@FOO.COM</em>创建用户主体，为应用服务帐户<em class="je">core-data-svc@FOO.COM</em>创建服务主体。这些是在kdc集群中创建的，用户的<em class="je">不安全的</em>密码只是用户名的前4个可能的字符，后跟123(即。爱丽丝/alic123)。</p><p id="d5ad" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">由于<em class="je">core-data-svc@FOO.COM</em>主体是一个应用程序服务，我们为这个帐户生成一个keytab，并使其在analytics-cluster的主节点上可用。该凭证保存在/etc/security/keytab/core-data-SVC . keytab中，拥有<strong class="ih hj">core-data-SVC:core-data-SVC</strong>和<strong class="ih hj">权限400 </strong>。有了这个keytab，应用程序服务就可以使用keytab进行身份验证来执行作业。</p><p id="e736" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因为这只是为了演示，所以为了简单起见，我们不使用边缘节点，而是使用主节点来启动作业。</p><h2 id="0656" class="ku jg hi bd jh kv kw kx jl ky kz la jp iq lb lc jt iu ld le jx iy lf lg kb lh bi translated"><strong class="ak">麻省理工学院FOO.COM KDC校区</strong></h2><p id="5d36" class="pw-post-body-paragraph if ig hi ih b ii kd ik il im ke io ip iq kf is it iu kg iw ix iy kh ja jb jc hb bi translated">部署的第一个集群是麻省理工学院KDC。它不需要建立到其他集群的信任，但是当其他集群被创建时，它们将与它建立信任。与该KDC建立信任将允许其他集群信任请求访问数据处理集群上的Hadoop的用户主体。GCS中存储的要创建的该集群的依赖项有:</p><pre class="kj kk kl km fd ma mb mc md aw me bi"><span id="27d1" class="ku jg hi mb b fi mf mg l mh mi">gs://{var.project}-<strong class="mb hj">dataproc-secrets</strong>/<br/>  kdc-cluster_principal.encrypted      (<em class="je">kdc secret</em>)</span><span id="44f5" class="ku jg hi mb b fi mm mg l mh mi">gs://{var.project}-<strong class="mb hj">dataproc-scripts</strong>/init-actions/<br/>  create-users.sh                     (<em class="je">setup test users</em>)</span></pre><h2 id="09ed" class="ku jg hi bd jh kv kw kx jl ky kz la jp iq lb lc jt iu ld le jx iy lf lg kb lh bi translated"><strong class="ak"> Metastore集群—HIVE-METASTORE.FOO.COM领域</strong></h2><p id="d8c5" class="pw-post-body-paragraph if ig hi ih b ii kd ik il im ke io ip iq kf is it iu kg iw ix iy kh ja jb jc hb bi translated">此群集部署了一个集中式配置单元Metastore，用于管理多个群集之间的共享元数据。它需要与<em class="je">FOO.COM</em>的单向信任，以允许经过身份验证的用户访问metastore资源(即Spark SQL作业在分析集群查询表上作为<em class="je">alice@FOO.COM</em>运行，分两步设置:</p><p id="495c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 1) </strong>在本地元存储集群上添加信任(自动执行)<br/> <strong class="ih hj"> 2) </strong>在远程kdc集群上添加信任(初始化设置-kerberos-trust.sh)</p><p id="bade" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">以下是metastore集群的依赖关系:</p><pre class="kj kk kl km fd ma mb mc md aw me bi"><span id="0f71" class="ku jg hi mb b fi mf mg l mh mi">gs://{var.project}-<strong class="mb hj">dataproc-secrets</strong>/<br/>  metastore-cluster_principal.encrypted  (<em class="je">kdc secret</em>)<br/>  trust_metastore-cluster_kdc-cluster_principal.encrypted  (trust w/ foo secret)</span><span id="87a7" class="ku jg hi mb b fi mm mg l mh mi">gs://{var.project}-<strong class="mb hj">dataproc-scripts</strong>/init-actions/<br/>  setup-kerberos-config.sh               (<em class="je">updates krb5.conf</em>)<br/>  setup-kerberos-trust.sh                (<em class="je">setup trust on remote kdc</em>)<br/>  setup-users-config.sh                  (<em class="je">setup test users</em>)<br/>  disable-history-server.sh              (<em class="je">disable unneeded services</em>)</span><span id="67d8" class="ku jg hi mb b fi mm mg l mh mi">gs://{var.project}-<strong class="mb hj">dataproc-scripts</strong>/shutdown-scripts/<br/>  shutdown-cleanup-trust.sh              (<em class="je">remove remote trust</em>)</span></pre><h2 id="9977" class="ku jg hi bd jh kv kw kx jl ky kz la jp iq lb lc jt iu ld le jx iy lf lg kb lh bi translated"><strong class="ak">分析集群—ANALYTICS.FOO.COM领域</strong></h2><p id="d008" class="pw-post-body-paragraph if ig hi ih b ii kd ik il im ke io ip iq kf is it iu kg iw ix iy kh ja jb jc hb bi translated">最后一个集群是终端用户集群，用于多个租户的数据处理。此群集需要与<em class="je">FOO.COM</em>建立信任，以及与metastore(metastore trusts analytics)建立反向信任，以允许HiveServer2主体访问metastore。设置步骤如下:</p><p id="6c4a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 1) </strong>在本地analytics-cluster上添加信任(自动执行)<br/> <strong class="ih hj"> 2) </strong>在远程kdc-cluster上添加信任(初始化设置-kerberos-trust.sh)<br/><strong class="ih hj">3)</strong>在本地analytics-cluster上添加反向信任(初始化设置-Kerberos-trust . sh)<br/><strong class="ih hj">4)</strong>在远程metastore-cluster上添加反向信任(初始化设置-Kerberos-trust . sh)</p><p id="dbba" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">以下是分析集群的依赖关系:</p><pre class="kj kk kl km fd ma mb mc md aw me bi"><span id="82e5" class="ku jg hi mb b fi mf mg l mh mi">gs://{var.project}-<strong class="mb hj">dataproc-secrets</strong>/<br/>  analytics-cluster_principal.encrypted      (<em class="je">kdc secret</em>)<br/>  trust_analytics-cluster_kdc-cluster_principal.encrypted           (trust w/ foo secret)<br/>  trust_metastore-cluster_analytics-cluster_principal.encrypted  (metastore trusts analytics secret)</span><span id="6f90" class="ku jg hi mb b fi mm mg l mh mi">gs://{var.project}-<strong class="mb hj">dataproc-scripts</strong>/init-actions/<br/>  setup-kerberos-config.sh               (<em class="je">updates krb5.conf</em>)<br/>  setup-kerberos-trust.sh                (<em class="je">setup trust on remote kdc</em>)<br/>  setup-users-config.sh                  (<em class="je">setup test users</em>)<br/>  disable-history-server.sh              (<em class="je">disable unneeded services</em>)</span><span id="5be7" class="ku jg hi mb b fi mm mg l mh mi">gs://{var.project}-<strong class="mb hj">dataproc-scripts</strong>/shutdown-scripts/<br/>  shutdown-cleanup-trust.sh              (<em class="je">remove remote trust</em>)</span></pre><h1 id="9fb0" class="jf jg hi bd jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc bi translated"><strong class="ak">验证Kerberos部署</strong></h1><h2 id="b32f" class="ku jg hi bd jh kv kw kx jl ky kz la jp iq lb lc jt iu ld le jx iy lf lg kb lh bi translated">宋承宪和Kinit</h2><p id="d59b" class="pw-post-body-paragraph if ig hi ih b ii kd ik il im ke io ip iq kf is it iu kg iw ix iy kh ja jb jc hb bi translated">登录，以alice身份验证，并在analytics-cluster上运行Hadoop命令。</p><pre class="kj kk kl km fd ma mb mc md aw me bi"><span id="66a3" class="ku jg hi mb b fi mf mg l mh mi"><em class="je">$ gcloud compute ssh alice@analytics-cluster-m --tunnel-through-iap<br/>$ kinit alice@FOO.COM                # remember insecure pwd alic123<br/>Password for </em><a class="ae jd" href="mailto:alice@ACME.COM" rel="noopener ugc nofollow" target="_blank"><em class="je">alice@FOO.COM</em></a><em class="je">:<br/>$ klist <br/>$ hadoop fs -ls /user/</em></span></pre><h2 id="625c" class="ku jg hi bd jh kv kw kx jl ky kz la jp iq lb lc jt iu ld le jx iy lf lg kb lh bi translated">MapReduce测试</h2><p id="f796" class="pw-post-body-paragraph if ig hi ih b ii kd ik il im ke io ip iq kf is it iu kg iw ix iy kh ja jb jc hb bi translated">在kerberized化的集群上执行一个作业，并将输出保存到数据湖桶中。</p><pre class="kj kk kl km fd ma mb mc md aw me bi"><span id="df9c" class="ku jg hi mb b fi mf mg l mh mi">$ hadoop jar /usr/lib/hadoop-mapreduce/hadoop-mapreduce-examples.jar teragen -Dmapreduce.job.maps=4 10000000 gs://jh-data-sandbox-us-data-lake/test.db/test</span></pre><h2 id="59c7" class="ku jg hi bd jh kv kw kx jl ky kz la jp iq lb lc jt iu ld le jx iy lf lg kb lh bi translated">直线测试</h2><p id="7890" class="pw-post-body-paragraph if ig hi ih b ii kd ik il im ke io ip iq kf is it iu kg iw ix iy kh ja jb jc hb bi translated">测试alice对HiveServer2的身份验证以及HiveServer2对Hive Metastore的请求。</p><pre class="kj kk kl km fd ma mb mc md aw me bi"><span id="32c5" class="ku jg hi mb b fi mf mg l mh mi">$ beeline -u "jdbc:hive2://localhost:10000/default;principal=hive/analytics-cluster-m@ANALYTICS.FOO.COM"<br/>jdbc:hive2://localhost:10000/default&gt; create database test_db location ‘gs://jh-data-sandbox-us-data-lake/test.db’;<br/>jdbc:hive2://localhost:10000/default&gt; show databases;<br/>jdbc:hive2://localhost:10000/default&gt; use test_db;<br/>jdbc:hive2://localhost:10000/default&gt; create external table test (one string) location 'gs://jh-data-sandbox-us-data-lake/test.db/test/';<br/>jdbc:hive2://localhost:10000/default&gt; describe formatted test;<br/>jdbc:hive2://localhost:10000/default&gt; select count(1) from test;<br/>jdbc:hive2://localhost:10000/default&gt; set hive.metastore.uris;<br/>jdbc:hive2://localhost:10000/default&gt; !q</span></pre><h2 id="d137" class="ku jg hi bd jh kv kw kx jl ky kz la jp iq lb lc jt iu ld le jx iy lf lg kb lh bi translated">火花和Metastore测试</h2><pre class="kj kk kl km fd ma mb mc md aw me bi"><span id="5a61" class="ku jg hi mb b fi mf mg l mh mi">$ spark-shell <br/>scala&gt; spark.sql("select count(1) from test_db.test").show(false)<br/>scala&gt; spark.catalog.listDatabases.show(false)<br/>scala&gt; spark.sql("use test_db")<br/>scala&gt; spark.sql("describe formatted test").show(false)<br/>scala&gt; println(spark.sparkContext.hadoopConfiguration.get("hive.metastore.uris"))<br/>scala&gt; :q</span></pre><h2 id="aac0" class="ku jg hi bd jh kv kw kx jl ky kz la jp iq lb lc jt iu ld le jx iy lf lg kb lh bi translated">应用服务帐户测试核心-数据-svc@FOO。计算机输出缩微胶片</h2><p id="0ebd" class="pw-post-body-paragraph if ig hi ih b ii kd ik il im ke io ip iq kf is it iu kg iw ix iy kh ja jb jc hb bi translated">Kinit使用keytab，在访问metastore的分析集群上运行spark作业。</p><pre class="kj kk kl km fd ma mb mc md aw me bi"><span id="a244" class="ku jg hi mb b fi mf mg l mh mi">$ gcloud compute ssh core-data-svc@analytics-cluster-m --tunnel-through-iap<br/> $ kinit -kt /etc/security/keytab/core-data-svc.keytab <a class="ae jd" href="mailto:core-data-svc@ACME.COM" rel="noopener ugc nofollow" target="_blank">core-data-svc@FOO.COM<br/> </a>$ spark-shell &lt;&lt;&lt; 'spark.sql("select count(1) from test_db.test").show(false)'</span></pre><h1 id="c013" class="jf jg hi bd jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc bi translated"><strong class="ak">总结</strong></h1><p id="0ccb" class="pw-post-body-paragraph if ig hi ih b ii kd ik il im ke io ip iq kf is it iu kg iw ix iy kh ja jb jc hb bi translated">在这篇博客中，我们学习了使用kerberos部署dataproc集群以及在KDC之间建立单向信任以实现互操作性的步骤。我们通过运行作业进一步验证了部署，这些作业不仅在本地Dataproc kerberized化的集群上执行，而且针对远程Hive Metastore验证了经过身份验证的测试用户。最后，我们通过使用keytab提供身份验证，完成了对自动化作业的验证。这些步骤有望为理解Dataproc上的Kerberos以及如何为您的数据湖配置多个集群提供一个良好的前提。</p><p id="4a1d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">由梅丽莎·阿维拉 &amp; <a class="ae jd" rel="noopener" href="/@jordan.hambleton">乔丹·汉伯顿</a></p></div></div>    
</body>
</html>