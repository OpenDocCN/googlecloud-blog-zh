<html>
<head>
<title>Export data from Apache Kafka to BigQuery using Dataproc Serverless</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Dataproc Serverless将数据从Apache Kafka导出到BigQuery</h1>
<blockquote>原文：<a href="https://medium.com/google-cloud/export-data-from-apache-kafka-to-bigquery-using-dataproc-serverless-4a666535117c?source=collection_archive---------1-----------------------#2022-08-01">https://medium.com/google-cloud/export-data-from-apache-kafka-to-bigquery-using-dataproc-serverless-4a666535117c?source=collection_archive---------1-----------------------#2022-08-01</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/872bb196c64a3363aa756ac3100512f3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YqIZcyTgUObwCI7XgxBbNg.png"/></div></div></figure><p id="377a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">data proc Spark无服务器版</strong>无需配置和管理集群即可运行批量工作负载。它可以动态地调整工作负载资源，比如执行器的数量，以便高效地运行您的工作负载。作为数据开发人员，这使我们能够专注于业务逻辑，而不是花时间管理基础设施。</p><p id="8b58" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">相比之下，计算引擎上的<strong class="is hj"> Dataproc在GCP上提供托管Hadoop和Spark服务。它非常适合希望调配和管理基础架构，然后在Spark上执行工作负载的用户。</strong></p><p id="4036" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> Dataproc无服务器模板:</strong>现成可用的、开源的、可定制的模板，基于Dataproc无服务器for Spark。这些模板帮助数据工程师进一步简化在Dataproc Serverless上的开发过程，根据他们的需求消费和定制现有的模板。</p><p id="c2dd" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在本文中，我们将探讨如何使用Dataproc Serverless for Spark从Kafka主题向BigQuery执行数据的批处理或流加载。</p><h2 id="d081" class="jo jp hi bd jq jr js jt ju jv jw jx jy jb jz ka kb jf kc kd ke jj kf kg kh ki bi translated">先决条件</h2><ul class=""><li id="9ba8" class="kj kk hi is b it kl ix km jb kn jf ko jj kp jn kq kr ks kt bi translated">安装并验证了Google Cloud SDK</li><li id="9625" class="kj kk hi is b it ku ix kv jb kw jf kx jj ky jn kq kr ks kt bi translated">云壳或预装Java 8、Maven 3和Git的机器</li></ul><h2 id="18b9" class="jo jp hi bd jq jr js jt ju jv jw jx jy jb jz ka kb jf kc kd ke jj kf kg kh ki bi translated">Kafka到BigQuery模板</h2><p id="d432" class="pw-post-body-paragraph iq ir hi is b it kl iv iw ix km iz ja jb kz jd je jf la jh ji jj lb jl jm jn hb bi translated">该模板将从Apache Kafka主题中读取数据，并将其写入BigQuery表。它主要支持结构化流，但也适用于批处理工作负载。它使用Spark BigQuery连接器和Spark Kafka结构化流连接器。</p><figure class="ld le lf lg fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lc"><img src="../Images/0aa4656dce35e8ebc83852785984a88f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GFm43ng-jc4GAlcbYJppLA.png"/></div></div></figure><p id="58ed" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">该模板允许通过执行命令配置以下参数:</p><ul class=""><li id="f8d4" class="kj kk hi is b it iu ix iy jb lh jf li jj lj jn kq kr ks kt bi translated"><em class="lk">kafka . bq . bootstrap . servers</em>:以逗号分隔的带有Kafka代理端口号的IP地址列表。例如:102.1.1.20:9092</li><li id="bff4" class="kj kk hi is b it ku ix kv jb kw jf kx jj ky jn kq kr ks kt bi translated"><em class="lk"> kafka.bq.topic </em>:逗号分隔的kafka主题列表。示例:topicA、topicB</li><li id="5913" class="kj kk hi is b it ku ix kv jb kw jf kx jj ky jn kq kr ks kt bi translated"><em class="lk">Kafka . bq . dataset</em>:big query的输出数据集，表驻留在其中或者需要被创建</li><li id="e5d2" class="kj kk hi is b it ku ix kv jb kw jf kx jj ky jn kq kr ks kt bi translated"><em class="lk">Kafka . bq . table</em>:big query的输出表名</li><li id="7ac6" class="kj kk hi is b it ku ix kv jb kw jf kx jj ky jn kq kr ks kt bi translated"><em class="lk">Kafka . bq . temp . GCS . bucket</em>:预先存在的GCS bucket名称，暂存临时文件。示例:模板-演示-kafkatobq</li><li id="37ae" class="kj kk hi is b it ku ix kv jb kw jf kx jj ky jn kq kr ks kt bi translated"><em class="lk">Kafka . bq . check point . location</em>:GCS桶位置，维护检查点文件。该位置保存关于偏移量的信息，并用于从最后处理的偏移量开始恢复流式传输。示例:GS://templates-demo-kafkatobq/check point</li><li id="914c" class="kj kk hi is b it ku ix kv jb kw jf kx jj ky jn kq kr ks kt bi translated"><em class="lk">Kafka . bq . starting . offset</em>:指定开始读取的偏移量。此属性控制模板的行为，无论是批量加载还是流加载数据。可接受的值:“最早”、“最新”或JSON字符串</li><li id="d161" class="kj kk hi is b it ku ix kv jb kw jf kx jj ky jn kq kr ks kt bi translated"><em class="lk">Kafka . bq . await . termination . time out</em>:在流终止前等待指定的时间(毫秒)</li><li id="42c4" class="kj kk hi is b it ku ix kv jb kw jf kx jj ky jn kq kr ks kt bi translated"><em class="lk">Kafka . bq . fail . on . data loss</em>:数据丢失时作业失败。可接受的值:真、假</li><li id="8fe4" class="kj kk hi is b it ku ix kv jb kw jf kx jj ky jn kq kr ks kt bi translated"><em class="lk">Kafka . bq . stream . Output . mode</em>:写入数据的输出模式。可接受的值:“追加”、“完成”、“更新”</li></ul><h2 id="5e1c" class="jo jp hi bd jq jr js jt ju jv jw jx jy jb jz ka kb jf kc kd ke jj kf kg kh ki bi translated">运行模板</h2><ol class=""><li id="6944" class="kj kk hi is b it kl ix km jb kn jf ko jj kp jn ll kr ks kt bi translated">请确保您已经启用了带有专用Google访问的子网。如果您使用的是GCP创建的“默认”VPC，您仍然需要启用如下的私人访问。</li></ol><figure class="ld le lf lg fd ij er es paragraph-image"><div class="er es lm"><img src="../Images/05be98625f05b67cf70708c5469b0700.png" data-original-src="https://miro.medium.com/v2/resize:fit:570/format:webp/0*4rZschTjV4V30ld7.png"/></div></figure><pre class="ld le lf lg fd ln lo lp lq aw lr bi"><span id="56b8" class="jo jp hi lo b fi ls lt l lu lv">gcloud compute networks subnets update default --region=us-central1 --enable-private-ip-google-access</span></pre><p id="c0fb" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">2.为jar文件创建一个GCS存储桶和暂存位置。</p><p id="ad38" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">3.在预装了各种工具的云壳中克隆git repo。或者使用任何预装JDK 8+，Maven和Git的机器。</p><pre class="ld le lf lg fd ln lo lp lq aw lr bi"><span id="a2c0" class="jo jp hi lo b fi ls lt l lu lv">git clone <a class="ae lw" href="https://github.com/GoogleCloudPlatform/dataproc-templates.git" rel="noopener ugc nofollow" target="_blank">https://github.com/GoogleCloudPlatform/dataproc-templates.git</a></span><span id="8304" class="jo jp hi lo b fi lx lt l lu lv">cd dataproc-templates/java</span></pre><p id="2fd5" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">4.认证gcloud CLI</p><pre class="ld le lf lg fd ln lo lp lq aw lr bi"><span id="80f5" class="jo jp hi lo b fi ls lt l lu lv">gcloud auth login</span></pre><p id="8479" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">5.执行KafkaToBQ模板</p><p id="bf72" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><em class="lk">样本执行命令:</em></p><pre class="ld le lf lg fd ln lo lp lq aw lr bi"><span id="e72f" class="jo jp hi lo b fi ls lt l lu lv">export GCP_PROJECT=my-gcp-project<br/>export REGION=us-west1<br/>export SUBNET=test-subnet<br/>export GCS_STAGING_LOCATION=gs://templates-demo-kafkatobq<br/>bin/start.sh \<br/>-- \<br/>--template KAFKATOBQ \<br/>--templateProperty project.id=$GCP_PROJECT \<br/>--templateProperty kafka.bq.checkpoint.location=gs://templates-demo-kafkatobq/checkpoint \<br/>--templateProperty kafka.bq.bootstrap.servers=102.1.1.20:9092 \<br/>--templateProperty kafka.bq.topic=msg-events \<br/>--templateProperty kafka.bq.starting.offset=earliest \<br/>--templateProperty kafka.bq.dataset=kafkatobq \<br/>--templateProperty kafka.bq.table=kafkaevents \<br/>--templateProperty kafka.bq.temp.gcs.bucket=templates-demo-kafkatobq \<br/>--templateProperty kafka.bq.await.termination.timeout=1200000</span></pre><p id="cf61" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">6.监控Spark批处理作业</p><p id="d561" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">提交作业后，您将能够在Dataproc批处理UI中查看作业。从那里，我们可以查看作业的指标和日志。</p><h2 id="1ce5" class="jo jp hi bd jq jr js jt ju jv jw jx jy jb jz ka kb jf kc kd ke jj kf kg kh ki bi translated">重要属性</h2><h2 id="1ead" class="jo jp hi bd jq jr js jt ju jv jw jx jy jb jz ka kb jf kc kd ke jj kf kg kh ki bi translated">kafka.bq.starting.offset的用法</h2><ul class=""><li id="9185" class="kj kk hi is b it kl ix km jb kn jf ko jj kp jn kq kr ks kt bi translated">对于批量加载，使用earliest，这意味着查询的起点被设置为最早的偏移量。</li></ul><pre class="ld le lf lg fd ln lo lp lq aw lr bi"><span id="b1ea" class="jo jp hi lo b fi ls lt l lu lv">kafka.bq.starting.offset=earliest</span></pre><ul class=""><li id="cde5" class="kj kk hi is b it iu ix iy jb lh jf li jj lj jn kq kr ks kt bi translated">对于流式加载，使用latest，这意味着只从最新的偏移量开始查询:</li></ul><pre class="ld le lf lg fd ln lo lp lq aw lr bi"><span id="efa6" class="jo jp hi lo b fi ls lt l lu lv">kafka.bq.starting.offset=latest</span></pre><ul class=""><li id="a114" class="kj kk hi is b it iu ix iy jb lh jf li jj lj jn kq kr ks kt bi translated">要从TopicPartition中仅读取特定的偏移量，请使用以下格式的json字符串:</li></ul><pre class="ld le lf lg fd ln lo lp lq aw lr bi"><span id="93f1" class="jo jp hi lo b fi ls lt l lu lv">kafka.bq.starting.offset=""" {"click-events":{"0":15,"1":-1},"msg-events":{"0":-2}} """</span></pre><p id="c589" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在json中，-2作为偏移量可以用来引用最早的，-1引用最新的。</p><p id="ce0d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">注意:选项<em class="lk"> kafka.bq.starting.offset </em>仅在应用程序第一次运行时相关。之后，使用存储在<em class="lk">Kafka . bq . check point . location</em>的检查点文件。</p><p id="ec23" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">注意:如果没有从执行命令中显式提供，此属性的默认值是earliest。</p><p id="746f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">要了解更多此属性，请参考<a class="ae lw" href="https://spark.apache.org/docs/2.2.0/structured-streaming-kafka-integration.html#:~:text=meaning-,startingOffsets,-%22earliest%22%2C%20%22latest%22%20(streaming" rel="noopener ugc nofollow" target="_blank">结构化流+ Kafka集成指南(Kafka broker版本0.10.0或更高版本)</a></p><h2 id="c2ff" class="jo jp hi bd jq jr js jt ju jv jw jx jy jb jz ka kb jf kc kd ke jj kf kg kh ki bi translated">kafka.bq.stream.output.mode的用法</h2><ul class=""><li id="a48d" class="kj kk hi is b it kl ix km jb kn jf ko jj kp jn kq kr ks kt bi translated">当只有流式数据集中的新行需要写入接收器时，使用追加输出模式。</li></ul><pre class="ld le lf lg fd ln lo lp lq aw lr bi"><span id="3f0d" class="jo jp hi lo b fi ls lt l lu lv">kafka.bq.stream.output.mode=append</span></pre><ul class=""><li id="8759" class="kj kk hi is b it iu ix iy jb lh jf li jj lj jn kq kr ks kt bi translated">每当有一些更新时，如果流数据集中的所有行都需要写入接收器，则使用完整输出模式。</li></ul><pre class="ld le lf lg fd ln lo lp lq aw lr bi"><span id="1188" class="jo jp hi lo b fi ls lt l lu lv">kafka.bq.stream.output.mode=complete</span></pre><ul class=""><li id="0b52" class="kj kk hi is b it iu ix iy jb lh jf li jj lj jn kq kr ks kt bi translated">当每次有一些更新时，只需要将流数据集中已更新的行写入接收器时，使用更新输出模式。</li></ul><pre class="ld le lf lg fd ln lo lp lq aw lr bi"><span id="d00e" class="jo jp hi lo b fi ls lt l lu lv">kafka.bq.stream.output.mode=update</span></pre><p id="80a0" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">欲了解更多详情，请参考<a class="ae lw" href="https://spark.apache.org/docs/2.2.1/api/java/org/apache/spark/sql/streaming/OutputMode.html" rel="noopener ugc nofollow" target="_blank">输出模式Spark JavaDoc </a></p><p id="3768" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">注意:如果没有从执行命令中显式提供，此属性的默认值为append。</p><h2 id="6b25" class="jo jp hi bd jq jr js jt ju jv jw jx jy jb jz ka kb jf kc kd ke jj kf kg kh ki bi translated">Kafka . bq . await . termination . time out的用法</h2><p id="b726" class="pw-post-body-paragraph iq ir hi is b it kl iv iw ix km iz ja jb kz jd je jf la jh ji jj lb jl jm jn hb bi translated">该属性用于在查询处于活动状态时防止进程退出。否则，它将返回查询是否在timeoutMs毫秒内终止。</p><pre class="ld le lf lg fd ln lo lp lq aw lr bi"><span id="bfed" class="jo jp hi lo b fi ls lt l lu lv">kafka.bq.await.termination.timeout=1800000</span></pre><p id="ce6c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">注意:如果没有在执行命令中明确提供，该属性的默认值为420000。</p><h2 id="8c21" class="jo jp hi bd jq jr js jt ju jv jw jx jy jb jz ka kb jf kc kd ke jj kf kg kh ki bi translated">其他高级作业配置</h2><ul class=""><li id="925e" class="kj kk hi is b it kl ix km jb kn jf ko jj kp jn kq kr ks kt bi translated">HISTORY_SERVER_CLUSER:作为Spark历史服务器的现有Dataproc集群。该属性可用于指定专用服务器，您可以在其中查看正在运行和已完成的Spark作业的状态。示例:</li></ul><pre class="ld le lf lg fd ln lo lp lq aw lr bi"><span id="f58d" class="jo jp hi lo b fi ls lt l lu lv">export HISTORY_SERVER_CLUSER=projects/&lt;project_id&gt;/regions/&lt;region&gt;/clusters/&lt;cluster_name&gt;</span></pre><ul class=""><li id="fd0c" class="kj kk hi is b it iu ix iy jb lh jf li jj lj jn kq kr ks kt bi translated">SPARK_PROPERTIES:如果您需要指定Dataproc无服务器支持的SPARK属性，比如调整驱动程序、内核、执行器等的数量。使用它来获得对火花配置的更多控制。示例:</li></ul><pre class="ld le lf lg fd ln lo lp lq aw lr bi"><span id="92f6" class="jo jp hi lo b fi ls lt l lu lv">export SPARK_PROPERTIES=spark.executor.instances=50,spark.dynamicAllocation.maxExecutors=200</span></pre><h2 id="533d" class="jo jp hi bd jq jr js jt ju jv jw jx jy jb jz ka kb jf kc kd ke jj kf kg kh ki bi translated">参考</h2><ul class=""><li id="fe59" class="kj kk hi is b it kl ix km jb kn jf ko jj kp jn kq kr ks kt bi translated"><a class="ae lw" href="https://cloud.google.com/dataproc-serverless/docs/overview" rel="noopener ugc nofollow" target="_blank"> Dataproc无服务器文档</a></li><li id="8931" class="kj kk hi is b it ku ix kv jb kw jf kx jj ky jn kq kr ks kt bi translated"><a class="ae lw" href="https://github.com/GoogleCloudPlatform/dataproc-templates" rel="noopener ugc nofollow" target="_blank"> Dataproc模板GitHub库</a></li><li id="07c6" class="kj kk hi is b it ku ix kv jb kw jf kx jj ky jn kq kr ks kt bi translated"><a class="ae lw" href="https://spark.apache.org/docs/2.2.0/structured-streaming-kafka-integration.html#structured-streaming-kafka-integration-guide-kafka-broker-versio" rel="noopener ugc nofollow" target="_blank">结构化流媒体+卡夫卡集成指南</a></li><li id="c56a" class="kj kk hi is b it ku ix kv jb kw jf kx jj ky jn kq kr ks kt bi translated"><a class="ae lw" rel="noopener" href="/google-cloud/cloud-spanner-export-query-results-using-dataproc-serverless-6f2f65b583a4"> Medium — Cloud Spanner使用Dataproc Serverless导出查询结果</a></li><li id="7feb" class="kj kk hi is b it ku ix kv jb kw jf kx jj ky jn kq kr ks kt bi translated"><a class="ae lw" rel="noopener" href="/google-cloud/dataproc-serverless-pyspark-template-for-ingesting-compressed-text-files-to-bigquery-c6eab8fb6bc9"> Medium — Dataproc无服务器PySpark模板，用于将压缩文本文件接收到BigQuery </a></li></ul></div></div>    
</body>
</html>