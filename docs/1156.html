<html>
<head>
<title>ML Design Pattern #3: Virtual Epochs</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">ML设计模式#3:虚拟时代</h1>
<blockquote>原文：<a href="https://medium.com/google-cloud/ml-design-pattern-3-virtual-epochs-f842296de730?source=collection_archive---------0-----------------------#2019-09-28">https://medium.com/google-cloud/ml-design-pattern-3-virtual-epochs-f842296de730?source=collection_archive---------0-----------------------#2019-09-28</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="b3ec" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">将机器学习模型训练和评估建立在样本总数的基础上，而不是建立在时期或步骤的基础上</h2></div><p id="17de" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><em class="jt">偶尔为ML工程师设计的一系列设计模式。</em> <a class="ae ju" rel="noopener" href="/@lakshmanok/machine-learning-design-patterns-58e6ecb013d7"> <em class="jt">完整列表在此。</em> </a></p><p id="e8ec" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">机器学习教程经常会有类似<a class="ae ju" href="https://www.kdnuggets.com/2018/06/keras-4-step-workflow.html" rel="noopener ugc nofollow" target="_blank">这种</a>的代码:</p><pre class="jv jw jx jy fd jz ka kb kc aw kd bi"><span id="5ad8" class="ke kf hi ka b fi kg kh l ki kj">model.fit(X_train, y_train, <br/>          batch_size=100, <br/>          epochs=15)</span></pre><p id="28a2" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这段代码假设您有一个适合内存的数据集，并且可以迭代<code class="du kk kl km ka b">epochs</code>次，而不会有机器故障的风险。这两种假设都是不合理的——ML数据集的范围达到万亿字节，当训练可能持续数小时时，机器故障的几率高得令人不安。</p><figure class="jv jw jx jy fd ko er es paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="er es kn"><img src="../Images/19195806a8abce30175c3ef4a1fc0694.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sWmGXaHoftnyF-_Hm5sRRw.jpeg"/></div></div></figure><p id="d3c2" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">TensorFlow刚出来的时候，它的卖点之一就是不做这种不合理的假设。但是构建生产就绪的ML模型所需的代码很难编写。在TensorFlow 2.0中，API更加直观。为了使上面的代码更有弹性，提供一个tf.dataset(不仅仅是一个numpy数组),它提供了迭代功能和延迟加载。Keras支持提供检查点能力的回调(参见<a class="ae ju" href="https://towardsdatascience.com/ml-design-pattern-2-checkpoints-e6ca25a4c5fe" rel="noopener" target="_blank"> ML设计模式#2 </a>)。现在的代码是:</p><pre class="jv jw jx jy fd jz ka kb kc aw kd bi"><span id="ea5f" class="ke kf hi ka b fi kg kh l ki kj">cp_callback = tf.keras.callbacks.ModelCheckpoint(...)<br/>history = model.fit(trainds, <br/>                    validation_data=evalds,<br/>                    epochs=15, <br/>                    batch_size=128,<br/>                    callbacks=[cp_callback])</span></pre><h2 id="bad6" class="ke kf hi bd kv kw kx ky kz la lb lc ld jg le lf lg jk lh li lj jo lk ll lm ln bi translated">时代是有问题的</h2><p id="3565" class="pw-post-body-paragraph ix iy hi iz b ja lo ij jc jd lp im jf jg lq ji jj jk lr jm jn jo ls jq jr js hb bi translated">然而，使用<code class="du kk kl km ka b">epochs</code>是一个坏主意。纪元可能很容易理解，但是在现实世界的ML模型中使用纪元会导致不好的效果。想象一下，你有一个包含100万个例子的训练数据集。例如，通过将历元数设置为15，可以简单地遍历该数据集15次。但是，这有几个问题:</p><ul class=""><li id="bdc4" class="lt lu hi iz b ja jb jd je jg lv jk lw jo lx js ly lz ma mb bi translated">历元的数量是整数，但是处理数据集14.3次和15次之间的训练时间差异可以是小时。如果模型在看到1430万个示例后已经收敛，您可能希望退出，而不是浪费处理70万个示例所需的计算资源。</li><li id="98f2" class="lt lu hi iz b ja mc jd md jg me jk mf jo mg js ly lz ma mb bi translated">每个时期检查一次，在检查点之间等待一百万个样本可能太长了。为了恢复能力，您可能希望更频繁地检查点。</li><li id="1278" class="lt lu hi iz b ja mc jd md jg me jk mf jo mg js ly lz ma mb bi translated">数据集随着时间的推移而增长。如果您获得了100，000个以上的示例，并且您训练了模型，并且获得了更高的错误，这是因为您需要提前停止还是新数据在某种程度上被破坏了？你不能说，因为以前的训练是在1500万个例子上，而新的训练是在1650万个例子上。</li></ul><h2 id="1844" class="ke kf hi bd kv kw kx ky kz la lb lc ld jg le lf lg jk lh li lj jo lk ll lm ln bi translated">固定步骤的数量不是答案</h2><p id="1cde" class="pw-post-body-paragraph ix iy hi iz b ja lo ij jc jd lp im jf jg lq ji jj jk lr jm jn jo ls jq jr js hb bi translated">如果固定步数呢？</p><pre class="jv jw jx jy fd jz ka kb kc aw kd bi"><span id="d659" class="ke kf hi ka b fi kg kh l ki kj">NUM_STEPS = 143000<br/>BATCH_SIZE = 100<br/>NUM_CHECKPOINTS = 15</span><span id="5ade" class="ke kf hi ka b fi mh kh l ki kj">cp_callback = tf.keras.callbacks.ModelCheckpoint(...)<br/>history = model.fit(trainds, <br/>                    validation_data=evalds,<br/>                    epochs=NUM_CHECKPOINTS,<br/>                    steps_per_epoch=NUM_STEPS // NUM_CHECKPOINTS, <br/>                    batch_size=BATCH_SIZE,<br/>                    callbacks=[cp_callback])</span></pre><p id="0130" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">假设批量大小为100，我们现在对143，000个步骤进行训练，而不是对原始数据集的15个时期进行训练。这给了我们更多的粒度，但是我们必须将一个“时期”定义为步骤总数的1/15，这样我们才能得到正确的检查点数量。只要我们确保无限地重复<code class="du kk kl km ka b">trainds</code>,这就会起作用:</p><pre class="jv jw jx jy fd jz ka kb kc aw kd bi"><span id="0f35" class="ke kf hi ka b fi kg kh l ki kj">trainds = trainds.repeat()</span></pre><p id="fcbb" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">当我们再得到10万个例子时会发生什么？轻松点。我们将它添加到我们的数据仓库中，但是不更新代码。因此，我们的代码仍然需要处理143，000个步骤，它将处理这么多数据。除了10%的例子是新的。如果模型收敛，太好了。如果没有，我们知道这些新的数据点是问题所在，因为我们没有比以前训练的时间更长！通过保持步数不变，我们已经能够区分新数据的影响和对更多数据的训练。</p><p id="248f" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">一旦我们训练了143，000步，我们就重新开始训练，并运行更长的时间(比如10，000步)，只要模型继续收敛，我们就继续训练更长的时间。然后，我们更新上面代码中的数字143，000(实际上，它将是代码的一个参数)来反映新的步骤数。</p><p id="86ee" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这一切都很好，直到你想做超参数调整。当您进行超参数调整时，您会想要更改批量大小。当您更改批处理大小时，您看到上面的代码发生了什么变化吗？没错——如果你把批量改为50，你会发现自己训练的时间减少了一半！显然，这是不行的。</p><h2 id="c3df" class="ke kf hi bd kv kw kx ky kz la lb lc ld jg le lf lg jk lh li lj jo lk ll lm ln bi translated">虚拟时代</h2><p id="d526" class="pw-post-body-paragraph ix iy hi iz b ja lo ij jc jd lp im jf jg lq ji jj jk lr jm jn jo ls jq jr js hb bi translated">答案是保持向模型显示的训练示例总数(而不是步骤数)不变:</p><pre class="jv jw jx jy fd jz ka kb kc aw kd bi"><span id="929d" class="ke kf hi ka b fi kg kh l ki kj">NUM_TRAINING_EXAMPLES = 1000 * 1000<br/>STOP_POINT = 14.3<br/><strong class="ka hj">TOTAL_TRAINING_EXAMPLES</strong> = int(STOP_POINT * NUM_TRAINING_EXAMPLES)<br/>BATCH_SIZE = 100<br/>NUM_CHECKPOINTS = 15</span><span id="a1e9" class="ke kf hi ka b fi mh kh l ki kj">steps_per_epoch = (TOTAL_TRAINING_EXAMPLES // <br/>                   (BATCH_SIZE*NUM_CHECKPOINTS))</span><span id="7575" class="ke kf hi ka b fi mh kh l ki kj">cp_callback = tf.keras.callbacks.ModelCheckpoint(...)<br/>history = model.fit(trainds, <br/>                    validation_data=evalds,<br/>                    epochs=NUM_CHECKPOINTS,<br/>                    steps_per_epoch=steps_per_epoch, <br/>                    batch_size=BATCH_SIZE,<br/>                    callbacks=[cp_callback])</span></pre><p id="e56d" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">当您获得更多数据时，首先使用旧设置对其进行训练，然后增加示例的数量以反映新数据，然后更改STOP_POINT以反映您必须遍历数据以达到收敛的次数。</p><figure class="jv jw jx jy fd ko er es paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="er es mi"><img src="../Images/7ee53bac245168b438bdb1ed55fb09ed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YNSN3rxhtaXmmDfe0szg2Q.png"/></div></div></figure><p id="4691" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在，这对于超参数调整是安全的，并且保留了保持步数不变的所有优点。</p><p id="7369" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">尽情享受吧！</p></div></div>    
</body>
</html>