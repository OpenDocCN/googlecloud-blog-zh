<html>
<head>
<title>Prediction with TensorFlow and Cloud Run</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">张量流和云运行预测</h1>
<blockquote>原文：<a href="https://medium.com/google-cloud/portable-prediction-with-tensorflow-and-cloud-run-669c1c73ebd1?source=collection_archive---------0-----------------------#2019-09-05">https://medium.com/google-cloud/portable-prediction-with-tensorflow-and-cloud-run-669c1c73ebd1?source=collection_archive---------0-----------------------#2019-09-05</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/068bb21df0e0e9880306023d4727b5ae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mPJi8FHvfnig4KuXyCI5XA.png"/></div></div></figure><p id="e862" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">AI-Platform是谷歌云平台(GCP) <strong class="is hj">服务，为ML管道</strong>提供工具和无服务器计算。由于有了<a class="ae jo" href="https://github.com/kubeflow/kubeflow" rel="noopener ugc nofollow" target="_blank"> <strong class="is hj"> Kubeflow </strong> </a> <strong class="is hj">项目</strong>，你可以在GCP<strong class="is hj">以完全无服务器方式</strong>共享、构建、培训和服务模型，或者在你的Kubernetes集群上的任何地方。你只需要专注于你的业务、你的模型和你的数据处理/转换。</p><p id="e6e5" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">机器学习管道有内部和外部两部分。在内部，您的数据科学家可以利用GPU、TPU和更多功能共享、构建和训练/超调模型。<strong class="is hj">为这一内部流程使用单一平台效率更高，AI-Platform在这方面非常出色。</strong></p><p id="641c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">ML管道的外部/可见部分是面向最终用户的:预测服务部分。<strong class="is hj"> AI-Platform在GCP部署模型</strong>也非常方便:简单、快速、无服务器、“按需付费”。听起来很完美…</p><p id="dc99" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">但趋势是<em class="jp">多云、</em>混合<em class="jp">部署</em>或<em class="jp">非厂商锁定</em>，大多数时候，用<strong class="is hj"> <em class="jp">容器。</em> </strong></p><p id="0216" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">有什么挑战？</p><blockquote class="jq"><p id="7286" class="jr js hi bd jt ju jv jw jx jy jz jn dx translated">我想利用容器的可移植性，以及像人工智能平台一样的无服务器预测服务。</p></blockquote><p id="90eb" class="pw-post-body-paragraph iq ir hi is b it ka iv iw ix kb iz ja jb kc jd je jf kd jh ji jj ke jl jm jn hb bi translated">问题是人工智能平台是谷歌特有的，而kubeflow不是无服务器的。Kubernetes上面的Knative 来了，Kubernetes提议为开发者提供无服务器的体验。GCP提出了一个管理实现的Knative: <a class="ae jo" href="https://cloud.google.com/run/" rel="noopener ugc nofollow" target="_blank"> <strong class="is hj">云运行</strong> </a> <strong class="is hj">。</strong>你可以<strong class="is hj">运行无服务器无状态容器。</strong></p><p id="1c83" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><em class="jp">我只使用了TensorFlow 1.x来构建我的模型，我将讲述它。但是，</em> <a class="ae jo" href="https://cloud.google.com/deep-learning-vm/" rel="noopener ugc nofollow" target="_blank"> <em class="jp"> AI-Platform支持更多的框架</em> </a></p><h1 id="fd00" class="kf kg hi bd kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc bi translated">构建符合云运行/知识的容器</h1><p id="1726" class="pw-post-body-paragraph iq ir hi is b it ld iv iw ix le iz ja jb lf jd je jf lg jh ji jj lh jl jm jn hb bi translated">从哪里开始？AI-Platform做的都是，我不知道做了什么，怎么处理的。这是无服务器的神奇之处，但也是最令人困惑的:你不知道真正做了什么！</p><blockquote class="li lj lk"><p id="9b16" class="iq ir jp is b it iu iv iw ix iy iz ja ll jc jd je lm jg jh ji ln jk jl jm jn hb bi translated">张量流模型是如何服务的？</p></blockquote><p id="972c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><a class="ae jo" href="https://www.tensorflow.org/tfx" rel="noopener ugc nofollow" target="_blank"> TensorFlow Extended (TFX) </a>是TensorFlow的一部分，用于构建端到端的ML管道。其中一个组件是<a class="ae jo" href="https://www.tensorflow.org/tfx/guide/serving" rel="noopener ugc nofollow" target="_blank"> TensorFlowServing </a>。嗯，听起来对我的问题不错。我们再深入一点。</p><h2 id="9f4d" class="lo kg hi bd kh lp lq lr kl ls lt lu kp jb lv lw kt jf lx ly kx jj lz ma lb mb bi translated">TensorFlowServing</h2><p id="a6a1" class="pw-post-body-paragraph iq ir hi is b it ld iv iw ix le iz ja jb lf jd je jf lg jh ji jj lh jl jm jn hb bi translated">TensorFlowServing组件是一个安装在linux 环境中为TensorFlow模型服务的<a class="ae jo" href="https://www.tensorflow.org/tfx/serving/setup" rel="noopener ugc nofollow" target="_blank">二进制文件。这个二进制文件在两个不同端口上启动一个带有gRPC和RestAPI端点的服务器。因此，提供模型和2个端口，就这样，您的模型就完成了！远比想象中容易！</a></p><p id="93dc" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> <em class="jp">在奖金</em></strong><em class="jp"/>中还有一个<a class="ae jo" href="https://www.tensorflow.org/tfx/serving/docker" rel="noopener ugc nofollow" target="_blank">码头工人形象</a>。什么都不用安装，直接运行镜像！完美它将<em class="jp">轻松在云上运行</em>！！</p><p id="27b3" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">让我们尝试一下并阅读文档。要运行容器，您必须运行以下命令</p><pre class="mc md me mf fd mg mh mi mj aw mk bi"><span id="22f6" class="lo kg hi mh b fi ml mm l mn mo">docker run -t --rm -p 8501:8501 \<br/>    -v "$TESTDATA/saved_model_half_plus:/models/half_plus_two" \<br/>    -e MODEL_NAME=half_plus_two \<br/>    tensorflow/serving &amp;</span></pre><p id="f1fb" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">第一个问题:</strong>你必须在容器中装入一个卷和服务它的模型。这打破了<a class="ae jo" href="https://cloud.google.com/run/docs/reference/container-contract" rel="noopener ugc nofollow" target="_blank">契约</a>的<em class="jp">无状态</em>部分。</p><p id="480e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><em class="jp">没问题，</em>有了docker，你就可以用这个TensorFlowServing docker图片作为基础图片，并在此基础上构建一些东西。例如，类似这样的事情:</p><ul class=""><li id="31e9" class="mp mq hi is b it iu ix iy jb mr jf ms jj mt jn mu mv mw mx bi translated">将模型复制到容器中</li><li id="51c8" class="mp mq hi is b it my ix mz jb na jf nb jj nc jn mu mv mw mx bi translated">将模型文件夹设置为<code class="du nd ne nf mh b">MODEL_NAME</code>变量。</li></ul><pre class="mc md me mf fd mg mh mi mj aw mk bi"><span id="8b23" class="lo kg hi mh b fi ml mm l mn mo">FROM <!-- -->tensorflow/serving<br/>COPY tf_models /models/tf_models<br/>ENV MODEL_NAME tf_models</span></pre><p id="082b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><em class="jp">简单的</em>！您的模型被嵌入到您的容器中，env变量被定义。并且，从基础映像继承而来的<code class="du nd ne nf mh b">tensorflow/serving</code>映像会自动运行该命令</p><pre class="mc md me mf fd mg mh mi mj aw mk bi"><span id="bccc" class="lo kg hi mh b fi ml mm l mn mo">tensorflow_model_server --port=8500 --rest_api_port=8501 \<br/>  --model_name=${MODEL_NAME} \<br/>  --model_base_path=${MODEL_BASE_PATH}/${MODEL_NAME}</span></pre><p id="16c1" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">第二个问题:</strong>服务器不监听Cloud Run/Knative的<code class="du nd ne nf mh b">$PORT</code>环境变量，不可定制。</p><p id="1a46" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">最后，<strong class="is hj">不能使用内置的TensorFlowServing docker映像和Cloud Run/Knative: </strong>契约不被尊重。</p><h2 id="832d" class="lo kg hi bd kh lp lq lr kl ls lt lu kp jb lv lw kt jf lx ly kx jj lz ma lb mb bi translated">构建TensorFlowServing自定义图像</h2><p id="393e" class="pw-post-body-paragraph iq ir hi is b it ld iv iw ix le iz ja jb lf jd je jf lg jh ji jj lh jl jm jn hb bi translated">因此，我们必须自己构建一个符合Cloud Run/Knative的TensorFlow服务映像。</p><p id="cca7" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">为此，我们必须编写一个<code class="du nd ne nf mh b"><a class="ae jo" href="https://github.com/guillaumeblaquiere/cloudrun-tensorflow-prediction/blob/master/Dockerfile" rel="noopener ugc nofollow" target="_blank">Dockerfile</a></code>，让我们从一个Ubuntu Xenial映像开始</p><pre class="mc md me mf fd mg mh mi mj aw mk bi"><span id="18de" class="lo kg hi mh b fi ml mm l mn mo">FROM ubuntu:xenial</span></pre><p id="aef7" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">安装TensorFlowServing</p><pre class="mc md me mf fd mg mh mi mj aw mk bi"><span id="49d1" class="lo kg hi mh b fi ml mm l mn mo">RUN apt update &amp;&amp; \</span><span id="35d6" class="lo kg hi mh b fi ng mm l mn mo">apt-get install -y curl &amp;&amp; \</span><span id="d419" class="lo kg hi mh b fi ng mm l mn mo">echo "deb <a class="ae jo" href="http://storage.googleapis.com/tensorflow-serving-apt" rel="noopener ugc nofollow" target="_blank">http://storage.googleapis.com/tensorflow-serving-apt</a> stable tensorflow-model-server tensorflow-model-server-universal" | tee /etc/apt/sources.list.d/tensorflow-serving.list &amp;&amp; \</span><span id="69d9" class="lo kg hi mh b fi ng mm l mn mo">curl <a class="ae jo" href="https://storage.googleapis.com/tensorflow-serving-apt/tensorflow-serving.release.pub.gpg" rel="noopener ugc nofollow" target="_blank">https://storage.googleapis.com/tensorflow-serving-apt/tensorflow-serving.release.pub.gpg</a> | apt-key add - &amp;&amp; \</span><span id="79b2" class="lo kg hi mh b fi ng mm l mn mo">apt update &amp;&amp; \</span><span id="dcbe" class="lo kg hi mh b fi ng mm l mn mo">apt-get install tensorflow-model-server</span></pre><p id="79dc" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">复制模型以供使用</p><pre class="mc md me mf fd mg mh mi mj aw mk bi"><span id="e242" class="lo kg hi mh b fi ml mm l mn mo">COPY exporter /models/tf_models</span></pre><p id="2df1" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">用正确的参数运行<code class="du nd ne nf mh b">tensorflow_model_server</code></p><pre class="mc md me mf fd mg mh mi mj aw mk bi"><span id="3bfe" class="lo kg hi mh b fi ml mm l mn mo">CMD tensorflow_model_server --port=8500 --rest_api_port=${PORT} --model_base_path=/models/tf_models --model_name=consumption</span></pre><p id="4ce1" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">仅此而已。Docker构建，Docker运行，成功了。</p><blockquote class="li lj lk"><p id="71ca" class="iq ir jp is b it iu iv iw ix iy iz ja ll jc jd je lm jg jh ji ln jk jl jm jn hb bi translated">潜在问题:无法停用gRPC端口(这里是8500，默认值)。如果Cloud Run/Knative <code class="du nd ne nf mh b"><em class="hi">$PORT</em></code>值设置为gRPC端口值，容器启动将失败</p></blockquote><h1 id="db1b" class="kf kg hi bd kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc bi translated">集成人工智能平台训练步骤</h1><p id="658f" class="pw-post-body-paragraph iq ir hi is b it ld iv iw ix le iz ja jb lf jd je jf lg jh ji jj lh jl jm jn hb bi translated">太好了，集装箱建好了！但是，在人工智能平台上的培训和服务容器之间有一个缺口:</p><blockquote class="li lj lk"><p id="79c2" class="iq ir jp is b it iu iv iw ix iy iz ja ll jc jd je lm jg jh ji ln jk jl jm jn hb bi translated">如何检索训练好的模型？</p></blockquote><p id="2b32" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">事实上，我从来没有提到模型是如何在训练后恢复的。为此，我编写了一个<code class="du nd ne nf mh b"><a class="ae jo" href="https://github.com/guillaumeblaquiere/cloudrun-tensorflow-prediction/blob/master/cloudbuild.yaml" rel="noopener ugc nofollow" target="_blank">cloudbuild.yaml</a></code>，用于将<a class="ae jo" href="https://cloud.google.com/cloud-build/" rel="noopener ugc nofollow" target="_blank">云构建器</a>与<a class="ae jo" href="https://github.com/GoogleCloudPlatform/cloud-builders" rel="noopener ugc nofollow" target="_blank">现有云构建器</a>一起使用。</p><p id="8256" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">第一步用<code class="du nd ne nf mh b">gsutil</code>命令从Google云存储中检索模型:这样，模型就可以被复制到容器中了。然后，用<code class="du nd ne nf mh b">docker</code>命令构建并推动容器。</p><pre class="mc md me mf fd mg mh mi mj aw mk bi"><span id="6c25" class="lo kg hi mh b fi ml mm l mn mo">steps:<br/>  - name: 'gcr.io/cloud-builders/gsutil'<br/>    args: [ 'cp', '-r', '${_EXPORT_BUCKET}', '.' ]<br/>  - name: 'gcr.io/cloud-builders/docker'<br/>    args: [ 'build', '-t', 'gcr.io/$PROJECT_ID/predict', '.' ]<br/>  - name: 'gcr.io/cloud-builders/docker'<br/>    args: ['push', 'gcr.io/$PROJECT_ID/predict']<br/>images:<br/>  - 'gcr.io/$PROJECT_ID/predict'<br/>substitutions:<br/>  _EXPORT_BUCKET: gs://my-bucket/path/to/export/exporter</span></pre><p id="5c09" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在，缺口被填补了。将训练好的模型导出到Google云存储，并进入容器的构建阶段。</p><p id="2e80" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">太好了！工作完成后，您就有了一个可移植的容器来为您训练过的模型提供服务。现在，<strong class="is hj">您可以部署它，并预测您想要的位置！</strong></p><h1 id="46c9" class="kf kg hi bd kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc bi translated">在云运行时部署</h1><p id="6113" class="pw-post-body-paragraph iq ir hi is b it ld iv iw ix le iz ja jb lf jd je jf lg jh ji jj lh jl jm jn hb bi translated">所有艰苦的工作都完成了。在GCP无服务器容器平台上测试和部署的时间:云运行。</p><p id="f95c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">首先，部署在云上运行</p><pre class="mc md me mf fd mg mh mi mj aw mk bi"><span id="18b1" class="lo kg hi mh b fi ml mm l mn mo">gcloud beta run deploy predict --image gcr.io/&lt;PROJECT_ID&gt;/predict</span></pre><p id="bbcb" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">然后使用<code class="du nd ne nf mh b">instances.json</code>文件执行请求(与您的模型相关)</p><pre class="mc md me mf fd mg mh mi mj aw mk bi"><span id="cf53" class="lo kg hi mh b fi ml mm l mn mo">curl -X "content-type: application/json" -X POST -d <a class="ae jo" href="http://twitter.com/instances" rel="noopener ugc nofollow" target="_blank">@instances</a>.json <a class="ae jo" href="https://predict-vqg64v3fcq-uc.a.run.app/v1/models/default:predict" rel="noopener ugc nofollow" target="_blank">https://predict-&lt;hash&gt;.run.app/v1/models/consumption:predict</a></span></pre><p id="3603" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">还有<em class="jp">轰</em>，这里预测</p><pre class="mc md me mf fd mg mh mi mj aw mk bi"><span id="ce97" class="lo kg hi mh b fi ml mm l mn mo">{    <br/>    "predictions": [<br/>        {            <br/>            "predicted": [5.77138042]<br/>        }<br/>    ]<br/>}</span></pre></div><div class="ab cl nh ni gp nj" role="separator"><span class="nk bw bk nl nm nn"/><span class="nk bw bk nl nm nn"/><span class="nk bw bk nl nm"/></div><div class="hb hc hd he hf"><h1 id="3895" class="kf kg hi bd kh ki no kk kl km np ko kp kq nq ks kt ku nr kw kx ky ns la lb lc bi translated">便携式和无服务器</h1><p id="b661" class="pw-post-body-paragraph iq ir hi is b it ld iv iw ix le iz ja jb lf jd je jf lg jh ji jj lh jl jm jn hb bi translated">将TensorFlowServing打包到一个符合Knative合同的定制容器中是非常棒的。容器可以在任何地方运行，在Knative上，在Kubernetes上，在VM上，在云上，在本地…你可以在你想要的地方利用你的ML模型！</p><p id="f1bc" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">此外，您还可以将它与运行无状态和无服务器容器的优秀产品Cloud Run一起使用。<strong class="is hj">提供无服务器预测模型完全符合云运行能力及其设计目的</strong>。</p><p id="eea6" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">但是，如果留在GCP，用云跑代替AI-Platform有什么优势？两个平台都是无服务器的，并且都执行在线预测，但是AI平台不需要额外的开发来为模型服务。那么，<strong class="is hj">用云跑</strong>好吗？我将在下一篇文章中讨论这个主题。</p></div><div class="ab cl nh ni gp nj" role="separator"><span class="nk bw bk nl nm nn"/><span class="nk bw bk nl nm nn"/><span class="nk bw bk nl nm"/></div><div class="hb hc hd he hf"><p id="b0b0" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">代码示例可在<a class="ae jo" href="https://github.com/guillaumeblaquiere/cloudrun-tensorflow-prediction" rel="noopener ugc nofollow" target="_blank">这里</a>获得</p></div></div>    
</body>
</html>