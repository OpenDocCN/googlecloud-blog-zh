<html>
<head>
<title>Understanding kubernetes networking: ingress</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">了解kubernetes网络:入口</h1>
<blockquote>原文：<a href="https://medium.com/google-cloud/understanding-kubernetes-networking-ingress-1bc341c84078?source=collection_archive---------0-----------------------#2017-12-17">https://medium.com/google-cloud/understanding-kubernetes-networking-ingress-1bc341c84078?source=collection_archive---------0-----------------------#2017-12-17</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="a9c1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在本系列的第一篇文章中，我描述了一个网络，该网络使pods能够在<a class="ae jd" href="https://kubernetes.io/" rel="noopener ugc nofollow" target="_blank"> kubernetes </a>集群中的节点之间相互连接。第二个<a class="ae jd" rel="noopener" href="/@betz.mark/understanding-kubernetes-networking-services-f0cb48e4cc82">关注的是</a>服务网络如何为pod提供负载平衡，以便集群内的客户端可以与它们可靠地通信。在这第三期也是最后一期文章中，我想以这些概念为基础，展示集群外部的客户端如何使用相同的服务网络连接到pods。由于各种原因，这可能是三个中最复杂的，第一部分和第二部分中介绍的概念是从后面的内容中获得更多价值的先决条件。</p><p id="b67b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">首先，刚刚从奥斯汀的kubecon 2017 回来，我想起了一些我可能在该系列早些时候已经阐明的事情。Kubernetes是一个迅速成熟的平台。该架构的大部分是可插拔的，这包括网络。我在这里描述的是谷歌Kubernetes引擎的默认实现。我还没有看到亚马逊的弹性Kubernetes服务，但我认为它也将接近那里的默认实现。在某种程度上，kubernetes有一个处理网络的“标准”方式，我认为这些帖子描述了它的基本方面。你必须从某个地方开始，当你开始考虑像<a class="ae jd" href="https://buoyant.io/2017/05/24/a-service-mesh-for-kubernetes-part-x-the-service-mesh-api/" rel="noopener ugc nofollow" target="_blank">统一服务网格</a>等替代方案时，掌握这些概念会有所帮助。说完这些，我们来谈谈入口。</p><figure class="jg jh ji jj fd jk er es paragraph-image"><div role="button" tabindex="0" class="jl jm di jn bf jo"><div class="er es jf"><img src="../Images/e4b704f7d996707d660c9f2be60bb64b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yjol6DXyAZVyFafOlMlCAQ.png"/></div></div></figure><h1 id="e7e5" class="jr js hi bd jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko bi translated">路由不是负载平衡</h1><p id="9657" class="pw-post-body-paragraph if ig hi ih b ii kp ik il im kq io ip iq kr is it iu ks iw ix iy kt ja jb jc hb bi translated">在<a class="ae jd" rel="noopener" href="/@betz.mark/understanding-kubernetes-networking-services-f0cb48e4cc82">的上一篇文章</a>中，我们创建了一个部署，其中有几个pod和一个分配了IP的服务，称为“集群IP ”,针对pod的请求被发送到这个IP。我将在这里继续构建这个例子。回想一下，服务的集群IP <code class="du ku kv kw kx b"><strong class="ih hj">10.3.241.152</strong></code>位于独立于pod网络和节点本身所在网络的IP地址范围内。我把这个地址空间称为“服务网络”，尽管它名不副实，上面没有连接的设备，完全由路由规则组成。在示例中，我们展示了这个网络是如何由一个名为<a class="ae jd" href="https://kubernetes.io/docs/reference/generated/kube-proxy/" rel="noopener ugc nofollow" target="_blank"> kube-proxy </a>的kubernetes组件与一个名为<a class="ae jd" href="http://www.netfilter.org/" rel="noopener ugc nofollow" target="_blank"> netfilter </a>的linux内核模块协作来实现的，以捕获和重新路由发送到集群IP的流量，从而将它发送到一个健康的pod。</p><figure class="jg jh ji jj fd jk er es paragraph-image"><div role="button" tabindex="0" class="jl jm di jn bf jo"><div class="er es jf"><img src="../Images/0c8344b075a59f93f765b79a338d6811.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ow5A6_zjjwdKkf2Yi1KgYw.png"/></div></div></figure><p id="0fe6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">到目前为止，我们一直在谈论“连接”和“请求”，甚至更模糊的“流量”，但要理解kubernetes ingress的工作方式，我们需要得到更具体的信息。连接和请求在OSI第4层(tcp)或第7层(http、rpc等)运行。Netfilter规则是路由规则，它们作用于第3层的IP数据包。包括netfilter在内的所有路由器都或多或少地只根据数据包中包含的信息做出路由决定；一般是从哪里来，去哪里。因此，用第3层术语来描述这种行为:到达节点的<code class="du ku kv kw kx b"><strong class="ih hj">eth0</strong></code>接口的、以<code class="du ku kv kw kx b"><strong class="ih hj">10.3.241.152:80</strong></code> <strong class="ih hj"> </strong>处的服务为目的地的每个分组由netfilter处理，匹配为我们的服务建立的规则，并被转发到健康的pod的IP。</p><p id="3cbc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">很明显，我们用来允许外部客户端访问我们的pod的任何机制都必须使用相同的路由基础设施。也就是说，这些外部客户端最终必须调用群集IP和端口，因为这是我们到目前为止讨论过的所有机器的“前端”,这使得我们可以不关心任何给定时间pod在哪里运行。然而，目前还不清楚如何实现这一点。服务的群集IP只能从节点的以太网接口访问。集群之外的任何东西都不知道如何处理该范围内的地址。我们如何将流量从一个公开可见的IP端点转发到一个只有当数据包已经在一个节点上时才可到达的IP？</p><p id="ee11" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果你试图想出这个问题的解决方案，你可以做的事情之一是使用<a class="ae jd" href="http://ipset.netfilter.org/iptables.man.html" rel="noopener ugc nofollow" target="_blank"> iptables </a>实用程序检查netfilter规则，如果你这样做了，你会发现一些乍一看似乎令人惊讶的事情:示例服务的规则并不局限于特定的原始网络。也就是说，来自任何地方的<em class="je">的任何数据包到达目的地为<code class="du ku kv kw kx b"><strong class="ih hj">10.3.241.152:80</strong></code>的节点的以太网接口都将匹配并被路由到一个pod。那么，我们能不能只给客户端一个集群IP，或许给它分配一个友好的域名，然后添加一个路由，将这些数据包发送到其中一个节点？</em></p><figure class="jg jh ji jj fd jk er es paragraph-image"><div role="button" tabindex="0" class="jl jm di jn bf jo"><div class="er es jf"><img src="../Images/e84a22c07a8e46bb872c054bda3922cc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*skurXk737KHhzbXPbV-Xcg.png"/></div></div></figure><p id="6b12" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果你那样设置事情，它将会工作。客户端调用集群IP，数据包沿着路由向下到达一个节点，然后被转发到一个pod。在这一点上，您可能会忍不住要打上蝴蝶结，但是这个解决方案存在一些严重的问题。第一，节点是短暂的，就像豆荚一样。它们不像pod一样短暂，但是它们可以迁移到新的虚拟机，集群可以扩大和缩小，等等。运行在第3层数据包上的路由器无法区分健康服务和不健康服务。他们希望路由中的下一跳稳定且可用。如果节点变得不可达，路由将中断，并且在大多数情况下会中断很长时间。即使路由是持久的，你也要让所有的外部流量通过一个节点，这可能不是最优的。</p><p id="3460" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">但是，我们引入客户端流量时，必须不依赖于群集中任何单个节点的运行状况。如果没有对路由器的主动管理，就没有可靠的方法来使用路由来做到这一点，而这正是kube-proxy在管理netfilter中的角色。将kubernetes的职责扩展到管理外部路由器对设计者来说可能没有多大意义，特别是考虑到我们已经有了将客户端流量分发到一组机器的成熟工具。它们被称为负载平衡器，毫不奇怪，这是kubernetes ingress的解决方案，实际上非常耐用。来看看到底是时候爬出第三层地下室，并再次谈论连接了。</p><p id="b395" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">要使用负载平衡器将客户端流量分发到集群中的节点，我们需要一个客户端可以连接到的公共IP，并且我们需要负载平衡器可以将请求转发到的节点本身的地址。由于上述原因，我们无法在网关路由器和使用服务网络(集群IP)的节点之间轻松创建稳定的静态路由。唯一可用的其他地址是节点的以太网接口所连接的网络上的地址，在本例中为<code class="du ku kv kw kx b"><strong class="ih hj">10.100.0.0/24</strong></code>。网关路由器已经知道如何将数据包发送到这些接口，从负载平衡器发送到路由器的连接将到达正确的位置。但是，如果一个客户端想要在端口80上连接到我们的服务，我们不能只是在节点的接口上向该端口发送数据包。</p><figure class="jg jh ji jj fd jk er es paragraph-image"><div role="button" tabindex="0" class="jl jm di jn bf jo"><div class="er es jf"><img src="../Images/4d4a4d71c1799aa5b22a66ac1aca9be6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*I03T4FnCjlPmHNXhao4arg.png"/></div></div></figure><p id="194a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">失败的原因显而易见。没有监听<code class="du ku kv kw kx b"><strong class="ih hj">10.100.0.3:80</strong></code>的进程(或者如果有，那是错误的进程)，我们希望拦截我们的请求并将其定向到一个pod的netfilter规则与目的地址不匹配。它们只匹配位于<code class="du ku kv kw kx b"><strong class="ih hj">10.3.241.152:80</strong></code>的服务网络上的集群IP。因此，当这些数据包到达该接口时无法传送，内核会以ECONNREFUSED响应。这给我们留下了一个难题:netfilter设置为转发数据包的网络不容易从网关路由到节点，而容易路由的网络不是netfilter转发的网络。解决这个问题的方法是在这些网络之间建立一座桥梁，这正是kubernetes用一种叫做节点端口的东西所做的。</p><h1 id="0f19" class="jr js hi bd jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko bi translated">节点端口服务</h1><p id="3e95" class="pw-post-body-paragraph if ig hi ih b ii kp ik il im kq io ip iq kr is it iu ks iw ix iy kt ja jb jc hb bi translated">我们在上一篇文章中创建的示例服务没有指定类型，因此采用了默认类型<code class="du ku kv kw kx b"><strong class="ih hj">ClusterIP</strong></code>。还有另外两种类型的服务添加了额外的功能，接下来重要的一种是类型<code class="du ku kv kw kx b"><strong class="ih hj">NodePort</strong></code>。下面是作为节点端口服务的示例服务。</p><pre class="jg jh ji jj fd ky kx kz bn la lb bi"><span id="effe" class="lc js hi kx b be ld le l lf lg">kind: Service<br/>apiVersion: v1<br/>metadata:<br/>  name: service-test<br/>spec:<br/>  type: NodePort<br/>  selector:<br/>    app: service_test_pod<br/>  ports:<br/>  - port: 80<br/>    targetPort: http</span></pre><p id="5f02" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">NodePort类型的服务是具有附加功能的ClusterIP服务:它可以在节点的IP地址以及服务网络上分配的集群IP上访问。完成的方式非常简单:当kubernetes创建一个节点端口服务时，kube-proxy在30000–32767范围内分配一个端口，并在每个节点的<code class="du ku kv kw kx b"><strong class="ih hj">eth0</strong></code>接口上打开这个端口(因此得名“节点端口”)。到此端口的连接被转发到服务的群集IP。如果我们创建上面的服务并运行<code class="du ku kv kw kx b"><strong class="ih hj">kubectl get svc service-test</strong></code>，我们可以看到为它分配的节点端口。</p><pre class="jg jh ji jj fd ky kx lh li aw lj bi"><span id="0271" class="lk js hi kx b fi ll lm l ln lg"><strong class="kx hj">$ kubectl get svc service-test<br/>NAME           CLUSTER-IP     EXTERNAL-IP   PORT(S)           AGE<br/>service-test   10.3.241.152   &lt;none&gt;        80:32213/TCP      1m</strong></span></pre><p id="b9bb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这种情况下，我们的服务被分配了节点端口32213。这意味着我们现在可以连接到示例集群中任一节点上的服务，在<code class="du ku kv kw kx b"><strong class="ih hj">10.100.0.2:32213</strong></code>或<code class="du ku kv kw kx b"><strong class="ih hj">10.100.0.3:32213</strong></code> <strong class="ih hj"> </strong>处，流量将被转发到该服务。有了这一部分，我们现在就有了一个完整的管道来对集群中所有节点的外部客户机请求进行负载平衡。</p><figure class="jg jh ji jj fd jk er es paragraph-image"><div role="button" tabindex="0" class="jl jm di jn bf jo"><div class="er es jf"><img src="../Images/71b77056af97be0ae0c126445a1b8275.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Uo_wGCIlFopJZbf6THu0OQ.png"/></div></div></figure><p id="fbcc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在上图中，客户端通过公共IP地址连接到负载平衡器，负载平衡器选择一个节点并在<code class="du ku kv kw kx b"><strong class="ih hj">10.100.0.3:32213</strong></code>连接到该节点，kube-proxy接收该连接并将其转发到集群IP <code class="du ku kv kw kx b"><strong class="ih hj">10.3.241.152:80</strong></code>处的服务，此时请求与netfilter规则匹配并在<code class="du ku kv kw kx b"><strong class="ih hj">10.0.2.2:8080</strong></code>被重定向到服务器pod。这可能看起来有点复杂，在某些方面确实如此，但很难想到一个更简单的解决方案来保持pod和服务网络提供的所有酷功能。</p><p id="a76d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这种机制并不是没有问题。节点端口的使用将您的服务公开给非标准端口上的客户端。这通常不是问题，因为负载平衡器可以公开常用端口，并对最终用户屏蔽节点端口。但是在一些场景中，比如Google Cloud上的内部负载平衡，你将被迫向上游传播节点端口。节点端口也是一种有限的资源，尽管2768个端口对于最大的集群来说可能已经足够了。对于大多数应用程序，您可以让kubernetes随机选择端口，但如果需要，您也可以显式设置它们。最后，对于在请求中保存源IP有一些限制。关于如何管理这些问题的信息，您可以参考关于该主题的<a class="ae jd" href="https://kubernetes.io/docs/tutorials/services/source-ip/#source-ip-for-services-with-typeclusterip" rel="noopener ugc nofollow" target="_blank">文档文章</a>。</p><p id="fafa" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">节点端口是所有外部流量进入kubernetes集群的基本机制。然而，它们本身并不是一个完整的解决方案。由于上述原因，无论您的客户端是内部的还是通过公共网络进入的，您都需要在集群前安装某种负载平衡器。该平台的设计者认识到了这一点，并提供了两种不同的方法来从kubernetes内部指定负载平衡器配置，所以接下来让我们快速看一下。</p><h1 id="9c6d" class="jr js hi bd jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko bi translated">负载平衡器服务和入口资源</h1><p id="f802" class="pw-post-body-paragraph if ig hi ih b ii kp ik il im kq io ip iq kr is it iu ks iw ix iy kt ja jb jc hb bi translated">最后这两个概念是kubernetes执行的更复杂的功能之一，但是我不打算在它们上面花太多时间，因为它们并没有真正改变我们刚刚讨论的任何内容。如上所述，所有外部流量最终都通过节点端口进入集群。设计者可以就此打住，让你去担心公共IP和负载平衡器，事实上，在某些情况下，比如在裸机上或在你的家庭实验室中运行，这就是你必须要做的。但是在支持API驱动的网络资源配置的环境中，kubernetes使得在一个地方定义所有东西成为可能。</p><p id="abcb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">第一种也是最简单的方法是第三种kubernetes服务，称为负载平衡器服务。假设您运行在像GCP或AWS这样支持API驱动的网络资源配置的环境中，类型为<code class="du ku kv kw kx b"><strong class="ih hj">LoadBalancer</strong></code>的服务具有NodePort服务的所有功能，并且能够构建完整的入口路径。</p><pre class="jg jh ji jj fd ky kx kz bn la lb bi"><span id="be18" class="lc js hi kx b be ld le l lf lg">kind: Service<br/>apiVersion: v1<br/>metadata:<br/>  name: service-test<br/>spec:<br/>  type: LoadBalancer<br/>  selector:<br/>    app: service_test_pod<br/>  ports:<br/>  - port: 80<br/>    targetPort: http</span></pre><p id="5cde" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果我们删除并重新创建Google Kubernetes引擎上的示例服务，我们很快就会看到<code class="du ku kv kw kx b"><strong class="ih hj">kubectl get svc service-test</strong></code>已经分配了一个外部IP。</p><pre class="jg jh ji jj fd ky kx lh li aw lj bi"><span id="69c2" class="lk js hi kx b fi ll lm l ln lg"><strong class="kx hj">$ kubectl get svc service-test<br/>NAME      CLUSTER-IP      EXTERNAL-IP     PORT(S)          AGE<br/>openvpn   10.3.241.52     35.184.97.156   80:32213/TCP     5m</strong></span></pre><p id="c008" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我说“很快”，尽管外部IP的分配可能需要几分钟的时间，考虑到必须启动的资源数量，这并不奇怪。例如，在GCP上，这需要系统创建一个外部IP、一个转发规则、一个目标代理、一个后端服务，可能还需要一个实例组。一旦分配了IP地址，您就可以通过它连接到您的服务，为它分配一个域名，并将其分发给客户端。只要服务没有被破坏和重新创建(很少有好的理由这么做)，IP就不会改变。</p><p id="eadf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">负载平衡器类型的服务有一些限制。您不能将lb配置为终止https流量。您不能使用虚拟主机或基于路径的路由，因此您不能使用单个负载平衡器以任何实际有用的方式代理多个服务。这些限制导致在1.2版本中添加了一个单独的kubernetes资源来配置负载平衡器，称为<a class="ae jd" href="https://kubernetes.io/docs/concepts/services-networking/ingress/" rel="noopener ugc nofollow" target="_blank">入口</a>。负载平衡器服务都是关于扩展单个服务来支持外部客户端。相比之下，入口是一个独立的资源，可以更加灵活地配置负载平衡器。入口API支持TLS终止、虚拟主机和基于路径的路由。它可以轻松地设置一个负载平衡器来处理多个后端服务。</p><p id="eca7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Ingress API是一个太大的主题，在这里无法详细讨论，因为正如前面提到的，它与Ingress在网络层的实际工作方式没有什么关系。实现遵循一个基本的kubernetes模式:一个资源类型和一个管理该类型的控制器。在这种情况下，资源是入口，其包括对网络资源的请求。下面是我们的测试服务的入口资源的样子。</p><pre class="jg jh ji jj fd ky kx kz bn la lb bi"><span id="442b" class="lc js hi kx b be ld le l lf lg">apiVersion: networking.k8s.io/v1<br/>kind: Ingress<br/>metadata:<br/>  name: test-ingress<br/>  annotations:<br/>    kubernetes.io/ingress.class: "gce"<br/>spec:<br/>  tls:<br/>    - secretName: my-ssl-secret<br/>  rules:<br/>  - host: testhost.com<br/>    http:<br/>      paths:<br/>      - path: /*<br/>        backend:<br/>          serviceName: service-test<br/>          servicePort: 80</span></pre><p id="97a7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">入口控制器负责通过将环境中的资源驱动到必要的状态来满足该请求。当使用入口时，您将服务创建为NodePort类型，并让入口控制器决定如何将流量发送到节点。GCE负载平衡器、AWS弹性负载平衡器以及nginx和haproxy等流行代理都有入口控制器实现。请注意，在某些环境中，将入口资源与负载平衡器服务混合会导致微妙的问题。这些都可以很容易地解决，但一般来说，即使是简单的服务也最好使用Ingress。</p><h1 id="e9c2" class="jr js hi bd jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko bi translated">主机端口和主机网络</h1><p id="8005" class="pw-post-body-paragraph if ig hi ih b ii kp ik il im kq io ip iq kr is it iu ks iw ix iy kt ja jb jc hb bi translated">我想谈的最后两件事实际上更属于有趣的好奇心范畴，而不是有用的工具。事实上，我认为它们是99.99%用例的反模式，任何使用它们的实现都应该得到自动设计审查。我考虑过把它们完全排除在外，但是它们是某种进入的途径，所以非常简短地看一下它们做什么是值得的。</p><p id="d7ba" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">第一个是主机端口。这是容器的属性(在ContainerPort结构中声明)，当设置为给定的整数端口号时，会导致该端口在节点上打开，并直接转发到容器。没有代理，端口只在运行容器的节点上打开。在添加<a class="ae jd" href="https://kubernetes.io/docs/concepts/workloads/controllers/daemonset/" rel="noopener ugc nofollow" target="_blank"> DaemonSets </a>和<a class="ae jd" href="https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/" rel="noopener ugc nofollow" target="_blank"> StatefulSets </a>之前的平台早期，这是一个可以用来确保在任何给定节点上只有一个类型的容器运行的技巧。例如，我曾经用它来实现一个elasticsearch集群，方法是将HostPort设置为9200，并指定与节点数量相同的副本。现在这将被认为是一个可怕的攻击，除非你正在实现一个kubernetes系统组件，否则你不太可能希望设置HostPort。</p><p id="ce33" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">第二个在kubernetes的上下文中更奇怪，这是一个pod的HostNetwork属性。当设置为true时，这与<code class="du ku kv kw kx b"><strong class="ih hj">docker run</strong></code>的<code class="du ku kv kw kx b"><strong class="ih hj">--network=host</strong></code>参数具有相同的效果。它使pod中的所有容器都使用节点的网络名称空间，即它们都可以访问<code class="du ku kv kw kx b"><strong class="ih hj">eth0</strong></code> <strong class="ih hj"> </strong>，并直接在该接口上打开端口。我不认为暗示你永远、永远都不需要这样做是牵强的。如果你对此有一个用例，那么你很可能已经是kubernetes的贡献者，不需要我的任何帮助。</p><h1 id="5ad7" class="jr js hi bd jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko bi translated">总结</h1><p id="9357" class="pw-post-body-paragraph if ig hi ih b ii kp ik il im kq io ip iq kr is it iu ks iw ix iy kt ja jb jc hb bi translated">这就结束了这个由三部分组成的kubernetes网络系列。我很喜欢了解这个平台并与之一起工作，我希望在这些文章中能感受到这种热情。我认为kubernetes预示着一场革命，它使我们有可能可靠地管理和互连集装箱车队，而不是服务器车队。从很多方面来说，它确实是一个瓶中的数据中心，因此存在相当多的底层复杂性也就不足为奇了。我写这些帖子是因为我认为一旦你学会了每个部分是如何工作的，它就会以一种非常优雅的方式变得有意义。希望我已经做出了贡献，让未来的新用户更容易进入这个平台。</p></div></div>    
</body>
</html>