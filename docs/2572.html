<html>
<head>
<title>Get Set Go with Vertex AI!</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">让顶点人工智能开始吧！</h1>
<blockquote>原文：<a href="https://medium.com/google-cloud/get-set-go-with-vertex-ai-fbefc69d74c4?source=collection_archive---------2-----------------------#2022-11-30">https://medium.com/google-cloud/get-set-go-with-vertex-ai-fbefc69d74c4?source=collection_archive---------2-----------------------#2022-11-30</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><h1 id="d6d9" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">概述:</h1><p id="8955" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">这个技术博客的目的是了解编写顶点AI管道的基础知识。这将有助于衡量如何设置和运行管道的基本理解和基础。大多数情况下，它将用于<a class="ae kb" href="https://cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning" rel="noopener ugc nofollow" target="_blank"> MLOPs </a>解决方案和/或在更大的解决方案架构中建立无服务器ML管道。</p><h1 id="00ac" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">目标:</h1><p id="1347" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">为一个ML模型构建端到端标准化和可重用的顶点AI管道。管道阶段将包括以下步骤:</p><ul class=""><li id="76bd" class="kc kd hi jf b jg ke jk kf jo kg js kh jw ki ka kj kk kl km bi translated">数据摄取(样本数据集)</li><li id="4f26" class="kc kd hi jf b jg kn jk ko jo kp js kq jw kr ka kj kk kl km bi translated">数据清理</li><li id="1577" class="kc kd hi jf b jg kn jk ko jo kp js kq jw kr ka kj kk kl km bi translated">模特培训</li><li id="31bd" class="kc kd hi jf b jg kn jk ko jo kp js kq jw kr ka kj kk kl km bi translated">条件模型部署</li><li id="5382" class="kc kd hi jf b jg kn jk ko jo kp js kq jw kr ka kj kk kl km bi translated">端点创建</li></ul><h1 id="e86d" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">技术堆栈:</h1><ul class=""><li id="559e" class="kc kd hi jf b jg jh jk jl jo ks js kt jw ku ka kj kk kl km bi translated"><a class="ae kb" href="https://cloud.google.com/storage/docs/introduction" rel="noopener ugc nofollow" target="_blank">云存储</a>:云存储用于保存文物。</li><li id="d777" class="kc kd hi jf b jg kn jk ko jo kp js kq jw kr ka kj kk kl km bi translated"><a class="ae kb" href="https://cloud.google.com/vertex-ai/docs/start/introduction-unified-platform" rel="noopener ugc nofollow" target="_blank"> Vertex AI </a> : Vertex AI是Google Cloud提供的一项服务，将AutoML和AI平台汇集到一个统一的API、客户端库和用户界面中。</li><li id="c0ea" class="kc kd hi jf b jg kn jk ko jo kp js kq jw kr ka kj kk kl km bi translated"><a class="ae kb" href="https://cloud.google.com/vertex-ai/docs/workbench/user-managed/introduction" rel="noopener ugc nofollow" target="_blank">工作台</a>:可以在工作台中创建笔记本，用于编写管道代码。</li><li id="e683" class="kc kd hi jf b jg kn jk ko jo kp js kq jw kr ka kj kk kl km bi translated"><a class="ae kb" href="https://cloud.google.com/vertex-ai/docs/pipelines" rel="noopener ugc nofollow" target="_blank">管道</a>:顶点管道用于查看编码管道的可视化编排。</li><li id="a679" class="kc kd hi jf b jg kn jk ko jo kp js kq jw kr ka kj kk kl km bi translated"><a class="ae kb" href="https://cloud.google.com/vertex-ai/docs/model-registry/introduction" rel="noopener ugc nofollow" target="_blank">模型注册</a>:所有创建的模型在这里都是可见的。这些将用于在线预测。</li><li id="ba79" class="kc kd hi jf b jg kn jk ko jo kp js kq jw kr ka kj kk kl km bi translated"><a class="ae kb" href="https://cloud.google.com/vertex-ai/docs/predictions/using-private-endpoints" rel="noopener ugc nofollow" target="_blank">端点</a>:通过使用端点，可以为模型提供服务。可以通过UI或SDK进行预测。</li></ul><h1 id="3cb1" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">问题陈述和ML解决方案:</h1><p id="7509" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">我们已经解决了一个基本的客户流失问题。其代码可在<a class="ae kb" href="https://github.com/manan-bedi2908/Customer_Churn-Deployment/blob/master/Customer_Churn.ipynb" rel="noopener ugc nofollow" target="_blank">这里</a>找到。我们已经把这段代码转换成了顶点AI流水线代码。</p><h1 id="c92a" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">解决方法:</h1><p id="81fe" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">Vertex AI是一个统一的MLOps平台，可以帮助数据科学家/ML工程师增加实验，更快地部署，并充满信心地管理模型。它可以被视为一个托管的管道运行程序，具有其他关键功能，如数据标记、AutoML支持的培训、端点管理等。</p><p id="c3b0" class="pw-post-body-paragraph jd je hi jf b jg ke ji jj jk kf jm jn jo kv jq jr js kw ju jv jw kx jy jz ka hb bi translated">Vertex AI是Google Cloud提供的一项服务，它将AutoML和AI平台整合到一个统一的API、客户端库和用户界面中。AutoML允许您在图像、表格、文本和视频数据集上训练模型，而无需编写代码，而AI平台中的训练则允许您运行自定义训练代码。使用Vertex AI，<a class="ae kb" href="https://cloud.google.com/vertex-ai/docs/training/training" rel="noopener ugc nofollow" target="_blank"> AutoML训练</a>和<a class="ae kb" href="https://cloud.google.com/vertex-ai/docs/training/custom-training" rel="noopener ugc nofollow" target="_blank">定制训练</a>都可以作为实施的选项。人们还可以用Vertex AI保存模型、部署模型和请求预测。出于这个博客的目的，我们将使用定制培训方法。</p><p id="aa87" class="pw-post-body-paragraph jd je hi jf b jg ke ji jj jk kf jm jn jo kv jq jr js kw ju jv jw kx jy jz ka hb bi translated">我们还必须考虑顶点人工智能特性目前在哪里可以实现。并非Vertex AI的所有特性在每个GC区域都可用。因此，在根据特定地区的服务可用性提出解决方案时，我们需要注意。<a class="ae kb" href="https://cloud.google.com/vertex-ai/docs/general/locations" rel="noopener ugc nofollow" target="_blank">这个</a>是指示哪个顶点AI特性在哪个区域可用的参考链接。</p><h1 id="1c88" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">IAM先决条件:</h1><p id="95ff" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">在构建管道之前，必须检查用户是否具有以下角色，以避免身份验证问题:</p><ul class=""><li id="7ee4" class="kc kd hi jf b jg ke jk kf jo kg js kh jw ki ka kj kk kl km bi translated"><strong class="jf hj">服务使用消费者</strong>:检查服务状态和操作的能力；、以及消费者项目消费者配额和账单。</li><li id="703f" class="kc kd hi jf b jg kn jk ko jo kp js kq jw kr ka kj kk kl km bi translated"><strong class="jf hj">存储对象管理</strong>:授予对对象的完全控制权，包括列出、创建、查看和删除对象。</li><li id="c11e" class="kc kd hi jf b jg kn jk ko jo kp js kq jw kr ka kj kk kl km bi translated"><strong class="jf hj">顶点AI管理员</strong>:授予对顶点AI中所有资源的完全访问权限。如果不能赋予admin角色，可以考虑将Vertex AI编辑角色赋予管道开发者。</li><li id="aa72" class="kc kd hi jf b jg kn jk ko jo kp js kq jw kr ka kj kk kl km bi translated">联网许可将根据具体情况而定。</li></ul><h1 id="ac87" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">管道任务:</h1><p id="d11d" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">一个MLOps管道可能有多个任务，如数据摄取、预处理、训练、测试等。所有这些都可以定义为单独的组件，我们可以设置它们之间的依赖关系。</p><p id="3ad3" class="pw-post-body-paragraph jd je hi jf b jg ke ji jj jk kf jm jn jo kv jq jr js kw ju jv jw kx jy jz ka hb bi translated">我们正在使用<a class="ae kb" href="https://www.kubeflow.org/docs/components/pipelines/sdk-v2/" rel="noopener ugc nofollow" target="_blank">新的Kubeflow Pipelines SDK版本</a>，它与Vertex AI和代表“特定领域语言”的<a class="ae kb" href="https://www.kubeflow.org/docs/components/pipelines/sdk/sdk-overview/#kfp.dsl" rel="noopener ugc nofollow" target="_blank"> DSL </a>兼容，因为它是用于管道定义的SDK的主要模块。我们还使用来自上述SDK的输入、输出和度量，因为它们是我们在组件之间传递对象的方式。当我们定义一个组件时，我们可以声明暗示组件输入和输出的参数类型。</p><p id="9d22" class="pw-post-body-paragraph jd je hi jf b jg ke ji jj jk kf jm jn jo kv jq jr js kw ju jv jw kx jy jz ka hb bi translated">我们管道的基本前提是数据摄取→数据预处理→模型训练→模型测试→检查准确度分数→如果准确度分数&gt;阈值，那么模型部署和端点创建。</p><h2 id="42cc" class="ky ig hi bd ih kz la lb il lc ld le ip jo lf lg it js lh li ix jw lj lk jb ll bi translated">数据接收和预处理:</h2><p id="6db0" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">在我们的例子中，我们从GCS桶中获取数据，并在管道本身中进行预处理步骤，使用Python中的<a class="ae kb" href="https://pandas.pydata.org/" rel="noopener ugc nofollow" target="_blank">熊猫</a>库处理<a class="ae kb" href="https://github.com/manan-bedi2908/Customer_Churn-Deployment/blob/master/Churn_Modelling.csv" rel="noopener ugc nofollow" target="_blank">数据集</a>。我们将对上述流失预测用例的数据集进行基本的<a class="ae kb" href="https://www.geeksforgeeks.org/ml-label-encoding-of-datasets-in-python/" rel="noopener ugc nofollow" target="_blank">标签编码</a>和<a class="ae kb" href="https://towardsdatascience.com/understanding-feature-importance-and-how-to-implement-it-in-python-ff0287b20285#:~:text=Feature%20Importance%20refers%20to%20techniques,to%20predict%20a%20certain%20variable." rel="noopener" target="_blank">特征重要性</a>。</p><h2 id="2dfe" class="ky ig hi bd ih kz la lb il lc ld le ip jo lf lg it js lh li ix jw lj lk jb ll bi translated">模型训练和测试:</h2><p id="122f" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">我们使用<a class="ae kb" href="https://www.geeksforgeeks.org/random-forest-classifier-using-scikit-learn/" rel="noopener ugc nofollow" target="_blank">随机森林分类器</a>进行模型训练和测试。</p><h2 id="62c7" class="ky ig hi bd ih kz la lb il lc ld le ip jo lf lg it js lh li ix jw lj lk jb ll bi translated">模型部署和端点创建:</h2><p id="4526" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">我们已经为模型的条件部署编写了一个逻辑。我们将在模型训练阶段检查准确性阈值。如果它高于所需的阈值，那么只有模型将被部署，端点将被创建。</p><h1 id="d9e2" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">管道结构:</h1><h2 id="1e25" class="ky ig hi bd ih kz la lb il lc ld le ip jo lf lg it js lh li ix jw lj lk jb ll bi translated">笔记本:</h2><ul class=""><li id="a8dc" class="kc kd hi jf b jg jh jk jl jo ks js kt jw ku ka kj kk kl km bi translated">笔记本可以从Vertex AI中的工作台访问。在Vertex AI的云控制台中，你可以从Vertex AI中查看你所有的笔记本实例。您在笔记本实例中运行的代码决定了作业、模型或其他资源的存储位置。换句话说，Vertex AI API请求在Vertex AI中创建资源。</li><li id="a30a" class="kc kd hi jf b jg kn jk ko jo kp js kq jw kr ka kj kk kl km bi translated">现在，我们可以创建一个完全由Google管理的托管笔记本或用户托管笔记本，我们可以指定笔记本实例将在其上旋转的机器类型的所有详细信息。</li><li id="d6f7" class="kc kd hi jf b jg kn jk ko jo kp js kq jw kr ka kj kk kl km bi translated">笔记本是我们写作工作中不可或缺的一部分。使用笔记本，我们可以在数据集上执行特征工程和数据准备，在自定义训练模型上构建和迭代，或者使用Vertex AI客户端库之一来创建复杂的模型，然后存储这些资源以在Vertex AI中使用。</li></ul><h2 id="261a" class="ky ig hi bd ih kz la lb il lc ld le ip jo lf lg it js lh li ix jw lj lk jb ll bi translated">组件:</h2><p id="5ff3" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">管道将有不同的任务。这些任务可以被视为流水线的独立组件。我们必须使用组件装饰器来为任务指定代码。该组件不要求您为每次代码更改构建新的容器映像，它旨在用于笔记本环境中的快速迭代。您可以通过调用@component decorator来创建一个轻量级组件。当管道运行时，这个装饰器将底层函数定义编译成实际运行的组件。我们可以指定以下参数:</p><ul class=""><li id="7f6e" class="kc kd hi jf b jg ke jk kf jo kg js kh jw ki ka kj kk kl km bi translated">base_image:加载函数将在其上运行的基本图像。我们可以在这里提供预建或定制的docker图像。在我们的例子中，我们使用Python 3.9作为基础映像(注意:在使用这些预构建的基础映像时，我们应该意识到这样一个事实，即在运行外部包的安装时，我们可能会面临一些问题。例如，软件包“scipy”在安装时有一些已知的问题。在这种情况下，我们可以将基础映像更改为以前版本的Python(从3.9到3.8)，并检查它是否工作。</li><li id="1a3a" class="kc kd hi jf b jg kn jk ko jo kp js kq jw kr ka kj kk kl km bi translated">output_component_file:这将组件加载到一个YAML文件中，以便重用。我们可以通过使用函数load_component_from_file( )从YAML文件中加载组件。</li><li id="0013" class="kc kd hi jf b jg kn jk ko jo kp js kq jw kr ka kj kk kl km bi translated">packages_to_install:在这里，我们可以指定要安装的包，这些包在我们的基本映像之外。例如，如果我们的base_image是Python3.9，我们可以通过将它指定到一个列表中来安装Pandas库。</li></ul><p id="46ac" class="pw-post-body-paragraph jd je hi jf b jg ke ji jj jk kf jm jn jo kv jq jr js kw ju jv jw kx jy jz ka hb bi translated">我们可以向函数提供输入参数，并且可以将函数的输出转换成命名的双重格式，以便以后存储和使用。下面是一个相同的例子:</p><pre class="lm ln lo lp fd lq lr ls bn lt lu bi"><span id="2ed1" class="lv ig hi lr b be lw lx l ly lz">#defining a component<br/>@component(<br/>packages_to_install=["sklearn", "pandas", "joblib","google-cloud-bigquery"],<br/>base_image="python:3.9",<br/>output_component_file="model_component.yaml",<br/>)<br/>def sklearn_train(<br/>dataset: Input[Dataset],<br/>metrics: Output[Metrics],<br/>model: Output[Model]<br/>)-&gt; NamedTuple("output", [("deploy", str)]):<br/>import pandas as pd<br/>#your code here<br/>deploy = latest_model_threshold_str<br/>return (deploy,)</span></pre><p id="93c8" class="pw-post-body-paragraph jd je hi jf b jg ke ji jj jk kf jm jn jo kv jq jr js kw ju jv jw kx jy jz ka hb bi translated"><a class="ae kb" href="https://github.com/pin-a-king/get-going-with-vertex-ai-v0/blob/ae247aabffb022cd09ae3f906ad65884afd56f16/vertex_ai_pipeline_pin.py" rel="noopener ugc nofollow" target="_blank">这里的</a>是定义样本组件的实际代码片段的链接。</p><h2 id="2d7e" class="ky ig hi bd ih kz la lb il lc ld le ip jo lf lg it js lh li ix jw lj lk jb ll bi translated">管道DSL:</h2><p id="b7ed" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">可以通过Python领域特定语言(DSL)来定义ML任务序列的规范。工作流的拓扑结构是通过将上游步骤的输出连接到下游步骤的输入来隐式定义的。管道定义中的一个步骤调用管道中的一个组件。在复杂的管道中，组件可以在循环中执行多次，也可以有条件地执行。使用管道DSL，我们可以建立不同组件之间的依赖关系。为了建立依赖关系，我们可以使用after()或者一个接一个地调用任务。PIPELINE_ROOT是GCS路径，我们将在这里存储每个管道运行的所有工件。我们可以利用不同的DSL功能，比如特定组件的条件执行。<a class="ae kb" href="https://github.com/pin-a-king/get-going-with-vertex-ai-v0/blob/ae247aabffb022cd09ae3f906ad65884afd56f16/vertex_ai_pipeline_pin.py" rel="noopener ugc nofollow" target="_blank">这里的</a>是定义管道组件的实际代码片段的链接。以下是定义管道的示例:</p><pre class="lm ln lo lp fd lq lr ls bn lt lu bi"><span id="e267" class="lv ig hi lr b be lw lx l ly lz">#define a pipeline and create a task from a component:<br/>@pipeline(<br/># Default pipeline root. You can override it when submitting the pipeline.<br/>pipeline_root = PIPELINE_ROOT,<br/># A name for the pipeline.<br/>name = "tech-blog-vertex-ai-pin-mlmd-pipeline",<br/>)<br/>def pipeline(<br/>output_data_path: str = "data.csv",<br/>project: str = PROJECT_ID,<br/>region: str = REGION<br/>):<br/>dataset_task = get_dataframe()<br/>model_task = sklearn_train(<br/>dataset_task.output<br/>)<br/>with dsl.Condition(model_task.outputs["deploy"] == "true", name = "if_deploy_tech_blog_model_vertex_ai_pin"):<br/>deploy_task = deploy_model(<br/>model = model_task.outputs["model"],<br/>project = project,<br/>region = region<br/>)</span></pre><h2 id="828f" class="ky ig hi bd ih kz la lb il lc ld le ip jo lf lg it js lh li ix jw lj lk jb ll bi translated">编译管道:</h2><p id="aa70" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">我们可以使用compile()将管道代码编译成序列化的JSON格式。这个JSON将用于触发管道。<a class="ae kb" href="https://github.com/pin-a-king/get-going-with-vertex-ai-v0/blob/ae247aabffb022cd09ae3f906ad65884afd56f16/vertex_ai_pipeline_pin.py" rel="noopener ugc nofollow" target="_blank">这里的</a>是编译管道的实际代码片段的链接。下面是相同的代码片段:</p><pre class="lm ln lo lp fd lq lr ls bn lt lu bi"><span id="7f23" class="lv ig hi lr b be lw lx l ly lz">compiler.Compiler().compile(<br/>pipeline_func = pipeline, package_path = "tech-blog-vertex-ai-pin-mlmd_pipeline.json"<br/>)</span></pre><h2 id="237b" class="ky ig hi bd ih kz la lb il lc ld le ip jo lf lg it js lh li ix jw lj lk jb ll bi translated">PipelineJob对象:</h2><p id="c17b" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">该客户端用于创建响应来触发管道。我们可以使用下面的函数，它是Python SDK的API客户端的一部分:</p><ul class=""><li id="2ed6" class="kc kd hi jf b jg ke jk kf jo kg js kh jw ki ka kj kk kl km bi translated"><a class="ae kb" href="https://cloud.google.com/vertex-ai/docs/pipelines/run-pipeline?hl=en#vertex-ai-sdk-for-python" rel="noopener ugc nofollow" target="_blank"> PipelineJob对象</a>:使用管道的序列化版本以及显示名称、enable_caching等其他参数触发管道。(当enable_caching为TRUE时，管道运行将存储元数据，对于后续运行，它将从失败或停止的地方继续运行；如果为FALSE，则管道将执行所有组件)。</li><li id="57d3" class="kc kd hi jf b jg kn jk ko jo kp js kq jw kr ka kj kk kl km bi translated"><a class="ae kb" href="https://cloud.google.com/vertex-ai/docs/pipelines/run-pipeline?hl=en#vertex-ai-sdk-for-python" rel="noopener ugc nofollow" target="_blank"> job.submit </a>:触发流水线运行。</li></ul><p id="5a6f" class="pw-post-body-paragraph jd je hi jf b jg ke ji jj jk kf jm jn jo kv jq jr js kw ju jv jw kx jy jz ka hb bi translated"><a class="ae kb" href="https://github.com/pin-a-king/get-going-with-vertex-ai-v0/blob/ae247aabffb022cd09ae3f906ad65884afd56f16/vertex_ai_pipeline_pin.py" rel="noopener ugc nofollow" target="_blank">这里的</a>是创建并提交管道作业的实际代码片段的链接。下面是相同的示例代码片段:</p><pre class="lm ln lo lp fd lq lr ls bn lt lu bi"><span id="98bd" class="lv ig hi lr b be lw lx l ly lz">run1 = aiplatform.PipelineJob(<br/>display_name = "tech-blog-vertex-ai-pin-mlmd-pipeline",<br/>template_path = "tech-blog-vertex-ai-pin-mlmd_pipeline.json",<br/>job_id = "tech-blog-vertex-ai-pin-mlmd-pipeline-{0}".format(TIMESTAMP),<br/>enable_caching = True,<br/>)<br/>run1.submit()</span></pre><h1 id="9ef1" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">顶点人工智能产生的假象:</h1><p id="483a" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">我们可以指定pipeline_root文件夹的位置，每个管道运行的所有元数据都将存储在该文件夹中，如上一节所述。下面是在提到的PIPELINE_ROOT桶中为每次运行保存的工件的屏幕截图:</p><figure class="lm ln lo lp fd mb er es paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="er es ma"><img src="../Images/a359ee44e070993e67704fdec08f3c4f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*C-RU5zJJbYrT_xrd"/></div></div></figure><h1 id="3109" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">在整体架构中包含顶点AI管道的可能方法:</h1><ul class=""><li id="af18" class="kc kd hi jf b jg jh jk jl jo ks js kt jw ku ka kj kk kl km bi translated">顶点人工智能管道可以单独用于EDA。</li><li id="18b5" class="kc kd hi jf b jg kn jk ko jo kp js kq jw kr ka kj kk kl km bi translated">除此之外，整个管道可以保存为JSON格式。这个JSON文件可以存储在一个GCS桶中，它可以用来触发管道运行。</li><li id="27d8" class="kc kd hi jf b jg kn jk ko jo kp js kq jw kr ka kj kk kl km bi translated">对于CICD实现，上述存储的管道版本可以根据需要进行更新或升级。</li><li id="99f5" class="kc kd hi jf b jg kn jk ko jo kp js kq jw kr ka kj kk kl km bi translated">我们可以使用一个<a class="ae kb" href="https://cloud.google.com/functions" rel="noopener ugc nofollow" target="_blank">云函数</a>从保存的JSON管道中触发一次运行。</li><li id="1050" class="kc kd hi jf b jg kn jk ko jo kp js kq jw kr ka kj kk kl km bi translated">我们还可以使用<a class="ae kb" href="https://cloud.google.com/scheduler" rel="noopener ugc nofollow" target="_blank">云调度器</a>作业来调度管道运行；在管道环境内或外部。</li></ul><h1 id="3892" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">顶点人工智能视觉:</h1><ul class=""><li id="7227" class="kc kd hi jf b jg jh jk jl jo ks js kt jw ku ka kj kk kl km bi translated">下面是管道执行的两个屏幕截图，其中第一个没有执行模型部署，第二个执行了模型部署:</li></ul><figure class="lm ln lo lp fd mb er es paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="er es ma"><img src="../Images/4dad29ee62b53636a20a0bc139f4eb21.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*rb9BnWNb9VUcvjXn"/></div></div></figure><figure class="lm ln lo lp fd mb er es paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="er es ma"><img src="../Images/3c1b116430c6c24dc48afe4d0b703fca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*gd15480L7asMCVfc"/></div></div></figure><ul class=""><li id="a66a" class="kc kd hi jf b jg ke jk kf jo kg js kh jw ki ka kj kk kl km bi translated">下面是的屏幕截图，如果我们想比较两个管道运行的指标:</li></ul><figure class="lm ln lo lp fd mb er es paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="er es ma"><img src="../Images/d12adcff9915143ea617c0d2edfb0e6b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*wse5s0RFJE0ooFB0"/></div></div></figure><ul class=""><li id="898b" class="kc kd hi jf b jg ke jk kf jo kg js kh jw ki ka kj kk kl km bi translated">下面是使用其规格创建的用户管理笔记本的屏幕截图:</li></ul><figure class="lm ln lo lp fd mb er es paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="er es ma"><img src="../Images/96c1a5c94762c8c0afcedc7bece00084.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*QZegQKt5ZEvFVVnP"/></div></div></figure><ul class=""><li id="3ebc" class="kc kd hi jf b jg ke jk kf jo kg js kh jw ki ka kj kk kl km bi translated">下面是在模型注册表中创建的模型的屏幕截图:</li></ul><figure class="lm ln lo lp fd mb er es paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="er es ma"><img src="../Images/42933d75330c3bde2d57e05a54ba384f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*QSKv-WgW2W7EBufb"/></div></div></figure><ul class=""><li id="2e5f" class="kc kd hi jf b jg ke jk kf jo kg js kh jw ki ka kj kk kl km bi translated">下面是向部署的模型发送预测请求的屏幕截图。它还必须遵循下述格式(JSON ):</li></ul><pre class="lm ln lo lp fd lq lr ls bn lt lu bi"><span id="97e4" class="lv ig hi lr b be lw lx l ly lz">{<br/>  "instances":<br/>  [<br/>    [<br/>      619,42,2,0.0,1,1,1,101348.88,0,0,0<br/>    ]<br/>  ]<br/>}</span></pre><figure class="lm ln lo lp fd mb er es paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="er es ma"><img src="../Images/b54aa9250342c28e02736e344e0f63f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*i6e2wZnXl9VaEMzo"/></div></div></figure><ul class=""><li id="5f61" class="kc kd hi jf b jg ke jk kf jo kg js kh jw ki ka kj kk kl km bi translated">下面是创建的端点的屏幕截图:</li></ul><figure class="lm ln lo lp fd mb er es paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="er es ma"><img src="../Images/87096e9b983fcddbc1cac2ced921ede2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*MnaC8ET15AyItZ8l"/></div></div></figure><h1 id="1956" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">代码:</h1><p id="a1b7" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">请在这里找到这个博客<a class="ae kb" href="https://github.com/pin-a-king/get-going-with-vertex-ai-v0" rel="noopener ugc nofollow" target="_blank">的全部代码</a>！</p><p id="d58e" class="pw-post-body-paragraph jd je hi jf b jg ke ji jj jk kf jm jn jo kv jq jr js kw ju jv jw kx jy jz ka hb bi translated">(PS:请注意，数据集已经保存在提到的GCS桶中)</p><h1 id="d974" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">最佳实践:</h1><ul class=""><li id="e7f5" class="kc kd hi jf b jg jh jk jl jo ks js kt jw ku ka kj kk kl km bi translated">如前所述，笔记本是在计算引擎实例上运行的，因此，只要不使用，建议停止笔记本实例，以节省底层计算引擎的运行成本。</li><li id="c10e" class="kc kd hi jf b jg kn jk ko jo kp js kq jw kr ka kj kk kl km bi translated">我们可以在一个端点上部署一个模型，或者在一个端点上部署多个模型；但在后一种情况下，我们需要<a class="ae kb" href="https://cloud.google.com/vertex-ai/docs/general/deployment#models-endpoint" rel="noopener ugc nofollow" target="_blank">相应地分割</a>流量以实现可伸缩性。</li><li id="a33a" class="kc kd hi jf b jg kn jk ko jo kp js kq jw kr ka kj kk kl km bi translated">一个端点可以多次使用。我们可以取消部署不必要的模型，并在同一个端点上部署新模型；而不是创造一个新的。</li><li id="ad68" class="kc kd hi jf b jg kn jk ko jo kp js kq jw kr ka kj kk kl km bi translated">如果不再使用该模型，我们应该从端点上取消部署该模型。然后我们可以删除端点。然后，我们可以删除顶点人工智能中的模型。</li><li id="818c" class="kc kd hi jf b jg kn jk ko jo kp js kq jw kr ka kj kk kl km bi translated">顶点AI资源如果长时间无人管理，会产生巨大的成本；所以如果不使用，我们应该删除各自的资源。</li><li id="2ead" class="kc kd hi jf b jg kn jk ko jo kp js kq jw kr ka kj kk kl km bi translated">顶点人工智能定价:顶点人工智能操作和等效的“遗留”操作的定价对于每个操作都是相同的。例如，如果您使用人工智能平台训练来训练模型，则使用顶点人工智能训练来训练模型的<a class="ae kb" href="https://cloud.google.com/vertex-ai/pricing#training" rel="noopener ugc nofollow" target="_blank">成本</a>是相同的。如果你使用的是传统的人工智能平台产品，那么计费可能会用“培训单位”来表示。Vertex Pipelines对每个管道运行收取0.03美元的运行执行费。您还需要为在顶点管道中使用的谷歌云资源付费，比如管道组件消耗的计算引擎资源。如需完整的定价信息，请点击<a class="ae kb" href="https://cloud.google.com/vertex-ai/pricing" rel="noopener ugc nofollow" target="_blank">此处</a>。</li></ul><h1 id="9ba7" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">参考资料:</h1><p id="9db5" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">以下参考资料是开始使用Vertex AI的良好起点:</p><ul class=""><li id="9e15" class="kc kd hi jf b jg ke jk kf jo kg js kh jw ki ka kj kk kl km bi translated"><a class="ae kb" href="https://www.youtube.com/watch?v=gT4qqHMiEpA" rel="noopener ugc nofollow" target="_blank">什么是顶点AI？</a></li><li id="c6a1" class="kc kd hi jf b jg kn jk ko jo kp js kq jw kr ka kj kk kl km bi translated"><a class="ae kb" href="https://www.youtube.com/playlist?list=PLIivdWyY5sqJAyUJbbsc8ZyGLNT4isnuB" rel="noopener ugc nofollow" target="_blank">原型到生产用顶点AI </a></li><li id="b9aa" class="kc kd hi jf b jg kn jk ko jo kp js kq jw kr ka kj kk kl km bi translated"><a class="ae kb" href="https://www.youtube.com/watch?v=766OilR6xWc" rel="noopener ugc nofollow" target="_blank">用顶点AI </a>建立端到端管道</li></ul></div></div>    
</body>
</html>