<html>
<head>
<title>A TensorFlow Glossary/Cheat Sheet</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">TensorFlow词汇表/备忘单</h1>
<blockquote>原文：<a href="https://medium.com/google-cloud/a-tensorflow-glossary-cheat-sheet-382583b22932?source=collection_archive---------0-----------------------#2017-08-29">https://medium.com/google-cloud/a-tensorflow-glossary-cheat-sheet-382583b22932?source=collection_archive---------0-----------------------#2017-08-29</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="7ea9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">已经有很多很棒的TensorFlow教程、Jupyter笔记本和MOOCs了。作为一个今年经历了很多的人，一个绊脚石是许多教程会使用我不熟悉的术语。此外，许多教程使用不同级别的TensorFlow API，或者不同的高级包装器，这增加了我的困惑。我想我应该写一个我经常遇到的术语表来帮忙。</p><p id="6eb2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我不是TF团队的一员，我还是TF和ML的学生，所以下面的一些可能不准确，请在评论中添加更正。</p><p id="087a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我还把一般的ML概念放在了最底层，假设许多试图使用TF的人已经对ML有了一些基本的熟悉。如果没有，Coursera课程可能是最好的高级入门课程。最后，这只是一个快速总结，这些主题中的大多数在维基百科、研究论文、在线课程等上都有更完整的解释。</p><p id="ec15" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在我开始之前，我将重复一些TF/ML教程的链接:</p><ul class=""><li id="e60e" class="jd je hi ih b ii ij im in iq jf iu jg iy jh jc ji jj jk jl bi translated">官方TF入门和教程当然在<a class="ae jm" href="https://www.tensorflow.org" rel="noopener ugc nofollow" target="_blank">tensorflow.org</a>上</li><li id="8d3d" class="jd je hi ih b ii jn im jo iq jp iu jq iy jr jc ji jj jk jl bi translated"><a class="ae jm" href="https://github.com/jtoy/awesome-tensorflow" rel="noopener ugc nofollow" target="_blank"> Awesome Tensorflow </a>是一个庞大的TF教程汇编</li><li id="f0ef" class="jd je hi ih b ii jn im jo iq jp iu jq iy jr jc ji jj jk jl bi translated">T4的Keras例子是流行架构实现的很好的例子</li><li id="e241" class="jd je hi ih b ii jn im jo iq jp iu jq iy jr jc ji jj jk jl bi translated"><a class="ae jm" href="http://coursera.com" rel="noopener ugc nofollow" target="_blank"> Coursera </a>有一个世界闻名的ML classs，现在又增加了一个深度学习类。斯坦福大学更深入的数学课程也在ITunes U上。</li><li id="fe7e" class="jd je hi ih b ii jn im jo iq jp iu jq iy jr jc ji jj jk jl bi translated"><a class="ae jm" href="http://Udacity" rel="noopener ugc nofollow" target="_blank"> Udacity </a>有基于TensorFlow的深度学习类和自动驾驶汽车类</li><li id="eb4c" class="jd je hi ih b ii jn im jo iq jp iu jq iy jr jc ji jj jk jl bi translated"><a class="ae jm" href="https://github.com/googlecloudplatform/cloudml-samples" rel="noopener ugc nofollow" target="_blank">Google Cloud ML sample repo</a>有几个教程，包括用不同级别的API解决相同问题的教程，这是一个有用的比较点。</li></ul><p id="a25f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">好了，在这个列表中，一些定义使用了后来定义的词汇:</p><ul class=""><li id="19fb" class="jd je hi ih b ii ij im in iq jf iu jg iy jh jc ji jj jk jl bi translated"><strong class="ih hj">首字母缩写</strong> : TF = TensorFlow。ML =机器学习</li></ul><h1 id="0880" class="js jt hi bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">TensorFlow API级别</h1><ul class=""><li id="4a85" class="jd je hi ih b ii kq im kr iq ks iu kt iy ku jc ji jj jk jl bi translated"><strong class="ih hj">底层API </strong>:制作TF Ops的TF图的TF代码。正如<a class="ae jm" href="https://www.tensorflow.org/tutorials/mandelbrot" rel="noopener ugc nofollow" target="_blank"> Mandelbrot教程</a>所证明的，你可以将这个API用于ML之外的目的。如果你对解决一个ML问题比创造新的ML方法更感兴趣，更高级别的API是一个更好的起点，尽管理解这个级别也是非常有帮助的。</li><li id="49ca" class="jd je hi ih b ii jn im jo iq jp iu jq iy jr jc ji jj jk jl bi translated"><strong class="ih hj"> Estimator API- </strong>一个更高级别的API，也是自TF Github repo以来最受官方支持的API。它提供了常见的ML模型的“估计量”。它大致基于<a class="ae jm" href="http://scikit-learn.org/" rel="noopener ugc nofollow" target="_blank">scikitlearn</a>(sk learn)Python ML API。<strong class="ih hj">非常令人困惑的一点:在某种程度上，这被称为“tf learn”API，因为代码在TF repo的</strong> <code class="du kv kw kx ky b"><strong class="ih hj">tf.contrib.learn</strong></code> <strong class="ih hj"> </strong>包中，但它与下面提到的TF learn项目没有关系。您也可以使用低级API来实现您自己的估算器。用低级API自己实现LinearClassifier是一个非常好的学习练习。</li><li id="9eb2" class="jd je hi ih b ii jn im jo iq jp iu jq iy jr jc ji jj jk jl bi translated"><strong class="ih hj">实验API- </strong>官方TensorFlow API，设计用于运行长时间运行的ML实验。如果训练一个模型需要几个小时或几天的时间，你需要一些标准的方法来跟踪度量，比如准确性、损失、保存模型检查点的方法等等。如果你正在使用Google Cloud ML引擎运行TensorFlow，这是最好的支持方法，我强烈推荐阅读Lak 使用它的这个<a class="ae jm" rel="noopener" href="/google-cloud/how-to-do-time-series-prediction-using-rnns-and-tensorflow-and-cloud-ml-engine-2ad2eeb189e8">教程，以及查看</a><a class="ae jm" href="https://github.com/googlecloudplatform/cloudml-samples" rel="noopener ugc nofollow" target="_blank"> Cloud ML samples repo </a>。最后，因为这个包在contrib中，所以它是一个不稳定的API，可能会有很大的变化。</li><li id="4770" class="jd je hi ih b ii jn im jo iq jp iu jq iy jr jc ji jj jk jl bi translated"><strong class="ih hj">TF learn</strong>—tflearn.org<a class="ae jm" href="http://tflearn.org" rel="noopener ugc nofollow" target="_blank">的又一高水平</a>独立于TF团队的TF API。<strong class="ih hj">与Estimator API无关，官方是TF的一部分，或者是Google出品。我不太了解这个API</strong></li><li id="142b" class="jd je hi ih b ii jn im jo iq jp iu jq iy jr jc ji jj jk jl bi translated">另一个高级API，可能是最流行的。早于TF，但支持TF作为一种可能的后端。也松散地模仿sklearn。自从谷歌聘用了TensorFlow的创建者以来，这已经成为tensor flow的一个更加官方的入口。</li><li id="b819" class="jd je hi ih b ii jn im jo iq jp iu jq iy jr jc ji jj jk jl bi translated"><strong class="ih hj">层</strong>-Core tensor flow和Keras都提供层，它们是构建神经网络层的便利函数，如卷积层。这些通常介于高级API和低级API之间，因为您直接将操作添加到图中，但是使用通用模式。</li><li id="4f84" class="jd je hi ih b ii jn im jo iq jp iu jq iy jr jc ji jj jk jl bi translated"><strong class="ih hj">TF slim</strong>——又一个像Keras一样的高级API，它在官方回购中，但不是很受欢迎</li><li id="2796" class="jd je hi ih b ii jn im jo iq jp iu jq iy jr jc ji jj jk jl bi translated"><strong class="ih hj"> Theano/PyTorch/Caffe — </strong>与TF竞争的流行深度学习框架。</li></ul><h1 id="e2cb" class="js jt hi bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">核心张量流概念</h1><ul class=""><li id="2d84" class="jd je hi ih b ii kq im kr iq ks iu kt iy ku jc ji jj jk jl bi translated"><strong class="ih hj">张量</strong> —多维矩阵，底层API的基础部分。对数学家来说，这可能更微妙，但在TF中，它总是一个多维矩阵。</li><li id="19e9" class="jd je hi ih b ii jn im jo iq jp iu jq iy jr jc ji jj jk jl bi translated"><strong class="ih hj"> Graph/Ops/Session /Node— </strong>通常，使用TF低级API，看起来像是在编写Python，但实际上，您只是在构建稍后将运行的Ops(操作)图。进程是运行图表和维护状态的方式。节点是由Ops创建的图形的一部分。TensorFlow的一个主要混淆点是，您编写的代码通常是在运行图形后运行，而不是在创建操作后运行。</li><li id="924f" class="jd je hi ih b ii jn im jo iq jp iu jq iy jr jc ji jj jk jl bi translated"><strong class="ih hj">稠密张量</strong> —其值通常在连续范围内的张量，意味着单个实值特征就足够了</li><li id="51b0" class="jd je hi ih b ii jn im jo iq jp iu jq iy jr jc ji jj jk jl bi translated"><strong class="ih hj">稀疏张量— </strong>实际上是一组张量，可以更容易地表示展开值或分类值</li><li id="9a70" class="jd je hi ih b ii jn im jo iq jp iu jq iy jr jc ji jj jk jl bi translated"><strong class="ih hj">要素列</strong>-通常给定一组输入数据，您会希望在将输入要素输入网络之前对其进行组合或修改。通常，您需要将分类特征或字符串特征映射到某种数值(实值或多维张量)。这第一层称为特性列。</li><li id="79ad" class="jd je hi ih b ii jn im jo iq jp iu jq iy jr jc ji jj jk jl bi translated"><strong class="ih hj">特征交叉— </strong>两个特征的组合，这在两个特征之间的关系很重要时很有用。参见<a class="ae jm" href="https://www.tensorflow.org/tutorials/linear" rel="noopener ugc nofollow" target="_blank">大比例线性模型</a>教程。</li><li id="6cda" class="jd je hi ih b ii jn im jo iq jp iu jq iy jr jc ji jj jk jl bi translated"><strong class="ih hj">队列— </strong> Tensorflow有一个<a class="ae jm" href="https://www.tensorflow.org/programmers_guide/threading_and_queues" rel="noopener ugc nofollow" target="_blank">队列的概念。这对于读入输入特征很有用，因为输入太大而无法读入内存，所以取而代之的是一个工人将输入加载到一个队列中，另一个操作将它从队列中取出进行处理。</a></li></ul><h1 id="2325" class="js jt hi bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">核心分类特征概念</h1><p id="1000" class="pw-post-body-paragraph if ig hi ih b ii kq ik il im kr io ip iq kz is it iu la iw ix iy lb ja jb jc hb bi translated">通常在TF中处理实值输入函数比分类特征简单得多。我们通常也将文本等自由形式的输入视为分类特征(例如，英语输入是分类的，可能的值是英语)。</p><p id="c658" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">一种尝试是将单词映射成数值，也许是用散列函数，或者只是从0到N排序，其中N是特征的数量。但是有一个问题。给定3个类别，红色、绿色和蓝色，如果我们将红色映射到0，将绿色映射到1，将蓝色映射到2，我们会使绿色和蓝色在价值上比红色和蓝色“更接近”网络，即使我们不是故意的。有各种各样的工具来处理这个问题。</p><ul class=""><li id="a26b" class="jd je hi ih b ii ij im in iq jf iu jg iy jh jc ji jj jk jl bi translated"><strong class="ih hj">词汇— </strong>分类特征的可能值的集合。它用于训练嵌入或为分类特征创建哈希桶。</li><li id="3498" class="jd je hi ih b ii jn im jo iq jp iu jq iy jr jc ji jj jk jl bi translated"><strong class="ih hj">散列桶— </strong>映射分类特征的最简单方法是将它们的值散列，可能是散列到一组桶中，桶的数量是确定的或者是超参数。</li><li id="9858" class="jd je hi ih b ii jn im jo iq jp iu jq iy jr jc ji jj jk jl bi translated"><strong class="ih hj">一个热门的编码— </strong>给定一个分类输入特征，如果我们简单地将可能的值映射到数字(比如红色—&gt;1，蓝色—&gt;2，绿色—&gt;3)我们会将红色和蓝色的含义放得更近(2–1 = 1)，即使它们在含义上并不比红色和绿色更近(3–1 = 2)。相反，一个热编码特征列将为红色、蓝色和绿色创建3个单独的节点，并且除了实际值为0和实际值为1之外，每个节点都有。这样一来，红色就不会比绿色更接近蓝色。</li><li id="6d0e" class="jd je hi ih b ii jn im jo iq jp iu jq iy jr jc ji jj jk jl bi translated"><strong class="ih hj"> Softmax — </strong>类似于sigmoid函数，但对于多个输入值，它将一组数值映射到一组总和为1的概率。它应该表示输入实例是给定类别的概率。一种非常常见的模式是，网络的最后一层具有与可能的类的数量相同的节点数，然后对logits运行softmax函数来生成每个类的概率。</li><li id="39f9" class="jd je hi ih b ii jn im jo iq jp iu jq iy jr jc ji jj jk jl bi translated">映射到概率的非常大或非常小的数字。从技术上讲，logit是logistic (softmax)函数的反函数，但在实践中，logit是指通过对概率运行logit函数而获得的值。</li><li id="151b" class="jd je hi ih b ii jn im jo iq jp iu jq iy jr jc ji jj jk jl bi translated"><strong class="ih hj">单词嵌入- </strong>从技术上讲，从单词中生成的任何种类的数字，但是在TF上下文中，单词嵌入通常指的是从分类特征中创建向量并训练这些向量。参见这里的<a class="ae jm" href="https://www.tensorflow.org/tutorials/word2vec" rel="noopener ugc nofollow" target="_blank"> word2vec </a>教程。它提供了比一次性编码更多的语义，因为相似的输入要素将具有更多相似的值。您使用固定大小的向量(深度),而不是类别的每个可能值的节点。向量是由网络训练的，在word2vec示例中，它是基于文本中的接近度来使用的，因此相似的向量值实际上在意义上更接近。这种方法的一个有趣的副作用是，您可以对嵌入进行矢量数学运算(例如，king-queen = man)。</li></ul><h1 id="b2ff" class="js jt hi bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">流行建筑</h1><ul class=""><li id="cd82" class="jd je hi ih b ii kq im kr iq ks iu kt iy ku jc ji jj jk jl bi translated"><strong class="ih hj">线性分类器— </strong>采用输入特征并将其与权重和偏差相结合以预测输出值的简单架构。一个内置的Esimators。</li><li id="d3d2" class="jd je hi ih b ii jn im jo iq jp iu jq iy jr jc ji jj jk jl bi translated"><strong class="ih hj"> DNNClassifier — </strong>深度神经网络分类器。涉及代表“隐藏特征”的节点中间层和代表非线性的激活函数。一个内置的估计器。</li><li id="992f" class="jd je hi ih b ii jn im jo iq jp iu jq iy jr jc ji jj jk jl bi translated"><strong class="ih hj">广度和深度— </strong>一个由<a class="ae jm" href="https://research.googleblog.com/2016/06/wide-deep-learning-better-together-with.html" rel="noopener ugc nofollow" target="_blank">谷歌论文</a>推广的架构，结合了线性分类器和深度神经网络分类器。直觉是“宽”的线性部分代表记忆具体的例子，而“深”的部分代表理解高层次的特征。例如，英语语法的许多部分都有基于词类的规则(由深部分学习)，但许多常见的例子打破了这些规则(由宽部分学习)。内置估值器之一。<a class="ae jm" href="https://www.tensorflow.org/versions/master/tutorials/wide_and_deep" rel="noopener ugc nofollow" target="_blank">见本教程。</a></li><li id="bb0d" class="jd je hi ih b ii jn im jo iq jp iu jq iy jr jc ji jj jk jl bi translated"><strong class="ih hj">卷积神经网络</strong> —卷积神经网络。一种流行的影像分类架构，使用横跨输入影像的网格来生成隐藏图层。例子包括LeNet、Nvidia、ImageNet</li><li id="e919" class="jd je hi ih b ii jn im jo iq jp iu jq iy jr jc ji jj jk jl bi translated"><strong class="ih hj">转移学习— </strong>使用现有训练模型作为起点，并为特定用例添加附加层的模型。直觉是经过高度训练的现有模型知道许多一般特征，这些特征是在特定示例上训练小型网络的良好起点。<a class="ae jm" href="https://codelabs.developers.google.com/codelabs/tensorflow-for-poets/" rel="noopener ugc nofollow" target="_blank"> TensorFlow for Poets </a>教程是一个很好的图像识别例子。</li><li id="c05c" class="jd je hi ih b ii jn im jo iq jp iu jq iy jr jc ji jj jk jl bi translated"><strong class="ih hj"> RNN </strong> —递归神经网络，一种为处理具有序列“记忆”的输入序列而设计的架构。LSTMs是RNNs的一个奇特版本。非常受自然语言处理(NLP)用例的欢迎</li><li id="9950" class="jd je hi ih b ii jn im jo iq jp iu jq iy jr jc ji jj jk jl bi translated"><strong class="ih hj">甘</strong> —一般对抗性神经网络，一个模型创建伪样本，另一个模型同时接受伪样本和真实样本，并被要求区分。使用ML生成新数据的流行方法。</li></ul><h1 id="569e" class="js jt hi bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">部署注意事项</h1><ul class=""><li id="7d39" class="jd je hi ih b ii kq im kr iq ks iu kt iy ku jc ji jj jk jl bi translated"><strong class="ih hj"> GPU/TPU — </strong>图形处理器单元/张量流处理单元。GPU是为矩阵数学优化的游戏卡制造的芯片。它们对深度学习项目或多或少是必不可少的，因为它们大大加快了训练速度。看这个<a class="ae jm" href="https://news.ycombinator.com/item?id=14396075" rel="noopener ugc nofollow" target="_blank"> HN关于购买自己的</a>的讨论，或者在AWS或谷歌云上租赁。谷歌宣布TPU是更专门用于深度学习的芯片，最终将在谷歌云上可用。</li><li id="a488" class="jd je hi ih b ii jn im jo iq jp iu jq iy jr jc ji jj jk jl bi translated"><strong class="ih hj">监视器/会话脱钩— </strong>通常在训练您的模型时，您会希望关注您的指标，如损失和准确性。通过附加Monitor，您可以在许多高级API中实现这一点。SessionRunHooks通过避免长时间运行的线程，取代了问题较少的监视器。</li><li id="a273" class="jd je hi ih b ii jn im jo iq jp iu jq iy jr jc ji jj jk jl bi translated"><strong class="ih hj">tensor board</strong>—tensor flow附带的GUI，用于显示训练期间的许多相关指标</li><li id="11ee" class="jd je hi ih b ii jn im jo iq jp iu jq iy jr jc ji jj jk jl bi translated"><strong class="ih hj">Apache Spark/Apache Beam/Apache Hadoop</strong>—常用于预处理特性的流行大数据框架</li><li id="6e11" class="jd je hi ih b ii jn im jo iq jp iu jq iy jr jc ji jj jk jl bi translated"><strong class="ih hj"> Apache Airflow </strong> —一个Airbnb项目，让编排所有的监控/记录/预处理/模型评估变得更加容易。</li><li id="3ae6" class="jd je hi ih b ii jn im jo iq jp iu jq iy jr jc ji jj jk jl bi translated"><strong class="ih hj">模型陈旧性— </strong>由于输入数据已经过时，实时模型的性能可能会随着时间的推移而发生漂移，因此在部署过程中，通常会使用新模型替换现有模型，或者使用新数据训练相同的模型</li><li id="fa71" class="jd je hi ih b ii jn im jo iq jp iu jq iy jr jc ji jj jk jl bi translated"><strong class="ih hj"> Google Cloud ML Engine — </strong>托管Tensorflow环境，在分布式集群上提供训练和预测</li></ul><h1 id="f2db" class="js jt hi bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated"><strong class="ak">一般ML概念</strong></h1><ul class=""><li id="6855" class="jd je hi ih b ii kq im kr iq ks iu kt iy ku jc ji jj jk jl bi translated"><strong class="ih hj">特性</strong>—ML模型使用的输入数据</li><li id="f4e6" class="jd je hi ih b ii jn im jo iq jp iu jq iy jr jc ji jj jk jl bi translated"><strong class="ih hj">特征工程— </strong>转换输入特征，使其对模型更有用。通常包括将类别映射到桶、将值正则化到-1和1之间、删除空值等。与特征工程相关的是理解你的输入数据，验证训练数据和生产数据足够相似，等等。</li><li id="761d" class="jd je hi ih b ii jn im jo iq jp iu jq iy jr jc ji jj jk jl bi translated"><strong class="ih hj">Condas/Numpy/Scipy/Jupyter notebooks/Numpy/pandas—</strong>对特征工程有用的Python工具和库。Jupyter笔记本作为一种与他人分享实验的方式特别有用。</li><li id="82eb" class="jd je hi ih b ii jn im jo iq jp iu jq iy jr jc ji jj jk jl bi translated"><strong class="ih hj">训练/评估/测试</strong> —训练是用于优化模型的数据，评估是用于在用新数据进行训练期间根据新数据评估模型，测试是用于提供最终结果</li><li id="f2cc" class="jd je hi ih b ii jn im jo iq jp iu jq iy jr jc ji jj jk jl bi translated"><strong class="ih hj">分类/回归— </strong>回归是预测一个数字(如房价)，分类是从一组类别或输出类进行预测(如从红/蓝/绿预测房子的颜色)。</li><li id="f1e5" class="jd je hi ih b ii jn im jo iq jp iu jq iy jr jc ji jj jk jl bi translated"><strong class="ih hj">线性回归- </strong>通过将输入特征与权重和偏差相乘并求和来预测输出的经典方法。对回归有用</li><li id="d757" class="jd je hi ih b ii jn im jo iq jp iu jq iy jr jc ji jj jk jl bi translated"><strong class="ih hj">逻辑回归— </strong>类似于线性回归，但预测概率，用于分类。</li><li id="22e5" class="jd je hi ih b ii jn im jo iq jp iu jq iy jr jc ji jj jk jl bi translated"><strong class="ih hj">神经网络— </strong>类似于线性/逻辑回归，但增加了一个激活函数，使得预测不是输入的线性组合的输出成为可能。经常使用中间层节点进行“深度学习”。</li><li id="00b7" class="jd je hi ih b ii jn im jo iq jp iu jq iy jr jc ji jj jk jl bi translated"><strong class="ih hj">梯度下降/随机梯度下降(SGD)/反向传播</strong> —基本损耗优化器算法，其他优化器通常基于该算法。SGD是梯度下降法，但它是对一批训练数据而不是全部数据进行的。反向传播类似于梯度下降，但用于神经网络</li><li id="29ad" class="jd je hi ih b ii jn im jo iq jp iu jq iy jr jc ji jj jk jl bi translated"><strong class="ih hj"> Loss/LogLoss </strong> —表示模型有多好的度量，以及优化器使用的度量。损失日志(logloss)通常被Kaggle(数据科学竞赛网站)用来对模型进行排名。</li><li id="e429" class="jd je hi ih b ii jn im jo iq jp iu jq iy jr jc ji jj jk jl bi translated"><strong class="ih hj">优化器— </strong>改变权重和偏差以减少损失的操作。通常是阿达格拉德或亚当。</li><li id="0c85" class="jd je hi ih b ii jn im jo iq jp iu jq iy jr jc ji jj jk jl bi translated"><strong class="ih hj">权重/偏差</strong>-权重是与输入要素相乘以预测输出值的值。偏差是给定权重为0的输出值。</li><li id="b4d8" class="jd je hi ih b ii jn im jo iq jp iu jq iy jr jc ji jj jk jl bi translated"><strong class="ih hj">收敛— </strong>收敛的算法最终会达到最优解，即使非常慢。一个不收敛的算法可能永远达不到最优解。</li><li id="f02e" class="jd je hi ih b ii jn im jo iq jp iu jq iy jr jc ji jj jk jl bi translated"><strong class="ih hj">学习率</strong>——优化者改变权重和偏差的速度。一般来说，高学习率训练得更快，但有不收敛的风险，而低学习率训练得更慢</li><li id="a992" class="jd je hi ih b ii jn im jo iq jp iu jq iy jr jc ji jj jk jl bi translated"><strong class="ih hj">过度拟合— </strong>当模型对输入数据表现出色，但对评估或测试数据表现不佳时</li><li id="e5f4" class="jd je hi ih b ii jn im jo iq jp iu jq iy jr jc ji jj jk jl bi translated"><strong class="ih hj">偏差/方差</strong>—输出的多少由特性决定。更多的差异通常意味着过度拟合，更多的偏差可能意味着一个坏的模型</li><li id="f8f5" class="jd je hi ih b ii jn im jo iq jp iu jq iy jr jc ji jj jk jl bi translated"><strong class="ih hj">正则化</strong> —减少过拟合的各种方法，包括将权重添加到损失函数中，随机丢弃层(丢弃)。</li><li id="d96b" class="jd je hi ih b ii jn im jo iq jp iu jq iy jr jc ji jj jk jl bi translated"><strong class="ih hj">学习曲线— </strong>打印出训练/评估指标随时间变化的图表，以评估模型质量。可以用TensorBoard完成</li><li id="c182" class="jd je hi ih b ii jn im jo iq jp iu jq iy jr jc ji jj jk jl bi translated"><strong class="ih hj">时期</strong> —您对训练数据运行了多少次优化</li><li id="9a28" class="jd je hi ih b ii jn im jo iq jp iu jq iy jr jc ji jj jk jl bi translated"><strong class="ih hj">批量大小— </strong>一次优化多少个训练样本</li><li id="c0b1" class="jd je hi ih b ii jn im jo iq jp iu jq iy jr jc ji jj jk jl bi translated"><strong class="ih hj">超参数(HParams)——</strong>ML模型采用许多参数，您必须猜测其中最适合的参数。超参数是您也将训练的参数，例如，如果您不知道最佳学习率，您可以将其设为超参数，网络将根据损失尝试找到最佳的参数。<strong class="ih hj"> </strong> <a class="ae jm" href="https://cloud.google.com/ml-engine/docs/concepts/hyperparameter-tuning-overview" rel="noopener ugc nofollow" target="_blank">参见本指南</a>关于超参数调谐。</li><li id="8d4b" class="jd je hi ih b ii jn im jo iq jp iu jq iy jr jc ji jj jk jl bi translated"><strong class="ih hj">激活函数— </strong>将非线性引入网络的数学函数。最受欢迎的是RELU，其次是谭。</li><li id="7366" class="jd je hi ih b ii jn im jo iq jp iu jq iy jr jc ji jj jk jl bi translated"><strong class="ih hj"> Sigmoid函数- </strong>将非常负数映射到非常接近0的数、接近1的巨数、0映射到. 5的函数。用于在逻辑回归中将数字映射到概率。</li><li id="37a2" class="jd je hi ih b ii jn im jo iq jp iu jq iy jr jc ji jj jk jl bi translated"><strong class="ih hj">准确度/精确度/召回率— </strong>准确度通常不能很好地代表性能，例如，如果95%的时间都在下雨，那么预测每天都会下雨的模型就有95%的准确度不是很好。参见维基百科<strong class="ih hj">。</strong></li><li id="de46" class="jd je hi ih b ii jn im jo iq jp iu jq iy jr jc ji jj jk jl bi translated"><strong class="ih hj">混淆矩阵— </strong>一种表示准确度/精确度/召回率的方式</li><li id="8816" class="jd je hi ih b ii jn im jo iq jp iu jq iy jr jc ji jj jk jl bi translated"><strong class="ih hj"> AUC(曲线下面积)、ROC(接收操作特性)</strong> —另一种可视化准确度/精确度/权衡指标的方法</li><li id="f121" class="jd je hi ih b ii jn im jo iq jp iu jq iy jr jc ji jj jk jl bi translated"><strong class="ih hj"> MSE(均方误差)——</strong>最常见的回归损失函数</li><li id="8358" class="jd je hi ih b ii jn im jo iq jp iu jq iy jr jc ji jj jk jl bi translated"><strong class="ih hj">交叉熵</strong>——最常见的分类损失函数</li><li id="f0e3" class="jd je hi ih b ii jn im jo iq jp iu jq iy jr jc ji jj jk jl bi translated"><strong class="ih hj">集成学习</strong> —用不同的参数训练多个模型来解决同一个问题</li><li id="f600" class="jd je hi ih b ii jn im jo iq jp iu jq iy jr jc ji jj jk jl bi translated"><strong class="ih hj">数值不稳定— </strong>由于计算机中浮点数表示的限制，许多深度学习算法可以运行具有非常大或非常小的值的问题</li><li id="c0cf" class="jd je hi ih b ii jn im jo iq jp iu jq iy jr jc ji jj jk jl bi translated"><strong class="ih hj">梯度爆炸</strong>——数值不稳定的常见情况</li></ul><p id="27ea" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">同样，请在评论中留下任何更正、补充或反馈。在推特上找我<a class="ae jm" href="http://twitter.com/waprin_io" rel="noopener ugc nofollow" target="_blank"> @waprin_io </a>。感谢<a class="ae jm" href="https://github.com/elibixby" rel="noopener ugc nofollow" target="_blank"> Eli Bixby </a>查看并提供一些修复。</p></div></div>    
</body>
</html>