# 了解 kubernetes 网络:入口

> 原文：<https://medium.com/google-cloud/understanding-kubernetes-networking-ingress-1bc341c84078?source=collection_archive---------0----------------------->

在本系列的第一篇文章中，我描述了一个网络，该网络使 pods 能够在 [kubernetes](https://kubernetes.io/) 集群中的节点之间相互连接。第二个[关注的是](/@betz.mark/understanding-kubernetes-networking-services-f0cb48e4cc82)服务网络如何为 pod 提供负载平衡，以便集群内的客户端可以与它们可靠地通信。在这第三期也是最后一期文章中，我想以这些概念为基础，展示集群外部的客户端如何使用相同的服务网络连接到 pods。由于各种原因，这可能是三个中最复杂的，第一部分和第二部分中介绍的概念是从后面的内容中获得更多价值的先决条件。

首先，刚刚从奥斯汀的 kubecon 2017 回来，我想起了一些我可能在该系列早些时候已经阐明的事情。Kubernetes 是一个迅速成熟的平台。该架构的大部分是可插拔的，这包括网络。我在这里描述的是谷歌 Kubernetes 引擎的默认实现。我还没有看到亚马逊的弹性 Kubernetes 服务，但我认为它也将接近那里的默认实现。在某种程度上，kubernetes 有一个处理网络的“标准”方式，我认为这些帖子描述了它的基本方面。你必须从某个地方开始，当你开始考虑像[统一服务网格](https://buoyant.io/2017/05/24/a-service-mesh-for-kubernetes-part-x-the-service-mesh-api/)等替代方案时，掌握这些概念会有所帮助。说完这些，我们来谈谈入口。

![](img/e4b704f7d996707d660c9f2be60bb64b.png)

# 路由不是负载平衡

在[的上一篇文章](/@betz.mark/understanding-kubernetes-networking-services-f0cb48e4cc82)中，我们创建了一个部署，其中有几个 pod 和一个分配了 IP 的服务，称为“集群 IP ”,针对 pod 的请求被发送到这个 IP。我将在这里继续构建这个例子。回想一下，服务的集群 IP `**10.3.241.152**`位于独立于 pod 网络和节点本身所在网络的 IP 地址范围内。我把这个地址空间称为“服务网络”，尽管它名不副实，上面没有连接的设备，完全由路由规则组成。在示例中，我们展示了这个网络是如何由一个名为 [kube-proxy](https://kubernetes.io/docs/reference/generated/kube-proxy/) 的 kubernetes 组件与一个名为 [netfilter](http://www.netfilter.org/) 的 linux 内核模块协作来实现的，以捕获和重新路由发送到集群 IP 的流量，从而将它发送到一个健康的 pod。

![](img/0c8344b075a59f93f765b79a338d6811.png)

到目前为止，我们一直在谈论“连接”和“请求”，甚至更模糊的“流量”，但要理解 kubernetes ingress 的工作方式，我们需要得到更具体的信息。连接和请求在 OSI 第 4 层(tcp)或第 7 层(http、rpc 等)运行。Netfilter 规则是路由规则，它们作用于第 3 层的 IP 数据包。包括 netfilter 在内的所有路由器都或多或少地只根据数据包中包含的信息做出路由决定；一般是从哪里来，去哪里。因此，用第 3 层术语来描述这种行为:到达节点的`**eth0**`接口的、以`**10.3.241.152:80**` 处的服务为目的地的每个分组由 netfilter 处理，匹配为我们的服务建立的规则，并被转发到健康的 pod 的 IP。

很明显，我们用来允许外部客户端访问我们的 pod 的任何机制都必须使用相同的路由基础设施。也就是说，这些外部客户端最终必须调用群集 IP 和端口，因为这是我们到目前为止讨论过的所有机器的“前端”,这使得我们可以不关心任何给定时间 pod 在哪里运行。然而，目前还不清楚如何实现这一点。服务的群集 IP 只能从节点的以太网接口访问。集群之外的任何东西都不知道如何处理该范围内的地址。我们如何将流量从一个公开可见的 IP 端点转发到一个只有当数据包已经在一个节点上时才可到达的 IP？

如果你试图想出这个问题的解决方案，你可以做的事情之一是使用 [iptables](http://ipset.netfilter.org/iptables.man.html) 实用程序检查 netfilter 规则，如果你这样做了，你会发现一些乍一看似乎令人惊讶的事情:示例服务的规则并不局限于特定的原始网络。也就是说，来自任何地方的*的任何数据包到达目的地为`**10.3.241.152:80**`的节点的以太网接口都将匹配并被路由到一个 pod。那么，我们能不能只给客户端一个集群 IP，或许给它分配一个友好的域名，然后添加一个路由，将这些数据包发送到其中一个节点？*

![](img/e84a22c07a8e46bb872c054bda3922cc.png)

如果你那样设置事情，它将会工作。客户端调用集群 IP，数据包沿着路由向下到达一个节点，然后被转发到一个 pod。在这一点上，您可能会忍不住要打上蝴蝶结，但是这个解决方案存在一些严重的问题。第一，节点是短暂的，就像豆荚一样。它们不像 pod 一样短暂，但是它们可以迁移到新的虚拟机，集群可以扩大和缩小，等等。运行在第 3 层数据包上的路由器无法区分健康服务和不健康服务。他们希望路由中的下一跳稳定且可用。如果节点变得不可达，路由将中断，并且在大多数情况下会中断很长时间。即使路由是持久的，你也要让所有的外部流量通过一个节点，这可能不是最优的。

但是，我们引入客户端流量时，必须不依赖于群集中任何单个节点的运行状况。如果没有对路由器的主动管理，就没有可靠的方法来使用路由来做到这一点，而这正是 kube-proxy 在管理 netfilter 中的角色。将 kubernetes 的职责扩展到管理外部路由器对设计者来说可能没有多大意义，特别是考虑到我们已经有了将客户端流量分发到一组机器的成熟工具。它们被称为负载平衡器，毫不奇怪，这是 kubernetes ingress 的解决方案，实际上非常耐用。来看看到底是时候爬出第三层地下室，并再次谈论连接了。

要使用负载平衡器将客户端流量分发到集群中的节点，我们需要一个客户端可以连接到的公共 IP，并且我们需要负载平衡器可以将请求转发到的节点本身的地址。由于上述原因，我们无法在网关路由器和使用服务网络(集群 IP)的节点之间轻松创建稳定的静态路由。唯一可用的其他地址是节点的以太网接口所连接的网络上的地址，在本例中为`**10.100.0.0/24**`。网关路由器已经知道如何将数据包发送到这些接口，从负载平衡器发送到路由器的连接将到达正确的位置。但是，如果一个客户端想要在端口 80 上连接到我们的服务，我们不能只是在节点的接口上向该端口发送数据包。

![](img/4d4a4d71c1799aa5b22a66ac1aca9be6.png)

失败的原因显而易见。没有监听`**10.100.0.3:80**`的进程(或者如果有，那是错误的进程)，我们希望拦截我们的请求并将其定向到一个 pod 的 netfilter 规则与目的地址不匹配。它们只匹配位于`**10.3.241.152:80**`的服务网络上的集群 IP。因此，当这些数据包到达该接口时无法传送，内核会以 ECONNREFUSED 响应。这给我们留下了一个难题:netfilter 设置为转发数据包的网络不容易从网关路由到节点，而容易路由的网络不是 netfilter 转发的网络。解决这个问题的方法是在这些网络之间建立一座桥梁，这正是 kubernetes 用一种叫做节点端口的东西所做的。

# 节点端口服务

我们在上一篇文章中创建的示例服务没有指定类型，因此采用了默认类型`**ClusterIP**`。还有另外两种类型的服务添加了额外的功能，接下来重要的一种是类型`**NodePort**`。下面是作为节点端口服务的示例服务。

```
kind: Service
apiVersion: v1
metadata:
  name: service-test
spec:
  type: NodePort
  selector:
    app: service_test_pod
  ports:
  - port: 80
    targetPort: http
```

NodePort 类型的服务是具有附加功能的 ClusterIP 服务:它可以在节点的 IP 地址以及服务网络上分配的集群 IP 上访问。完成的方式非常简单:当 kubernetes 创建一个节点端口服务时，kube-proxy 在 30000–32767 范围内分配一个端口，并在每个节点的`**eth0**`接口上打开这个端口(因此得名“节点端口”)。到此端口的连接被转发到服务的群集 IP。如果我们创建上面的服务并运行`**kubectl get svc service-test**`，我们可以看到为它分配的节点端口。

```
**$ kubectl get svc service-test
NAME           CLUSTER-IP     EXTERNAL-IP   PORT(S)           AGE
service-test   10.3.241.152   <none>        80:32213/TCP      1m**
```

在这种情况下，我们的服务被分配了节点端口 32213。这意味着我们现在可以连接到示例集群中任一节点上的服务，在`**10.100.0.2:32213**`或`**10.100.0.3:32213**` 处，流量将被转发到该服务。有了这一部分，我们现在就有了一个完整的管道来对集群中所有节点的外部客户机请求进行负载平衡。

![](img/71b77056af97be0ae0c126445a1b8275.png)

在上图中，客户端通过公共 IP 地址连接到负载平衡器，负载平衡器选择一个节点并在`**10.100.0.3:32213**`连接到该节点，kube-proxy 接收该连接并将其转发到集群 IP `**10.3.241.152:80**`处的服务，此时请求与 netfilter 规则匹配并在`**10.0.2.2:8080**`被重定向到服务器 pod。这可能看起来有点复杂，在某些方面确实如此，但很难想到一个更简单的解决方案来保持 pod 和服务网络提供的所有酷功能。

这种机制并不是没有问题。节点端口的使用将您的服务公开给非标准端口上的客户端。这通常不是问题，因为负载平衡器可以公开常用端口，并对最终用户屏蔽节点端口。但是在一些场景中，比如 Google Cloud 上的内部负载平衡，你将被迫向上游传播节点端口。节点端口也是一种有限的资源，尽管 2768 个端口对于最大的集群来说可能已经足够了。对于大多数应用程序，您可以让 kubernetes 随机选择端口，但如果需要，您也可以显式设置它们。最后，对于在请求中保存源 IP 有一些限制。关于如何管理这些问题的信息，您可以参考关于该主题的[文档文章](https://kubernetes.io/docs/tutorials/services/source-ip/#source-ip-for-services-with-typeclusterip)。

节点端口是所有外部流量进入 kubernetes 集群的基本机制。然而，它们本身并不是一个完整的解决方案。由于上述原因，无论您的客户端是内部的还是通过公共网络进入的，您都需要在集群前安装某种负载平衡器。该平台的设计者认识到了这一点，并提供了两种不同的方法来从 kubernetes 内部指定负载平衡器配置，所以接下来让我们快速看一下。

# 负载平衡器服务和入口资源

最后这两个概念是 kubernetes 执行的更复杂的功能之一，但是我不打算在它们上面花太多时间，因为它们并没有真正改变我们刚刚讨论的任何内容。如上所述，所有外部流量最终都通过节点端口进入集群。设计者可以就此打住，让你去担心公共 IP 和负载平衡器，事实上，在某些情况下，比如在裸机上或在你的家庭实验室中运行，这就是你必须要做的。但是在支持 API 驱动的网络资源配置的环境中，kubernetes 使得在一个地方定义所有东西成为可能。

第一种也是最简单的方法是第三种 kubernetes 服务，称为负载平衡器服务。假设您运行在像 GCP 或 AWS 这样支持 API 驱动的网络资源配置的环境中，类型为`**LoadBalancer**`的服务具有 NodePort 服务的所有功能，并且能够构建完整的入口路径。

```
kind: Service
apiVersion: v1
metadata:
  name: service-test
spec:
  type: LoadBalancer
  selector:
    app: service_test_pod
  ports:
  - port: 80
    targetPort: http
```

如果我们删除并重新创建 Google Kubernetes 引擎上的示例服务，我们很快就会看到`**kubectl get svc service-test**`已经分配了一个外部 IP。

```
**$ kubectl get svc service-test
NAME      CLUSTER-IP      EXTERNAL-IP     PORT(S)          AGE
openvpn   10.3.241.52     35.184.97.156   80:32213/TCP     5m**
```

我说“很快”，尽管外部 IP 的分配可能需要几分钟的时间，考虑到必须启动的资源数量，这并不奇怪。例如，在 GCP 上，这需要系统创建一个外部 IP、一个转发规则、一个目标代理、一个后端服务，可能还需要一个实例组。一旦分配了 IP 地址，您就可以通过它连接到您的服务，为它分配一个域名，并将其分发给客户端。只要服务没有被破坏和重新创建(很少有好的理由这么做)，IP 就不会改变。

负载平衡器类型的服务有一些限制。您不能将 lb 配置为终止 https 流量。您不能使用虚拟主机或基于路径的路由，因此您不能使用单个负载平衡器以任何实际有用的方式代理多个服务。这些限制导致在 1.2 版本中添加了一个单独的 kubernetes 资源来配置负载平衡器，称为[入口](https://kubernetes.io/docs/concepts/services-networking/ingress/)。负载平衡器服务都是关于扩展单个服务来支持外部客户端。相比之下，入口是一个独立的资源，可以更加灵活地配置负载平衡器。入口 API 支持 TLS 终止、虚拟主机和基于路径的路由。它可以轻松地设置一个负载平衡器来处理多个后端服务。

Ingress API 是一个太大的主题，在这里无法详细讨论，因为正如前面提到的，它与 Ingress 在网络层的实际工作方式没有什么关系。实现遵循一个基本的 kubernetes 模式:一个资源类型和一个管理该类型的控制器。在这种情况下，资源是入口，其包括对网络资源的请求。下面是我们的测试服务的入口资源的样子。

```
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: test-ingress
  annotations:
    kubernetes.io/ingress.class: "gce"
spec:
  tls:
    - secretName: my-ssl-secret
  rules:
  - host: testhost.com
    http:
      paths:
      - path: /*
        backend:
          serviceName: service-test
          servicePort: 80
```

入口控制器负责通过将环境中的资源驱动到必要的状态来满足该请求。当使用入口时，您将服务创建为 NodePort 类型，并让入口控制器决定如何将流量发送到节点。GCE 负载平衡器、AWS 弹性负载平衡器以及 nginx 和 haproxy 等流行代理都有入口控制器实现。请注意，在某些环境中，将入口资源与负载平衡器服务混合会导致微妙的问题。这些都可以很容易地解决，但一般来说，即使是简单的服务也最好使用 Ingress。

# 主机端口和主机网络

我想谈的最后两件事实际上更属于有趣的好奇心范畴，而不是有用的工具。事实上，我认为它们是 99.99%用例的反模式，任何使用它们的实现都应该得到自动设计审查。我考虑过把它们完全排除在外，但是它们是某种进入的途径，所以非常简短地看一下它们做什么是值得的。

第一个是主机端口。这是容器的属性(在 ContainerPort 结构中声明)，当设置为给定的整数端口号时，会导致该端口在节点上打开，并直接转发到容器。没有代理，端口只在运行容器的节点上打开。在添加 [DaemonSets](https://kubernetes.io/docs/concepts/workloads/controllers/daemonset/) 和 [StatefulSets](https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/) 之前的平台早期，这是一个可以用来确保在任何给定节点上只有一个类型的容器运行的技巧。例如，我曾经用它来实现一个 elasticsearch 集群，方法是将 HostPort 设置为 9200，并指定与节点数量相同的副本。现在这将被认为是一个可怕的攻击，除非你正在实现一个 kubernetes 系统组件，否则你不太可能希望设置 HostPort。

第二个在 kubernetes 的上下文中更奇怪，这是一个 pod 的 HostNetwork 属性。当设置为 true 时，这与`**docker run**`的`**--network=host**`参数具有相同的效果。它使 pod 中的所有容器都使用节点的网络名称空间，即它们都可以访问`**eth0**` ，并直接在该接口上打开端口。我不认为暗示你永远、永远都不需要这样做是牵强的。如果你对此有一个用例，那么你很可能已经是 kubernetes 的贡献者，不需要我的任何帮助。

# 总结

这就结束了这个由三部分组成的 kubernetes 网络系列。我很喜欢了解这个平台并与之一起工作，我希望在这些文章中能感受到这种热情。我认为 kubernetes 预示着一场革命，它使我们有可能可靠地管理和互连集装箱车队，而不是服务器车队。从很多方面来说，它确实是一个瓶中的数据中心，因此存在相当多的底层复杂性也就不足为奇了。我写这些帖子是因为我认为一旦你学会了每个部分是如何工作的，它就会以一种非常优雅的方式变得有意义。希望我已经做出了贡献，让未来的新用户更容易进入这个平台。