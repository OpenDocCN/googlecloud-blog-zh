<html>
<head>
<title>YouTube-8M Training &amp; Inference</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">YouTube-8M训练和推理</h1>
<blockquote>原文：<a href="https://medium.com/google-cloud/youtube-8m-training-inference-eb37ac5f708f?source=collection_archive---------4-----------------------#2020-04-30">https://medium.com/google-cloud/youtube-8m-training-inference-eb37ac5f708f?source=collection_archive---------4-----------------------#2020-04-30</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="2bc5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">计算机视觉|视频理解</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jd"><img src="../Images/26dcb0a0a426723a0365ed340cea2584.png" data-original-src="https://miro.medium.com/v2/resize:fit:960/format:webp/1*3CBSrFIgHG3Lr4Ml6MKDGQ.png"/></div></figure><p id="7c18" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在之前的<a class="ae jl" href="https://nyghtowl.com/youtube-8m-dataset-c2ee9c79d136" rel="noopener ugc nofollow" target="_blank"> YouTube-8M数据集帖子</a>的基础上，这篇帖子涵盖了使用<a class="ae jl" href="https://github.com/google/youtube-8m" rel="noopener ugc nofollow" target="_blank"> GitHub repo </a>的入门部分提供的内容进行模型训练。所涉及的模型的目标是搜索视频中的特定时刻，这被称为时间概念定位。</p><p id="f0a8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">过去，元数据用于搜索视频。这些较新的模型能够在这些主题出现的特定时间戳对视频中的特定片段进行分类。例如，模型可以帮助识别视频中所有有巧克力、有人睡觉或有人滑冰的点。</p><p id="fb1b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">下面逐步介绍如何训练示例模型，使用YouTube-8M项目提供的代码评估和运行推理。示例代码是Python，使用TensorFlow。这是一个很好的例子，说明了如何使用该数据集。</p><h1 id="5076" class="jm jn hi bd jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj bi translated">文件结构设置</h1><p id="c533" class="pw-post-body-paragraph if ig hi ih b ii kk ik il im kl io ip iq km is it iu kn iw ix iy ko ja jb jc hb bi translated">首先，在您对模型进行定型、评估和运行预测的服务器上设置以下文件结构。</p><ul class=""><li id="6deb" class="kp kq hi ih b ii ij im in iq kr iu ks iy kt jc ku kv kw kx bi translated">${HOME}/ yt8m/code/</li><li id="bb5c" class="kp kq hi ih b ii ky im kz iq la iu lb iy lc jc ku kv kw kx bi translated">$ { HOME }/yt8m/车型/车架/</li><li id="369c" class="kp kq hi ih b ii ky im kz iq la iu lb iy lc jc ku kv kw kx bi translated">$ { HOME }/yt8m/2/架/列/</li><li id="f902" class="kp kq hi ih b ii ky im kz iq la iu lb iy lc jc ku kv kw kx bi translated">${HOME}/yt8m/3/frame/validate/</li><li id="b6a3" class="kp kq hi ih b ii ky im kz iq la iu lb iy lc jc ku kv kw kx bi translated">$ { HOME }/yt8m/3/帧/测试/</li></ul><h2 id="2697" class="ld jn hi bd jo le lf lg js lh li lj jw iq lk ll ka iu lm ln ke iy lo lp ki lq bi translated">起始代码</h2><p id="1c93" class="pw-post-body-paragraph if ig hi ih b ii kk ik il im kl io ip iq km is it iu kn iw ix iy ko ja jb jc hb bi translated">从GitHub repo中提取启动代码。</p><pre class="je jf jg jh fd lr ls lt lu aw lv bi"><span id="3d98" class="ld jn hi ls b fi lw lx l ly lz">cd ~/yt8m/code &amp;&amp; git clone https://github.com/google/youtube-8m.git</span></pre><h2 id="62f2" class="ld jn hi bd jo le lf lg js lh li lj jw iq lk ll ka iu lm ln ke iy lo lp ki lq bi translated">数据</h2><p id="5364" class="pw-post-body-paragraph if ig hi ih b ii kk ik il im kl io ip iq km is it iu kn iw ix iy ko ja jb jc hb bi translated">下载数据并将其放入正在训练的数据文件中，在谷歌云中验证、测试或引用它们。关于这些数据的更多信息以及在哪里可以找到这些数据都在这个<a class="ae jl" href="https://nyghtowl.com/youtube-8m-dataset-c2ee9c79d136" rel="noopener ugc nofollow" target="_blank">的帖子</a>中。</p><p id="7213" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">使用这些文件夹进行存储:</p><ul class=""><li id="9acd" class="kp kq hi ih b ii ij im in iq kr iu ks iy kt jc ku kv kw kx bi translated">$ { HOME }/yt8m/2/架/列/</li><li id="4735" class="kp kq hi ih b ii ky im kz iq la iu lb iy lc jc ku kv kw kx bi translated">${HOME}/yt8m/3/frame/validate/</li><li id="b3e0" class="kp kq hi ih b ii ky im kz iq la iu lb iy lc jc ku kv kw kx bi translated">$ { HOME }/yt8m/3/帧/测试/</li></ul><h2 id="852d" class="ld jn hi bd jo le lf lg js lh li lj jw iq lk ll ka iu lm ln ke iy lo lp ki lq bi translated">启动器算法</h2><p id="2593" class="pw-post-body-paragraph if ig hi ih b ii kk ik il im kl io ip iq km is it iu kn iw ix iy ko ja jb jc hb bi translated">一旦建立了结构并且数据就绪，您就可以开始使用初始的starter算法来创建模型了。代码库提供了一些算法供实验。</p><p id="a97a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">框架级逻辑回归模型</strong></p><p id="00e9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">逻辑模型在“一对一”方法中接受训练，这意味着它有助于从多个类别中得出单个预测。在该算法中，1000个类中的每一个都有一个模型，并且使用分段逻辑模型。为每一帧产生每一类的预测分数，最多5个分段，并且这些预测被平均(平均池)以获得分段级预测。这种类型的模型就像有一个评委小组给出预测，并对最终预测的结果进行平均。</p><p id="f7c6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">深度框架包(DBoF)池模型</strong></p><p id="7fd3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">该模型最初是受用于视频分类的经典单词包表示的启发。从片段中随机选择的一组帧被用作输入，并且特征被提取。这是一个卷积神经网络，其中卷积层是对帧应用权重的上采样。这在帧级别上提供了输入要素的强表示，因为这是一种提供更多要素细节的技术(增加下一图层的输入大小)。第二层将前一层汇集成段级结果(减小大小)。因此，它将参数扩展到帧级别，然后将它们收缩到片段级别，以显示片段的概要预测。更多的输入和功能可以稍微改善结果。例如，包括像素和音频可以帮助提高分数。</p><h1 id="bb1e" class="jm jn hi bd jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj bi translated">火车</h1><p id="428a" class="pw-post-body-paragraph if ig hi ih b ii kk ik il im kl io ip iq km is it iu kn iw ix iy ko ja jb jc hb bi translated">为了训练模型，移动到<em class="ma"> youtube-8m </em>文件夹(如果你做了上面的设置，它应该在~/ yt8m/code/目录下)来运行命令或确保调整到有意义的位置。</p><h2 id="e069" class="ld jn hi bd jo le lf lg js lh li lj jw iq lk ll ka iu lm ln ke iy lo lp ki lq bi translated"><strong class="ak">框架层次的Logistic回归模型</strong></h2><p id="5820" class="pw-post-body-paragraph if ig hi ih b ii kk ik il im kl io ip iq km is it iu kn iw ix iy ko ja jb jc hb bi translated">使用终端命令运行帧级逻辑回归模型。</p><pre class="je jf jg jh fd lr ls lt lu aw lv bi"><span id="cafd" class="ld jn hi ls b fi lw lx l ly lz">python3 train.py --frame_features --model=FrameLevelLogisticModel \<br/>--feature_names="rgb,audio" --feature_sizes="1024,128" \<br/>--train_data_pattern=${HOME}/yt8m/2/frame/train/train*.tfrecord \<br/>--train_dir="${HOME}/yt8m/models/frame/sample_model_logistic" \<br/>--start_new_model</span></pre><p id="6100" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">使用之前的system I设置(仅n1-standard-8 CPU)，它训练了12个小时，每秒处理400-500个示例，循环18，000多个步骤。损失从8-9左右开始，下降到5-6，并在5小时后保持不变。所以你可以少跑几步，但是要考虑调整超级参数。生成的模型存储在<strong class="ih hj"> <em class="ma"> sample_model_logistic文件夹</em> </strong>中。运行所花的时间是一个很好的例子，说明为什么GPU是很好的用途。我将在以后的文章中对此进行更深入的探讨。</p><p id="37e5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">深度框架包(DBoF)池模型</strong></p><p id="654b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">使用以下命令运行DBoF模型的启动代码。</p><pre class="je jf jg jh fd lr ls lt lu aw lv bi"><span id="daa1" class="ld jn hi ls b fi lw lx l ly lz">python3 train.py --frame_features --model=DbofModel \<br/>--feature_names="rgb,audio" --feature_sizes="1024,128" \<br/>--train_data_pattern=${HOME}/yt8m/2/frame/train/train*.tfrecord \<br/>--train_dir="${HOME}/yt8m/models/frame/sample_model_dbof" \<br/>--start_new_model</span></pre><p id="fd81" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">生成的模型将存储在sample_model_dbof文件夹中。注意，我的机器没有足够的计算机能力来完成这个模型的训练。所以你肯定需要一个GPU来运行这个。</p><h2 id="e08a" class="ld jn hi bd jo le lf lg js lh li lj jw iq lk ll ka iu lm ln ke iy lo lp ki lq bi translated">Train.py标志和默认值</h2><p id="0aac" class="pw-post-body-paragraph if ig hi ih b ii kk ik il im kl io ip iq km is it iu kn iw ix iy ko ja jb jc hb bi translated">请注意，有许多标志可以传递到上述命令中，以调整hyper参数和训练设置。标志和标准设置可以在GitHub repo <em class="ma"> train.py </em>文件中找到。以下是文件中的标志和默认值:</p><ul class=""><li id="2b49" class="kp kq hi ih b ii ij im in iq kr iu ks iy kt jc ku kv kw kx bi translated">train_dir="/tmp/yt8m_model/"</li><li id="4b3a" class="kp kq hi ih b ii ky im kz iq la iu lb iy lc jc ku kv kw kx bi translated">train_data_pattern= " "</li><li id="bf32" class="kp kq hi ih b ii ky im kz iq la iu lb iy lc jc ku kv kw kx bi translated">feature_names="mean_rgb "</li><li id="a2f7" class="kp kq hi ih b ii ky im kz iq la iu lb iy lc jc ku kv kw kx bi translated">feature _ sizes = " 1024 "</li><li id="8526" class="kp kq hi ih b ii ky im kz iq la iu lb iy lc jc ku kv kw kx bi translated">框架_特征=假</li><li id="412f" class="kp kq hi ih b ii ky im kz iq la iu lb iy lc jc ku kv kw kx bi translated">段标签=假</li><li id="8a01" class="kp kq hi ih b ii ky im kz iq la iu lb iy lc jc ku kv kw kx bi translated">model="LogisticModel "</li><li id="8515" class="kp kq hi ih b ii ky im kz iq la iu lb iy lc jc ku kv kw kx bi translated">start_new_model=False(你必须添加它来启动一个新模型，否则它不会)</li><li id="f520" class="kp kq hi ih b ii ky im kz iq la iu lb iy lc jc ku kv kw kx bi translated">num_gpu=1</li><li id="5310" class="kp kq hi ih b ii ky im kz iq la iu lb iy lc jc ku kv kw kx bi translated">batch_size=1024</li><li id="35d2" class="kp kq hi ih b ii ky im kz iq la iu lb iy lc jc ku kv kw kx bi translated">正则化_惩罚=1.0</li><li id="f1dc" class="kp kq hi ih b ii ky im kz iq la iu lb iy lc jc ku kv kw kx bi translated">基础学习率=0.01</li><li id="7481" class="kp kq hi ih b ii ky im kz iq la iu lb iy lc jc ku kv kw kx bi translated">学习率衰减=0.95</li><li id="b8e6" class="kp kq hi ih b ii ky im kz iq la iu lb iy lc jc ku kv kw kx bi translated">学习率衰减示例=4000000</li><li id="a839" class="kp kq hi ih b ii ky im kz iq la iu lb iy lc jc ku kv kw kx bi translated">次数=5</li><li id="35e1" class="kp kq hi ih b ii ky im kz iq la iu lb iy lc jc ku kv kw kx bi translated">max_steps=None(训练循环的最大迭代次数)</li><li id="abb6" class="kp kq hi ih b ii ky im kz iq la iu lb iy lc jc ku kv kw kx bi translated">导出模型步骤=1000</li><li id="92af" class="kp kq hi ih b ii ky im kz iq la iu lb iy lc jc ku kv kw kx bi translated">num_readers=8(多少个线程用于读取输入文件)</li><li id="1a56" class="kp kq hi ih b ii ky im kz iq la iu lb iy lc jc ku kv kw kx bi translated">optimizer="AdamOptimizer "</li><li id="304a" class="kp kq hi ih b ii ky im kz iq la iu lb iy lc jc ku kv kw kx bi translated">剪辑_渐变_正常=1.0</li><li id="f1f1" class="kp kq hi ih b ii ky im kz iq la iu lb iy lc jc ku kv kw kx bi translated">日志设备位置=假</li></ul><p id="c0b3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">查看<em class="ma"> train.py </em>文件以获得关于每一个的更多细节，并尝试使用它们和改变缺省值。</p><h2 id="c56e" class="ld jn hi bd jo le lf lg js lh li lj jw iq lk ll ka iu lm ln ke iy lo lp ki lq bi translated">模型输出文件</h2><p id="1480" class="pw-post-body-paragraph if ig hi ih b ii kk ik il im kl io ip iq km is it iu kn iw ix iy ko ja jb jc hb bi translated">训练完成后，模型文件存储在创建的文件夹中。文件夹中有几个文件，包括一个<em class="ma"> graph.pbtxt </em>文件，该文件可以加载到TensorBoard中，以便在训练时可视化模型性能。</p><p id="d68c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">要关注的主要文件是3种类型，它们在文件夹中有许多版本。默认情况下，使用TensorFlow的检查点保存方法，该方法将模型的训练权重分割成一组检查点格式的二进制文件。有一个索引文件可以帮助导航哪个权重存储在哪个碎片中。这种保存方式的价值在于，您可以在多台机器上训练模型，并将数据分散到不同的机器上以加快训练速度。你也可以停止和重新开始训练，它会知道它离开了。</p><p id="b292" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">下面列出了文件夹中的文件类型:</p><ul class=""><li id="e1a1" class="kp kq hi ih b ii ij im in iq kr iu ks iy kt jc ku kv kw kx bi translated"><strong class="ih hj">元文件</strong>(。meta):存储在恢复检查点之前需要导入的已保存图形结构</li><li id="755a" class="kp kq hi ih b ii ky im kz iq la iu lb iy lc jc ku kv kw kx bi translated"><strong class="ih hj">索引文件</strong>(。index):它是一个字符串-字符串不可变表。每个键是一个张量的名称，它的值是一个序列化的BundleEntryProto。每个BundleEntryProto描述了张量的元数据:哪个“数据”文件包含张量的内容、该文件中的偏移量、校验和、一些辅助数据等。</li><li id="45db" class="kp kq hi ih b ii ky im kz iq la iu lb iy lc jc ku kv kw kx bi translated"><strong class="ih hj">数据文件</strong>(。data-00000-of-00001):它是TensorBundle集合，保存所有变量的值</li></ul><h1 id="5565" class="jm jn hi bd jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj bi translated">评价</h1><p id="fc6a" class="pw-post-body-paragraph if ig hi ih b ii kk ik il im kl io ip iq km is it iu kn iw ix iy ko ja jb jc hb bi translated">一旦你有了一个工作模型，验证并评估它，看看它是否足够通用于新的例子。</p><p id="08df" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">使用以下命令评估模型:</p><pre class="je jf jg jh fd lr ls lt lu aw lv bi"><span id="4e45" class="ld jn hi ls b fi lw lx l ly lz"># Frame-level<br/>python3 eval.py \<br/>--eval_data_pattern=${HOME}/yt8m/3/frame/validate/validate*.tfrecord<br/>--train_dir ${HOME}/yt8m/models/frame/sample_model_logistic \<br/>--segment_labels --run_once</span><span id="3d71" class="ld jn hi ls b fi mb lx l ly lz">OR </span><span id="bdbe" class="ld jn hi ls b fi mb lx l ly lz">#DBoF<br/>python3 eval.py \<br/>--eval_data_pattern=${HOME}/yt8m/3/frame/validate/validate*.tfrecord<br/>--train_dir ${HOME}/yt8m/models/frame/sample_model_dbof \<br/>--segment_labels --run_once</span></pre><p id="a57f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在<em class="ma">框架级模型</em>上运行评估需要20分钟。总共处理了235，256个示例。注意，这个文件中有特定的标志来帮助调整评估函数的工作方式。以下是最终的评估指标和详细信息。</p><ul class=""><li id="60b8" class="kp kq hi ih b ii ij im in iq kr iu ks iy kt jc ku kv kw kx bi translated">处理的例子= 235 256</li><li id="9886" class="kp kq hi ih b ii ky im kz iq la iu lb iy lc jc ku kv kw kx bi translated">Avg_Hit(首次预测的准确率)= 0.558</li><li id="1cfa" class="kp kq hi ih b ii ky im kz iq la iu lb iy lc jc ku kv kw kx bi translated">Avg_PERR(等召回率下的精度)= 0.558</li><li id="697e" class="kp kq hi ih b ii ky im kz iq la iu lb iy lc jc ku kv kw kx bi translated">Avg_Loss(平均损失)= 19.756</li></ul><p id="614e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">常用于测量物体检测器的精度:</p><ul class=""><li id="dd7e" class="kp kq hi ih b ii ij im in iq kr iu ks iy kt jc ku kv kw kx bi translated">MAP(平均精确度/精确度-召回曲线下面积的平均值)= 0.752</li><li id="fee6" class="kp kq hi ih b ii ky im kz iq la iu lb iy lc jc ku kv kw kx bi translated">GAP(基于每个示例的前20个预测的全局平均精度)= 0.778</li></ul><p id="fa78" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这些结果已经足够了，你可以做得更好。调整网络、获取更多数据和尝试不同的模型结构是提高性能的方法。</p><h1 id="efbf" class="jm jn hi bd jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj bi translated">推理</h1><p id="7e13" class="pw-post-body-paragraph if ig hi ih b ii kk ik il im kl io ip iq km is it iu kn iw ix iy ko ja jb jc hb bi translated">要使用该模型对从未见过的新数据进行预测，请使用以下命令。</p><pre class="je jf jg jh fd lr ls lt lu aw lv bi"><span id="adf9" class="ld jn hi ls b fi lw lx l ly lz">#Frame-level<br/>python3 inference.py \<br/>--train_dir ${HOME}/yt8m/models/frame/sample_model_logistic \<br/>--output_file=${HOME}/yt8m/models/frame/sample_model_logistic/ks.csv<br/>--input_data_pattern=${HOME}/yt8m/3/frame/test/test*.tfrecord \<br/>--segment_labels --batch_size=64</span><span id="8f26" class="ld jn hi ls b fi mb lx l ly lz">OR </span><span id="935e" class="ld jn hi ls b fi mb lx l ly lz"># DBoF<br/>python3 inference.py \<br/>--train_dir ${HOME}/yt8m/models/frame/sample_model_logistic \<br/>--output_file=${HOME}/yt8m/models/frame/sample_model_dbof/ks.csv \<br/>--input_data_pattern=${HOME}/yt8m/3/frame/test/test*.tfrecord \<br/>--segment_labels --batch_size=64</span></pre><p id="c064" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">运行耗时13分钟，在<em class="ma">帧级模型上处理了2062258个示例。</em></p><p id="bbb2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">完成后，它将输出一个文件用于预测，并共享结果文件的位置，<em class="ma"> ks.csv </em>(我将其缩短以适应上面的行，但您可以随意命名。)<em class="ma">，</em>在你的<em class="ma"> /tmp/ </em>目录下。<em class="ma"> </em>推理完成后会列出确切的目录。您可以使用<em class="ma"> vocabulary.csv </em>文件来转换数字，以查看预测的类别。您无法通过查看原始文件来验证这是否正确，因为它是经过压缩的。关于压缩的更多信息在之前的关于数据集的<a class="ae jl" href="https://nyghtowl.com/youtube-8m-dataset-c2ee9c79d136" rel="noopener ugc nofollow" target="_blank">博客文章</a>中提供，学术论文在下面的参考资料部分列出。</p><p id="4cef" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了评估您在推理结果上的表现，您仍然可以在竞赛结束后提交竞赛，以从Kaggle获得您的模型表现如何的分数。您还可以使用自己的数据集来运行该模型并查看结果。不，您需要做大量的工作来将数据集设置为模型。</p><p id="b010" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果要将预测与结果进行比较，可以对验证数据集运行预测，并在预测和标注之间进行数字比较。如果您已经使用如上所述的验证来评估和调整模型，这并不理想；然而，这是一种实际看到它看起来像什么的方法。</p><h1 id="1854" class="jm jn hi bd jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj bi translated">包裹</h1><p id="d58f" class="pw-post-body-paragraph if ig hi ih b ii kk ik il im kl io ip iq km is it iu kn iw ix iy ko ja jb jc hb bi translated">所涵盖的内容是如何为YouTube-8M数据集开发主题的时间本地化模型。这一步通过训练，评估和运行在完成的模型推理的例子。</p><p id="1354" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">还有许多其他模式可供探索，您可以从Kaggle竞赛的获胜者开始，看看在每个竞赛的讨论板上分享解决方案的其他人。对于最新的Kaggle竞赛，<a class="ae jl" href="https://www.kaggle.com/c/youtube8m-2019/discussion/112869" rel="noopener ugc nofollow" target="_blank">这个</a>是最近的解决方案。</p><p id="59cb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">大多数解决方案利用某种类型的集合模型。这些可以是有趣的和有趣的实验。最好的情况是从成功和简单的东西开始。进行调整和扩展。你的模型越复杂，你可能需要的计算能力就越强。</p><p id="3364" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">此外，还有其他视频数据集可以探索，如DeepMind的<a class="ae jl" href="https://deepmind.com/research/open-source/kinetics" rel="noopener ugc nofollow" target="_blank">动力学</a>数据集。这是用于人体动作分类的良好建立的视频数据集。这是在视频领域探索的一个很好的选择。有超过65万个视频剪辑，涵盖了7K个类别，包括像演奏乐器或拥抱这样的动作。每个剪辑是一个持续10秒钟的单个动作。越来越多的人使用像ImageNet这样的数据集，这是视频表示预训练视频的一个很好的选择。</p><p id="d61f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在你有了，继续探索计算机视觉模型。</p><h1 id="aa8d" class="jm jn hi bd jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj bi translated">资源</h1><ul class=""><li id="eae6" class="kp kq hi ih b ii kk im kl iq mc iu md iy me jc ku kv kw kx bi translated"><a class="ae jl" href="http://cs231n.stanford.edu/reports/2017/pdfs/705.pdf" rel="noopener ugc nofollow" target="_blank"> YouTube-8M视频分类</a></li><li id="3c76" class="kp kq hi ih b ii ky im kz iq la iu lb iy lc jc ku kv kw kx bi translated"><a class="ae jl" href="https://static.googleusercontent.com/media/research.google.com/en//youtube8m/workshop2019/c_15.pdf" rel="noopener ugc nofollow" target="_blank">逻辑回归仍然有效:IVUL-KAUST团队的3d YouTube 8M挑战解决方案</a></li><li id="2f41" class="kp kq hi ih b ii ky im kz iq la iu lb iy lc jc ku kv kw kx bi translated"><a class="ae jl" href="https://arxiv.org/pdf/1706.08217.pdf" rel="noopener ugc nofollow" target="_blank">谷歌云平台中提高YouTube-8M分类准确率的有效方法</a></li></ul></div></div>    
</body>
</html>