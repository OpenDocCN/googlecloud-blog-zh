<html>
<head>
<title>Uploading data to Cloud Datastore using Dataflow</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用数据流将数据上传到云数据存储</h1>
<blockquote>原文：<a href="https://medium.com/google-cloud/uploading-data-to-cloud-datastore-using-dataflow-26c2588b9a8d?source=collection_archive---------0-----------------------#2018-07-18">https://medium.com/google-cloud/uploading-data-to-cloud-datastore-using-dataflow-26c2588b9a8d?source=collection_archive---------0-----------------------#2018-07-18</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="634c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在我之前的一篇<a class="ae jd" rel="noopener" href="/google-cloud/search-on-google-cloud-platform-cloud-datastore-615c14cb1bb">文章</a>中，我从csv文件上传了120万条记录到云数据库。我正在读取文件，列出200个解析过的行，然后把它们作为json顺序发布到web服务器上(这里的<a class="ae jd" href="https://github.com/zdenulo/gcp-search/blob/master/cloud_datastore/upload.py" rel="noopener ugc nofollow" target="_blank">是完整的脚本)。当然，这相当慢，也就是说，这个过程需要大约2.5个小时才能完成。只是后来我想起有一个更快的方法，那就是使用云数据流，所以只是为了好玩，我写了管道从csv文件上传数据到数据存储。</a></p><p id="9ff3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Dataflow是Google云平台的无服务器服务，使用Apache Beam框架运行数据处理。这意味着你只需要写数据处理管道和定义一些设置，仅此而已。它与Google云产品有很好的集成，比如云存储、BigQuery、BigTable、Datastore、Pub/Sub。数据流将创建虚拟机，虚拟机将执行作业，作业完成后，它将关闭一切。很简单。</p><p id="14f4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我用全部代码(Python)【https://github.com/zdenulo/upload-data-datastore-dataflow】T4创建了Github知识库，我将解释它是如何完成的。</p><p id="535c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">最重要的文件是upload.py，其中定义了所有内容。注意:Apache Beam for Python目前只支持Python 2.7(不是3.x)。</p><pre class="je jf jg jh fd ji jj jk jl aw jm bi"><span id="df1d" class="jn jo hi jj b fi jp jq l jr js">import csv<br/>import datetime<br/><br/>import apache_beam as beam<br/>from apache_beam.options.pipeline_options import PipelineOptions<br/>from apache_beam.io.gcp.datastore.v1.datastoreio import WriteToDatastore<br/>from google.cloud.proto.datastore.v1 import entity_pb2<br/>from googledatastore import helper as datastore_helper<br/><br/>from settings import PROJECT, BUCKET, INPUT_FILENAME<br/><br/><br/>class CSVtoDict(beam.DoFn):<br/>    """Converts line into dictionary"""<br/>    def process(self, element, headers):<br/>        rec = ""<br/>        element = element.encode('utf-8')<br/>        try:<br/>            for line in csv.reader([element]):<br/>                rec = line<br/><br/>            if len(rec) == len(headers):<br/>                data = {header.strip(): val.strip() for header, val in zip(headers, rec)}<br/>                return [data]<br/>            else:<br/>                print "bad: {}".format(rec)<br/>        except Exception:<br/>            pass<br/><br/><br/>class CreateEntities(beam.DoFn):<br/>    """Creates Datastore entity"""<br/>    def process(self, element):<br/>        entity = entity_pb2.Entity()<br/>        sku = int(element.pop('sku'))<br/>        element['regularPrice'] = float(element['regularPrice'])<br/>        element['salePrice'] = float(element['salePrice'])<br/>        element['name'] = unicode(element['name'].decode('utf-8'))<br/>        element['type'] = unicode(element['type'].decode('utf-8'))<br/>        element['url'] = unicode(element['url'].decode('utf-8'))<br/>        element['image'] = unicode(element['image'].decode('utf-8'))<br/>        element['inStoreAvailability'] = unicode(element['inStoreAvailability'])<br/><br/>        datastore_helper.add_key_path(entity.key, 'Productx', sku)<br/>        datastore_helper.add_properties(entity, element)<br/>        return [entity]<br/><br/><br/>def dataflow(run_local):<br/>    if run_local:<br/>        input_file_path = 'sample.csv'<br/>    else:<br/>        input_file_path = 'gs://' + BUCKET + '/' + INPUT_FILENAME<br/><br/>    JOB_NAME = 'datastore-upload-{}'.format(datetime.datetime.now().strftime('%Y-%m-%d-%H%M%S'))<br/><br/>    pipeline_options = {<br/>        'project': PROJECT,<br/>        'staging_location': 'gs://' + BUCKET + '/staging',<br/>        'runner': 'DataflowRunner',<br/>        'job_name': JOB_NAME,<br/>        'disk_size_gb': 100,<br/>        'temp_location': 'gs://' + BUCKET + '/temp',<br/>        'save_main_session': True<br/>    }<br/><br/>    if run_local:<br/>        pipeline_options['runner'] = 'DirectRunner'<br/><br/>    options = PipelineOptions.from_dictionary(pipeline_options)<br/>    with beam.Pipeline(options=options) as p:<br/><br/>        (p | 'Reading input file' &gt;&gt; beam.io.ReadFromText(input_file_path)<br/>         | 'Converting from csv to dict' &gt;&gt; beam.ParDo(CSVtoDict(),<br/>                                                       ['sku', 'name', 'regularPrice', 'salePrice', 'type', 'url', 'image',<br/>                                                        'inStoreAvailability'])<br/>         | 'Create entities' &gt;&gt; beam.ParDo(CreateEntities())<br/>         | 'Write entities into Datastore' &gt;&gt; WriteToDatastore(PROJECT)<br/>         )<br/><br/><br/>if __name__ == '__main__':<br/>    run_locally = False<br/>    dataflow(run_locally)</span></pre><p id="faed" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">数据流功能包含定义选项的主要部分以及完成工作的管道。它包括4个步骤:</p><ol class=""><li id="f48d" class="jt ju hi ih b ii ij im in iq jv iu jw iy jx jc jy jz ka kb bi translated">读取输入文件(从谷歌云存储桶)</li><li id="ec36" class="jt ju hi ih b ii kc im kd iq ke iu kf iy kg jc jy jz ka kb bi translated">根据标题列名，将csv行解析到字典中</li><li id="61a8" class="jt ju hi ih b ii kc im kd iq ke iu kf iy kg jc jy jz ka kb bi translated">创建数据存储实体(不保存)</li><li id="3220" class="jt ju hi ih b ii kc im kd iq ke iu kf iy kg jc jy jz ka kb bi translated">将实体保存到数据存储中</li></ol><p id="2a62" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">有两种自定义转换:</p><ul class=""><li id="3ad0" class="jt ju hi ih b ii ij im in iq jv iu jw iy jx jc kh jz ka kb bi translated">csv字典—将CSV行转换为字典</li><li id="5e34" class="jt ju hi ih b ii kc im kd iq ke iu kf iy kg jc kh jz ka kb bi translated">CreateEntities —基于字典创建实体—将发送到WriteToDatastore转换的原始缓冲区消息</li></ul><p id="434e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">使用run_locally变量，您可以定义是本地运行管道还是使用数据流运行管道。</p><p id="9c2b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在安装apache beam库之前，可以使用以下命令执行作业:</p><pre class="je jf jg jh fd ji jj jk jl aw jm bi"><span id="b9fa" class="jn jo hi jj b fi jp jq l jr js">python upload.py</span></pre><p id="bee6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">以下是一些截图:</p><p id="4a7e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这是管道在数据流用户界面中的外观</p><figure class="je jf jg jh fd kj er es paragraph-image"><div class="er es ki"><img src="../Images/5a075cba7198ca346720cf8c86c033f7.png" data-original-src="https://miro.medium.com/v2/resize:fit:580/format:webp/0*ic9kKQ-a74C93wUZ.png"/></div></figure><p id="1047" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">和一些统计数据。</p><figure class="je jf jg jh fd kj er es paragraph-image"><div role="button" tabindex="0" class="kn ko di kp bf kq"><div class="er es km"><img src="../Images/394b77d812a0d17c8e7dde4f286079f3.png" data-original-src="https://miro.medium.com/v2/resize:fit:920/format:webp/0*cLm_kRoGdrwGiejz.png"/></div></div></figure><p id="0789" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">可以看出，整个工作花费了16.5分钟(其中还包括虚拟机的调配)。图中显示了处理数据的工作人员(VM)数量，该数量随着时间的推移而增加，并在工作完成前达到峰值(60个工作人员)。下图显示了消耗的资源。稍加努力，可以计算出这一执行成本约为0.5美元加上数据存储成本。</p><figure class="je jf jg jh fd kj er es paragraph-image"><div class="er es km"><img src="../Images/f7ab9e5c598ecc2022105fcafc32e56b.png" data-original-src="https://miro.medium.com/v2/resize:fit:920/format:webp/0*wckujHa2ZUfY3Uti.png"/></div></figure><p id="4407" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，只需几行代码，就可以编写数据管道，将数据从csv文件加载到数据存储中。其他一切都由谷歌云管理。实际上有一个模板<a class="ae jd" href="https://cloud.google.com/dataflow/docs/templates/provided-templates#gcstexttodatastore" rel="noopener ugc nofollow" target="_blank">将文本从云存储上传到云数据存储</a>，但在这种情况下，每一行都应该编码为json，并基于它创建数据存储实体。</p></div></div>    
</body>
</html>