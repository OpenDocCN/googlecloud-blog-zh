<html>
<head>
<title>Moving Data from BigQuery to GCS — using GCP Dataproc Serverless and PySpark</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用GCP Dataproc Serverless和PySpark将数据从BigQuery移动到GCS</h1>
<blockquote>原文：<a href="https://medium.com/google-cloud/moving-data-from-bigquery-to-gcs-using-gcp-dataproc-serverless-and-pyspark-f6481b86bcd1?source=collection_archive---------0-----------------------#2022-06-28">https://medium.com/google-cloud/moving-data-from-bigquery-to-gcs-using-gcp-dataproc-serverless-and-pyspark-f6481b86bcd1?source=collection_archive---------0-----------------------#2022-06-28</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/></div><div class="ab cl if ig gp ih" role="separator"><span class="ii bw bk ij ik il"/><span class="ii bw bk ij ik il"/><span class="ii bw bk ij ik"/></div><div class="hb hc hd he hf"><figure class="in io ip iq fd ir er es paragraph-image"><div role="button" tabindex="0" class="is it di iu bf iv"><div class="er es im"><img src="../Images/b4dc5e19645a72075ed500ed8e647c66.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xTM0Rb36sgv2dlUtxzTB-A.png"/></div></div></figure><p id="0be8" class="pw-post-body-paragraph iy iz hi ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hb bi translated"><a class="ae jw" href="https://github.com/GoogleCloudPlatform/dataproc-templates" rel="noopener ugc nofollow" target="_blank"> Dataproc模板</a>允许我们使用Java和Python在Dataproc无服务器上运行常见用例，而不需要我们自己开发。这些模板实现了常见的Spark工作负载，让我们可以轻松地定制和运行它们。</p><p id="3240" class="pw-post-body-paragraph iy iz hi ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hb bi translated">如果您不熟悉Dataproc Serverless，或者您正在寻找使用Dataproc Serverless将数据从GCS迁移到BigQuery的PySpark模板，那么可以使用这个<a class="ae jw" rel="noopener" href="/@ppaglilla/getting-started-with-dataproc-serverless-pyspark-templates-e32278a6a06e"> blogpost </a>。</p><h1 id="6148" class="jx jy hi bd jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku bi translated">先决条件</h1><p id="796e" class="pw-post-body-paragraph iy iz hi ja b jb kv jd je jf kw jh ji jj kx jl jm jn ky jp jq jr kz jt ju jv hb bi translated">为了运行这些模板，我们需要:</p><ul class=""><li id="0da7" class="la lb hi ja b jb jc jf jg jj lc jn ld jr le jv lf lg lh li bi translated">Google Cloud SDK已安装并通过验证</li><li id="3c87" class="la lb hi ja b jb lj jf lk jj ll jn lm jr ln jv lf lg lh li bi translated">Python 3.7以上版本已安装</li><li id="5449" class="la lb hi ja b jb lj jf lk jj ll jn lm jr ln jv lf lg lh li bi translated">启用了专用Google访问的VPC子网。默认子网是合适的，只要启用了私有Google访问。您可以在这里查看所有的Dataproc无服务器网络需求。</li></ul><h1 id="0374" class="jx jy hi bd jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku bi translated">主要优势</h1><ul class=""><li id="d8ca" class="la lb hi ja b jb kv jf kw jj lo jn lp jr lq jv lf lg lh li bi translated">使用Dataproc Serverless运行Spark batch工作负载，而无需提供和管理您自己的集群。</li><li id="850b" class="la lb hi ja b jb lj jf lk jj ll jn lm jr ln jv lf lg lh li bi translated"><a class="ae jw" href="https://github.com/GoogleCloudPlatform/dataproc-templates/tree/main/python/dataproc_templates/bigquery" rel="noopener ugc nofollow" target="_blank"> BigQueryToGCS </a>模板是开源的，完全可定制，可用于简单的工作。</li><li id="427e" class="la lb hi ja b jb lj jf lk jj ll jn lm jr ln jv lf lg lh li bi translated">您可以将BigQuery中的数据以Parquert、AVRO、CSV和JSON格式导入GCS。</li></ul><h1 id="b1c8" class="jx jy hi bd jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku bi translated">配置参数</h1><p id="2374" class="pw-post-body-paragraph iy iz hi ja b jb kv jd je jf kw jh ji jj kx jl jm jn ky jp jq jr kz jt ju jv hb bi translated">该模板包括以下用于配置执行的参数:</p><ul class=""><li id="1138" class="la lb hi ja b jb jc jf jg jj lc jn ld jr le jv lf lg lh li bi translated"><code class="du lr ls lt lu b">bigquery.gcs.input.table</code> : BigQuery输入表名(格式:project:dataset.table)</li><li id="7ee2" class="la lb hi ja b jb lj jf lk jj ll jn lm jr ln jv lf lg lh li bi translated"><code class="du lr ls lt lu b">bigquery.gcs.output.format</code>:输出文件格式。实木复合地板、avro、csv、json之一</li><li id="a12b" class="la lb hi ja b jb lj jf lk jj ll jn lm jr ln jv lf lg lh li bi translated"><code class="du lr ls lt lu b">bigquery.gcs.output.location</code>:输出文件的GCS位置(格式:gs://BUCKET/…)</li><li id="fdbc" class="la lb hi ja b jb lj jf lk jj ll jn lm jr ln jv lf lg lh li bi translated"><code class="du lr ls lt lu b">bigquery.gcs.output.mode</code>:输出写入模式。append、overwrite、ignore、errorifexists之一。默认为追加。你可以在这里了解每种保存模式的行为<a class="ae jw" href="https://spark.apache.org/docs/latest/sql-data-sources-load-save-functions.html#save-modes" rel="noopener ugc nofollow" target="_blank">。</a></li></ul><h1 id="c51c" class="jx jy hi bd jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku bi translated">使用</h1><ol class=""><li id="9bac" class="la lb hi ja b jb kv jf kw jj lo jn lp jr lq jv lv lg lh li bi translated">如果你要使用“默认的”由GCP生成的VPC网络，请确保你已经启用了私有谷歌访问子网。您仍然需要启用如下的私人访问。</li></ol><figure class="in io ip iq fd ir er es paragraph-image"><div class="er es lw"><img src="../Images/7fcf3ba5eaa2b4f649a5de439d4cd41c.png" data-original-src="https://miro.medium.com/v2/resize:fit:570/format:webp/0*wz7cvV8I27_uF31L.png"/></div></figure><p id="0693" class="pw-post-body-paragraph iy iz hi ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hb bi translated">2.创建一个GCS存储桶，用作Dataproc的暂存位置。这个桶将用于存储运行我们的无服务器集群所需的依赖关系。</p><pre class="in io ip iq fd lx lu ly lz aw ma bi"><span id="b1f7" class="mb jy hi lu b fi mc md l me mf">export STAGING_BUCKET=”my-staging-bucket”<br/>gsutil mb gs://$STAGING_BUCKET</span></pre><p id="db1a" class="pw-post-body-paragraph iy iz hi ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hb bi translated">3.克隆Dataproc模板库并导航到Python。模板的目录</p><pre class="in io ip iq fd lx lu ly lz aw ma bi"><span id="8671" class="mb jy hi lu b fi mc md l me mf">git clone <a class="ae jw" href="https://github.com/GoogleCloudPlatform/dataproc-templates.git" rel="noopener ugc nofollow" target="_blank">https://github.com/GoogleCloudPlatform/dataproc-templates.git</a><br/>cd dataproc-templates/python</span></pre><p id="7122" class="pw-post-body-paragraph iy iz hi ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hb bi translated">4.配置Dataproc无服务器作业</p><p id="29d0" class="pw-post-body-paragraph iy iz hi ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hb bi translated">为了将作业提交给Dataproc Serverless，我们将使用提供的bin/start.sh脚本。该脚本要求我们使用环境变量来配置Dataproc无服务器集群。</p><p id="4674" class="pw-post-body-paragraph iy iz hi ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hb bi translated">强制性配置包括:</p><ul class=""><li id="7696" class="la lb hi ja b jb jc jf jg jj lc jn ld jr le jv lf lg lh li bi translated"><code class="du lr ls lt lu b">GCP_PROJECT</code>:无服务器运行Dataproc的GCP项目。</li><li id="6464" class="la lb hi ja b jb lj jf lk jj ll jn lm jr ln jv lf lg lh li bi translated"><code class="du lr ls lt lu b">REGION</code>:运行Dataproc无服务器的区域。</li><li id="dc5e" class="la lb hi ja b jb lj jf lk jj ll jn lm jr ln jv lf lg lh li bi translated"><code class="du lr ls lt lu b">GCS_STAGING_LOCATION</code>:一个GCS位置，Dataproc将在此存储登台资产。应该在我们之前创建的桶内。</li></ul><pre class="in io ip iq fd lx lu ly lz aw ma bi"><span id="cafa" class="mb jy hi lu b fi mc md l me mf"># Project ID to run the Dataproc Serverless Job<br/>export GCP_PROJECT=&lt;project_id&gt;</span><span id="ce03" class="mb jy hi lu b fi mg md l me mf"># GCP region where the job should be submitted<br/>export REGION=&lt;region&gt;</span><span id="7446" class="mb jy hi lu b fi mg md l me mf"># The staging location for Dataproc<br/>export GCS_STAGING_LOCATION=gs://$STAGING_BUCKET/staging</span></pre><p id="69ad" class="pw-post-body-paragraph iy iz hi ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hb bi translated">在我们的例子中，GCS的BigQuery需要在类路径中有可用的<a class="ae jw" href="https://cloud.google.com/dataproc-serverless/docs/guides/bigquery-connector-spark-example" rel="noopener ugc nofollow" target="_blank"> Spark BigQuery连接器</a>。连接器是公开托管的，所以我们将使用<code class="du lr ls lt lu b">JARS</code>环境变量来添加它。您还可以选择将JAR文件存储在您自己的存储桶中。</p><p id="def1" class="pw-post-body-paragraph iy iz hi ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hb bi translated">为了以AVRO文件格式导出BigQuery数据，我们还需要spark-avro.jar，它已经包含在<code class="du lr ls lt lu b">bin/start.sh</code>中</p><pre class="in io ip iq fd lx lu ly lz aw ma bi"><span id="c71b" class="mb jy hi lu b fi mc md l me mf"># Path to the Spark BigQuery Connector JAR file<br/>export JARS=”gs://spark-lib/bigquery/spark-bigquery-latest_2.12.jar”</span></pre><p id="6938" class="pw-post-body-paragraph iy iz hi ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hb bi translated">5.对GCS Dataproc模板执行BigQuery</p><p id="dbfd" class="pw-post-body-paragraph iy iz hi ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hb bi translated">配置作业后，我们就可以触发它了。我们将运行<code class="du lr ls lt lu b">bin/start.sh</code>脚本，指定我们想要运行的模板和执行的参数值。</p><pre class="in io ip iq fd lx lu ly lz aw ma bi"><span id="13da" class="mb jy hi lu b fi mc md l me mf">./bin/start.sh \<br/>— — template=BIGQUERYTOGCS \<br/>— bigquery.gcs.input.table=&lt;projectId:datasetName.tableName&gt; \<br/>— bigquery.gcs.output.format=&lt;csv|parquet|avro|json&gt; \<br/>— bigquery.gcs.output.mode=&lt;overwrite|append|ignore|errorifexists&gt; \<br/>— bigquery.gcs.output.location=&lt;gs://bucket/path&gt;</span></pre><p id="bf53" class="pw-post-body-paragraph iy iz hi ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hb bi translated"><strong class="ja hj">注意</strong>:提交作业将要求您启用Dataproc API，如果尚未启用的话。</p><p id="1396" class="pw-post-body-paragraph iy iz hi ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hb bi translated">6.监控Spark批处理作业</p><p id="5c5d" class="pw-post-body-paragraph iy iz hi ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hb bi translated">提交作业后，我们将能够在<a class="ae jw" href="https://console.cloud.google.com/dataproc/batches" rel="noopener ugc nofollow" target="_blank"> Dataproc批处理UI </a>中看到。从那里，我们可以查看作业的指标和日志。</p><h1 id="6b0c" class="jx jy hi bd jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku bi translated">参考</h1><ul class=""><li id="8ac1" class="la lb hi ja b jb kv jf kw jj lo jn lp jr lq jv lf lg lh li bi translated"><a class="ae jw" href="https://cloud.google.com/dataproc-serverless/docs/overview" rel="noopener ugc nofollow" target="_blank"> Dataproc无服务</a></li><li id="2890" class="la lb hi ja b jb lj jf lk jj ll jn lm jr ln jv lf lg lh li bi translated"><a class="ae jw" href="https://github.com/GoogleCloudPlatform/dataproc-templates" rel="noopener ugc nofollow" target="_blank"> Dataproc模板库</a></li></ul></div></div>    
</body>
</html>