<html>
<head>
<title>Comparing AI Platform Machine Types using YouTube-8M</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用YouTube-8M比较AI平台机器类型</h1>
<blockquote>原文：<a href="https://medium.com/google-cloud/comparing-ai-platforms-machine-types-using-youtube-8m-1522623f9c74?source=collection_archive---------3-----------------------#2020-05-19">https://medium.com/google-cloud/comparing-ai-platforms-machine-types-using-youtube-8m-1522623f9c74?source=collection_archive---------3-----------------------#2020-05-19</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="b14d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">当训练神经网络模型时，时间是至关重要的。这就是为什么使用不同的机器配置，包括GPU、TPU和多个服务器。</p><p id="aa03" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在过去的几个月里，我一直在探索YouTube-8M项目，之前有关于该项目的帖子，视频数据集，算法以及如何在云中运行它们。在这篇文章中，我在不同的AI平台标准机器配置上训练了来自<em class="jd">入门代码</em>的两个算法，以观察它们如何进行比较。AI平台提供了许多<a class="ae je" href="https://cloud.google.com/ai-platform/training/docs/machine-types" rel="noopener ugc nofollow" target="_blank">规模层，这些规模层是不同机器类型和机器数量</a>的既定配置，以运行作业。</p><p id="f591" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这篇文章介绍了如何运行不同规模的层，以及两种算法(框架级逻辑回归和深度框架模型)在不同层和类型上的时间和成本比较。</p><h1 id="cd4a" class="jf jg hi bd jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc bi translated">命令行标志</h1><p id="bddb" class="pw-post-body-paragraph if ig hi ih b ii kd ik il im ke io ip iq kf is it iu kg iw ix iy kh ja jb jc hb bi translated">YouTube-8M项目在<em class="jd">入门代码</em> repo中包含一个yaml文件，用于在AI平台上运行该项目时设置其配置。您可以每次修改这个文件来改变层，或者您可以做一些更简单的事情，即传入改变层(<code class="du ki kj kk kl b">--scale-tier)</code>和类型(<code class="du ki kj kk kl b">--master-machine-type)</code>)的标志。</p><p id="53bb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">关于如何传入规模层，有几种不同的格式</p><pre class="km kn ko kp fd kq kl kr ks aw kt bi"><span id="6791" class="ku jg hi kl b fi kv kw l kx ky">--scale-tier='BASIC_TPU'<br/>--scale-tier=basic-tpu</span></pre><p id="3213" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在为规模层传入标志时，必须指定<code class="du ki kj kk kl b">--runtime-version</code>，否则会出现错误:</p><p id="a5aa" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jd">“当主Docker映像URI为空时，必须提供运行时版本。”</em></p><p id="ece2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">将以下内容用于此项目。</p><pre class="km kn ko kp fd kq kl kr ks aw kt bi"><span id="a5ba" class="ku jg hi kl b fi kv kw l kx ky">--<!-- -->runtime-version<!-- -->=1.14</span></pre><h1 id="4eef" class="jf jg hi bd jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc bi translated">扩展层级</h1><p id="2fcc" class="pw-post-body-paragraph if ig hi ih b ii kd ik il im ke io ip iq kf is it iu kg iw ix iy kh ja jb jc hb bi translated">我在以下规模层的起始代码中试验运行了两种不同的算法，帧级逻辑和深度帧包(DBoF)。</p><ul class=""><li id="bead" class="kz la hi ih b ii ij im in iq lb iu lc iy ld jc le lf lg lh bi translated"><em class="jd"> STANDARD_1 </em> : 1台主机，8个vcpu | 8 GB内存，4台工作机，8个vcpu | 8 GB内存，3台参数服务器，4个VCPUs | 15 GB内存</li><li id="d6c2" class="kz la hi ih b ii li im lj iq lk iu ll iy lm jc le lf lg lh bi translated"><em class="jd"> PREMIUM_1 </em> : 1台主服务器配16个虚拟CPU | 14.4 GB内存，4台工作服务器配16个虚拟CPU | 14.4 GB内存，3台参数服务器配8个虚拟VCPUs | 52GB内存</li><li id="7a00" class="kz la hi ih b ii li im lj iq lk iu ll iy lm jc le lf lg lh bi translated"><em class="jd"> BASIC_GPU: </em> 1个工作人员，配备1个K80 GPU | 8个VCPUs | 30 GB内存</li><li id="0d46" class="kz la hi ih b ii li im lj iq lk iu ll iy lm jc le lf lg lh bi translated"><em class="jd">基本_TPU </em> : 1个主处理器，带4个VCPUs | 15 GB内存和8个TPU v2内核</li><li id="0416" class="kz la hi ih b ii li im lj iq lk iu ll iy lm jc le lf lg lh bi translated"><em class="jd">自定义</em>:更多信息如下</li></ul><p id="45a0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">传入比例层标志时的示例代码</p><pre class="km kn ko kp fd kq kl kr ks aw kt bi"><span id="b5b3" class="ku jg hi kl b fi kv kw l kx ky">JOB_NAME=yt8m_train_frame_$(date +%Y%m%d_%H%M%S)</span><span id="dbd5" class="ku jg hi kl b fi ln kw l kx ky">gcloud --verbosity=debug ai-platform jobs submit training \<br/>$JOB_NAME --package-path=youtube-8m --module-name=youtube-8m.train \ --staging-bucket=$OUTPUT_BUCKET \<br/><strong class="kl hj">--scale-tier=basic-tpu </strong><strong class="kl hj">--runtime-version=1.14 </strong><strong class="kl hj">--region=us-central1\</strong><br/>-- --train_data_pattern='$TRAIN_BUCKET/train*.tfrecord' \<br/>--frame_features --model=FrameLevelLogisticModel \<br/>--feature_names="rgb,audio" --feature_sizes="1024,128" \<br/>--train_dir=$OUTPUT_BUCKET/$JOB_NAME --start_new_model</span></pre><h2 id="f65d" class="ku jg hi bd jh lo lp lq jl lr ls lt jp iq lu lv jt iu lw lx jx iy ly lz kb ma bi translated">仅CPU</h2><p id="66aa" class="pw-post-body-paragraph if ig hi ih b ii kd ik il im ke io ip iq kf is it iu kg iw ix iy kh ja jb jc hb bi translated">注意，<a class="ae je" rel="noopener" href="/google-cloud/youtube-8m-on-ai-platform-f0a0f8688ce9">上一篇关于如何在AI平台上运行这个项目的文章</a>涵盖了在BASIC_GPU上运行这个项目。使用STANDARD_1和PREMIUM_1没有足够的内存来运行模型。您可以考虑使用允许您增加主内存和工作内存的自定义设置。此外，要指出的是，在以前的帖子中，我在一台服务器上运行了这些模型，只有至少30 GB内存的CPU，我能够运行帧级，但不能运行DBoF。您也许可以找到一个只使用CPU运行DBoF的多工作器配置，但最终，在训练神经网络时使用TPU和GPU是有意义的。</p><h2 id="90c9" class="ku jg hi bd jh lo lp lq jl lr ls lt jp iq lu lv jt iu lw lx jx iy ly lz kb ma bi translated"><strong class="ak">GPU</strong></h2><p id="4d27" class="pw-post-body-paragraph if ig hi ih b ii kd ik il im ke io ip iq kf is it iu kg iw ix iy kh ja jb jc hb bi translated">人工智能平台让您可以访问3种不同类型的图形处理器进行机器配置。标准秤层仅包括k80，您必须使用自定义层来利用其他层。这些是不同类型的GPU，按性能的升序排列。</p><ul class=""><li id="0cae" class="kz la hi ih b ii ij im in iq lb iu lc iy ld jc le lf lg lh bi translated">K80</li><li id="323f" class="kz la hi ih b ii li im lj iq lk iu ll iy lm jc le lf lg lh bi translated">p100</li><li id="bd88" class="kz la hi ih b ii li im lj iq lk iu ll iy lm jc le lf lg lh bi translated">v100</li></ul><p id="9a80" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">当您添加这些不同类型的GPU时，模型的复杂性和数据量将影响您获得的性能提升。</p><h2 id="1a7c" class="ku jg hi bd jh lo lp lq jl lr ls lt jp iq lu lv jt iu lw lx jx iy ly lz kb ma bi translated">TPU入口</h2><p id="7d98" class="pw-post-body-paragraph if ig hi ih b ii kd ik il im ke io ip iq kf is it iu kg iw ix iy kh ja jb jc hb bi translated">TPU秤等级是为您的项目获取TPU的快捷方式。当请求TPU时，你必须指定一个地区；否则，您可以将其关闭。如果您没有选择系统中有TPU的区域，可能会出现以下错误:</p><p id="88dc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">"<em class="jd">资源耗尽美国西部1区没有任何区域拥有所有请求类型的加速器."</em></p><p id="9cf1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">当我离开region时，它默认为<em class="jd"> us-west1 </em>，查看TPU类型和区域列表，它似乎位于<em class="jd"> us-central1 </em>区域。在此<a class="ae je" href="https://cloud.google.com/tpu/docs/types-zones" rel="noopener ugc nofollow" target="_blank">链接</a>中可以找到TPU类型和区域的列表。</p><h2 id="6755" class="ku jg hi bd jh lo lp lq jl lr ls lt jp iq lu lv jt iu lw lx jx iy ly lz kb ma bi translated">自定义层</h2><p id="f9ed" class="pw-post-body-paragraph if ig hi ih b ii kd ik il im ke io ip iq kf is it iu kg iw ix iy kh ja jb jc hb bi translated">定制层听起来确实如此，它提供了机器配置的灵活性。</p><p id="0db1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">使用自定义缩放层时，必须传入master-machine-type。</p><pre class="km kn ko kp fd kq kl kr ks aw kt bi"><span id="8da2" class="ku jg hi kl b fi kv kw l kx ky">--master-machine-type=[<em class="jd">MACHINE TYPE OPTIONS</em>]</span></pre><p id="ac5a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我使用的机器类型选项。</p><ul class=""><li id="e41a" class="kz la hi ih b ii ij im in iq lb iu lc iy ld jc le lf lg lh bi translated"><em class="jd"> complex-model-m-gpu </em> : 4个K80 GPUs | 8个vcpu | 30gb内存</li><li id="86d3" class="kz la hi ih b ii li im lj iq lk iu ll iy lm jc le lf lg lh bi translated"><em class="jd"> complex-model-l-gpu </em> : 8个K80 GPUs | 16个VCPUs | 60 GB内存</li><li id="bbe6" class="kz la hi ih b ii li im lj iq lk iu ll iy lm jc le lf lg lh bi translated"><em class="jd">标配-p100 </em> : 1个P100 GPU | 8个VCPUs | 30GB内存</li><li id="2fbe" class="kz la hi ih b ii li im lj iq lk iu ll iy lm jc le lf lg lh bi translated"><em class="jd">complex-model-m-p100</em>:4个P100 GPU | 16个VCPUs | 60 GB内存</li><li id="7205" class="kz la hi ih b ii li im lj iq lk iu ll iy lm jc le lf lg lh bi translated"><em class="jd">标准-v100 </em> : 1个V100 GPU | 8个vcpu | 30gb内存</li><li id="8962" class="kz la hi ih b ii li im lj iq lk iu ll iy lm jc le lf lg lh bi translated"><em class="jd">大型号v100 </em> : 1个V100 GPU | 16个vcpu | 52gb内存</li></ul><p id="6921" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">传入自定义层和机器类型标志时的示例代码。</p><pre class="km kn ko kp fd kq kl kr ks aw kt bi"><span id="aeea" class="ku jg hi kl b fi kv kw l kx ky">JOB_NAME=yt8m_train_frame_$(date +%Y%m%d_%H%M%S)</span><span id="760c" class="ku jg hi kl b fi ln kw l kx ky">gcloud --verbosity=debug ai-platform jobs submit training \<br/>$JOB_NAME --package-path=youtube-8m --module-name=youtube-8m.train \ --staging-bucket=$OUTPUT_BUCKET \<br/><strong class="kl hj">--scale-tier=custom --master-machine-type=standard_p100 \<br/></strong><strong class="kl hj">--runtime-version=1.14 </strong><strong class="kl hj">\</strong><br/>-- --train_data_pattern='$TRAIN_BUCKET/train*.tfrecord' \<br/>--frame_features --model=FrameLevelLogisticModel \<br/>--feature_names="rgb,audio" --feature_sizes="1024,128" \<br/>--train_dir=$OUTPUT_BUCKET/$JOB_NAME --start_new_model</span></pre><p id="ebd0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">请注意，对于机器类型、配置以及增加员工数量的能力，还有更精细的控制空间。更多信息可以在文章顶部的链接中找到。在这次演示中，我坚持使用一些标准配置，并且没有在提供的范围之外增加工作人员。因此，对于大多数示例，它保持在单个机器上，并且定制中的所有示例都包括GPU。</p><p id="5c62" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">有关配置的更多详细信息，请参见下面的截图并查看<a class="ae je" href="https://cloud.google.com/ai-platform/training/docs/machine-types#compare-machine-types" rel="noopener ugc nofollow" target="_blank">文档</a>:</p><figure class="km kn ko kp fd mc er es paragraph-image"><div class="er es mb"><img src="../Images/3e4d4c6b72df0e930e0561e9de3276cc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jowk1NEsTE6ry-U-2ZAQFQ.png"/></div></figure><h2 id="fb9d" class="ku jg hi bd jh lo lp lq jl lr ls lt jp iq lu lv jt iu lw lx jx iy ly lz kb ma bi translated">定额</h2><p id="7ad4" class="pw-post-body-paragraph if ig hi ih b ii kd ik il im ke io ip iq kf is it iu kg iw ix iy kh ja jb jc hb bi translated">以下是为我的项目自动设置的配额。</p><ul class=""><li id="4471" class="kz la hi ih b ii ij im in iq lb iu lc iy ld jc le lf lg lh bi translated">V2 TPU 16号</li><li id="f879" class="kz la hi ih b ii li im lj iq lk iu ll iy lm jc le lf lg lh bi translated">TPU V3街16号</li><li id="32fc" class="kz la hi ih b ii li im lj iq lk iu ll iy lm jc le lf lg lh bi translated">2 P4</li><li id="d027" class="kz la hi ih b ii li im lj iq lk iu ll iy lm jc le lf lg lh bi translated">2 V100</li><li id="5913" class="kz la hi ih b ii li im lj iq lk iu ll iy lm jc le lf lg lh bi translated">40 K80</li><li id="c457" class="kz la hi ih b ii li im lj iq lk iu ll iy lm jc le lf lg lh bi translated">40 P100</li></ul><p id="1bd6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">当我尝试用两个以上V100s的机器类型进行实验时，我在得到的错误中发现了这个问题。如果您的工作需要您扩大机器的规模，那么您需要提出配额增加请求。如果我在不久的将来获得超过2台V100s的访问权限，我将运行其他类型的机器，并在下面添加详细信息。</p><h1 id="3f50" class="jf jg hi bd jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc bi translated">性能比较</h1><p id="99bb" class="pw-post-body-paragraph if ig hi ih b ii kd ik il im ke io ip iq kf is it iu kg iw ix iy kh ja jb jc hb bi translated">现在有趣的是，比较两种不同算法在所有这些不同配置下的性能。人工智能平台和任何托管服务的好处在于，你可以一次启动所有这些服务，它们可以并行运行。</p><p id="12bd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">提醒一下，预定义比例轮胎的价格是每培训单位每小时0.49美元，这是基本价格。要得到工作的成本，用<em class="jd">乘以消耗的毫升单位</em>。<em class="jd">消耗的ML单位</em> (MLU)相当于包含工作持续时间的训练单位。</p><p id="01e1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果您自己尝试，时间和成本可能会略有不同，但应该在下面提供的几分钟范围内。</p><h2 id="391c" class="ku jg hi bd jh lo lp lq jl lr ls lt jp iq lu lv jt iu lw lx jx iy ly lz kb ma bi translated">框架级逻辑</h2><p id="2586" class="pw-post-body-paragraph if ig hi ih b ii kd ik il im ke io ip iq kf is it iu kg iw ix iy kh ja jb jc hb bi translated">每个要点提供了规模层级/机器类型、总培训时间和总成本。</p><ul class=""><li id="7a7c" class="kz la hi ih b ii ij im in iq lb iu lc iy ld jc le lf lg lh bi translated"><em class="jd"> BASIC_GPU: </em> 13小时9分21.85 MLU * $ 0.49 = $ 10.71</li><li id="2cf4" class="kz la hi ih b ii li im lj iq lk iu ll iy lm jc le lf lg lh bi translated"><em class="jd">基本_TPU </em> : <em class="jd"> </em> 20小时51分198.58 MLU * $ 0.49 = $ 97.31</li><li id="4af0" class="kz la hi ih b ii li im lj iq lk iu ll iy lm jc le lf lg lh bi translated"><em class="jd">复杂模型m图形处理器:</em> 11小时30分59.27 MLU * $ 0.49 = $ 29.04</li><li id="40f4" class="kz la hi ih b ii li im lj iq lk iu ll iy lm jc le lf lg lh bi translated"><em class="jd">复杂-模型-l-gpu </em> : 11小时7分钟，114.72 MLU * $ 0.49 = $ 56.21</li><li id="c973" class="kz la hi ih b ii li im lj iq lk iu ll iy lm jc le lf lg lh bi translated"><em class="jd">标准-p100</em>:12小时45分47.39 MLU * $ 0.49 = $ 23.22</li><li id="dba9" class="kz la hi ih b ii li im lj iq lk iu ll iy lm jc le lf lg lh bi translated"><em class="jd">复杂型号m-p100 </em> : 11小时57分159.61 MLU * $ 0.49 = $ 78.21</li><li id="73fc" class="kz la hi ih b ii li im lj iq lk iu ll iy lm jc le lf lg lh bi translated">标准版v100  : 12小时19分71.39 MLU * $ 0.49 = $ 34.98</li><li id="620e" class="kz la hi ih b ii li im lj iq lk iu ll iy lm jc le lf lg lh bi translated">大型号v100  : 13小时17分钟，79.28 MLU * $ 0.49 = $ 38.85</li></ul><p id="1443" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jd">基本GPU </em>配置是下一个最低成本选项<em class="jd">标准p100 </em>的一半成本，但运行时间几乎要多30分钟。这是确定时间价值的一个很好的例子。你能等30分钟训练结束吗？大概吧。培训时，您很可能需要多次运行这些机器来调整和试验模型。这些额外的时间可以累积起来，使用一台可以节省一些时间的机器似乎更划算(尤其是考虑到最后期限)。</p><h2 id="02cf" class="ku jg hi bd jh lo lp lq jl lr ls lt jp iq lu lv jt iu lw lx jx iy ly lz kb ma bi translated">深框架包(DBoF)</h2><p id="7f73" class="pw-post-body-paragraph if ig hi ih b ii kd ik il im ke io ip iq kf is it iu kg iw ix iy kh ja jb jc hb bi translated">每个要点提供了规模层级/机器类型、总培训时间和总成本。</p><ul class=""><li id="4b7e" class="kz la hi ih b ii ij im in iq lb iu lc iy ld jc le lf lg lh bi translated"><em class="jd">基本_GPU: </em> 1天10小时56.26 MLU * $ 0.49 = $ 27.57</li><li id="c135" class="kz la hi ih b ii li im lj iq lk iu ll iy lm jc le lf lg lh bi translated"><em class="jd">基本_ TPU</em>:<em class="jd">T3】内存不足，以非零状态退出</em></li><li id="8f72" class="kz la hi ih b ii li im lj iq lk iu ll iy lm jc le lf lg lh bi translated"><em class="jd">复杂模型m GPU:</em>1天4小时145.95 MLU * $ 0.49 = $ 71.52</li><li id="9745" class="kz la hi ih b ii li im lj iq lk iu ll iy lm jc le lf lg lh bi translated"><em class="jd"> complex-model-l-gpu </em> : 1天3小时286.36 MLU * $ 0.49 = $ 140.32</li><li id="90fe" class="kz la hi ih b ii li im lj iq lk iu ll iy lm jc le lf lg lh bi translated"><em class="jd">标准-p100 </em> : 16小时59分63.14 MLU * $ 0.49 = $ 30.94</li><li id="01c2" class="kz la hi ih b ii li im lj iq lk iu ll iy lm jc le lf lg lh bi translated"><em class="jd">复杂型号m-p100 </em> : 16小时22分219.11 MLU * $ 0.49 = $ 107.36</li><li id="af29" class="kz la hi ih b ii li im lj iq lk iu ll iy lm jc le lf lg lh bi translated"><em class="jd">标准-v100 </em> : 16小时24分钟，92.8 MLU * $ 0.49 = $ 45.47</li><li id="b9f8" class="kz la hi ih b ii li im lj iq lk iu ll iy lm jc le lf lg lh bi translated"><em class="jd">大型号v100 </em> : 15小时23分91.76 MLU * $ 0.49 = $ 44.96</li></ul><p id="ead1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于这种模式，很明显v100 GPUS略快，并且几乎与p100一样具有成本效益。考虑到时间因素，这几乎是最快也是最便宜的选择。此外，当在复杂模型下添加更多GPU时，成本显著增加，但时间并没有改善多少。在这种使用情况下，单个GPU可以完成工作，但在其他情况下，基于模型、数据和时间的限制，需要多个GPU。</p><p id="693f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">还要指出的是，如果您想试验TPU，那么创建一个使用它们的自定义层，并使用一个比BASIC_TPU配置具有更多内存(至少30 GB)的main/master。</p><p id="d712" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">总的来说，对于这两种型号，v100 GPUs显示出强大的性能，但在考虑时间和成本权衡时，单个p100是最佳选择。</p><h1 id="986c" class="jf jg hi bd jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc bi translated">包裹</h1><p id="192a" class="pw-post-body-paragraph if ig hi ih b ii kd ik il im ke io ip iq kf is it iu kg iw ix iy kh ja jb jc hb bi translated">这篇文章重点回顾了不同的人工智能平台规模层和机器类型如何使用YouTube-8M示例算法执行。扩展GPU、TPU和服务器的数量取决于模型的复杂程度、数据量以及完成工作所需的时间。这些将帮助您确定使用什么，使用几个服务器或GPU不一定更快。在启动平台之前，花时间了解您的需求是非常重要的。</p><p id="ad5d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这篇文章表明，对于这个特定的项目和代码提供的两种算法，考虑到时间和成本，使用standard-p100的定制层是最佳选择。如果您研究其他型号，不同的配置可能更适合您的需求。此外，我并没有穷尽所有可以定制这些配置的方法，因此可能会有更好的选择。我要求你去寻找它，如果你找到了就告诉我。</p></div></div>    
</body>
</html>