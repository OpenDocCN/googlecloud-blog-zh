<html>
<head>
<title>Jupyter + Tensorflow + Nvidia GPU + Docker + Google Compute Engine</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">jupyter+tensor flow+Nvidia GPU+Docker+Google计算引擎</h1>
<blockquote>原文：<a href="https://medium.com/google-cloud/jupyter-tensorflow-nvidia-gpu-docker-google-compute-engine-4a146f085f17?source=collection_archive---------0-----------------------#2017-06-07">https://medium.com/google-cloud/jupyter-tensorflow-nvidia-gpu-docker-google-compute-engine-4a146f085f17?source=collection_archive---------0-----------------------#2017-06-07</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="5a1f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">TL；DR:按照这个食谱</strong>在Google Cloud上与Tensorflow、Jupyter、Docker和Nvidia GPUs一起工作，节省时间，减少麻烦。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/0cee4f661d56e02f1f2a6fdc1a24ad26.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mx_ahBVWCK-trNGTNx4RBA.png"/></div></div></figure><p id="edc0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">动机</strong> : <strong class="ih hj">企业喜欢快速、数据驱动的洞察力</strong>，他们雇佣数据科学家来创造这种洞察力。实践<a class="ae jp" href="https://en.wikipedia.org/wiki/Data_science" rel="noopener ugc nofollow" target="_blank">数据科学</a>是一个探索性的迭代过程，需要大量的计算资源和时间。为了更好地支持探索性迭代，数据科学家经常使用像<a class="ae jp" href="http://jupyter.org/" rel="noopener ugc nofollow" target="_blank"> Jupyter </a>这样的笔记本，并加速他们越来越多地使用的<a class="ae jp" href="https://en.wikipedia.org/wiki/Graphics_processing_unit" rel="noopener ugc nofollow" target="_blank">GPU</a>的<a class="ae jp" href="http://tensorflow.org" rel="noopener ugc nofollow" target="_blank"> Tensorflow </a>作业的计算。然而，GPU价格昂贵，而且需要小心管理资源，因为<strong class="ih hj">企业也喜欢高效的操作</strong>。</p><p id="e83b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">目前云计算中有一种趋势是使用Kubernetes和Docker来提高资源利用率。<strong class="ih hj">如果像Jupyter和GPU这样的数据科学工具可以用Docker和Kubernetes </strong>来管理岂不是很棒？它可以节省时间和金钱。这是可能的，在我达到这个工作配置之前，我遇到了几个版本/依赖性问题。请重复使用！</p><h1 id="c4e0" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">创建一个GCE实例</h1><p id="ad4a" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">首先，创建访问Jupyter (8888)和Tensorboard (6006)的防火墙规则</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es kt"><img src="../Images/53a097eb0e315523901ccf573690291a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ddhaSJbfBDL37SKlluFpgA.png"/></div></div></figure><p id="0c24" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">然后创建一个GCE实例。对于该实例:</p><ul class=""><li id="b919" class="ku kv hi ih b ii ij im in iq kw iu kx iy ky jc kz la lb lc bi translated">使用操作系统<strong class="ih hj"> Ubuntu 16.04 LTS </strong></li><li id="7c07" class="ku kv hi ih b ii ld im le iq lf iu lg iy lh jc kz la lb lc bi translated">分配一个<strong class="ih hj"> 50GB </strong>启动盘</li><li id="00a7" class="ku kv hi ih b ii ld im le iq lf iu lg iy lh jc kz la lb lc bi translated">指定您至少需要一个<strong class="ih hj"> K80 GPU </strong></li><li id="4791" class="ku kv hi ih b ii ld im le iq lf iu lg iy lh jc kz la lb lc bi translated">使用“<strong class="ih hj"> jupyter </strong>”和“<strong class="ih hj"> tensorboard </strong>”进行标记，以应用您创建的防火墙规则</li></ul><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es li"><img src="../Images/27d7016b106fa290eba2caec32ae7b78.png" data-original-src="https://miro.medium.com/v2/resize:fit:986/format:webp/1*Qd0mJLBKhA83nEAtpr-Vhw.png"/></div></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lj"><img src="../Images/f9c01f564bcba90ce54a0335107cfc6c.png" data-original-src="https://miro.medium.com/v2/resize:fit:910/format:webp/1*0fV2QB-yc71D9yMwmubzHQ.png"/></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lk"><img src="../Images/96c3f250f30dc2c1e47ef8552d856148.png" data-original-src="https://miro.medium.com/v2/resize:fit:912/format:webp/1*RI8WAclKn3IyhBTOfCqZjg.png"/></div></figure><h1 id="e123" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">安装并验证CUDA可以访问GPU</h1><p id="c681" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">使用Nvidia的CUDA库来访问GPU。</p><p id="f3bc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">下一步是SSH到您创建的计算节点，然后使用这个脚本[ <a class="ae jp" href="https://cloud.google.com/compute/docs/gpus/add-gpus" rel="noopener ugc nofollow" target="_blank"> source </a> ]来安装CUDA:</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="ll lm l"/></div></figure><p id="38a0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">您可以使用<code class="du ln lo lp lq b">wget</code>将源<em class="lr">要点</em>和管道拉入bash:</p><pre class="je jf jg jh fd ls lq lt lu aw lv bi"><span id="b15e" class="lw jr hi lq b fi lx ly l lz ma">wget -O - -q '<a class="ae jp" href="https://gist.githubusercontent.com/allenday/f426e0f146d86bfc3dada06eda55e123/raw/41b6d3bc8ab2dfe1e1d09135851c8f11b8dc8db3/install-cuda.sh" rel="noopener ugc nofollow" target="_blank">https://gist.githubusercontent.com/allenday/f426e0f146d86bfc3dada06eda55e123/raw/41b6d3bc8ab2dfe1e1d09135851c8f11b8dc8db3/install-cuda.sh</a>' | sudo bash</span></pre><p id="4e3c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果<strong class="ih hj"> CUDA </strong>安装成功，运行<code class="du ln lo lp lq b">nvidia-smi</code>将显示一个描述可用<strong class="ih hj"> Tesla K80 </strong> GPU的表格。</p><pre class="je jf jg jh fd ls lq lt lu aw lv bi"><span id="a350" class="lw jr hi lq b fi lx ly l lz ma">nvidia-smi</span></pre><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="ll lm l"/></div></figure><h1 id="3eea" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">安装Docker(-引擎)和Nvidia-Docker</h1><p id="c565" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">对于<code class="du ln lo lp lq b">docker</code>，你需要Docker的<code class="du ln lo lp lq b">docker-ce</code>版本，而不是Ubuntu自带的<code class="du ln lo lp lq b">docker.io</code>包。使用从[ <a class="ae jp" href="https://docs.docker.com/engine/installation/linux/ubuntu/" rel="noopener ugc nofollow" target="_blank">源</a>派生的脚本。</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="ll lm l"/></div></figure><p id="a531" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">或者用我的:</p><pre class="je jf jg jh fd ls lq lt lu aw lv bi"><span id="290a" class="lw jr hi lq b fi lx ly l lz ma">wget -O - -q '<a class="ae jp" href="https://gist.githubusercontent.com/allenday/c875eaf21a2b416f6478c0a48e428f6a/raw/f7feca1acc1a992afa84f347394fd7e4bfac2599/install-docker-ce.sh" rel="noopener ugc nofollow" target="_blank">https://gist.githubusercontent.com/allenday/c875eaf21a2b416f6478c0a48e428f6a/raw/f7feca1acc1a992afa84f347394fd7e4bfac2599/install-docker-ce.sh</a>' | sudo bash</span></pre><p id="8554" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">然后从deb文件[ <a class="ae jp" href="https://github.com/NVIDIA/nvidia-docker/releases/" rel="noopener ugc nofollow" target="_blank">源</a> ]安装<code class="du ln lo lp lq b">nvidia-docker</code>:</p><pre class="je jf jg jh fd ls lq lt lu aw lv bi"><span id="9b66" class="lw jr hi lq b fi lx ly l lz ma">wget <a class="ae jp" href="https://github.com/NVIDIA/nvidia-docker/releases/download/v1.0.1/nvidia-docker_1.0.1-1_amd64.deb" rel="noopener ugc nofollow" target="_blank">https://github.com/NVIDIA/nvidia-docker/releases/download/v1.0.1/nvidia-docker_1.0.1-1_amd64.deb</a></span><span id="5d88" class="lw jr hi lq b fi mb ly l lz ma">sudo dpkg -i nvidia-docker*.deb</span></pre><h1 id="439e" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">验证GPU在Docker容器中是否可见</h1><p id="89ab" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">开始<code class="du ln lo lp lq b">nvidia-docker-plugin</code>。<strong class="ih hj">必须作为根用户</strong>运行。</p><pre class="je jf jg jh fd ls lq lt lu aw lv bi"><span id="e835" class="lw jr hi lq b fi lx ly l lz ma">sudo nvidia-docker-plugin &amp;</span></pre><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="ll lm l"/></div></figure><p id="f6d5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在确保docker容器可以看到GPU:</p><pre class="je jf jg jh fd ls lq lt lu aw lv bi"><span id="6e6e" class="lw jr hi lq b fi lx ly l lz ma">sudo nvidia-docker run --rm nvidia/cuda nvidia-smi</span></pre><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="ll lm l"/></div></figure><p id="e51a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如上所示，您将得到与在提示符下运行<code class="du ln lo lp lq b">nvidia-smi</code>时相同类型的表，而不是在Docker容器中运行。</p><h1 id="4e10" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">[可选]创建快照卷</h1><p id="6594" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">如果你按照上面的步骤去做，你可能会注意到这花了一些时间。当你运行一个GPU实例时，成本会更高。如果您以后需要一个支持GPU的实例，您可以通过快照这个工作映像，然后从它启动，来避免重复这些步骤和浪费时间/金钱。</p><h1 id="efdb" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">发射Jupyter和Tensorboard</h1><pre class="je jf jg jh fd ls lq lt lu aw lv bi"><span id="d069" class="lw jr hi lq b fi lx ly l lz ma">sudo nvidia-docker run --rm --name tf1 -p 8888:8888 -p 6006:6006 gcr.io/tensorflow/tensorflow:latest-gpu jupyter notebook --allow-root</span></pre><p id="1cb1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果上面的命令显示一行类似于:</p><pre class="je jf jg jh fd ls lq lt lu aw lv bi"><span id="6b3f" class="lw jr hi lq b fi lx ly l lz ma">http://localhost:8888/?token=c8caba947dfd4c97414447c074325faf399cf8a157d0ce2f</span></pre><p id="35d0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">…你在做生意。找到您的GCE实例的外部IP地址，并在端口8888上连接到它，例如<code class="du ln lo lp lq b"><a class="ae jp" href="http://EXTERNAL_IP:8888/," rel="noopener ugc nofollow" target="_blank">http://EXTERNAL_IP:8888/</a></code>，在您的控制台中键入(类似的)令牌，您就有了一台运行Tensorflow的支持GPU的Jupyter笔记本。</p><h1 id="290d" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">请参见</h1><div class="mc md ez fb me mf"><a rel="noopener follow" target="_blank" href="/@gooshan/for-those-who-had-trouble-in-past-months-of-getting-google-s-tensorflow-to-work-inside-a-docker-9ec7a4df945b"><div class="mg ab dw"><div class="mh ab mi cl cj mj"><h2 class="bd hj fi z dy mk ea eb ml ed ef hh bi translated">用Docker和GPU运行TensorFlow</h2><div class="mm l"><p class="bd b fp z dy mk ea eb ml ed ef dx translated">medium.com</p></div></div><div class="mn l"><div class="mo l mp mq mr mn ms jn mf"/></div></div></a></div><div class="mc md ez fb me mf"><a href="https://vxlabs.com/2017/03/17/miniconda3-tensorflow-keras-on-google-compute-engine-gpu-instance-the-step-by-step-guide/" rel="noopener  ugc nofollow" target="_blank"><div class="mg ab dw"><div class="mh ab mi cl cj mj"><h2 class="bd hj fi z dy mk ea eb ml ed ef hh bi translated">谷歌计算引擎GPU实例:一步一步指南。</h2><div class="mt l"><h3 class="bd b fi z dy mk ea eb ml ed ef dx translated">在使用SSH端口连接到实例之后，重定向:SSH-L 8889:localhost:8888 CP Botha @ EXTERNAL _ IP...</h3></div><div class="mm l"><p class="bd b fp z dy mk ea eb ml ed ef dx translated">vxlabs.com</p></div></div><div class="mn l"><div class="mu l mp mq mr mn ms jn mf"/></div></div></a></div></div></div>    
</body>
</html>