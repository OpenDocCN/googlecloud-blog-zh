<html>
<head>
<title>Framework for building a configuration driven Data Lake on GCP using Data Fusion and Composer</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用数据融合和Composer在GCP构建配置驱动的数据湖的框架</h1>
<blockquote>原文：<a href="https://medium.com/google-cloud/building-a-data-lake-on-gcp-using-data-fusion-and-composer-49d1ba4b1d73?source=collection_archive---------2-----------------------#2021-01-15">https://medium.com/google-cloud/building-a-data-lake-on-gcp-using-data-fusion-and-composer-49d1ba4b1d73?source=collection_archive---------2-----------------------#2021-01-15</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="52a3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">本系列的第一篇文章概述了使用数据融合进行数据集成和使用Cloud Composer进行编排的数据湖解决方案架构。</p><p id="183f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在本文中，我将概述基于该架构的详细解决方案设计。本文假设您对GCP数据融合和Composer有一些基本的了解。如果您是GCP的新手，您可以先阅读本系列的<a class="ae jd" href="https://nehajo.medium.com/designing-a-data-lake-on-gcp-with-data-fusion-and-composer-e2ea0a753525" rel="noopener">上一篇文章</a>,了解架构中使用的不同服务，然后再继续。</p><h1 id="323d" class="je jf hi bd jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb bi translated">设计方法</h1><p id="29ff" class="pw-post-body-paragraph if ig hi ih b ii kc ik il im kd io ip iq ke is it iu kf iw ix iy kg ja jb jc hb bi translated">这里描述的解决方案设计提供了一个框架，通过使用简单的配置来接收大量的源对象。一旦开发了框架，向数据湖摄取添加新的源/对象只需要为新的源添加新的配置。</p><p id="5e35" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我将在不久的将来发布这个框架的代码。请留意最新消息。 </p><h1 id="2c76" class="je jf hi bd jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb bi translated">设计组件</h1><p id="10bb" class="pw-post-body-paragraph if ig hi ih b ii kc ik il im kd io ip iq ke is it iu kf iw ix iy kg ja jb jc hb bi translated">解决方案设计包括4个主要部分。</p><ul class=""><li id="b423" class="ki kj hi ih b ii ij im in iq kk iu kl iy km jc kn ko kp kq bi translated"><a class="ae jd" href="https://cloud.google.com/data-fusion" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj">数据融合</strong> </a> <strong class="ih hj">管道</strong>进行数据移动</li><li id="8d53" class="ki kj hi ih b ii kr im ks iq kt iu ku iy kv jc kn ko kp kq bi translated"><strong class="ih hj">定制摄取前</strong>和<strong class="ih hj">摄取后任务</strong></li><li id="a31e" class="ki kj hi ih b ii kr im ks iq kt iu ku iy kv jc kn ko kp kq bi translated"><strong class="ih hj">配置</strong>为可重用组件和任务提供输入</li><li id="28a0" class="ki kj hi ih b ii kr im ks iq kt iu ku iy kv jc kn ko kp kq bi translated"><a class="ae jd" href="https://cloud.google.com/composer" rel="noopener ugc nofollow" target="_blank"><strong class="ih hj">Composer</strong></a><strong class="ih hj">DAGs</strong>执行定制任务，根据配置调用数据融合管道</li></ul><p id="68b3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我从编排解决方案所有部分的Composer DAG的高级视图开始，然后在接下来的部分中提供对解决方案不同部分的深入了解。</p><h1 id="0fe4" class="je jf hi bd jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb bi translated">Composer DAG结构</h1><p id="ab0f" class="pw-post-body-paragraph if ig hi ih b ii kc ik il im kd io ip iq ke is it iu kf iw ix iy kg ja jb jc hb bi translated">Composer <a class="ae jd" href="https://nehajo.medium.com/designing-a-data-lake-on-gcp-with-data-fusion-and-composer-e2ea0a753525" rel="noopener"> DAG </a>是工作流编排器。它可以大致包括下图所示的组件。</p><figure class="kx ky kz la fd lb er es paragraph-image"><div class="er es kw"><img src="../Images/0470aba15e00343f92ad205f1d98c636.png" data-original-src="https://miro.medium.com/v2/resize:fit:1228/format:webp/1*orwR02yhNlVtkQjqdf0_Pg.png"/></div><figcaption class="le lf et er es lg lh bd b be z dx translated"><em class="li">作曲DAG的组件</em></figcaption></figure><p id="ddae" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">DAG读取配置文件<em class="kh">(将在下一节中详细介绍)</em>以获取详细信息，例如源和目标详细信息<em class="kh">、</em>，并将该信息传递给接收前和接收后任务以及数据融合管道。下图描述了整个流程。</p><figure class="kx ky kz la fd lb er es paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="er es lj"><img src="../Images/6d780261c1ab8bce70c584cdfdf140c7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*y_5E79oaaWjWxx3VSHQjRg.png"/></div></div><figcaption class="le lf et er es lg lh bd b be z dx translated">工作流程</figcaption></figure><p id="0a7b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="kh">每个摄取前或摄取后任务都是DAG中不同的气流任务，并调用包含任务逻辑的python代码。下面是基于上述方法的Composer DAG的截图。</em></p><p id="b797" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">基于上述流程，下面是一个示例Composer DAG，包括摄取前和摄取后任务，以及对数据融合管道的调用。</p><figure class="kx ky kz la fd lb er es paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="er es lo"><img src="../Images/b8f51f28c0824360b0c4f43e6fe950ac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2IkdnzfUVEh5Xk_lvfAk1A.png"/></div></div></figure><h1 id="cc66" class="je jf hi bd jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb bi translated">摄入配置</h1><p id="548d" class="pw-post-body-paragraph if ig hi ih b ii kc ik il im kd io ip iq ke is it iu kf iw ix iy kg ja jb jc hb bi translated">此解决方案中的配置分为三个级别:</p><figure class="kx ky kz la fd lb er es paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="er es lp"><img src="../Images/ff88fc94ee8a9fa04df9f67aae7acb99.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gGYMFYAFk9RY8lWfeMbyMA.png"/></div></div><figcaption class="le lf et er es lg lh bd b be z dx translated"><em class="li">样本环境配置</em></figcaption></figure><p id="622e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">环境配置</strong>GCP项目ID、数据融合实例、GCS桶信息等信息。</p><figure class="kx ky kz la fd lb er es paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="er es lq"><img src="../Images/8931e419deda8e1ef1d5f11512f04c28.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ewo_uAmQOaiOjX-eX3w9Yw.png"/></div></div><figcaption class="le lf et er es lg lh bd b be z dx translated"><em class="li">DAG配置示例</em></figcaption></figure><p id="bb54" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> DAG配置</strong>为每个源系统提供DAG所需的信息。</p><figure class="kx ky kz la fd lb er es paragraph-image"><div class="er es lr"><img src="../Images/101ebeaaa634da267cc25fd7c190a3ed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1080/format:webp/1*u8eNlP4e-Eb_hnOPmnqRXg.png"/></div><figcaption class="le lf et er es lg lh bd b be z dx translated">任务配置示例</figcaption></figure><p id="42b9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">任务配置</strong>指定数据融合管道的输入，例如源、定界符和要触发的管道。</p><h2 id="4f01" class="ls jf hi bd jg lt lu lv jk lw lx ly jo iq lz ma js iu mb mc jw iy md me ka mf bi translated">DAGs中的动态任务生成</h2><p id="6f8f" class="pw-post-body-paragraph if ig hi ih b ii kc ik il im kd io ip iq ke is it iu kf iw ix iy kg ja jb jc hb bi translated">DAG被编写为基于任务配置文件动态地生成Composer任务。以这种方式生成的每个任务将使用提供的源规范触发相应的数据融合管道。</p><h1 id="c175" class="je jf hi bd jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb bi translated">数据融合管道和定制插件</h1><p id="c86b" class="pw-post-body-paragraph if ig hi ih b ii kc ik il im kd io ip iq ke is it iu kf iw ix iy kg ja jb jc hb bi translated">下面显示的是一个从GCS加载文件到BQ的数据融合管道。<em class="kh">这是一个简单的例子，您可以根据自己对各种数据源的需求，使用额外的逻辑编写UI驱动的管道。</em></p><figure class="kx ky kz la fd lb er es paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="er es mg"><img src="../Images/0f30077a56213f5bc00c4bba5ceba5ae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jkJe11MYWVfXCRW3pURU_Q.png"/></div></div></figure><p id="d884" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">上面的管道使用Wrangler插件来解析文件布局。您甚至可以更进一步，编写自己的* *定制插件，该插件可以读取多个文件，每个文件都有不同的布局，动态解析它们并一次性加载到各自的目标中。尽管编写定制插件需要java编程技能，但是当您在文件中发现新的场景时，编写通用的自动解析逻辑会变得很棘手。</p><p id="a7b3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="kh">* *数据融合提供了多种源、</em> <a class="ae jd" href="https://cdap.atlassian.net/wiki/spaces/DOCS/pages/554434650/Data+Pipeline+Plugin+Types" rel="noopener ugc nofollow" target="_blank"> <em class="kh">和外挂</em> </a> <em class="kh">开箱即用。如果您需要执行某些非常符合您的需求且开箱即用的转换，您也可以</em> <a class="ae jd" href="https://cdap.atlassian.net/wiki/spaces/DOCS/pages/480313897/Developing+Plugins+Guide" rel="noopener ugc nofollow" target="_blank"> <em class="kh">编写您自己的定制插件</em> </a> <em class="kh">并在您的管道中使用它们。</em></p><h1 id="746b" class="je jf hi bd jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb bi translated">从Composer调用数据融合管道</h1><p id="27ac" class="pw-post-body-paragraph if ig hi ih b ii kc ik il im kd io ip iq ke is it iu kf iw ix iy kg ja jb jc hb bi translated">现在我们已经深入了解了数据融合管道和Composer DAG需要执行的任务，那么Composer如何调用数据融合管道呢？</p><p id="8d29" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><a class="ae jd" href="http://airflow.apache.org/docs/apache-airflow-providers-google/stable/operators/cloud/datafusion.html" rel="noopener ugc nofollow" target="_blank">CloudDataFusionStartPipelineOperator</a>允许从气流DAG触发数据融合管道。在这个<a class="ae jd" href="https://cloud.google.com/blog/products/data-analytics/easier-management-for-cloud-etl-elt-pipelines" rel="noopener ugc nofollow" target="_blank"> GCP的博客</a>中有更多关于这个运营商的信息。</p><figure class="kx ky kz la fd lb er es paragraph-image"><div class="er es mh"><img src="../Images/8e1db52e8cde8e0911dce92baa543b57.png" data-original-src="https://miro.medium.com/v2/resize:fit:1116/format:webp/1*-cb0nO9RbkFPcXqRLGwVOg.png"/></div><figcaption class="le lf et er es lg lh bd b be z dx translated">调用数据融合管道的示例气流任务</figcaption></figure><h1 id="3d77" class="je jf hi bd jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb bi translated">从Composer中调用Python可执行文件执行摄取前和摄取后任务</h1><p id="e4cd" class="pw-post-body-paragraph if ig hi ih b ii kc ik il im kd io ip iq ke is it iu kf iw ix iy kg ja jb jc hb bi translated">通常，有些定制任务需要在数据摄取工作流中执行，但是不属于或者不能在ETL工具中执行。一些典型的例子包括定制源文件的清理以去除数据中不兼容的特殊字符，更新目标表中的列描述以支持数据可发现性，基于某些条件归档处理过的文件，以及在前面示出的DAG中示出的每个任务结束时在定制审计表中定制记录工作流状态。</p><p id="0695" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这些任务可以用python编码，然后可以在Airflow <a class="ae jd" href="https://airflow.apache.org/docs/apache-airflow/stable/_api/airflow/operators/python/index.html" rel="noopener ugc nofollow" target="_blank"> PythonOperator </a>的帮助下从Composer内部调用。我不会深入讨论这个操作符的细节，因为已经有很多关于它的文章了。</p><figure class="kx ky kz la fd lb er es paragraph-image"><div class="er es mi"><img src="../Images/d87d491b7883f51e4c777ed877e1e539.png" data-original-src="https://miro.medium.com/v2/resize:fit:916/format:webp/1*xm5WfGdsWWhmyftKUNUbtA.png"/></div><figcaption class="le lf et er es lg lh bd b be z dx translated">用于执行自定义任务的Python运算符片段</figcaption></figure><h1 id="cf15" class="je jf hi bd jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb bi translated">关键要点</h1><p id="ca1e" class="pw-post-body-paragraph if ig hi ih b ii kc ik il im kd io ip iq ke is it iu kf iw ix iy kg ja jb jc hb bi translated">上述解决方案设计提供了一个框架，可以将混合生态系统中的数据接收到数据湖中。它通过使用简单的配置来提供关于环境、源和目标的细节，以及要执行的数据融合管道的细节。扩展数据湖以添加更多的源很容易，只需要为新的源对象添加配置。</p><p id="6270" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了将数据从源移动到目标，使用了数据融合管道。不属于ETL工具或不能在ETL工具中执行的自定义任务可以用Python编写，并集成到Composer DAG中，用于工作流的端到端编排。</p><h1 id="95ae" class="je jf hi bd jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb bi translated">接下来呢？</h1><p id="1cbd" class="pw-post-body-paragraph if ig hi ih b ii kc ik il im kd io ip iq ke is it iu kf iw ix iy kg ja jb jc hb bi translated">您可能已经在示例DAG屏幕截图中注意到了“应用数据字典”这一摄取后任务。该任务将业务元数据和列描述更新到加载到数据湖的表中。</p><p id="a9f3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">确保数据的可发现性是获取数据湖中可用数据价值的一个重要方面，而业务元数据是实现这一目标的关键因素。在下一篇文章中，我将进一步详细介绍如何在GCP上实现数据平台的数据可发现性。</p></div></div>    
</body>
</html>