<html>
<head>
<title>Understand end-to-end latency for Oracle to BigQuery replication with Datastream and Dataflow</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">了解Oracle与数据流和数据流的BigQuery复制的端到端延迟</h1>
<blockquote>原文：<a href="https://medium.com/google-cloud/understand-end-to-end-latency-for-oracle-to-bigquery-replication-with-datastream-and-dataflow-55f350526eb1?source=collection_archive---------0-----------------------#2022-08-30">https://medium.com/google-cloud/understand-end-to-end-latency-for-oracle-to-bigquery-replication-with-datastream-and-dataflow-55f350526eb1?source=collection_archive---------0-----------------------#2022-08-30</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="29b9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">本文的目标是解释在使用数据流和数据流将数据从Oracle复制到BigQuery时，我们如何控制端到端延迟。</p><p id="6e7c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">GCP数据流是一种无服务器的变更数据捕获(CDC)和复制服务，允许您跨异构数据库同步数据。</p><p id="79cd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这种复制分两步处理。首先，Datastream从事务日志中获取数据库更改，并且在其当前状态下能够将这些更改缓冲和具体化为Google云存储上的文件。第二步由数据流连续作业处理，该作业在文件到达时从Google云存储中读取文件，并将缓冲的更改流式传输到BigQuery。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jd"><img src="../Images/6856159f1c64fd181a582a865761c66f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1360/format:webp/1*OdACYe1Etz-vH4QRDf5MIA.png"/></div></figure><p id="2b7b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这张高级图已经表明，至少有几个地方会影响源数据库中的更改被复制和供BigQuery用户使用的速度。让我们更深入地了解延迟的最重要来源。</p><h1 id="c57b" class="jl jm hi bd jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki bi translated">神谕</h1><p id="dba0" class="pw-post-body-paragraph if ig hi ih b ii kj ik il im kk io ip iq kl is it iu km iw ix iy kn ja jb jc hb bi translated">对于Oracle，Datastream使用Oracle LogMiner来查询数据库的重做日志文件。在Oracle数据库的新版本(如19c)中，CONTINUOUS_MINE选项已被弃用，Logminer失去了连续挖掘在线重做日志的能力。但这不会影响数据流，因为数据流使用LogMiner从所谓的归档重做日志中读取数据。那么什么是归档重做日志呢？归档重做日志可以理解为重做日志文件的物理副本。但是什么是重做日志文件呢？；)每一个数据修改操作(更新、插入、删除、改变等)。)首先被写入所谓的重做日志缓冲区。然后，使用进程名LGWR(日志写入程序)将更改事件写入活动重做日志文件。我认为下面的图片很好地捕捉到了这一点:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ko"><img src="../Images/477a499e7dd9c59fef88f1a3f30f1e3a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/0*NP_q_HNMpk2-_n9C.jpg"/></div><figcaption class="kp kq et er es kr ks bd b be z dx translated">图片来源:<a class="ae kt" href="https://subscription.packtpub.com/book/big+data+and+business+intelligence/9781782171201/1/ch01lvl1sec16/the-archivelog-mode" rel="noopener ugc nofollow" target="_blank"> Oracle Database 12c备份和恢复生存指南</a></figcaption></figure><p id="f4e3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">可以将单个数据库实例配置为具有多个重做日志文件。事实上，如果数据库在ARCHIVELOG模式下工作(这是数据流所要求的)，它至少需要两个文件来保证一个文件始终可用于写入(活动重做日志),而另一个文件则被归档。这就带来了延迟—只有当活动重做日志变满时，才会归档最近的更改。LGWR进程以循环方式写入重做日志文件:当当前重做日志文件填满时，LGWR开始写入下一个可用的重做日志文件。当最后一个可用的重做日志文件填满时，LGWR会返回到第一个重做日志文件并写入其中，再次开始循环。当活动重做日志文件变满时，另一个称为ARCn的内部进程负责归档该文件，因此命名为归档重做日志文件。</p><p id="1590" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">当活动重做日志文件变满并且LGWR进程开始写入下一个文件的时刻<strong class="ih hj">称为重做日志文件切换</strong>。此阶段的延迟由重做日志文件切换频率和归档该文件所需的时间决定。Oracle的经验法则是，在DML活动高峰时，每小时不要切换超过3个日志(20分钟的重做)，以防止过多的检查点。这相当于20分钟的延迟。</p><p id="ec4d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这里有哪些选项:</p><ul class=""><li id="8c06" class="ku kv hi ih b ii ij im in iq kw iu kx iy ky jc kz la lb lc bi translated">您可以将数据库配置为定期切换重做日志文件(由数据流推荐)</li><li id="48c9" class="ku kv hi ih b ii ld im le iq lf iu lg iy lh jc kz la lb lc bi translated">您可以使用以下SQL命令手动执行重做日志文件切换(当您使用数据流时非常有用):</li></ul><p id="a217" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">更改系统切换日志文件</strong></p><p id="3957" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如何知道是否有新的归档重做日志文件？重做日志文件成功归档后，查询<strong class="ih hj"> V$ARCHIVED_LOG </strong>视图会发现新的记录。此视图还将帮助您测量新的归档重做日志文件可供数据流使用需要多长时间。</p><p id="af93" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">信号源的总延迟:可配置，但接近30分钟</strong></p><h1 id="4112" class="jl jm hi bd jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki bi translated">数据流</h1><p id="d729" class="pw-post-body-paragraph if ig hi ih b ii kj ik il im kk io ip iq kl is it iu km iw ix iy kn ja jb jc hb bi translated">数据流不断对源数据库进行采样，以获取新的归档重做日志文件。如果您想知道这里的延迟是什么，我们需要更好地理解这个步骤是如何工作的。因此，让我们看看替代解决方案，如Kafka Connect与Log Miner如何处理它。如果您检查git上可用的Kafka Connect代码，您会发现<a class="ae kt" href="https://github.com/klc213bk/kafka-connect-logminer/blob/main/src/main/java/com/transglobe/kafka/connect/oracle/LogMinerThread2.java" rel="noopener ugc nofollow" target="_blank"><strong class="ih hj">logminerethread</strong></a>类。通过连续的while(true)循环处理提取存档文件，一旦文件被识别，代码发送logMinerSelectSql <strong class="ih hj">以提取</strong>相应的更改:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="er es li"><img src="../Images/cf7129ccb08105553fabeb8aa6cfa2b0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*p9HLTYJBYMtHsuHR7c1ZKw.png"/></div></div></figure><p id="1688" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这里，我们应该区分Oracle数据库上发生更改时的时间戳(所谓的事件时间戳)和数据流开始处理与该更改相对应的记录时由数据流分配的时间戳(所谓的读取时间戳)。两者之间的差异由数据流监控为<strong class="ih hj">数据新鲜度</strong>度量:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="er es ln"><img src="../Images/d5d5d1beb3770d121ccb25b0cb3fabaf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Y7dZa8w8IIllP79H"/></div></div></figure><p id="97f9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">数据流处理一个事件所花费的时间由数据流监控，作为<strong class="ih hj">系统延迟</strong>指标。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="er es ln"><img src="../Images/37aa4a9390b883819c11502be19d34c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CoWmOP9Hnkgv3Ep9OVoE0g.png"/></div></div></figure><p id="0708" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这背后的直觉是这样的。想象一下，你想乘一辆公共汽车从家到工作地点。你去火车站，你看到公共汽车刚刚离开。你到达车站的那一刻就是你的事件时间戳。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="er es lo"><img src="../Images/fdf15ef69115a8075b60084374cb3ce3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*_s2KrbEEkIGcemog.jpg"/></div></div></figure><p id="038d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">既然车已经开走了，你需要等下一辆。当它来的时候，你进入公共汽车——你确认车票的时刻就是你的阅读时间戳。<strong class="ih hj">数据新鲜度</strong>因此可以理解为你出现在公交车站的时刻和你验证车票的时刻之间的时间差。你坐下来，车就开了。让你到达目的地汽车站的时间是<strong class="ih hj">系统延迟</strong>。</p><p id="a9ce" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">那么当数据流发生变化时会发生什么呢？</strong></p><p id="98e6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">数据流stream缓冲这些更改，然后将它们作为文件物化到Google云存储中。默认情况下，无论何时达到最大文件大小或最大超时值(以先到者为准)，都会创建新文件。默认情况下，文件每50 MB或30秒轮换一次，这是此阶段系统延迟的一个很好的近似值。您可以使用Datastream API修改这两个数字:<a class="ae kt" href="https://cloud.google.com/datastream/docs/manage-streams#modifyastream" rel="noopener ugc nofollow" target="_blank">https://cloud . Google . com/Datastream/docs/manage-streams # createastream</a>。</p><p id="b53c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此，在总数据新鲜度+系统延迟中，解释将更改记录移动到Google云存储上的文件需要多长时间，以便从在源数据库中创建更改的时刻到数据流将缓冲的更改具体化为Google云存储上的文件的时刻。您可以在数据流监控中观察到<strong class="ih hj">总延迟</strong>:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="er es ln"><img src="../Images/99186ad141e8a6b908fd51025130bfc2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dLuGxqzXmqDLh75PEFW11w.png"/></div></div></figure><p id="edbb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">数据流阶段的总延迟:可配置，但也可能需要几分钟</strong></p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="er es lp"><img src="../Images/5a3a0502eb4d3c69337e9ef5fd6847f5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YLtHZYxfpOnNLqVkkKCnnQ.png"/></div></div></figure><h1 id="f242" class="jl jm hi bd jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki bi translated">数据流</h1><p id="3a1c" class="pw-post-body-paragraph if ig hi ih b ii kj ik il im kk io ip iq kl is it iu km iw ix iy kn ja jb jc hb bi translated">有数据流模板用于实例化连续数据流作业，将更改从Google云存储移动到BigQuery:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="er es lq"><img src="../Images/c49d47fe24db373c31399af2eb1760c0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*btRbxJygUra36FSk56aOoA.png"/></div></div></figure><p id="8546" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">您将被要求指定三个必需的参数:</p><p id="1e49" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Google云存储上的位置，数据流将缓冲的更改具体化为文件。</p><p id="0f38" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">2/您需要在数据流使用的Google云存储上启用PubSub通知。数据流将监听相应的事件，以了解数据流写入桶的任何新文件。</p><div class="lr ls ez fb lt lu"><a href="https://cloud.google.com/datastream/docs/implementing-datastream-dataflow-analytics#enable-pub-sub-notifs" rel="noopener  ugc nofollow" target="_blank"><div class="lv ab dw"><div class="lw ab lx cl cj ly"><h2 class="bd hj fi z dy lz ea eb ma ed ef hh bi translated">为分析实施数据流和数据流|谷歌云</h2><div class="mb l"><h3 class="bd b fi z dy lz ea eb ma ed ef dx translated">为具有许多独立数据源的企业发送反馈，访问整个组织的企业数据…</h3></div><div class="mc l"><p class="bd b fp z dy lz ea eb ma ed ef dx translated">cloud.google.com</p></div></div><div class="md l"><div class="me l mf mg mh md mi jj lu"/></div></div></a></div><p id="8e32" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">3/当在云存储上具体化对文件的改变时，数据流使用的文件格式(可用选项是avro或json，并且您应该坚持您选择的创建数据流流)。</p><p id="cee0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">当您启动此作业并访问要复制源表的BigQuery数据集时，您会发现每个源表都有两个目标表，其中一个带有后缀“_log ”,其中附加了所有更改，并且每个记录都包含有关它所代表的更改类型的信息，即它是插入、更新还是删除。您可以通过配置参数指示数据流作业定期将新的更改合并到最终目标表中。每个合并操作都会在BigQuery上产生开销，因此您需要平衡开销和数据延迟。我强烈推荐下面这篇文章，它很好地解释了这种权衡:<a class="ae kt" href="https://cloud.google.com/architecture/database-replication-to-bigquery-using-change-data-capture" rel="noopener ugc nofollow" target="_blank">https://cloud . Google . com/architecture/database-replication-to-big query-using-change-data-capture</a></p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="er es mj"><img src="../Images/b15dd23f3c1eecdd4b9c13d5602a6aa6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*uxGhJY5S9-2HacCd"/></div></div></figure><p id="8893" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">数据流作业将把变更事件传递给BigQuery。与数据流类似，数据流作业需要首先从源获取变更事件(对于数据流作业，源是Google云存储)，因此数据新鲜度和系统延迟的概念也适用于这一步。</p><p id="8d4b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">数据流模板定义了一个表示逻辑执行计划的任务图。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="er es mk"><img src="../Images/2fc7e90730e593fad2f0eed50227064c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*MqxfwvCnhlzSWhtH"/></div></div></figure><p id="accf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">当运行该图时，数据流会将这个逻辑计划编译成物理计划，并将任务分解成执行阶段。它们的名称(F142、F145、…)无助于理解它们对应于哪个任务，但是从本文的角度来看，需要注意的是，每个这样的阶段都有自己的数据新鲜度。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="er es ml"><img src="../Images/ab9a92e144e863dadf7069f63900b529.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*QY0heq8dJ6OyTRyQ"/></div></div></figure><p id="eef1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在图表上监控数据流作业指标更加方便。这里我们有按阶段划分的数据新鲜度:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="er es mm"><img src="../Images/5314802ac59d69a11e643519471c51f5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*2fiQlcJFPjksqwWn"/></div></div></figure><p id="5cfd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这里，我们汇总了所有阶段的最大和平均数据新鲜度:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="er es mm"><img src="../Images/3cf47678673438228c7fda826e886378.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Ebcqtlu421smRWqt"/></div></div></figure><p id="9e54" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">每个阶段都需要一些时间来处理我们的更改，因此这是系统延迟的一个来源。同样，数据流有助于我们分阶段了解系统延迟:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="er es mm"><img src="../Images/e8a25b6223663c0bc2dad64fb20b6fee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*XTQSFNZNeEnDEtIJ"/></div></div></figure><p id="5a5c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们还可以跟踪所有阶段的最大值和平均值:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="er es mm"><img src="../Images/2fbd5144629c1c36ce26056024180ee9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*_sw6qkzz82Y4UgMH"/></div></div></figure><p id="e1f9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">数据新鲜度</strong> + <strong class="ih hj">系统延迟</strong>定义数据流作业引入的<strong class="ih hj">总延迟</strong>。</p><p id="8bab" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">我们能否控制数据流带来的延迟？</strong></p><p id="640c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">配置数据流作业时，您可以指定要为此作业分配的计算资源。这些资源由数据流工作者使用的VM的类型和工作者的数量来表示。您还可以启用工作线程的自动缩放，并通过设置此作业可以使用的最小和最大工作线程数来指定自动缩放边界。也许不太明显，但是这些设置对延迟有影响。怎么会？想象一下，在源和数据流上有大量的变化，它们将具体化为Google云存储上的文件。数据流工作者将努力尽快处理这些文件，但这在很大程度上取决于有哪些资源可用。</p><p id="f7d7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此，Dataflow recommender可能会向您显示一条消息，指示在当前最大工作线程数和要处理的更改数的情况下，CPU利用率相当高，添加额外的工作线程应该会提高性能和数据新鲜度。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="er es mn"><img src="../Images/b419d784566a33ddc29ea63dd7334d56.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vRdvFbO6a4kqHkVjz8JZaA.png"/></div></div></figure><p id="5811" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">请记住，尽管增加额外的工作人员也会增加成本，因此调整数据流作业的总延迟是延迟和成本之间的权衡。</p><p id="61a2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">数据流作业的总系统延迟:几秒钟，但也可能需要几分钟</strong></p><h1 id="0f6c" class="jl jm hi bd jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki bi translated">BigQuery</h1><p id="a705" class="pw-post-body-paragraph if ig hi ih b ii kj ik il im kk io ip iq kl is it iu km iw ix iy kn ja jb jc hb bi translated">对于复制到BigQuery的每个表，数据流作业将相应的更改事件流式传输到具有以下命名模式的辅助BigQuery日志表中:<table_name> _log</table_name></p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mo"><img src="../Images/31c4e08e92f868142c1d2f52be1ed057.png" data-original-src="https://miro.medium.com/v2/resize:fit:370/format:webp/1*NCBxQtcL8qxP_E9-Qmq-nQ.png"/></div></figure><p id="a671" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这些是仅追加表，每个_log表都有一个名为<strong class="ih hj"><em class="mp">_ metadata _ change _ type</em></strong>的列，它描述了更改的类型(插入、更新、删除):</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ko"><img src="../Images/f6a95f56460d10238629c823632a8b0f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/0*3JZAzlV8liJcgh1x.jpg"/></div></figure><p id="1600" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果您的用户确实需要尽快访问新数据，您可以让他们访问这些日志表。您还可以稍微取悦您的用户，用视图覆盖这些表，这些视图负责动态地将更改与final table合并，以便在用户查询中使用时产生表的最新状态。否则，用户将不得不在他们的SQL查询中显式添加这个逻辑。这种方法不会给系统带来任何额外的延迟(除了计算表状态所花费的时间)，但这带来了额外的成本，当您的用户运行许多引用这些视图的SQL查询时，这些成本就会累积起来。</p><p id="5725" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">有一种替代方法可能更加经济高效，但会增加端到端复制延迟。也就是说，我们为将Datastream在Google云存储上暂存的更改移动到BigQuery而配置的相同数据流作业也可以配置为执行SQL Merge命令，该命令每隔X分钟将_log表中的更改合并到最终表中。x由名为<strong class="ih hj">mergefrequencyments的数据流作业配置参数控制。X还描述了在讨论端到端复制延迟时会增加多少延迟:只能访问最终表的用户需要等待X分钟，然后最新的更改才会合并到这些表中。</strong></p><p id="3a25" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">从延迟的角度来看，您希望增加合并的频率。但是另一方面，在BigQuery上更频繁的合并操作会产生更多的BigQuery开销。</p><p id="bc07" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">big query上的总系统延迟:</strong>此阶段的延迟完全取决于您的需求，是可配置的，可能低至几分钟，但也可能需要几个小时。</p><h1 id="a99d" class="jl jm hi bd jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki bi translated">摘要</h1><p id="52d3" class="pw-post-body-paragraph if ig hi ih b ii kj ik il im kk io ip iq kl is it iu km iw ix iy kn ja jb jc hb bi translated">数据流和数据流将帮助您在Oracle和BigQuery之间建立近乎实时的复制。然而，术语“接近实时”并不一定指毫秒。您更应该期待长达30分钟的端到端延迟，其中大部分价值可归因于Oracle LogMiner如何使源更改可供下游使用。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mq"><img src="../Images/c2cda3ebf2935b0d828002def4b2441b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1306/format:webp/1*OirAteGQNJOQYu98YoXxfg.png"/></div></figure><p id="d12c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对总延迟的另一个有意义的贡献来自于这样一个事实，即首先存放在仅附加BigQuery日志表中的更改事件不会立即合并到最终表中，而是以可配置的时间间隔合并。根据您的要求，此阶段的延迟可能低至几分钟，但也可能需要几个小时。</p><blockquote class="mr ms mt"><p id="0c76" class="if ig mp ih b ii ij ik il im in io ip mu ir is it mv iv iw ix mw iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="hi">本文由</em></strong><a class="ae kt" href="https://www.linkedin.com/in/lukasz-olejniczak-1a75a613/" rel="noopener ugc nofollow" target="_blank"><strong class="ih hj"><em class="hi">Lukasz Olejniczak</em></strong></a><strong class="ih hj"><em class="hi">和</em></strong><a class="ae kt" href="https://www.linkedin.com/in/tomasz-sza%C5%82ankiewicz-529b82113/" rel="noopener ugc nofollow" target="_blank"><strong class="ih hj"><em class="hi">Tomasz szaankiewicz</em></strong></a><strong class="ih hj"><em class="hi">合著。所表达的观点是作者的观点，不一定反映谷歌的观点。</em> </strong></p></blockquote><p id="1b6b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果你喜欢这篇文章，请为它鼓掌。有关基于google云的数据科学、数据工程和AI/ML主题的更多详细信息，请关注我的<a class="ae kt" href="https://www.linkedin.com/in/lukasz-olejniczak-1a75a613/" rel="noopener ugc nofollow" target="_blank"><strong class="ih hj"><em class="mp">LinkedIn</em></strong></a><strong class="ih hj"><em class="mp">。</em> </strong></p></div></div>    
</body>
</html>