<html>
<head>
<title>Importing data from GCS to JDBC Databases using Dataproc Serverless</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Dataproc无服务器将数据从GCS导入JDBC数据库</h1>
<blockquote>原文：<a href="https://medium.com/google-cloud/import-data-from-gcs-to-jdbc-databases-using-dataproc-serverless-c7154b242430?source=collection_archive---------5-----------------------#2022-12-23">https://medium.com/google-cloud/import-data-from-gcs-to-jdbc-databases-using-dataproc-serverless-c7154b242430?source=collection_archive---------5-----------------------#2022-12-23</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/e5e75b3788a4dfd421df60dfc9bb795f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*94OqXLa7z6FdANr6.png"/></div></div></figure><blockquote class="iq ir is"><p id="daae" class="it iu iv iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">Spark是最<strong class="iw hj">流行的大数据分布式处理框架之一。</strong>如果您希望将现有的spark工作负载迁移到云，或者在云上创建新的spark作业，您不再需要担心重新调整作业属性或调整集群规模。<a class="ae js" href="https://cloud.google.com/dataproc-serverless/docs/overview" rel="noopener ugc nofollow" target="_blank"> <strong class="iw hj"> Dataproc无服务器</strong> </a>通过运行spark工作负载来加速您在Google Cloud上的旅程，而无需担心基础设施的供应和管理。</p></blockquote><p id="749f" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je jt jg jh ji ju jk jl jm jv jo jp jq jr hb bi translated">Google Cloud社区已经建立了一个开源的知识库，其中包含了Dataproc Serverless最常见的用例。在这篇博文中，我们浏览了来自资源库的<a class="ae js" href="https://github.com/GoogleCloudPlatform/dataproc-templates/blob/main/python/dataproc_templates/gcs/gcs_to_jdbc.py" rel="noopener ugc nofollow" target="_blank"> GCS到JDBC Pyspark模板</a>。</p><figure class="jx jy jz ka fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es jw"><img src="../Images/437fc83b3e17f52622afada24ef66976.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*l7tYEBEd6OHfMOiuUdp5OA.png"/></div></div></figure><p id="c7a5" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je jt jg jh ji ju jk jl jm jv jo jp jq jr hb bi translated">在我们进入任何细节之前，让我们回顾一下使用模板的<strong class="iw hj">主要优势</strong>:</p><ol class=""><li id="372d" class="kb kc hi iw b ix iy jb jc jt kd ju ke jv kf jr kg kh ki kj bi translated">Dataproc无服务器模板是开源的，可以很容易地为工作负载迁移进行克隆和定制。</li><li id="5284" class="kb kc hi iw b ix kk jb kl jt km ju kn jv ko jr kg kh ki kj bi translated">无需调配或管理基础架构。</li><li id="62dd" class="kb kc hi iw b ix kk jb kl jt km ju kn jv ko jr kg kh ki kj bi translated">支持多种文件格式，即JSON、Avro、Parquet和CSV。</li><li id="39c0" class="kb kc hi iw b ix kk jb kl jt km ju kn jv ko jr kg kh ki kj bi translated">这些模板是配置驱动的，只需更改连接参数，就可以非常容易地用于类似的用例。</li></ol><h1 id="4123" class="kp kq hi bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">先决条件</h1><p id="6a5e" class="pw-post-body-paragraph it iu hi iw b ix ln iz ja jb lo jd je jt lp jh ji ju lq jl jm jv lr jp jq jr hb bi translated">为了运行这些模板，我们需要:</p><ul class=""><li id="f091" class="kb kc hi iw b ix iy jb jc jt kd ju ke jv kf jr ls kh ki kj bi translated">Google Cloud SDK已安装并通过验证。</li><li id="bee1" class="kb kc hi iw b ix kk jb kl jt km ju kn jv ko jr ls kh ki kj bi translated">Python 3.7+已安装。</li><li id="e810" class="kb kc hi iw b ix kk jb kl jt km ju kn jv ko jr ls kh ki kj bi translated">启用了专用Google访问的VPC子网。默认子网是合适的，只要启用了私有Google访问。</li><li id="4467" class="kb kc hi iw b ix kk jb kl jt km ju kn jv ko jr ls kh ki kj bi translated">目标数据库的JDBC jar。</li></ul><h1 id="8275" class="kp kq hi bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">执行Dataproc模板的步骤</h1><p id="4d5e" class="pw-post-body-paragraph it iu hi iw b ix ln iz ja jb lo jd je jt lp jh ji ju lq jl jm jv lr jp jq jr hb bi translated">1.克隆Dataproc模板库并导航到Python模板文件夹。</p><pre class="jx jy jz ka fd lt lu lv bn lw lx bi"><span id="0b5e" class="ly kq hi lu b be lz ma l mb mc">git clone https://github.com/GoogleCloudPlatform/dataproc-templates.git<br/>cd dataproc-templates/python</span></pre><p id="0035" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je jt jg jh ji ju jk jl jm jv jo jp jq jr hb bi translated">2.获取身份验证凭据以提交作业。</p><pre class="jx jy jz ka fd lt lu lv bn lw lx bi"><span id="2bb8" class="ly kq hi lu b be lz ma l mb mc">gcloud auth application-default login</span></pre><p id="3ade" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je jt jg jh ji ju jk jl jm jv jo jp jq jr hb bi translated">3.为jar文件创建一个GCS存储桶和暂存位置。</p><pre class="jx jy jz ka fd lt lu lv bn lw lx bi"><span id="290c" class="ly kq hi lu b be lz ma l mb mc">export STAGING_BUCKET=”my-gcs-staging-bucket”<br/>gsutil mb gs://$STAGING_BUCKET</span></pre><p id="c059" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je jt jg jh ji ju jk jl jm jv jo jp jq jr hb bi translated">4.通过导出提交所需的变量来配置Dataproc无服务器作业—</p><p id="0c5f" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je jt jg jh ji ju jk jl jm jv jo jp jq jr hb bi translated"><code class="du md me mf lu b">GCP_PROJECT</code>:运行Dataproc无服务器的GCP项目id</p><p id="1cff" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je jt jg jh ji ju jk jl jm jv jo jp jq jr hb bi translated"><code class="du md me mf lu b">REGION</code>:运行Dataproc无服务器的区域</p><p id="0cb2" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je jt jg jh ji ju jk jl jm jv jo jp jq jr hb bi translated"><code class="du md me mf lu b">GCS_STAGING_LOCATION</code> : GCS暂存桶位置，在步骤3中创建</p><p id="b5fa" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je jt jg jh ji ju jk jl jm jv jo jp jq jr hb bi translated"><code class="du md me mf lu b">SUBNET</code>:运行Dataproc无服务器的VPC子网，如果不使用默认子网(格式:<em class="iv">projects/&lt;project _ id&gt;/regions/&lt;region&gt;/subnetworks/&lt;子网&gt; ) </em></p><p id="1452" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je jt jg jh ji ju jk jl jm jv jo jp jq jr hb bi translated"><code class="du md me mf lu b">JARS</code>:作业中使用逗号分隔的罐子。对于这个用例，它应该包括目标数据库的JDBC驱动程序jar。</p><pre class="jx jy jz ka fd lt lu lv bn lw lx bi"><span id="1b36" class="ly kq hi lu b be lz ma l mb mc"># Project ID to run the Dataproc Serverless Job<br/>export GCP_PROJECT=&lt;project_id&gt;# GCP region where the job should be submitted<br/>export REGION=&lt;region&gt;# The staging location for Dataproc<br/>export GCS_STAGING_LOCATION=gs://$STAGING_BUCKET/staging<br/>export SUBNET=&lt;subnet&gt; # Optional if default  <br/>export JARS="&lt;gcs_path_to_jdbc_jar_files&gt;/mysql-connector-java-8.0.29.jar,&lt;gcs_path_to_jdbc_jar_files&gt;/postgresql-42.2.6.jar,&lt;gcs_path_to_jdbc_jar_files&gt;/mssql-jdbc-6.4.0.jre8.jar"</span></pre><p id="0b4f" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je jt jg jh ji ju jk jl jm jv jo jp jq jr hb bi translated">5.根据环境收集以下参数的值:</p><p id="f4db" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je jt jg jh ji ju jk jl jm jv jo jp jq jr hb bi translated"><em class="iv">gcs . JDBC . input . location</em>:输入文件的GCS位置</p><p id="120e" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je jt jg jh ji ju jk jl jm jv jo jp jq jr hb bi translated"><em class="iv">GCS . JDBC . Input . format</em>:<em class="iv"/>输入文件格式(avro、parquet、csv、json中的一种)</p><p id="8680" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je jt jg jh ji ju jk jl jm jv jo jp jq jr hb bi translated"><em class="iv">GCS . JDBC . output . table</em>:JDBC输出表名</p><p id="02e0" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je jt jg jh ji ju jk jl jm jv jo jp jq jr hb bi translated"><em class="iv"> gcs.jdbc.output.mode </em>:输出写模式(append、overwrite、ignore、errorifexists中的一种)，默认为append</p><p id="2c59" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je jt jg jh ji ju jk jl jm jv jo jp jq jr hb bi translated"><em class="iv">GCS . JDBC . output . url</em>:JDBC输出URL。目标数据库的变化。</p><p id="e649" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je jt jg jh ji ju jk jl jm jv jo jp jq jr hb bi translated"><em class="iv">GCS . JDBC . output . driver</em>:<em class="iv"/>JDBC输出驱动名称</p><p id="8e37" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je jt jg jh ji ju jk jl jm jv jo jp jq jr hb bi translated"><em class="iv">GCS . JDBC . batch . size</em>:<em class="iv"/>JDBC输出批量大小，决定每次往返要插入多少行。默认为1000</p><figure class="jx jy jz ka fd ij"><div class="bz dy l di"><div class="mg mh l"/></div></figure><p id="75e0" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je jt jg jh ji ju jk jl jm jv jo jp jq jr hb bi translated">6.现在让我们执行模板。注意有<a class="ae js" href="https://github.com/GoogleCloudPlatform/dataproc-templates/tree/main/python#run-using-pypi-package" rel="noopener ugc nofollow" target="_blank"> <em class="iv">四种方式提交</em> </a>的作业。在这篇博文中，我们通过存储库中的<a class="ae js" href="https://github.com/GoogleCloudPlatform/dataproc-templates/blob/main/python/bin/start.sh" rel="noopener ugc nofollow" target="_blank"> bin/start.sh </a>文件提交spark无服务器作业。</p><h2 id="ef6d" class="mi kq hi bd kr mj mk ml kv mm mn mo kz jt mp mq ld ju mr ms lh jv mt mu ll mv bi translated">样本执行</h2><pre class="jx jy jz ka fd lt lu lv bn lw lx bi"><span id="5bed" class="ly kq hi lu b be lz ma l mb mc">export GCP_PROJECT=&lt;gcp-project-id&gt; <br/>export REGION=&lt;region&gt;  <br/>export GCS_STAGING_LOCATION=&lt;gcs staging location&gt; <br/>export SUBNET=&lt;subnet&gt;   <br/>export JARS="&lt;gcs_path_to_jdbc_jar_files&gt;/mysql-connector-java-8.0.29.jar"<br/><br/>./bin/start.sh \<br/>-- --template=GCSTOJDBC \<br/>--gcs.jdbc.input.location="gs://&lt;gcs_bucket&gt;/&lt;path_to_input_files&gt;"<br/>--gcs.jdbc.input.format="&lt;avro/parquet/csv/json&gt;" \<br/>--gcs.jdbc.output.url="jdbc:mysql://&lt;hostname&gt;:&lt;port&gt;/&lt;dbname&gt;?user=&lt;username&gt;&amp;password=&lt;password&gt;" \<br/>--gcs.jdbc.output.driver="com.mysql.cj.jdbc.Driver" \<br/>--gcs.jdbc.output.table="&lt;output table name&gt;" \<br/>--gcs.jdbc.output.mode="&lt;append/overwrite/ignore/errorifexists&gt;" \<br/>--gcs.jdbc.batch.size=5000</span></pre><p id="b11a" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je jt jg jh ji ju jk jl jm jv jo jp jq jr hb bi translated">7.监控火花工作。提交作业后，作业指标和日志应在<a class="ae js" href="https://console.cloud.google.com/dataproc/batches" rel="noopener ugc nofollow" target="_blank"> Dataproc批处理UI </a>中可用。</p><h2 id="53ce" class="mi kq hi bd kr mj mk ml kv mm mn mo kz jt mp mq ld ju mr ms lh jv mt mu ll mv bi translated">附加性能</h2><ul class=""><li id="dca9" class="kb kc hi iw b ix ln jb lo jt mw ju mx jv my jr ls kh ki kj bi translated">如果你想提供<a class="ae js" href="https://cloud.google.com/dataproc-serverless/docs/concepts/properties" rel="noopener ugc nofollow" target="_blank">额外的火花属性</a>，可以通过在执行命令中添加下面的代码片段来提供。</li></ul><pre class="jx jy jz ka fd lt lu lv bn lw lx bi"><span id="3e3f" class="ly kq hi lu b be lz ma l mb mc">--properties=&lt;spark.something.key&gt;=&lt;value&gt;</span></pre><ul class=""><li id="c597" class="kb kc hi iw b ix iy jb jc jt kd ju ke jv kf jr ls kh ki kj bi translated">如果您需要使用spark JDBC编写器支持的<a class="ae js" href="https://spark.apache.org/docs/latest/sql-data-sources-jdbc.html#data-source-option" rel="noopener ugc nofollow" target="_blank">属性</a>，您可以相应地克隆和定制代码。</li></ul><h1 id="d55b" class="kp kq hi bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">参考</h1><ul class=""><li id="22e1" class="kb kc hi iw b ix ln jb lo jt mw ju mx jv my jr ls kh ki kj bi translated"><a class="ae js" href="https://github.com/GoogleCloudPlatform/dataproc-templates" rel="noopener ugc nofollow" target="_blank"> Github库</a></li><li id="34a9" class="kb kc hi iw b ix kk jb kl jt km ju kn jv ko jr ls kh ki kj bi translated"><a class="ae js" rel="noopener" href="/google-cloud/importing-data-from-databases-into-gcs-via-jdbc-using-dataproc-serverless-f330cb0160f0"> JDBC2GCS无服务器模板</a></li></ul></div></div>    
</body>
</html>