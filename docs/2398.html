<html>
<head>
<title>Managing Streaming Dataflow Job using Kubernetes Config Connector</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Kubernetes配置连接器管理数据流作业</h1>
<blockquote>原文：<a href="https://medium.com/google-cloud/managing-streaming-dataflow-job-using-kubernetes-config-connector-cb6422b770ac?source=collection_archive---------1-----------------------#2022-10-02">https://medium.com/google-cloud/managing-streaming-dataflow-job-using-kubernetes-config-connector-cb6422b770ac?source=collection_archive---------1-----------------------#2022-10-02</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="ca65" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Kubernetes配置连接器(KCC)是一个开源插件，允许我们通过Kubernetes管理GCP资源，从而将其作为基础设施代码保存。每当通过集群应用更改时，配置连接器定制资源(CR)将创建和管理Kubernetes资源。Kubernetes配置连接器，支持各种Google云资源，如Dataflow、PubSub、Bigquery等。</p><p id="f2ad" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">假设我们想要创建一个从PubSub到Bigquery的数据流作业，这将要求我们创建一组资源，如PubSub主题、Bigquery表、存储桶，作为作业的临时路径，以及一个数据流作业。</p><p id="e384" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这里有一个来自Google Cloud的关于如何使用KCC创建流作业的可用示例。</p><ul class=""><li id="b405" class="jd je hi ih b ii ij im in iq jf iu jg iy jh jc ji jj jk jl bi translated">定义发布订阅主题</li></ul><pre class="jm jn jo jp fd jq jr js jt aw ju bi"><span id="bdf7" class="jv jw hi jr b fi jx jy l jz ka">apiVersion: pubsub.cnrm.cloud.google.com/v1beta1<br/>kind: PubSubTopic<br/>metadata:<br/>  name: dataflowjob-dep-streaming</span></pre><ul class=""><li id="a371" class="jd je hi ih b ii ij im in iq jf iu jg iy jh jc ji jj jk jl bi translated">定义Bigquery数据集和表</li></ul><pre class="jm jn jo jp fd jq jr js jt aw ju bi"><span id="738e" class="jv jw hi jr b fi jx jy l jz ka">apiVersion: bigquery.cnrm.cloud.google.com/v1beta1<br/>kind: BigQueryDataset<br/>metadata:<br/>  name: dataflowjobdepstreaming<br/>---<br/>apiVersion: bigquery.cnrm.cloud.google.com/v1beta1<br/>kind: BigQueryTable<br/>metadata:<br/>  name: dataflowjobdepstreaming<br/>spec:<br/>  datasetRef:<br/>    name: dataflowjobdepstreaming</span></pre><ul class=""><li id="0c01" class="jd je hi ih b ii ij im in iq jf iu jg iy jh jc ji jj jk jl bi translated">创建一个存储桶</li></ul><p id="107f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因为在这个例子中，我们希望在删除资源时确保存储桶被销毁，所以我们将<code class="du kb kc kd jr b">force-destroy</code>的注释设置为true。</p><pre class="jm jn jo jp fd jq jr js jt aw ju bi"><span id="83ff" class="jv jw hi jr b fi jx jy l jz ka">apiVersion: storage.cnrm.cloud.google.com/v1beta1<br/>kind: StorageBucket<br/>metadata:<br/>  annotations:<br/>    cnrm.cloud.google.com/force-destroy: "true"<br/>  name: ${PROJECT_ID?}-dataflowjob-dep-streaming</span></pre><ul class=""><li id="7eda" class="jd je hi ih b ii ij im in iq jf iu jg iy jh jc ji jj jk jl bi translated">创建数据流工作规范</li></ul><p id="04de" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">以下示例将使用来自Google的可用公共模板创建一个数据流作业。我们使用我们已经在工作规范中定义的所有资源。由于这是一个示例，我们将<code class="du kb kc kd jr b">on-delete</code>注释设置为cancel。然而，对于生产用途，我们希望确保首先处理所有数据，还有另一个值叫做<code class="du kb kc kd jr b">drain</code>。所有规格都可以在这个YAML <a class="ae ke" href="https://github.com/GoogleCloudPlatform/k8s-config-connector/blob/9f5538f382b0304b1a57a6c485b3d50b31d93eab/scripts/generate-google3-docs/resource-reference/generated/resource-docs/dataflow/dataflowflextemplatejob.md" rel="noopener ugc nofollow" target="_blank">规格</a>中看到。一般来说，如果我们已经创建了一个模板，我们可以将它放入存储桶，并创建一个YAML规范，将该模板指向我们的模板。</p><pre class="jm jn jo jp fd jq jr js jt aw ju bi"><span id="015e" class="jv jw hi jr b fi jx jy l jz ka"><br/>apiVersion: dataflow.cnrm.cloud.google.com/v1beta1<br/>kind: DataflowJob<br/>metadata:<br/>  annotations:<br/>    cnrm.cloud.google.com/on-delete: "cancel"<br/>  labels:<br/>    label-one: "value-one"<br/>  name: dataflowjob-sample-streaming<br/>spec:<br/>  tempGcsLocation: gs://${PROJECT_ID?}-dataflowjob-dep-streaming/tmp<br/>  templateGcsPath: gs://dataflow-templates/2020-02-03-01_RC00/PubSub_to_BigQuery<br/>  parameters:<br/>    inputTopic: projects/${PROJECT_ID?}/topics/dataflowjob-dep-streaming<br/>    outputTableSpec: ${PROJECT_ID?}:dataflowjobdepstreaming.dataflowjobdepstreaming<br/>  zone: us-central1-a<br/>  machineType: "n1-standard-1"<br/>  maxWorkers: 3</span></pre><p id="0fa1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">假设我们想要创建一个新的流作业，那么我们可以定义以下步骤来创建所述作业。</p><figure class="jm jn jo jp fd kg er es paragraph-image"><div class="er es kf"><img src="../Images/dca39998f88196ad9c5476405203c230.png" data-original-src="https://miro.medium.com/v2/resize:fit:242/format:webp/1*vT_8p_-yCFxJg5cIb6KiZA.png"/></div><figcaption class="kj kk et er es kl km bd b be z dx translated">用于创建新流式作业的CI/CD定义。</figcaption></figure></div></div>    
</body>
</html>