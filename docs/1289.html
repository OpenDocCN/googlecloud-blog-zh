<html>
<head>
<title>How to carry out CI/CD in Machine Learning (“MLOps”) using Kubeflow ML pipelines (#3)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何使用Kubeflow ML管道在机器学习(“MLOps”)中执行CI/CD(# 3)</h1>
<blockquote>原文：<a href="https://medium.com/google-cloud/how-to-carry-out-ci-cd-in-machine-learning-mlops-using-kubeflow-ml-pipelines-part-3-bdaf68082112?source=collection_archive---------0-----------------------#2020-02-16">https://medium.com/google-cloud/how-to-carry-out-ci-cd-in-machine-learning-mlops-using-kubeflow-ml-pipelines-part-3-bdaf68082112?source=collection_archive---------0-----------------------#2020-02-16</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="b26a" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">将您的ML组件设置为在有新代码(CI)时自动重建，并在有新数据(CD)时启动再训练实验</h2></div><p id="62c1" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在之前的文章中，我向您展示了如何开始使用Kubeflow Pipelines和T2 Jupyter笔记本作为Kubeflow ML pipeline的组件。Kubeflow Pipelines已经有了足够的改变(好的方面！—变得更简单)在这篇文章中，我将从头开始。换句话说，我将展示如何设置集群、笔记本和提交管道。也就是说，如果有些概念不太清楚，我建议你回去看看那两篇文章。</p><figure class="jv jw jx jy fd jz er es paragraph-image"><div role="button" tabindex="0" class="ka kb di kc bf kd"><div class="er es ju"><img src="../Images/8e6f6e1c93e7347c852e8fd4074db293.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_QnEVouU7caNSowYBfyMzQ.jpeg"/></div></div><figcaption class="kg kh et er es ki kj bd b be z dx translated">如果我们有CI/CD和食物一起吃不是很好吗？厨师可以根据市场上的供应情况(CI)更改项目描述，您可以在点餐时对其进行调整(“额外鹰嘴豆泥”)当您提交订单时，厨房就会做出合适的食物？(光盘)</figcaption></figure><p id="34c8" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在这个自述文件中可以找到<a class="ae jt" href="https://github.com/GoogleCloudPlatform/training-data-analyst/blob/master/courses/machine_learning/deepdive/06_structured/pipelines/README.md" rel="noopener ugc nofollow" target="_blank">的全套说明——请在阅读本文时随意跟随。</a></p><h2 id="3794" class="kk kl hi bd km kn ko kp kq kr ks kt ku jg kv kw kx jk ky kz la jo lb lc ld le bi translated">1.设置托管的Kubeflow管道</h2><p id="b874" class="pw-post-body-paragraph ix iy hi iz b ja lf ij jc jd lg im jf jg lh ji jj jk li jm jn jo lj jq jr js hb bi translated">Kubeflow管道中的ML管道由步骤的有向无环图(DAG)组成，每个步骤都是一个容器。例如，这个管道由五个步骤组成——预处理、超参数训练、微调最佳模型、部署它和部署前端webapp。在这种情况下，实际的应用程序并不重要，所以我不会在本文中深入讨论。</p><figure class="jv jw jx jy fd jz er es paragraph-image"><div role="button" tabindex="0" class="ka kb di kc bf kd"><div class="er es lk"><img src="../Images/dccc08f0bf4c3bc9b16a11ca0c720f7f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QPAaRa969z3UDQKUXRiv5g.png"/></div></div><figcaption class="kg kh et er es ki kj bd b be z dx translated">ML管道由ML步骤组成，每个步骤都是一个Docker容器</figcaption></figure><p id="36fa" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">管道在Google Kubernetes引擎(GKE)集群上执行。这个集群是长期存在的，您可以使用Kubeflow Pipelines API向它提交管道。</p><p id="8789" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">幸运的是，您不需要设置GKE集群，在其上安装Kubeflow，并配置所有必要的权限来允许远程提交。Google Cloud Marketplace上有一张<a class="ae jt" href="https://console.cloud.google.com/marketplace/details/google-cloud-ai-platform/kubeflow-pipelines" rel="noopener ugc nofollow" target="_blank">预建的托管ML Pipelines图片</a>。你也可以从<a class="ae jt" href="https://console.google.com/ai-platform/pipelines/clusters" rel="noopener ugc nofollow" target="_blank">https://console.google.com/ai-platform/pipelines/clusters</a>那里得到它并创建一个新的实例。</p><p id="b6fb" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">集群启动后(这需要2-3分钟)，单击管道仪表板链接以查看可用管道和正在执行的管道运行:</p><figure class="jv jw jx jy fd jz er es paragraph-image"><div role="button" tabindex="0" class="ka kb di kc bf kd"><div class="er es lk"><img src="../Images/51e9cfc7dec8f47828677bf69e6f2726.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kGBtEUK-FUQ_e5rR1FuJLg.png"/></div></div><figcaption class="kg kh et er es ki kj bd b be z dx translated">出现的集群有一个到ML Pipelines仪表板的链接</figcaption></figure><figure class="jv jw jx jy fd jz er es paragraph-image"><div role="button" tabindex="0" class="ka kb di kc bf kd"><div class="er es lk"><img src="../Images/3b0f2f18e72a41ceb547f28fe083e45a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iosiC7nTq4W2CfCqJ_A5Jw.png"/></div></div><figcaption class="kg kh et er es ki kj bd b be z dx translated">使用仪表板手动上传管道，并查看过去和正在进行的实验</figcaption></figure><h2 id="f116" class="kk kl hi bd km kn ko kp kq kr ks kt ku jg kv kw kx jk ky kz la jo lb lc ld le bi translated">2a。建立你的个人发展环境</h2><p id="b808" class="pw-post-body-paragraph ix iy hi iz b ja lf ij jc jd lg im jf jg lh ji jj jk li jm jn jo lj jq jr js hb bi translated">虽然您可以使用仪表板与Kubeflow管道进行交互，但您更有可能使用AI平台笔记本进行开发活动。</p><p id="e388" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">为kfp开发和普通开发之间有一个关键的区别——您希望在集群上代表您执行代码。向您的用户提供对某段代码的授权是不可行的——因此，创建一个服务帐户:</p><pre class="jv jw jx jy fd ll lm ln lo aw lp bi"><span id="60a2" class="kk kl hi lm b fi lq lr l ls lt">SA_NAME=kfpdemo<br/>gcloud iam service-accounts create $SA_NAME \<br/>       --display-name $SA_NAME --project "$PROJECT_ID"</span></pre><p id="dea1" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">然后，将您希望ML管道拥有的权限授予这个服务帐户。例如，如果您希望ML管道能够启动数据流作业，您应该:</p><pre class="jv jw jx jy fd ll lm ln lo aw lp bi"><span id="3eb8" class="kk kl hi lm b fi lq lr l ls lt">gcloud projects add-iam-policy-binding $PROJECT_ID \<br/>    --member=serviceAccount:$SA_NAME@$PROJECT_ID.iam.gserviceaccount.com \<br/>    --role=roles/dataflow.developer</span></pre><p id="accf" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">脚本<a class="ae jt" href="https://github.com/GoogleCloudPlatform/training-data-analyst/blob/master/courses/machine_learning/deepdive/06_structured/pipelines/setup_auth.sh" rel="noopener ugc nofollow" target="_blank"> setup_auth.sh </a>创建了一个服务帐户，并赋予它云存储、发布/订阅、BigQuery、数据流和人工智能平台(从CloudShell运行)的扩展角色。然后，它还将机密复制到Kubeflow集群，以便Kubeflow集群可以使用此服务帐户:</p><pre class="jv jw jx jy fd ll lm ln lo aw lp bi"><span id="d228" class="kk kl hi lm b fi lq lr l ls lt">gcloud iam service-accounts keys create application_default_credentials.json --iam-account $SA_NAME@$PROJECT_ID.iam.gserviceaccount.com</span><span id="8599" class="kk kl hi lm b fi lu lr l ls lt"># Attempt to create a k8s secret. If already exists, override.<br/>kubectl create secret generic user-gcp-sa \<br/>  --from-file=user-gcp-sa.json=application_default_credentials.json \<br/>  -n $NAMESPACE --dry-run -o yaml  |  kubectl apply -f -</span></pre><p id="db00" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在，我们可以转到GCP控制台的人工智能平台|笔记本部分，创建一个笔记本。但是，当我们创建AI平台笔记本时，让它使用您刚刚设置的服务帐户:</p><figure class="jv jw jx jy fd jz er es paragraph-image"><div role="button" tabindex="0" class="ka kb di kc bf kd"><div class="er es lv"><img src="../Images/54ca2f742d0e3e2f60032196c991a0e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4gWqrvubwv17VrLcTUAB_g.png"/></div></div><figcaption class="kg kh et er es ki kj bd b be z dx translated">用户的开发环境应该使用一个在kfp集群中存储了秘密的服务帐户。</figcaption></figure><p id="8ad2" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这在企业开发环境中是如何工作的？您将有一个Terraform脚本，它为每个用户创建托管管道、一组服务帐户(每个服务帐户只有一个用户拥有actAs权限)和笔记本实例。每个用户都可以使用“他们的”服务帐户创建笔记本实例。笔记本本身将被限制为单用户模式，以确保所有操作都是可审计的。</p><h2 id="8342" class="kk kl hi bd km kn ko kp kq kr ks kt ku jg kv kw kx jk ky kz la jo lb lc ld le bi translated">2b。为管道步骤创建Docker容器</h2><p id="6014" class="pw-post-body-paragraph ix iy hi iz b ja lf ij jc jd lg im jf jg lh ji jj jk li jm jn jo lj jq jr js hb bi translated">现在开发环境已经设置好了，我们可以开发ML组件，编写一个管道来连接各个步骤并执行管道。</p><p id="0386" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">每个步骤都需要是一个容器。因此，通过在docker文件中捕获依赖关系来将代码容器化。例如，这是用于将模型部署到AI平台的docker文件:</p><pre class="jv jw jx jy fd ll lm ln lo aw lp bi"><span id="1287" class="kk kl hi lm b fi lq lr l ls lt">FROM google/cloud-sdk:latest</span><span id="bbb0" class="kk kl hi lm b fi lu lr l ls lt">RUN mkdir -p /babyweight/src &amp;&amp; \<br/>    cd /babyweight/src &amp;&amp; \<br/>    git clone <a class="ae jt" href="https://github.com/GoogleCloudPlatform/training-data-analyst" rel="noopener ugc nofollow" target="_blank">https://github.com/GoogleCloudPlatform/training-data-analyst</a></span><span id="33c4" class="kk kl hi lm b fi lu lr l ls lt">COPY deploy.sh ./</span><span id="f372" class="kk kl hi lm b fi lu lr l ls lt">ENTRYPOINT ["bash", "./deploy.sh"]</span></pre><p id="67f9" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">注意一些技巧——从一个有用的起始图片开始。在这种情况下，部署一个模型需要运行一个gcloud命令，所以我从一个提供最新gcloud的映像开始。如果我需要来自源代码控制的文件，我可以git克隆我的存储库来为培训师提供源代码。</p><p id="85af" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">容器的入口点是从本地目录复制的run deploy.sh。实际上，该脚本由以下命令组成:</p><pre class="jv jw jx jy fd ll lm ln lo aw lp bi"><span id="d1da" class="kk kl hi lm b fi lq lr l ls lt">gcloud ai-platform versions create ${MODEL_VERSION} \<br/>       --model ${MODEL_NAME} --origin ${MODEL_LOCATION} \<br/>       --runtime-version $TFVERSION</span><span id="ee25" class="kk kl hi lm b fi lu lr l ls lt">echo $MODEL_NAME &gt; /model.txt<br/>echo $MODEL_VERSION &gt; /version.txt</span></pre><p id="c1d3" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我将简要描述echo命令的原因。</p><p id="c744" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们有容器的代码是不够的，我们必须构建容器并使其对集群可用。您可以使用云构建来实现这一点:</p><pre class="jv jw jx jy fd ll lm ln lo aw lp bi"><span id="357d" class="kk kl hi lm b fi lq lr l ls lt">gcloud builds submit . --config cloudbuild.yaml</span></pre><p id="17dd" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">其中cloudbuild.yaml指定了Google容器注册表(gcr.io)中的标签:</p><pre class="jv jw jx jy fd ll lm ln lo aw lp bi"><span id="866e" class="kk kl hi lm b fi lq lr l ls lt">steps:<br/>    - name: 'gcr.io/cloud-builders/docker'<br/>      dir:  '${DIR_IN_REPO}'   # remove-for-manual<br/>      args: [ 'build', '-t', 'gcr.io/${PROJECT_ID}/${CONTAINER_NAME}:${TAG_NAME}', '.' ]<br/>images:<br/>    - 'gcr.io/${PROJECT_ID}/${CONTAINER_NAME}:${TAG_NAME}'</span></pre><p id="1a1b" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在我们在gcr.io中有了一个Docker映像，我们可以在Jupyter笔记本中试用它:</p><pre class="jv jw jx jy fd ll lm ln lo aw lp bi"><span id="9d3f" class="kk kl hi lm b fi lq lr l ls lt">!docker run -t gcr.io/${PROJECT_ID}/babyweight-pipeline-deploycmle:latest gs://${BUCKET}/babyweight/hyperparam/17 babyweight local</span></pre><h2 id="89a3" class="kk kl hi bd km kn ko kp kq kr ks kt ku jg kv kw kx jk ky kz la jo lb lc ld le bi translated">2c。编写一个管道来连接这些步骤</h2><p id="c3a1" class="pw-post-body-paragraph ix iy hi iz b ja lf ij jc jd lg im jf jg lh ji jj jk li jm jn jo lj jq jr js hb bi translated">一旦我们将所有ML步骤容器化，我们就可以编写一个管道将这些步骤连接成一个DAG。这是在Python中使用kfp API完成的:</p><pre class="jv jw jx jy fd ll lm ln lo aw lp bi"><span id="3974" class="kk kl hi lm b fi lq lr l ls lt"><a class="ae jt" href="http://twitter.com/dsl" rel="noopener ugc nofollow" target="_blank">@dsl</a>.pipeline(<br/>  name='babyweight',<br/>  description='Train Babyweight model from scratch'<br/>)<br/>def preprocess_train_and_deploy(<br/>    project='ai-analytics-solutions',<br/>    bucket='ai-analytics-solutions-kfpdemo',<br/>    start_year='2000'<br/>):<br/>    """End-to-end Pipeline to train and deploy babyweight model"""<br/>    # Step 1: create training dataset using Apache Beam on Cloud Dataflow<br/>    preprocess = dsl.ContainerOp(<br/>          name='preprocess',<br/>          # image needs to be a compile-time string<br/>          image='gcr.io/ai-analytics-solutions/babyweight-pipeline-bqtocsv:latest',<br/>          arguments=[<br/>            '--project', project,<br/>            '--mode', 'cloud',<br/>            '--bucket', bucket,<br/>            '--start_year', start_year<br/>          ],<br/>          file_outputs={'bucket': '/output.txt'}<br/>      ).apply(use_gcp_secret('user-gcp-sa'))</span><span id="a0af" class="kk kl hi lm b fi lu lr l ls lt"># Step 2: Do hyperparameter tuning of the model on Cloud ML Engine<br/>    hparam_train = dsl.ContainerOp(<br/>        name='hypertrain',<br/>        # image needs to be a compile-time string<br/>        image='gcr.io/ai-analytics-solutions/babyweight-pipeline-hypertrain:latest',<br/>        arguments=[<br/>            preprocess.outputs['bucket']<br/>        ],<br/>        file_outputs={'jobname': '/output.txt'}<br/>      ).apply(use_gcp_secret('user-gcp-sa'))</span></pre><p id="6f5a" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">上面代码片段的要点是:</p><ul class=""><li id="2668" class="lw lx hi iz b ja jb jd je jg ly jk lz jo ma js mb mc md me bi translated">用`@dsl.pipeline `修饰该函数</li><li id="309a" class="lw lx hi iz b ja mf jd mg jg mh jk mi jo mj js mb mc md me bi translated">该函数的参数可用于配置运行</li><li id="cebe" class="lw lx hi iz b ja mf jd mg jg mh jk mi jo mj js mb mc md me bi translated">在我的例子中，每一步都是一个ContainerOp，它引用我们推送到gcr.io的Docker图像。</li><li id="3bc7" class="lw lx hi iz b ja mf jd mg jg mh jk mi jo mj js mb mc md me bi translated">您可以将参数传递给容器。这些将成为入口点的命令行参数</li><li id="8837" class="lw lx hi iz b ja mf jd mg jg mh jk mi jo mj js mb mc md me bi translated">指定步骤输出的显示位置</li><li id="2823" class="lw lx hi iz b ja mf jd mg jg mh jk mi jo mj js mb mc md me bi translated">步骤1 (bucket)的输出是步骤2 (preprocess.outputs['bucket'])的输入—注意，步骤的名称用于引用需要哪个步骤的输出。您可以使用这里的任何步骤，只要它不会引入循环依赖。</li></ul><p id="6375" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">当我们说预处理步骤的输出将在/output.txt中时，我们必须确保将数据放在那里。这就是为什么上一节中我的deploy.sh在文件的后续步骤中回显了一些必要的输入。</p><h2 id="c4dd" class="kk kl hi bd km kn ko kp kq kr ks kt ku jg kv kw kx jk ky kz la jo lb lc ld le bi translated">2d。手动执行管道</h2><p id="a874" class="pw-post-body-paragraph ix iy hi iz b ja lf ij jc jd lg im jf jg lh ji jj jk li jm jn jo lj jq jr js hb bi translated">一旦您编写了管道，您就可以使用kfp附带的命令行编译器来编译它，然后手动将它上传到仪表板。但是您也可以使用Python API直接提交代码。这在仪表板上更方便:</p><pre class="jv jw jx jy fd ll lm ln lo aw lp bi"><span id="5d79" class="kk kl hi lm b fi lq lr l ls lt">args = {<br/>    'project' : PROJECT, <br/>    'bucket' : BUCKET<br/>}</span><span id="da08" class="kk kl hi lm b fi lu lr l ls lt">client = kfp.Client(host=PIPELINES_HOST)<br/>pipeline = client.create_run_from_pipeline_func(<br/>     preprocess_train_and_deploy,<br/>     args)</span></pre><p id="3613" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">通过在GCP控制台中查看集群的设置，可以获得集群的PIPELINES_HOST。</p><p id="2222" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这将启动管道并在集群上保留日志。</p><h2 id="dafe" class="kk kl hi bd km kn ko kp kq kr ks kt ku jg kv kw kx jk ky kz la jo lb lc ld le bi translated">3a。设置持续集成(CI)</h2><p id="37f4" class="pw-post-body-paragraph ix iy hi iz b ja lf ij jc jd lg im jf jg lh ji jj jk li jm jn jo lj jq jr js hb bi translated">现在我们已经有了正确工作的代码，我们准备好设置持续集成了。基本上，每当Docker所依赖的任何文件被提交到源存储库时，我们都希望重新构建Docker映像。</p><p id="865a" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">为了简单起见，我组织了代码，使每个步骤都在一个自包含的目录中:</p><figure class="jv jw jx jy fd jz er es paragraph-image"><div role="button" tabindex="0" class="ka kb di kc bf kd"><div class="er es mk"><img src="../Images/ecb232352dddfd59b20ab85c745f0cb3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0a8Gt-J5gJZCT3fCVHO-jQ.png"/></div></div></figure><p id="1bd8" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">因此，我们所要做的就是<a class="ae jt" href="https://console.cloud.google.com/cloud-build/triggers" rel="noopener ugc nofollow" target="_blank">将GitHub存储库连接到GCP </a>账户，并从GitHub设置一系列云构建触发器:</p><figure class="jv jw jx jy fd jz er es paragraph-image"><div class="er es ml"><img src="../Images/3f67902284a5a0c901428077b6b48872.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/format:webp/1*EDEBnLNp9PQbWZoxybeEHg.png"/></div></figure><pre class="jv jw jx jy fd ll lm ln lo aw lp bi"><span id="5563" class="kk kl hi lm b fi lq lr l ls lt">create_github_trigger() {<br/>    DIR_IN_REPO=$(pwd | sed "s%${REPO_NAME}/% %g" | awk '{print $2}')<br/>    gcloud beta builds triggers create github \<br/>      --build-config="${DIR_IN_REPO}/cloudbuild.yaml" \<br/>      --included-files="${DIR_IN_REPO}/**" \<br/>      --branch-pattern="^master$" \<br/>      --repo-name=${REPO_NAME} --repo-owner=${REPO_OWNER} <br/>}</span><span id="72c1" class="kk kl hi lm b fi lu lr l ls lt">for container_dir in $(ls -d */ | sed 's%/%%g'); do<br/>    cd $container_dir<br/>    create_github_trigger<br/>    cd ..<br/>done</span></pre><p id="59f0" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><em class="mm">注意:为了验证这一点，你必须派生出我的GitHub repo，并用你的fork进行尝试——你可能没有权限将GoogleCloudPlatform repos连接到你自己的GCP项目。</em></p><p id="c400" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在，无论何时提交文件，相应的触发器都会启动云构建:</p><figure class="jv jw jx jy fd jz er es paragraph-image"><div role="button" tabindex="0" class="ka kb di kc bf kd"><div class="er es mn"><img src="../Images/b4c971eb0692118838b7f202e81f1bf1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Zrer1A8_UJKtDdXjB_KfIQ.png"/></div></div></figure><h2 id="2dcf" class="kk kl hi bd km kn ko kp kq kr ks kt ku jg kv kw kx jk ky kz la jo lb lc ld le bi translated">3b。设置连续部署(CD)</h2><p id="64d7" class="pw-post-body-paragraph ix iy hi iz b ja lf ij jc jd lg im jf jg lh ji jj jk li jm jn jo lj jq jr js hb bi translated">与web应用程序不同，每当我们更新包含管道的ML组件时，我们不希望重新运行每个ML模型。因此，请仔细考虑哪种类型的事件需要重新执行，以及重新执行是整个管道还是部分管道。</p><p id="d797" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">一个常见的场景是，每当我们有新数据时，我们都希望重新训练模型(或者我们可能只想微调训练)。让我们假设我们想要训练并立即部署更新的模型(例如，我们没有A/B测试等的准备阶段。).在这种情况下，我们将创建一个新的管道方法，它只包含训练和部署步骤，并启动它来响应云存储中的新文件。</p><p id="22b2" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">触发云存储的最简单方法是使用云功能。所以，我们可以做:</p><pre class="jv jw jx jy fd ll lm ln lo aw lp bi"><span id="7ee5" class="kk kl hi lm b fi lq lr l ls lt">def handle_newfile(data, context):<br/>    filename = data['filename']<br/>    mlp_babyweight.finetune_and_deploy(filename)</span></pre><p id="a2b4" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">其中，微调和部署方法为:</p><pre class="jv jw jx jy fd ll lm ln lo aw lp bi"><span id="51d6" class="kk kl hi lm b fi lq lr l ls lt">def finetune_and_deploy(filename):<br/>    """invoked from a Cloud Function or a Cloud Run, it launches a Pipeline on kfp"""<br/>    import kfp<br/>    import sys<br/>    <br/>    if 'babyweight/preproc/train' in filename:<br/>        PIPELINES_HOST = os.environ.get('PIPELINES_HOST', "Environment variable PIPELINES_HOST not set")<br/>        PROJECT = os.environ.get('PROJECT', "Environment variable PROJECT not set")<br/>        BUCKET = os.environ.get('BUCKET', "Environment variable BUCKET not set")<br/>        print("New file {}: Launching ML pipeline on {} to finetune model in {}".format(<br/>            filename, PIPELINES_HOST, BUCKET))<br/>        sys.stdout.flush()<br/>        client = kfp.Client(host=PIPELINES_HOST)<br/>        args = {<br/>            'project' : PROJECT, <br/>            'bucket' : BUCKET,<br/>        }<br/>        pipeline = client.create_run_from_pipeline_func(train_and_deploy, args)<br/>        return 'Fine tuning job Launched!'</span></pre><p id="5b36" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">然后，我们可以使用以下方式部署云功能:</p><pre class="jv jw jx jy fd ll lm ln lo aw lp bi"><span id="9b16" class="kk kl hi lm b fi lq lr l ls lt">gcloud functions deploy handle_newfile --runtime python37 \<br/>    --set-env-vars PROJECT=${PROJECT},BUCKET=${BUCKET},PIPELINES_HOST=${PIPELINES_HOST},HPARAM_JOB=${HPARAM_JOB} \<br/>    --trigger-resource=${BUCKET}  \<br/>    --trigger-event=google.storage.object.finalize</span></pre><p id="5942" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">请注意，我的存储库向您展示了一个更复杂的设置。我将执行代码容器化，并使用Cloud Run启动它。虽然我们可以从云存储中触发云运行，但这需要设置发布/订阅主题等。因此，我触发了一个云函数，然后让云函数调用云运行。</p><p id="ee56" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">如果我们在preproc目录下的云存储中创建一个新文件，那么将启动训练和部署ML阶段，并更新模型。</p><p id="1c26" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">尽情享受吧！</p><h2 id="cfec" class="kk kl hi bd km kn ko kp kq kr ks kt ku jg kv kw kx jk ky kz la jo lb lc ld le bi translated">后续步骤:</h2><ul class=""><li id="1eed" class="lw lx hi iz b ja lf jd lg jg mo jk mp jo mq js mb mc md me bi translated">在GitHub中尝试这个README.md文件中的步骤</li><li id="4fee" class="lw lx hi iz b ja mf jd mg jg mh jk mi jo mj js mb mc md me bi translated">阅读关于这个话题的<a class="ae jt" href="https://cloud.google.com/solutions/machine-learning/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning" rel="noopener ugc nofollow" target="_blank">谷歌云解决方案</a>——与解决方案相关的GitHub repo给你Terraform脚本等。在企业环境中这样做。</li></ul></div></div>    
</body>
</html>