<html>
<head>
<title>Using Dataproc Serverless to migrate your Hive data to Bigquery</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Dataproc Serverless将配置单元数据迁移到Bigquery</h1>
<blockquote>原文：<a href="https://medium.com/google-cloud/using-dataproc-serverless-to-migrate-your-hive-data-to-bigquery-8e2d4fcd1c24?source=collection_archive---------3-----------------------#2022-12-13">https://medium.com/google-cloud/using-dataproc-serverless-to-migrate-your-hive-data-to-bigquery-8e2d4fcd1c24?source=collection_archive---------3-----------------------#2022-12-13</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="5a38" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi jd translated"><span class="l je jf jg bm jh ji jj jk jl di">我们</span>可以使用Dataproc Serverless来运行Spark batch工作负载，而无需配置和管理我们自己的集群。我们可以指定工作负载参数，然后将工作负载提交给Dataproc无服务器服务。</p><p id="305c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><a class="ae jm" href="https://cloud.google.com/dataproc-serverless/docs" rel="noopener ugc nofollow" target="_blank"> <em class="jn"> Dataproc无服务器</em> </a> <em class="jn">帮助用户完成整个基础设施管理工作—执行他们的</em><a class="ae jm" href="http://spark.apache.org/" rel="noopener ugc nofollow" target="_blank"><em class="jn">Apache Spark</em></a><em class="jn">工作负载用户是</em> <strong class="ih hj"> <em class="jn">而不是</em> </strong> <em class="jn"> </em> <strong class="ih hj"> <em class="jn">需要</em> </strong> <em class="jn">先创建一个集群才能执行任何操作。用户只需根据自己的使用情况选择一个模板，只需点击几下鼠标和几个命令，即可完成各自的工作。</em></p><figure class="jp jq jr js fd jt er es paragraph-image"><div role="button" tabindex="0" class="ju jv di jw bf jx"><div class="er es jo"><img src="../Images/01099aafd37c8b098ded41cd3f556321.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TTfFvucv0QjUEmtHReLt_Q.png"/></div></div><figcaption class="ka kb et er es kc kd bd b be z dx translated">使用Dataproc无服务器从Hive到Bigquery的迁移</figcaption></figure></div><div class="ab cl ke kf gp kg" role="separator"><span class="kh bw bk ki kj kk"/><span class="kh bw bk ki kj kk"/><span class="kh bw bk ki kj"/></div><div class="hb hc hd he hf"><h2 id="62b9" class="kl km hi bd kn ko kp kq kr ks kt ku kv iq kw kx ky iu kz la lb iy lc ld le lf bi translated">目标</h2><p id="250f" class="pw-post-body-paragraph if ig hi ih b ii lg ik il im lh io ip iq li is it iu lj iw ix iy lk ja jb jc hb bi translated">这篇博客文章将分享关于如何使用“<a class="ae jm" href="https://github.com/GoogleCloudPlatform/dataproc-templates/tree/main/java/src/main/java/com/google/cloud/dataproc/templates/hive" rel="noopener ugc nofollow" target="_blank">Hive to big query</a>data proc无服务器模板”进行数据迁移的完整细节。该模板将从Apache Hive表中读取数据，并将其写入BigQuery表。</p></div><div class="ab cl ke kf gp kg" role="separator"><span class="kh bw bk ki kj kk"/><span class="kh bw bk ki kj kk"/><span class="kh bw bk ki kj"/></div><div class="hb hc hd he hf"><h2 id="34b2" class="kl km hi bd kn ko kp kq kr ks kt ku kv iq kw kx ky iu kz la lb iy lc ld le lf bi translated">设置您的GCP项目和基础设施</h2><ol class=""><li id="cf93" class="ll lm hi ih b ii lg im lh iq ln iu lo iy lp jc lq lr ls lt bi translated">登录到您的GCP项目并启用Dataproc API(如果它被禁用的话)</li><li id="ce89" class="ll lm hi ih b ii lu im lv iq lw iu lx iy ly jc lq lr ls lt bi translated">确保子网启用了私有Google访问，如果您要使用GCP生成的“默认”VPC网络，那么也必须启用私有访问，如下所示:</li></ol><figure class="jp jq jr js fd jt er es paragraph-image"><div role="button" tabindex="0" class="ju jv di jw bf jx"><div class="er es lz"><img src="../Images/1d96118efc365e205a42ee7736e81987.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LPcitxbKUL7HHL3-fib42w.png"/></div></div></figure><pre class="jp jq jr js fd ma mb mc bn md me bi"><span id="acb3" class="mf km hi mb b be mg mh l mi mj">gcloud compute networks subnets update default --region=us-central1 --enable-private-ip-google-access</span></pre><p id="fbf7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">3.为jar文件创建一个GCS存储桶和暂存位置。</p><pre class="jp jq jr js fd ma mb mc bn md me bi"><span id="b695" class="mf km hi mb b be mg mh l mi mj">export GCS_STAGING_BUCKET="my-gcs-staging-bucket"<br/>gsutil mb gs://$GCS_STAGING_BUCKET</span></pre><p id="f7c3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">4.要配置Dataproc无服务器作业，您需要导出以下变量</p><p id="b0a2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du mk ml mm mb b">GCP_PROJECT</code>:运行Dataproc无服务器的GCP项目id。</p><p id="2aa6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du mk ml mm mb b">REGION</code>:运行Dataproc无服务器的区域。</p><p id="cbfb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du mk ml mm mb b">GCS_STAGING_LOCATION</code> : GCS暂存桶位置，Dataproc将在此存储暂存资产(参见步骤3)。</p></div><div class="ab cl ke kf gp kg" role="separator"><span class="kh bw bk ki kj kk"/><span class="kh bw bk ki kj kk"/><span class="kh bw bk ki kj"/></div><div class="hb hc hd he hf"><h2 id="0f0f" class="kl km hi bd kn ko kp kq kr ks kt ku kv iq kw kx ky iu kz la lb iy lc ld le lf bi translated">执行Dataproc模板的步骤</h2><ol class=""><li id="ec11" class="ll lm hi ih b ii lg im lh iq ln iu lo iy lp jc lq lr ls lt bi translated">克隆Dataproc模板库并导航到Java模板文件夹。</li></ol><pre class="jp jq jr js fd ma mb mc bn md me bi"><span id="476d" class="mf km hi mb b be mg mh l mi mj">git clone https://github.com/GoogleCloudPlatform/dataproc-templates.git<br/>cd dataproc-templates/java</span></pre><p id="01bc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">2.获取身份验证凭据(以提交作业)。</p><pre class="jp jq jr js fd ma mb mc bn md me bi"><span id="30de" class="mf km hi mb b be mg mh l mi mj">gcloud auth application-default login</span></pre><p id="8e30" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">3.通过导出提交所需的变量来配置Dataproc无服务器作业(如<em class="jn">“设置您的GCP项目&amp;”</em>中的步骤4所述)。</p><pre class="jp jq jr js fd ma mb mc bn md me bi"><span id="3740" class="mf km hi mb b be mg mh l mi mj">export GCP_PROJECT=&lt;project_id&gt; # your Google Cloud project<br/>export REGION=&lt;region&gt; # your region for ex: us-central1<br/>export JARS="gs://spark-lib/bigquery/spark-bigquery-latest_2.12.jar" # JAR dependencies<br/>export SUBNET=&lt;subnet&gt; # optional if you are using default<br/># export GCS_STAGING_LOCATION=&lt;gcs-staging-bucket-folder&gt; # already done at step 3(Under Setup GCP Project &amp; Infra)</span></pre><p id="032a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">4.执行以下命令:-</p><pre class="jp jq jr js fd ma mb mc bn md me bi"><span id="0684" class="mf km hi mb b be mg mh l mi mj">GCP_PROJECT=&lt;gcp-project-id&gt; \<br/>REGION=&lt;region&gt;  \<br/>SUBNET=&lt;subnet&gt;   \<br/>GCS_STAGING_LOCATION=&lt;gcs-staging-bucket-folder&gt; \<br/>HISTORY_SERVER_CLUSTER=&lt;history-server&gt; \<br/>bin/start.sh \<br/>--properties=spark.hadoop.hive.metastore.uris=thrift://&lt;hostname-or-ip&gt;:9083 \<br/>-- --template HIVETOBIGQUERY \<br/>--templateProperty hivetobq.bigquery.location=&lt;required_bigquery destination&gt; \<br/>--templateProperty hivetobq.sql=&lt;hive_sql&gt; \<br/>--templateProperty hivetobq.write.mode=&lt;Append|Overwrite|ErrorIfExists|Ignore&gt; \ <br/>--templateProperty hivetobq.temp.gcs.bucket=&lt;gcs_bucket_path&gt;</span></pre><p id="46a8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jn">注意:请用双引号将SQL查询括起来。对于ex: </em></p><pre class="jp jq jr js fd ma mb mc bn md me bi"><span id="8455" class="mf km hi mb b be mg mh l mi mj">--templateProperty  hivetobq.sql="select * from dbname.tablename"</span></pre><p id="f0f6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jn">此外，还有两个可选属性以及“Hive to BigQuery”模板。请在下面找到他们的详细信息:- </em></p><pre class="jp jq jr js fd ma mb mc bn md me bi"><span id="a188" class="mf km hi mb b be mg mh l mi mj">--templateProperty hivetobq.temp.table='temporary_view_name' <br/>--templateProperty hivetobq.temp.query='select * from global_temp.temporary_view_name'</span></pre><p id="a7fa" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这些属性负责在将数据加载到BigQuery之前应用一些spark sql转换。我们唯一需要记住的是，Spark临时视图的名称和查询中的表名应该完全匹配。否则，将会出现如下错误:-"找不到表或视图:"</p><p id="bce4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jn">除了以上，以防万一你需要</em> <a class="ae jm" href="https://cloud.google.com/dataproc-serverless/docs/concepts/properties" rel="noopener ugc nofollow" target="_blank"> <em class="jn">指定Dataproc Serverless支持的spark属性</em> </a> <em class="jn">例如:调整驱动、内核、执行器等的数量——你可以编辑start.sh文件中的OPT_PROPERTIES值。</em></p><p id="9f13" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">5.监控Spark批处理作业</p><p id="eb9b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">提交作业后，我们将能够在<a class="ae jm" href="https://console.cloud.google.com/dataproc/batches" rel="noopener ugc nofollow" target="_blank"> Dataproc批处理UI </a>中看到它。从那里，我们可以查看作业的指标和日志。</p></div><div class="ab cl ke kf gp kg" role="separator"><span class="kh bw bk ki kj kk"/><span class="kh bw bk ki kj kk"/><span class="kh bw bk ki kj"/></div><div class="hb hc hd he hf"><h2 id="c634" class="kl km hi bd kn ko kp kq kr ks kt ku kv iq kw kx ky iu kz la lb iy lc ld le lf bi translated">参考</h2><ul class=""><li id="87f5" class="ll lm hi ih b ii lg im lh iq ln iu lo iy lp jc mn lr ls lt bi translated"><a class="ae jm" href="https://cloud.google.com/dataproc-serverless/docs/overview" rel="noopener ugc nofollow" target="_blank"> Dataproc无服务器</a></li><li id="19fa" class="ll lm hi ih b ii lu im lv iq lw iu lx iy ly jc mn lr ls lt bi translated"><a class="ae jm" href="https://github.com/GoogleCloudPlatform/dataproc-templates" rel="noopener ugc nofollow" target="_blank"> Dataproc模板库</a></li></ul><p id="b280" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如有任何疑问/建议，请联系:dataproc-templates-support-external@googlegroups.com</p></div></div>    
</body>
</html>