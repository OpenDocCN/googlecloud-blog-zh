<html>
<head>
<title>How to prevent OOMs while streaming data to GCS via Apache Beam/Dataflow?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何在通过Apache Beam/Dataflow向GCS传输数据时防止OOMs？</h1>
<blockquote>原文：<a href="https://medium.com/google-cloud/how-to-prevent-ooms-while-streaming-data-to-gcs-via-apache-beam-dataflow-53ec37987626?source=collection_archive---------0-----------------------#2022-11-16">https://medium.com/google-cloud/how-to-prevent-ooms-while-streaming-data-to-gcs-via-apache-beam-dataflow-53ec37987626?source=collection_archive---------0-----------------------#2022-11-16</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="6bde" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们承认，当你处理大量数据时，流式传输是一项具有挑战性的任务。我在将数据传输到GCS时遇到的一个常见问题是内存不足(OOM)错误。别慌，你不是一个人，每个人都会这样。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jd"><img src="../Images/e01cebc5dbaf92376be4682e3e1a6d3f.png" data-original-src="https://miro.medium.com/v2/resize:fit:960/0*dU7u51zbdlXKHFXZ"/></div><figcaption class="jl jm et er es jn jo bd b be z dx translated">不要惊慌，你并不孤单</figcaption></figure></div><div class="ab cl jp jq gp jr" role="separator"><span class="js bw bk jt ju jv"/><span class="js bw bk jt ju jv"/><span class="js bw bk jt ju"/></div><div class="hb hc hd he hf"><h1 id="2767" class="jw jx hi bd jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt bi translated">让我们看看后端发生了什么</h1><p id="a59f" class="pw-post-body-paragraph if ig hi ih b ii ku ik il im kv io ip iq kw is it iu kx iw ix iy ky ja jb jc hb bi translated">假设我们有一个包含以下Java代码的管道。我们用动态目的地和固定数量的碎片将拼花文件写入GC。</p><pre class="je jf jg jh fd kz la lb lc aw ld bi"><span id="8f41" class="le jx hi la b fi lf lg l lh li">.apply( "WriteParquetFile(s)",<br/>        FileIO.&lt;Destination,GenericRecord&gt;<em class="lj">writeDynamic</em>()<br/>                .by(new DestinationBuilder())<br/>                .via(ParquetIO.<em class="lj">sink</em>(schema))<br/>                .to(options.getOutputBucket())<br/>                .withCompression(Compression.<em class="lj">SNAPPY</em>)<br/>                .withNumShards(options.getNumShards())                .withDestinationCoder(AvroCoder.<em class="lj">of</em>(Destination.class))<br/>                .withNaming(key-&gt; FileIO.Write.<em class="lj">defaultNaming</em>(key.getPath(),".parquet") )<br/>);</span></pre><p id="529a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">神奇的事情发生在<a class="ae lk" href="https://github.dev/apache/beam/blob/master/sdks/java/core/src/main/java/org/apache/beam/sdk/io/WriteFiles.java" rel="noopener ugc nofollow" target="_blank">WriteFiles.java</a>梁库中，在我们的例子中是在<em class="lj">WriteShardedBundlesToTempFiles</em>pttransform中，代码如下:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="er es ll"><img src="../Images/24bb5deb680925f6490782303494d1c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vFNNOxasfB7UUjUIwVdvRA.png"/></div></div><figcaption class="jl jm et er es jn jo bd b be z dx translated">数据被分成碎片，然后写入GCS</figcaption></figure><p id="1185" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">那么实际上发生了什么呢？如下所示，对于每个窗口及其窗格(多个，以防您有早/晚触发)，我们应用GroupByKey。关键是目的地和碎片的组合。它们被散列，但是由于散列有相当大的空间，你可以假设<strong class="ih hj">组数= # keys x # shards </strong>。分组后，Beam使用GCS连接器进行写入。默认情况下，GCS连接器为每个组创建1MB的缓冲区，并通过GCS API执行可恢复的上传。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="er es lq"><img src="../Images/853ba2a14455b3f3c26f0a9386257c4e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eb78mcp-9KqXR9kcZtZmig.png"/></div></div><figcaption class="jl jm et er es jn jo bd b be z dx translated">具有动态目的地和碎片的FileIO</figcaption></figure><p id="23a4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们举几个例子来看看内存影响。</p><ol class=""><li id="ff50" class="lr ls hi ih b ii ij im in iq lt iu lu iy lv jc lw lx ly lz bi translated"><strong class="ih hj">没有提前点火的窗户</strong>。假设每个窗口平均有10个动态目的地，我们有5个碎片。如果没有提前触发，窗口触发器将按顺序触发。平行化将受到限制。那么，只有GCS缓冲区起作用:1个窗口x 10个目的地x 5个碎片x 1MB缓冲区= 50MB。在缓冲区之上，我们还有实际的数据。</li><li id="35d9" class="lr ls hi ih b ii ma im mb iq mc iu md iy me jc lw lx ly lz bi translated"><strong class="ih hj">有早期点火的窗户。由于我们有早期触发，多个窗口触发器开始并行触发。假设我们当前打开了10个窗口，因为我们有未排序的最新数据。目的地和碎片同上。那么我们的GCS缓冲区至少消耗10个窗口x 10个目的地x 5个碎片x 1MB = 500 MB。</strong></li></ol><p id="d498" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如您所见，当您并行执行许多写操作时，事情可能会突然变得非常糟糕。好的一面是，这些写操作中的每一个都由单个线程处理，并且通过数据流引擎在虚拟机之间进行分配。</p></div><div class="ab cl jp jq gp jr" role="separator"><span class="js bw bk jt ju jv"/><span class="js bw bk jt ju jv"/><span class="js bw bk jt ju"/></div><div class="hb hc hd he hf"><h1 id="73af" class="jw jx hi bd jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt bi translated">我们有什么选择来防止OOMs并增加吞吐量？</h1><ol class=""><li id="d17e" class="lr ls hi ih b ii ku im kv iq mf iu mg iy mh jc lw lx ly lz bi translated"><strong class="ih hj"> VM大小</strong>定义了一台机器上所有线程的共享内存。您应该提供更大的机器(例如，highmem机器)或使用数据流垂直自动缩放来避免OOMs。</li><li id="3651" class="lr ls hi ih b ii ma im mb iq mc iu md iy me jc lw lx ly lz bi translated"><strong class="ih hj">number of worker harness threads</strong>参数定义了每个虚拟机的线程数量。默认情况下，流式管道的值为300。通过降低该限制，我们降低了流水线的并行性，但是我们也限制了内存消耗。总是有权衡的。请注意，数据流具有工作负载重新平衡功能，因此它在机器之间移动工作负载，以避免一台机器过度拥挤。</li><li id="b332" class="lr ls hi ih b ii ma im mb iq mc iu md iy me jc lw lx ly lz bi translated"><strong class="ih hj"> numShards </strong>定义了我们为每个键和窗口创建的碎片数量。一个键的每个窗口/窗格都被分成碎片，以进一步减少每个线程的消息大小，并并行写入GC。碎片可以帮助你调整在GCS中创建的文件的大小，同时也可以并行写入GCS。如果您发现GCS吞吐量很低，增加碎片的数量可能会有所帮助。</li><li id="2513" class="lr ls hi ih b ii ma im mb iq mc iu md iy me jc lw lx ly lz bi translated"><strong class="ih hj"> gcsUploadBufferSizeBytes </strong>定义GCS可恢复上传操作的缓冲区大小。无论数据大小如何，每个GCS编写器线程都会在开始时分配这个缓冲区。Beam中默认设置为<a class="ae lk" href="https://github.com/apache/beam/blob/master/runners/google-cloud-dataflow-java/src/main/java/org/apache/beam/runners/dataflow/DataflowRunner.java#L223" rel="noopener ugc nofollow" target="_blank"> 1MB </a>，而原来的GCS连接器使用<a class="ae lk" href="https://github.com/GoogleCloudDataproc/hadoop-connectors/blob/master/util/src/main/java/com/google/cloud/hadoop/util/AsyncWriteChannelOptions.java#L42" rel="noopener ugc nofollow" target="_blank"> 8MB </a>。光束覆盖这个领域，以避免OOMs的情况下，太多的作家开放。</li><li id="d032" class="lr ls hi ih b ii ma im mb iq mc iu md iy me jc lw lx ly lz bi translated"><strong class="ih hj">管道分支</strong>可用于根据高容量主题设置参数。有些主题和分区会生成更多的文件。对于那些人来说，最好提供更多的碎片来划分数据。我们建议<a class="ae lk" href="https://beam.apache.org/documentation/pipelines/design-your-pipeline/#branching-pcollections" rel="noopener ugc nofollow" target="_blank">大容量的分支p集合</a>为它们设置更大的numShards。</li></ol></div><div class="ab cl jp jq gp jr" role="separator"><span class="js bw bk jt ju jv"/><span class="js bw bk jt ju jv"/><span class="js bw bk jt ju"/></div><div class="hb hc hd he hf"><h1 id="f9b0" class="jw jx hi bd jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt bi translated">如何监控？</h1><p id="4168" class="pw-post-body-paragraph if ig hi ih b ii ku ik il im kv io ip iq kw is it iu kx iw ix iy ky ja jb jc hb bi translated">数据流作业度量页面允许您查看内存消耗和许多其他度量。如果您启用<a class="ae lk" href="https://cloud.google.com/dataflow/docs/guides/profiling-a-pipeline#enable_for_pipelines" rel="noopener ugc nofollow" target="_blank">数据流分析选项</a>，那么您甚至可以看到堆空间的使用情况。</p><p id="98a6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">一个被忽视但很重要的指标是<strong class="ih hj">并行度</strong>。它帮助我们在写入阶段看到每个窗口的<em class="lj">键数。首先，通过转到“执行细节”选项卡并尝试找到WriteShardsIntoTempFiles的PTransform，找出正确的融合阶段。如下图所示，它处于F33阶段。</em></p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="er es mi"><img src="../Images/14e86144bc7032c7c4a5d149b37da3cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-b0aXCnMnDzk2c9FEMQINA.png"/></div></div><figcaption class="jl jm et er es jn jo bd b be z dx translated">数据流将连续的转换融合到一个阶段中。您可以在“执行细节”选项卡中找到写转换的阶段。</figcaption></figure><p id="f6bd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">发现阶段(在我的例子中为F33)后，转到作业指标选项卡并选择并行度。在那里你会看到钥匙的数量。我的是100 (5个目的地和20个碎片)。这表示平均每个窗口的数据分为100组。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="er es mj"><img src="../Images/a844e107b2c2b118cbb4ac63da35a8da.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lbchISDZbda8nHZjSqkjsg.png"/></div></div><figcaption class="jl jm et er es jn jo bd b be z dx translated">并行度度量仅适用于启用了流式引擎的管道。它显示了键的数量以及每个阶段的并行度。</figcaption></figure><p id="c1d5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果有更多的窗口/窗格同时被触发，可能会有更多的组。并行度定义了估计的键，而不是实际触发的分组。我们也可以发现这一点！在<strong class="ih hj">计时器</strong>指标下，我们看到所有等待和已处理的窗格/窗口。在我的例子中，我通常有大约200个窗格同时启动，最后峰值达到2.5K。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="er es mk"><img src="../Images/1cddf9f761ea48af738f471cef0270f5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eFvOp0eJNj9jt4aREMUbGg.png"/></div></div><figcaption class="jl jm et er es jn jo bd b be z dx translated">计时器显示发射的数量。由于我的管道中有早期点火，我看到的点火比并行性更多。</figcaption></figure><p id="3c38" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">即使有2.5K的峰值(每个窗格1MB缓冲区x 2.5K = 2.5 MB)，<strong class="ih hj">我也不应该有任何内存中断。发生了什么事</strong>？</p><p id="9eda" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">所以我检查了我的输出文件，发现每个parquet文件都有几百个字节。<strong class="ih hj">每条消息都有自己的文件！</strong></p><p id="22f6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">以下代码来自FileIO-WriteShardsIntoTempFilesFn。对于每个输入消息，选择一个目的地写入器。目标编写器是一个哈希映射。你猜怎么着？我还没有为目标类实现我的Java POJO的散列函数！这就是为什么对于每一台机器，由于每个对象都有唯一的java hash，所以会创建一个新的writer。默认情况下，每个写入器都有自己的1MB缓冲区，尽管我只有几百字节大小的消息。结果是数百万条消息和数千兆字节的内存使用。通过在我的POJO中添加一个简单的散列函数，问题就解决了。现在，我有几千字节大小的文件。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="er es ml"><img src="../Images/432710534c5f6af7f5f1779221c9a8e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UPfzacZQwvclqLg_ltijGw.png"/></div></div><figcaption class="jl jm et er es jn jo bd b be z dx translated">FileIO—writeshardsintotempfiles fn。每条消息都被发送到一个编写器，编写器是根据消息的哈希来选择的。</figcaption></figure></div></div>    
</body>
</html>