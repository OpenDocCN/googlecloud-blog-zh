<html>
<head>
<title>Loading data from Hive to Bigquery (via Spark BQ connector) using Dataproc Serverless</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Dataproc无服务器将数据从Hive加载到Bigquery(通过Spark BQ连接器)</h1>
<blockquote>原文：<a href="https://medium.com/google-cloud/loading-data-from-hive-to-bigquery-via-spark-bq-connector-using-dataproc-serverless-3a870d0ff64f?source=collection_archive---------5-----------------------#2022-12-01">https://medium.com/google-cloud/loading-data-from-hive-to-bigquery-via-spark-bq-connector-using-dataproc-serverless-3a870d0ff64f?source=collection_archive---------5-----------------------#2022-12-01</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/c66ef4b5c5f939d66a1fa2c0f5a3dff0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Dg6V8HTNkH20Jg-r.png"/></div></div></figure><p id="0f8f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在无服务器处理时代，在专用集群上运行Spark作业会增加更多的处理开销，并占用开发人员宝贵的开发时间。将完全托管的随需应变服务器与Spark jobs结合使用，有助于开发人员专注于核心应用程序逻辑，而在框架上花费很少或没有时间。谷歌的Dataproc Serverless就是谷歌云平台提供的这样一款产品。</p><p id="5ba7" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在本文中，我们将讨论无服务器Dataproc如何通过sql将数据从Hive表加载到bigquery，用于ETL或ELT目的。</p><h1 id="91da" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">主要优势</h1><ol class=""><li id="d916" class="km kn hi is b it ko ix kp jb kq jf kr jj ks jn kt ku kv kw bi translated">使用<strong class="is hj"> Dataproc无服务器</strong>运行Spark批处理工作负载，无需管理Spark框架。</li><li id="b85e" class="km kn hi is b it kx ix ky jb kz jf la jj lb jn kt ku kv kw bi translated"><a class="ae lc" href="https://github.com/GoogleCloudPlatform/dataproc-templates/blob/main/java/src/main/java/com/google/cloud/dataproc/templates/hive/HiveToBigQuery.java" rel="noopener ugc nofollow" target="_blank"><strong class="is hj">hivetobiqquery</strong></a>模板是开源的，配置驱动的，随时可以使用。</li><li id="1aff" class="km kn hi is b it kx ix ky jb kz jf la jj lb jn kt ku kv kw bi translated">支持的加载模式有追加、覆盖、错误存在和忽略。</li></ol><h1 id="1d0d" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">使用</h1><ol class=""><li id="ff55" class="km kn hi is b it ko ix kp jb kq jf kr jj ks jn kt ku kv kw bi translated">如果你要使用“默认的”由GCP生成的VPC网络，请确保你已经启用了私有谷歌访问子网。您仍然需要启用如下的私人访问。</li></ol><figure class="le lf lg lh fd ij er es paragraph-image"><div class="er es ld"><img src="../Images/516511504ac158645daf746635ffef55.png" data-original-src="https://miro.medium.com/v2/resize:fit:570/format:webp/0*SI2YUxBo_pM881fB.png"/></div></figure><pre class="le lf lg lh fd li lj lk bn ll lm bi"><span id="373d" class="ln jp hi lj b be lo lp l lq lr">gcloud compute networks subnets update default --region=us-central1 --enable-private-ip-google-access</span></pre><p id="288b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">2.为jar文件创建一个GCS存储桶和暂存位置。</p><p id="3ee4" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">3.在预装了<a class="ae lc" href="https://cloud.google.com/shell/docs/how-cloud-shell-works" rel="noopener ugc nofollow" target="_blank">各种工具</a>的云壳中克隆git repo。或者使用任何预装JDK 8+，Maven和Git的机器。</p><pre class="le lf lg lh fd li lj lk bn ll lm bi"><span id="ee38" class="ln jp hi lj b be lo lp l lq lr">git clone https://github.com/GoogleCloudPlatform/dataproc-templates.gitcd dataproc-templates/java</span></pre><p id="c9a6" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">4.获取身份验证凭据(以提交作业)。</p><pre class="le lf lg lh fd li lj lk bn ll lm bi"><span id="274f" class="ln jp hi lj b be lo lp l lq lr">gcloud auth application-default login</span></pre><p id="2bbe" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">5.执行HiveToBigquery模板。<br/>例如:</p><pre class="le lf lg lh fd li lj lk bn ll lm bi"><span id="c0db" class="ln jp hi lj b be lo lp l lq lr">GCP_PROJECT=&lt;gcp-project-id&gt; \<br/>REGION=&lt;region&gt;  \<br/>SUBNET=&lt;subnet&gt;   \<br/>GCS_STAGING_LOCATION=&lt;gcs-staging-bucket-folder&gt; \<br/>HISTORY_SERVER_CLUSTER=&lt;history-server&gt; \<br/>bin/start.sh \<br/>--properties=spark.hadoop.hive.metastore.uris=thrift://&lt;hostname-or-ip&gt;:9083 \<br/>-- --template HIVETOBIGQUERY \<br/>--templateProperty hivetobq.bigquery.location=&lt;project.dataset.tableß∂&gt; \<br/>--templateProperty hivetobq.sql=&lt;hive_sql&gt; \<br/>--templateProperty hivetobq.write.mode=&lt;Append|Overwrite|ErrorIfExists|Ignore&gt; \ <br/>--templateProperty hivetobq.temp.gcs.bucket=&lt;gcs_bucket_path&gt;</span></pre><p id="2df9" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">双引号中的Hive SQL查询。例子，</p><pre class="le lf lg lh fd li lj lk bn ll lm bi"><span id="b53f" class="ln jp hi lj b be lo lp l lq lr">--templateProperty  hivetobq.sql="select * from dbname.tablename"</span></pre><p id="4a91" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">注意</strong>:如果尚未启用，它会要求您启用Dataproc Api。</p><p id="f611" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">6.到目前为止，这个过程将把数据从Hive表/查询加载到bigquery。如果您想要转换数据，模板提供了一种方法，一旦将源数据加载到数据集中，就可以对其执行自定义sql。</p><pre class="le lf lg lh fd li lj lk bn ll lm bi"><span id="f7ba" class="ln jp hi lj b be lo lp l lq lr">--templateProperty hivetobq.temp.table='temporary_view_name' <br/>--templateProperty hivetobq.temp.query='select * from global_temp.temporary_view_name'</span></pre><p id="1b29" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">上述属性负责在将数据加载到BigQuery时应用一些spark sql转换。唯一需要记住的是，Spark临时视图的名称和查询中的表名应该完全匹配。否则，将会出现如下错误:“找不到表或视图”</p></div></div>    
</body>
</html>