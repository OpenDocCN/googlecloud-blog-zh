<html>
<head>
<title>Apache Spark and Jupyter Notebooks made easy with Dataproc component gateway</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Apache Spark和Jupyter笔记本电脑通过Dataproc组件网关变得简单</h1>
<blockquote>原文：<a href="https://medium.com/google-cloud/apache-spark-and-jupyter-notebooks-made-easy-with-dataproc-component-gateway-fa91d48d6a5a?source=collection_archive---------0-----------------------#2020-03-12">https://medium.com/google-cloud/apache-spark-and-jupyter-notebooks-made-easy-with-dataproc-component-gateway-fa91d48d6a5a?source=collection_archive---------0-----------------------#2020-03-12</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="098a" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">使用新的Dataproc可选组件和组件网关特性来轻松设置和使用Jupyter笔记本电脑</h2></div><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ix"><img src="../Images/7eebe12b4bbb7d3838de214ed47a620b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ITz23f880aFggnAT9sqoLw.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">基于谷歌云的Apache Spark和Jupyter笔记本架构</figcaption></figure><p id="78c9" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">作为Jupyter笔记本的长期用户和粉丝，我一直在寻找设置和使用笔记本的最佳方式，尤其是在云中。我相信Jupyter笔记本是学习、原型制作以及在某些情况下制作数据项目的完美工具，因为它们允许您交互式地运行代码并立即看到结果。它们是一个很好的协作工具，因为它们的背景来自于在科学界的使用和共享。</p><p id="2f4b" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">过去，您可能在桌面上用Python使用过Jupyter笔记本，但却难以处理非常大的数据集。然而，现在有了许多可用的内核，您可以在Jupyter中使用Apache Spark对大规模数据进行分布式处理，但也可以在同一个笔记本中继续使用您的Python库。</p><p id="a162" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">然而，使用Jupyter笔记本电脑设置Apache Spark集群可能会很复杂，因此在这个新的“<strong class="jp hj"> Apache Spark和Jupyter Cloud data proc上的笔记本电脑”</strong>系列文章的第1部分中，我将向您展示由于有了像<a class="ae kj" href="https://cloud.google.com/dataproc/docs/concepts/components/overview" rel="noopener ugc nofollow" target="_blank">可选组件</a>和<a class="ae kj" href="https://cloud.google.com/dataproc/docs/concepts/accessing/dataproc-gateways" rel="noopener ugc nofollow" target="_blank">组件网关</a>这样的新功能，开始使用是多么容易。</p><h1 id="b76c" class="kk kl hi bd km kn ko kp kq kr ks kt ku io kv ip kw ir kx is ky iu kz iv la lb bi translated">用Spark和Jupyter创建一个Dataproc集群</h1><p id="fe00" class="pw-post-body-paragraph jn jo hi jp b jq lc ij js jt ld im jv jw le jy jz ka lf kc kd ke lg kg kh ki hb bi translated">您可以使用Google Cloud控制台、gcloud CLI或<a class="ae kj" href="https://cloud.google.com/dataproc/docs/reference/libraries" rel="noopener ugc nofollow" target="_blank"> Dataproc客户端库</a>创建一个云Dataproc集群。</p><p id="40be" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">我们将从已经安装了gcloud的<a class="ae kj" href="https://console.cloud.google.com/?cloudshell=true" rel="noopener ugc nofollow" target="_blank">云Shell </a>中使用gcloud CLI(如果您不熟悉Google Cloud，请查看<a class="ae kj" href="https://codelabs.developers.google.com/codelabs/cloud-shell/index.html?index=..%2F..index#2" rel="noopener ugc nofollow" target="_blank">云Shell入门&amp; gcloud codelab </a>)。</p><p id="888b" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">也可以通过安装<a class="ae kj" href="https://cloud.google.com/sdk/gcloud" rel="noopener ugc nofollow" target="_blank">云SDK </a>在本地使用gcloud CLI。</p><p id="04c7" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">要在云shell或您的终端窗口中开始，设置您的项目ID，您将在那里创建您的Dataproc集群</p><pre class="iy iz ja jb fd lh li lj lk aw ll bi"><span id="e294" class="lm kl hi li b fi ln lo l lp lq">gcloud config set project &lt;project-id&gt;</span></pre><h2 id="58d0" class="lm kl hi bd km lr ls lt kq lu lv lw ku jw lx ly kw ka lz ma ky ke mb mc la md bi translated"><strong class="ak">启用产品API和IAM角色</strong></h2><p id="b528" class="pw-post-body-paragraph jn jo hi jp b jq lc ij js jt ld im jv jw le jy jz ka lf kc kd ke lg kg kh ki hb bi translated">运行这个命令来启用云数据平台上的Apache Spark和Jupyter笔记本系列文章中需要的所有API。</p><pre class="iy iz ja jb fd lh li lj lk aw ll bi"><span id="96b4" class="lm kl hi li b fi ln lo l lp lq">gcloud services enable dataproc.googleapis.com \<br/>  compute.googleapis.com \<br/>  storage-component.googleapis.com \<br/>  bigquery.googleapis.com \<br/>  bigquerystorage.googleapis.com</span></pre><p id="8733" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">如果您不是管理员或没有启用API的正确权限，请要求您的GCP组织或项目的管理员启用上述API。</p><p id="53ff" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">他们还需要给你正确的<a class="ae kj" href="https://cloud.google.com/dataproc/docs/concepts/iam/iam#roles" rel="noopener ugc nofollow" target="_blank"> <strong class="jp hj"> Dataproc IAM角色</strong> </a>和Google <a class="ae kj" href="https://cloud.google.com/storage/docs/access-control/iam-roles" rel="noopener ugc nofollow" target="_blank">云存储IAM角色</a>来创建和使用你的Dataproc集群。</p><h2 id="1fab" class="lm kl hi bd km lr ls lt kq lu lv lw ku jw lx ly kw ka lz ma ky ke mb mc la md bi translated"><strong class="ak">创建一个由您的Dataproc集群使用的GCS bucket</strong></h2><p id="6faf" class="pw-post-body-paragraph jn jo hi jp b jq lc ij js jt ld im jv jw le jy jz ka lf kc kd ke lg kg kh ki hb bi translated">在离您的数据最近的区域创建一个Google云存储桶，并给它一个唯一的名称。这将用于Dataproc集群。</p><pre class="iy iz ja jb fd lh li lj lk aw ll bi"><span id="7795" class="lm kl hi li b fi ln lo l lp lq">REGION=us-central1<br/>BUCKET_NAME=&lt;your-bucket-name&gt;</span><span id="a781" class="lm kl hi li b fi me lo l lp lq">gsutil mb -c standard -l ${REGION} gs://${BUCKET_NAME}</span></pre><p id="6d6a" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">您应该会看到以下输出</p><blockquote class="mf mg mh"><p id="5b40" class="jn jo mi jp b jq jr ij js jt ju im jv mj jx jy jz mk kb kc kd ml kf kg kh ki hb bi translated">正在创建gs:// <your-bucket-name> /...</your-bucket-name></p></blockquote><p id="edb1" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated"><strong class="jp hj">使用Jupyter &amp;组件网关</strong>创建您的Dataproc集群</p><p id="9eba" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">为集群设置环境变量</p><pre class="iy iz ja jb fd lh li lj lk aw ll bi"><span id="9d4c" class="lm kl hi li b fi ln lo l lp lq">REGION=us-central1 <br/>ZONE=us-central1-a <br/>CLUSTER_NAME=spark-jupyter-&lt;your-name&gt; <br/>BUCKET_NAME=&lt;your-bucket-name&gt;</span></pre><p id="c568" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">然后运行这个<code class="du mm mn mo li b">gcloud</code>命令，用所有必要的组件创建集群，以便在集群上使用Jupyter。</p><pre class="iy iz ja jb fd lh li lj lk aw ll bi"><span id="650d" class="lm kl hi li b fi ln lo l lp lq">gcloud beta dataproc clusters create ${CLUSTER_NAME} \<br/>  --region=${REGION} \<br/>  <!-- -->--zone<!-- -->=${<!-- -->ZONE} \<br/>  --image-version=1.5 \<br/>  --master-machine-type=n1-standard-4 \<br/>  --worker-machine-type=n1-standard-4 \<br/>  --bucket=${BUCKET_NAME} \<br/>  --optional-components=ANACONDA,JUPYTER \<br/>  --enable-component-gateway \<br/>  --metadata 'PIP_PACKAGES=google-cloud-bigquery google-cloud-storage' \<br/>  --initialization-actions gs://goog-dataproc-initialization-actions-${REGION}/python/pip-install.sh</span></pre><p id="b716" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">创建集群时，您应该会看到以下输出</p><blockquote class="mf mg mh"><p id="8c30" class="jn jo mi jp b jq jr ij js jt ju im jv mj jx jy jz mk kb kc kd ml kf kg kh ki hb bi translated">等待操作[项目/spark-jupyter-笔记本/区域/us-central 1/操作/随机字母-数字-abcd123456]。<br/>正在等待集群创建操作…</p></blockquote><p id="e9db" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">创建您的集群需要2到3分钟，一旦准备就绪，您将能够从<a class="ae kj" href="https://console.cloud.google.com/dataproc/clusters" rel="noopener ugc nofollow" target="_blank"> Dataproc云控制台UI </a>访问您的集群。</p><p id="fac0" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">创建集群后，您应该会看到以下输出:</p><blockquote class="mf mg mh"><p id="d4f8" class="jn jo mi jp b jq jr ij js jt ju im jv mj jx jy jz mk kb kc kd ml kf kg kh ki hb bi translated">已创建[https://data proc . Google APIs . com/v1beta 2/projects/project-id/regions/us-central 1/clusters/spark-jupyter-your-name]集群，该集群位于区域[us-central1-a]中。</p></blockquote><h2 id="3b04" class="lm kl hi bd km lr ls lt kq lu lv lw ku jw lx ly kw ka lz ma ky ke mb mc la md bi translated">gcloud dataproc创建命令中使用的标志</h2><p id="3b25" class="pw-post-body-paragraph jn jo hi jp b jq lc ij js jt ld im jv jw le jy jz ka lf kc kd ke lg kg kh ki hb bi translated">下面是在<code class="du mm mn mo li b">gcloud dataproc create</code>命令中使用的标志的分类</p><pre class="iy iz ja jb fd lh li lj lk aw ll bi"><span id="a954" class="lm kl hi li b fi ln lo l lp lq">--region=${REGION} <br/>--zone=${ZONE} </span></pre><p id="9f93" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">指定将在其中创建分类的地区和区域。您可以在此处查看<a class="ae kj" href="https://cloud.google.com/compute/docs/regions-zones#available" rel="noopener ugc nofollow" target="_blank">可用区域列表。</a> Zone是可选的，除非当您使用n2机器类型时，您必须指定一个Zone。</p><pre class="iy iz ja jb fd lh li lj lk aw ll bi"><span id="0bb5" class="lm kl hi li b fi ln lo l lp lq">--image-version=1.4</span></pre><p id="8c9f" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">要在集群中使用的映像版本。你可以在这里看到<a class="ae kj" href="https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-versions" rel="noopener ugc nofollow" target="_blank">可用版本列表</a>。</p><pre class="iy iz ja jb fd lh li lj lk aw ll bi"><span id="e2fc" class="lm kl hi li b fi ln lo l lp lq">--bucket=${BUCKET_NAME}</span></pre><p id="dff3" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">指定您之前创建的用于集群的Google云存储桶。如果您没有提供GCS存储桶，将会为您创建一个。</p><p id="3d81" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">这也是保存笔记本的位置，即使您删除了集群，因为GCS存储桶不会被删除。</p><pre class="iy iz ja jb fd lh li lj lk aw ll bi"><span id="2403" class="lm kl hi li b fi ln lo l lp lq">--master-machine-type=n1-standard-4<br/>--worker-machine-type=n1-standard-4</span></pre><p id="7230" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">用于Dataproc集群的机器类型。您可以在这里看到可用的<a class="ae kj" href="https://cloud.google.com/compute/docs/machine-types" rel="noopener ugc nofollow" target="_blank">机器类型列表。</a></p><p id="c0d7" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated"><strong class="jp hj"> <em class="mi">注:请关注该系列的后续文章，推荐使用何种机器类型以及如何启用自动缩放</em> </strong></p><pre class="iy iz ja jb fd lh li lj lk aw ll bi"><span id="3875" class="lm kl hi li b fi ln lo l lp lq">--optional-components=ANACONDA,JUPYTER</span></pre><p id="c3a8" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">为可选组件<a class="ae kj" href="https://cloud.google.com/dataproc/docs/concepts/components/overview" rel="noopener ugc nofollow" target="_blank">设置这些值</a>将在您的集群上安装Jupyter和Anaconda(Jupyter笔记本所需的)的所有必要库。</p><pre class="iy iz ja jb fd lh li lj lk aw ll bi"><span id="72bb" class="lm kl hi li b fi ln lo l lp lq">--enable-component-gateway</span></pre><p id="54c4" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">启用<a class="ae kj" href="https://cloud.google.com/dataproc/docs/concepts/accessing/dataproc-gateways" rel="noopener ugc nofollow" target="_blank">组件网关</a>创建一个使用Apache Knox和反向代理的应用引擎链接，提供对Jupyter和JupyterLab web接口的简单、安全和认证的访问，这意味着您不再需要创建SSH隧道。</p><p id="eb1e" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">它还将为集群上的其他工具创建链接，包括Yarn Resource manager和Spark History Server，这些工具对于查看作业性能和集群使用模式非常有用。</p><pre class="iy iz ja jb fd lh li lj lk aw ll bi"><span id="7ed6" class="lm kl hi li b fi ln lo l lp lq">--metadata 'PIP_PACKAGES=google-cloud-bigquery google-cloud-storage' <br/>--initialization-actions gs://goog-dataproc-initialization-actions-${REGION}/python/pip-install.sh</span></pre><p id="2b8b" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">安装最新版本的<a class="ae kj" href="https://googleapis.dev/python/bigquery/latest/index.html" rel="noopener ugc nofollow" target="_blank"> Google Cloud BigQuery python库</a>和<a class="ae kj" href="https://googleapis.dev/python/storage/latest/client.html" rel="noopener ugc nofollow" target="_blank"> Google Cloud Storage python库</a>。在笔记本中使用BigQuery和GCS时，它们将用于执行各种任务。</p><h1 id="27f1" class="kk kl hi bd km kn ko kp kq kr ks kt ku io kv ip kw ir kx is ky iu kz iv la lb bi translated">访问Jupyter或JupyterLab web界面</h1><p id="1e20" class="pw-post-body-paragraph jn jo hi jp b jq lc ij js jt ld im jv jw le jy jz ka lf kc kd ke lg kg kh ki hb bi translated">一旦集群准备就绪，您可以在Google Cloud console for Dataproc中找到到Jupyter和JupyterLab web接口的组件网关链接，方法是单击您创建的集群并转到<strong class="jp hj"> Web接口</strong>选项卡。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mp"><img src="../Images/900c1472e6a607702d68f1185d755658.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6eNJc6DjMbp6JPEvuHb5Lg.png"/></div></div></figure><p id="561e" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">或者，您可以通过运行这个<code class="du mm mn mo li b">gcloud</code>命令来获得链接。</p><pre class="iy iz ja jb fd lh li lj lk aw ll bi"><span id="9d79" class="lm kl hi li b fi ln lo l lp lq">REGION=us-central1<br/>CLUSTER_NAME=spark-jupyter-&lt;your-name&gt;</span><span id="d254" class="lm kl hi li b fi me lo l lp lq">gcloud beta dataproc clusters describe ${CLUSTER_NAME} \<br/>  --region=${REGION}</span></pre><p id="be99" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">这将显示具有以下格式的链接的输出。</p><pre class="iy iz ja jb fd lh li lj lk aw ll bi"><span id="3e2a" class="lm kl hi li b fi ln lo l lp lq">clusterName: spark-jupyter-&lt;your-name&gt;<br/>clusterUuid: XXXX-1111-2222-3333-XXXXXX<br/>config:<br/>  configBucket: bucket-name<br/>  endpointConfig:<br/>    enableHttpPortAccess: true<br/>    httpPorts:<br/>      Jupyter: <a class="ae kj" href="https://gsbrebdjijhgjlmsdqkc2byoua-dot-us-east1.dataproc.googleusercontent.com/jupyter/" rel="noopener ugc nofollow" target="_blank">https://</a><a class="ae kj" href="https://gsbrebdjijhgjlmsdqkc2byoua-dot-us-east1.dataproc.googleusercontent.com/hdfs/dfshealth.html" rel="noopener ugc nofollow" target="_blank">random-characters</a><a class="ae kj" href="https://gsbrebdjijhgjlmsdqkc2byoua-dot-us-east1.dataproc.googleusercontent.com/jupyter/" rel="noopener ugc nofollow" target="_blank">-dot-us-east1.dataproc.googleusercontent.com/jupyter/</a><br/>      JupyterLab: <a class="ae kj" href="https://gsbrebdjijhgjlmsdqkc2byoua-dot-us-east1.dataproc.googleusercontent.com/jupyter/lab/" rel="noopener ugc nofollow" target="_blank">https://</a><a class="ae kj" href="https://gsbrebdjijhgjlmsdqkc2byoua-dot-us-east1.dataproc.googleusercontent.com/hdfs/dfshealth.html" rel="noopener ugc nofollow" target="_blank">random-characters</a><a class="ae kj" href="https://gsbrebdjijhgjlmsdqkc2byoua-dot-us-east1.dataproc.googleusercontent.com/jupyter/lab/" rel="noopener ugc nofollow" target="_blank">-dot-us-east1.dataproc.googleusercontent.com/jupyter/lab/</a><br/>...</span></pre><p id="c051" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">你会注意到你可以访问经典笔记本界面Jupyter或者被描述为Jupyter项目下一代UI的<a class="ae kj" href="https://jupyterlab.readthedocs.io/en/stable/getting_started/overview.html" rel="noopener ugc nofollow" target="_blank"> JupyterLab </a>。</p><p id="fdc8" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">JupyterLab中有许多很棒的新UI功能，所以如果你是使用笔记本的新手或正在寻找最新的改进，建议使用JupyterLab，因为根据官方文件，它最终将取代经典的Jupyter界面。</p><h1 id="7d52" class="kk kl hi bd km kn ko kp kq kr ks kt ku io kv ip kw ir kx is ky iu kz iv la lb bi translated">Python 3、PySpark、R和Scala内核</h1><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mq"><img src="../Images/a8dc3a505d4ab1b2ae70e54c7f4a7f51.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VewHWLFn1H4HsuKzX-iCEQ.png"/></div></div></figure><p id="0ce5" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">基于您在创建Dataproc集群时选择的映像版本，您将有不同的内核可用:</p><ul class=""><li id="1e19" class="mr ms hi jp b jq jr jt ju jw mt ka mu ke mv ki mw mx my mz bi translated"><strong class="jp hj">镜像版本1.3: </strong> Python 2和PySpark</li><li id="3daf" class="mr ms hi jp b jq na jt nb jw nc ka nd ke ne ki mw mx my mz bi translated"><strong class="jp hj">镜像版本1.4: </strong> Python 3、PySpark (Python)、R和Spylon (Scala)</li><li id="fcde" class="mr ms hi jp b jq na jt nb jw nc ka nd ke ne ki mw mx my mz bi translated"><strong class="jp hj">镜像版本预览(1.5): </strong> Python 3、PySpark (Python)、R、Spylon (Scala)</li></ul><p id="ee64" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">您应该使用image或更高版本，这样您就可以利用Python 3内核来运行PySpark代码，或者利用Spylon内核来运行Scala代码。</p><h1 id="7a25" class="kk kl hi bd km kn ko kp kq kr ks kt ku io kv ip kw ir kx is ky iu kz iv la lb bi translated">创建您的第一个PySpark Jupyter笔记本</h1><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es nf"><img src="../Images/697c74dd153e5e7a0eb61f94b21abc04.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bDl1Zag6z39HJUmWvhDUfQ.png"/></div></div></figure><p id="7763" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">在launcher选项卡中，单击Python 3笔记本图标，创建一个具有Python 3内核(不是PySpark内核)的笔记本，允许您在笔记本中配置SparkSession，并包含使用<a class="ae kj" href="https://cloud.google.com/bigquery/docs/reference/storage" rel="noopener ugc nofollow" target="_blank"> BigQuery存储API </a>所需的<a class="ae kj" href="https://github.com/GoogleCloudDataproc/spark-bigquery-connector" rel="noopener ugc nofollow" target="_blank"> spark-bigquery-connector </a>。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ng"><img src="../Images/587cf343398ecb9d6fb39d1c3f5f6ae2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*v2gjZBDWZ7Hvx0ENZCx7VA.png"/></div></div></figure><p id="96df" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">一旦笔记本在第一个单元格中打开，检查集群的Scala版本，这样就可以包含正确版本的spark-bigquery-connector jar。</p><p id="1d3a" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated"><strong class="jp hj">输入[1]: </strong></p><pre class="iy iz ja jb fd lh li lj lk aw ll bi"><span id="ada5" class="lm kl hi li b fi ln lo l lp lq">!scala -version</span></pre><p id="df48" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated"><strong class="jp hj">输出[1]: </strong></p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es nh"><img src="../Images/ffa9c2eac9240bbbd6c6c3173ff3a4b4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dOpjH7XG--f_a2BS1tYGgA.png"/></div></div></figure><p id="26a3" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">创建一个Spark会话，并包含spark-bigquery-connector jar</p><p id="16ff" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated"><strong class="jp hj">输入[2]: </strong></p><pre class="iy iz ja jb fd lh li lj lk aw ll bi"><span id="24a0" class="lm kl hi li b fi ln lo l lp lq"><strong class="li hj">from</strong> <strong class="li hj">pyspark.sql</strong> <strong class="li hj">import</strong> SparkSession<br/>spark = SparkSession.builder \<br/>  .appName('Jupyter BigQuery Storage')\<br/>  .config('spark.jars', 'gs://spark-lib/bigquery/spark-bigquery-latest_2.12.jar') \<br/>  .getOrCreate()</span></pre><p id="9eac" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">通过从公共BigQuery数据集中读入数据来创建Spark数据帧。这利用了<a class="ae kj" href="https://github.com/GoogleCloudDataproc/spark-bigquery-connector" rel="noopener ugc nofollow" target="_blank">spark-bigquery-connector</a>和big query存储API将数据加载到Spark集群中。</p><p id="ed0b" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">如果您的Scala版本是2.11，请使用下面的jar</p><pre class="iy iz ja jb fd lh li lj lk aw ll bi"><span id="3b9c" class="lm kl hi li b fi ln lo l lp lq">gs://spark-lib/bigquery/spark-bigquery-latest.jar</span></pre><p id="5352" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">如果您的Scala版本是2.12，请使用下面的jar</p><pre class="iy iz ja jb fd lh li lj lk aw ll bi"><span id="19f4" class="lm kl hi li b fi ln lo l lp lq">gs://spark-lib/bigquery/spark-bigquery-latest_2.12.jar</span></pre><p id="a4ae" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">我们将创建一个Spark数据框架，并从维基百科页面浏览量的<a class="ae kj" rel="noopener" href="/@marcacohen/processing-10tb-of-wikipedia-page-views-part-1-b984d8ebe146"> BigQuery公共数据集中加载数据。您会注意到我们没有对数据运行查询，因为我们使用bigquery-storage-connector将数据加载到Spark中，在Spark中进行数据处理。</a></p><p id="65d7" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated"><strong class="jp hj">输入【3】:</strong></p><pre class="iy iz ja jb fd lh li lj lk aw ll bi"><span id="2bb1" class="lm kl hi li b fi ln lo l lp lq">table = "bigquery-public-data.wikipedia.pageviews_2020"</span><span id="4ba1" class="lm kl hi li b fi me lo l lp lq">df = spark.read \<br/>  .format("bigquery") \<br/>  .option("table", table) \<br/>  .load()</span><span id="f96a" class="lm kl hi li b fi me lo l lp lq">df.printSchema()</span></pre><p id="bce0" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated"><strong class="jp hj">输出[3]: </strong></p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ni"><img src="../Images/4edb0e3d7d266edb10cc8c856308233b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Yjv0b9CR1V2Beu-TK9d0ZA.png"/></div></div></figure><p id="4c70" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">创建一个新的聚合Spark数据框架并打印该模式</p><p id="c098" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated"><strong class="jp hj">输入【4】:</strong></p><pre class="iy iz ja jb fd lh li lj lk aw ll bi"><span id="7018" class="lm kl hi li b fi ln lo l lp lq">df_agg = df \<br/>  .select('wiki', 'views') \<br/>  .where("datehour = '2020-03-03'") \<br/>  .groupBy('wiki') \<br/>  .sum('views')</span><span id="e387" class="lm kl hi li b fi me lo l lp lq">df_agg.printSchema()</span></pre><p id="76a0" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated"><strong class="jp hj">输出[4]: </strong></p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es nj"><img src="../Images/7f73f47ebf9361437226de85c3b80ccb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-39EJWmJY1Xh_jFG8EJKyQ.png"/></div></div></figure><p id="f26c" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">使用数据帧上的<code class="du mm mn mo li b">.show()</code>函数运行聚合，这将启动Spark作业来处理数据，然后显示Spark数据帧的输出，限于前20行。</p><p id="3c0d" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated"><strong class="jp hj">输入【5】:</strong></p><pre class="iy iz ja jb fd lh li lj lk aw ll bi"><span id="427d" class="lm kl hi li b fi ln lo l lp lq">df_agg.show()</span></pre><p id="1cfa" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated"><strong class="jp hj">输出[5]: </strong></p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es nk"><img src="../Images/9b194b66d94dc89f808f0fdf23fef56e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OL1_dLe3K64fjsNrQ6TzAA.png"/></div></div></figure><p id="cc91" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">现在您应该已经有了您的第一个Jupyter笔记本，并在您的Dataproc集群上运行。为您的笔记本命名，它将自动保存到创建集群时使用的GCS存储桶中。您可以使用这个<code class="du mm mn mo li b">gsutil</code>命令来检查。</p><pre class="iy iz ja jb fd lh li lj lk aw ll bi"><span id="1f1f" class="lm kl hi li b fi ln lo l lp lq">BUCKET_NAME=&lt;your-bucket-name&gt;</span><span id="c549" class="lm kl hi li b fi me lo l lp lq">gsutil ls gs://${BUCKET_NAME}/notebooks/jupyter</span></pre><h1 id="1af8" class="kk kl hi bd km kn ko kp kq kr ks kt ku io kv ip kw ir kx is ky iu kz iv la lb bi translated">更多使用案例的笔记本示例</h1><p id="f339" class="pw-post-body-paragraph jn jo hi jp b jq lc ij js jt ld im jv jw le jy jz ka lf kc kd ke lg kg kh ki hb bi translated">本系列的下一篇文章将重点介绍Jupyter笔记本，这些笔记本采用常见的Apache Spark模式来加载数据、保存数据，并使用各种Google云平台产品和开源工具绘制数据:</p><ul class=""><li id="670c" class="mr ms hi jp b jq jr jt ju jw mt ka mu ke mv ki mw mx my mz bi translated">Spark和BigQuery存储API</li><li id="5231" class="mr ms hi jp b jq na jt nb jw nc ka nd ke ne ki mw mx my mz bi translated">Spark和谷歌云存储</li><li id="af18" class="mr ms hi jp b jq na jt nb jw nc ka nd ke ne ki mw mx my mz bi translated">火花和阿帕奇冰山/三角洲湖</li><li id="14c9" class="mr ms hi jp b jq na jt nb jw nc ka nd ke ne ki mw mx my mz bi translated">使用熊猫绘制火花数据帧</li></ul><p id="7c34" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">您还可以在云数据平台GitHub repo 上访问即将发布的<a class="ae kj" href="http://github.com/GoogleCloudDataproc/cloud-dataproc/tree/master/notebooks" rel="noopener ugc nofollow" target="_blank">示例笔记本</a></p><h1 id="09f2" class="kk kl hi bd km kn ko kp kq kr ks kt ku io kv ip kw ir kx is ky iu kz iv la lb bi translated">授予群集的服务帐户访问数据的权限</h1><p id="e880" class="pw-post-body-paragraph jn jo hi jp b jq lc ij js jt ld im jv jw le jy jz ka lf kc kd ke lg kg kh ki hb bi translated">在上面的例子中，我们正在访问一个公共数据集，但是对于您的用例，您最有可能以受限的访问权限访问您公司的数据。Jupyter notebook和Dataproc集群将尝试使用底层Google计算机引擎(GCE)虚拟机的服务帐户而不是您自己的Google凭据来访问Google云平台服务中的数据。</p><p id="631f" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">您可以通过运行这个命令来找到您的集群的服务帐户，该命令描述GCE中的主虚拟机，它将具有与您的Dataproc集群相同的名称，后跟<code class="du mm mn mo li b"><strong class="jp hj">-m</strong></code></p><pre class="iy iz ja jb fd lh li lj lk aw ll bi"><span id="5bde" class="lm kl hi li b fi ln lo l lp lq">ZONE=us-central1-a <br/>CLUSTER_NAME=spark-jupyter-&lt;your-name&gt;</span><span id="be59" class="lm kl hi li b fi me lo l lp lq">gcloud compute instances describe ${CLUSTER_NAME}-m \<br/>  --zone=${ZONE}</span></pre><p id="e0ce" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">这将给出一个很长的属性列表，包括服务帐户和范围，如示例输出所示。</p><pre class="iy iz ja jb fd lh li lj lk aw ll bi"><span id="0faa" class="lm kl hi li b fi ln lo l lp lq">serviceAccounts:- <br/>  email: &lt;random-number&gt;-compute@developer.gserviceaccount.com  <br/>  scopes:  - <a class="ae kj" href="https://www.googleapis.com/auth/bigquery" rel="noopener ugc nofollow" target="_blank">https://www.googleapis.com/auth/bigquery</a>  - <a class="ae kj" href="https://www.googleapis.com/auth/bigtable.admin.table" rel="noopener ugc nofollow" target="_blank">https://www.googleapis.com/auth/bigtable.admin.table</a>  - <a class="ae kj" href="https://www.googleapis.com/auth/bigtable.data" rel="noopener ugc nofollow" target="_blank">https://www.googleapis.com/auth/bigtable.data</a>  - <a class="ae kj" href="https://www.googleapis.com/auth/cloud.useraccounts.readonly" rel="noopener ugc nofollow" target="_blank">https://www.googleapis.com/auth/cloud.useraccounts.readonly</a>  - <a class="ae kj" href="https://www.googleapis.com/auth/devstorage.full_control" rel="noopener ugc nofollow" target="_blank">https://www.googleapis.com/auth/devstorage.full_control</a>  - <a class="ae kj" href="https://www.googleapis.com/auth/devstorage.read_write" rel="noopener ugc nofollow" target="_blank">https://www.googleapis.com/auth/devstorage.read_write</a>  - <a class="ae kj" href="https://www.googleapis.com/auth/logging.write" rel="noopener ugc nofollow" target="_blank">https://www.googleapis.com/auth/logging.write</a></span></pre><p id="8662" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">或者，您可以在Google Cloud控制台中查看服务帐户，方法是转到Dataproc集群中的<strong class="jp hj"> VM Instances </strong>选项卡，然后单击主VM实例。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es nl"><img src="../Images/5dd99f8ab066416d3b4b082ea8d7d6bc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bB_ttptnMvqJQ_7bE2Jc1A.png"/></div></div></figure><p id="5ee7" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">进入虚拟机页面后，滚动到底部，您将看到虚拟机的服务帐户。对于群集中的所有虚拟机实例，这是相同的服务帐户。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es nm"><img src="../Images/c97a7480a95170bed442e26b442c92df.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vfz-qlUQEe1hFHHz6nTBdQ.png"/></div></div></figure><p id="6408" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">然后，您应该为服务帐户提供正确的<a class="ae kj" href="https://cloud.google.com/bigquery/docs/access-control#bigquery" rel="noopener ugc nofollow" target="_blank"> <strong class="jp hj"> BigQuery IAM角色</strong> </a> <strong class="jp hj">和</strong> <a class="ae kj" href="https://cloud.google.com/storage/docs/access-control/iam-roles" rel="noopener ugc nofollow" target="_blank"> <strong class="jp hj"> GCS IAM角色</strong> </a>来访问您需要的BigQuery数据集或GCS存储桶。</p><p id="bc9c" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">有关提供正确访问的更多详细信息，请阅读本解决方案，以<a class="ae kj" href="https://cloud.google.com/solutions/help-secure-the-pipeline-from-your-data-lake-to-your-data-warehouse" rel="noopener ugc nofollow" target="_blank">帮助保护从数据湖到数据仓库的管道。</a></p><h1 id="aced" class="kk kl hi bd km kn ko kp kq kr ks kt ku io kv ip kw ir kx is ky iu kz iv la lb bi translated">删除您的Dataproc集群</h1><p id="f2a6" class="pw-post-body-paragraph jn jo hi jp b jq lc ij js jt ld im jv jw le jy jz ka lf kc kd ke lg kg kh ki hb bi translated">一旦您在Jupyter笔记本中完成了所有工作，并且所有Spark作业都完成了处理，建议您删除Dataproc集群，这可以通过云控制台或使用gcloud命令来完成:</p><pre class="iy iz ja jb fd lh li lj lk aw ll bi"><span id="d2f1" class="lm kl hi li b fi ln lo l lp lq">REGION=us-central1 <br/>CLUSTER_NAME=spark-jupyter-&lt;your-name&gt; </span><span id="8c13" class="lm kl hi li b fi me lo l lp lq">gcloud beta dataproc clusters delete ${CLUSTER_NAME} \<br/>  --region=${REGION}</span></pre><p id="b14a" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">如前所述，您可以随时删除和重新创建您的集群，并且您的所有笔记本仍将保存在Google云存储桶中，当您删除Dataproc集群时，该存储桶不会被删除。</p><h1 id="6dc1" class="kk kl hi bd km kn ko kp kq kr ks kt ku io kv ip kw ir kx is ky iu kz iv la lb bi translated">下一步是什么</h1><ul class=""><li id="909a" class="mr ms hi jp b jq lc jt ld jw nn ka no ke np ki mw mx my mz bi translated">请关注下一篇文章系列，它将更深入地介绍在Jupyter笔记本中使用bigquery-storage-connector。</li><li id="e53a" class="mr ms hi jp b jq na jt nb jw nc ka nd ke ne ki mw mx my mz bi translated">在<a class="ae kj" rel="noopener" href="/@tfayyaz"> Medium (@tfayyaz) </a>和<a class="ae kj" href="http://twitter.com/tfayyaz" rel="noopener ugc nofollow" target="_blank"> Twitter (tfayyaz) </a>上关注我，了解更多关于Dataproc的最新更新并分享反馈。</li><li id="b1d9" class="mr ms hi jp b jq na jt nb jw nc ka nd ke ne ki mw mx my mz bi translated">请在评论中或在<a class="ae kj" href="https://stackoverflow.com/questions/tagged/google-cloud-dataproc" rel="noopener ugc nofollow" target="_blank"> google-cloud-dataproc </a>标签下的Stackoverflow上提问。</li><li id="2a43" class="mr ms hi jp b jq na jt nb jw nc ka nd ke ne ki mw mx my mz bi translated">在Dataproc上愉快地使用Spark和Jupyter笔记本。</li></ul></div></div>    
</body>
</html>