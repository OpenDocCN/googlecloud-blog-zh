# 了解 Oracle 与数据流和数据流的 BigQuery 复制的端到端延迟

> 原文：<https://medium.com/google-cloud/understand-end-to-end-latency-for-oracle-to-bigquery-replication-with-datastream-and-dataflow-55f350526eb1?source=collection_archive---------0----------------------->

本文的目标是解释在使用数据流和数据流将数据从 Oracle 复制到 BigQuery 时，我们如何控制端到端延迟。

GCP 数据流是一种无服务器的变更数据捕获(CDC)和复制服务，允许您跨异构数据库同步数据。

这种复制分两步处理。首先，Datastream 从事务日志中获取数据库更改，并且在其当前状态下能够将这些更改缓冲和具体化为 Google 云存储上的文件。第二步由数据流连续作业处理，该作业在文件到达时从 Google 云存储中读取文件，并将缓冲的更改流式传输到 BigQuery。

![](img/6856159f1c64fd181a582a865761c66f.png)

这张高级图已经表明，至少有几个地方会影响源数据库中的更改被复制和供 BigQuery 用户使用的速度。让我们更深入地了解延迟的最重要来源。

# 神谕

对于 Oracle，Datastream 使用 Oracle LogMiner 来查询数据库的重做日志文件。在 Oracle 数据库的新版本(如 19c)中，CONTINUOUS_MINE 选项已被弃用，Logminer 失去了连续挖掘在线重做日志的能力。但这不会影响数据流，因为数据流使用 LogMiner 从所谓的归档重做日志中读取数据。那么什么是归档重做日志呢？归档重做日志可以理解为重做日志文件的物理副本。但是什么是重做日志文件呢？；)每一个数据修改操作(更新、插入、删除、改变等)。)首先被写入所谓的重做日志缓冲区。然后，使用进程名 LGWR(日志写入程序)将更改事件写入活动重做日志文件。我认为下面的图片很好地捕捉到了这一点:

![](img/477a499e7dd9c59fef88f1a3f30f1e3a.png)

图片来源: [Oracle Database 12c 备份和恢复生存指南](https://subscription.packtpub.com/book/big+data+and+business+intelligence/9781782171201/1/ch01lvl1sec16/the-archivelog-mode)

可以将单个数据库实例配置为具有多个重做日志文件。事实上，如果数据库在 ARCHIVELOG 模式下工作(这是数据流所要求的)，它至少需要两个文件来保证一个文件始终可用于写入(活动重做日志),而另一个文件则被归档。这就带来了延迟—只有当活动重做日志变满时，才会归档最近的更改。LGWR 进程以循环方式写入重做日志文件:当当前重做日志文件填满时，LGWR 开始写入下一个可用的重做日志文件。当最后一个可用的重做日志文件填满时，LGWR 会返回到第一个重做日志文件并写入其中，再次开始循环。当活动重做日志文件变满时，另一个称为 ARCn 的内部进程负责归档该文件，因此命名为归档重做日志文件。

当活动重做日志文件变满并且 LGWR 进程开始写入下一个文件的时刻**称为重做日志文件切换**。此阶段的延迟由重做日志文件切换频率和归档该文件所需的时间决定。Oracle 的经验法则是，在 DML 活动高峰时，每小时不要切换超过 3 个日志(20 分钟的重做)，以防止过多的检查点。这相当于 20 分钟的延迟。

这里有哪些选项:

*   您可以将数据库配置为定期切换重做日志文件(由数据流推荐)
*   您可以使用以下 SQL 命令手动执行重做日志文件切换(当您使用数据流时非常有用):

**更改系统切换日志文件**

如何知道是否有新的归档重做日志文件？重做日志文件成功归档后，查询 **V$ARCHIVED_LOG** 视图会发现新的记录。此视图还将帮助您测量新的归档重做日志文件可供数据流使用需要多长时间。

**信号源的总延迟:可配置，但接近 30 分钟**

# 数据流

数据流不断对源数据库进行采样，以获取新的归档重做日志文件。如果您想知道这里的延迟是什么，我们需要更好地理解这个步骤是如何工作的。因此，让我们看看替代解决方案，如 Kafka Connect 与 Log Miner 如何处理它。如果您检查 git 上可用的 Kafka Connect 代码，您会发现[**logminerethread**](https://github.com/klc213bk/kafka-connect-logminer/blob/main/src/main/java/com/transglobe/kafka/connect/oracle/LogMinerThread2.java)类。通过连续的 while(true)循环处理提取存档文件，一旦文件被识别，代码发送 logMinerSelectSql **以提取**相应的更改:

![](img/cf7129ccb08105553fabeb8aa6cfa2b0.png)

这里，我们应该区分 Oracle 数据库上发生更改时的时间戳(所谓的事件时间戳)和数据流开始处理与该更改相对应的记录时由数据流分配的时间戳(所谓的读取时间戳)。两者之间的差异由数据流监控为**数据新鲜度**度量:

![](img/d5d5d1beb3770d121ccb25b0cb3fabaf.png)

数据流处理一个事件所花费的时间由数据流监控，作为**系统延迟**指标。

![](img/37aa4a9390b883819c11502be19d34c8.png)

这背后的直觉是这样的。想象一下，你想乘一辆公共汽车从家到工作地点。你去火车站，你看到公共汽车刚刚离开。你到达车站的那一刻就是你的事件时间戳。

![](img/fdf15ef69115a8075b60084374cb3ce3.png)

既然车已经开走了，你需要等下一辆。当它来的时候，你进入公共汽车——你确认车票的时刻就是你的阅读时间戳。**数据新鲜度**因此可以理解为你出现在公交车站的时刻和你验证车票的时刻之间的时间差。你坐下来，车就开了。让你到达目的地汽车站的时间是**系统延迟**。

**那么当数据流发生变化时会发生什么呢？**

数据流 stream 缓冲这些更改，然后将它们作为文件物化到 Google 云存储中。默认情况下，无论何时达到最大文件大小或最大超时值(以先到者为准)，都会创建新文件。默认情况下，文件每 50 MB 或 30 秒轮换一次，这是此阶段系统延迟的一个很好的近似值。您可以使用 Datastream API 修改这两个数字:[https://cloud . Google . com/Datastream/docs/manage-streams # createastream](https://cloud.google.com/datastream/docs/manage-streams#modifyastream)。

因此，在总数据新鲜度+系统延迟中，解释将更改记录移动到 Google 云存储上的文件需要多长时间，以便从在源数据库中创建更改的时刻到数据流将缓冲的更改具体化为 Google 云存储上的文件的时刻。您可以在数据流监控中观察到**总延迟**:

![](img/99186ad141e8a6b908fd51025130bfc2.png)

**数据流阶段的总延迟:可配置，但也可能需要几分钟**

![](img/5a3a0502eb4d3c69337e9ef5fd6847f5.png)

# 数据流

有数据流模板用于实例化连续数据流作业，将更改从 Google 云存储移动到 BigQuery:

![](img/c49d47fe24db373c31399af2eb1760c0.png)

您将被要求指定三个必需的参数:

Google 云存储上的位置，数据流将缓冲的更改具体化为文件。

2/您需要在数据流使用的 Google 云存储上启用 PubSub 通知。数据流将监听相应的事件，以了解数据流写入桶的任何新文件。

[](https://cloud.google.com/datastream/docs/implementing-datastream-dataflow-analytics#enable-pub-sub-notifs) [## 为分析实施数据流和数据流|谷歌云

### 为具有许多独立数据源的企业发送反馈，访问整个组织的企业数据…

cloud.google.com](https://cloud.google.com/datastream/docs/implementing-datastream-dataflow-analytics#enable-pub-sub-notifs) 

3/当在云存储上具体化对文件的改变时，数据流使用的文件格式(可用选项是 avro 或 json，并且您应该坚持您选择的创建数据流流)。

当您启动此作业并访问要复制源表的 BigQuery 数据集时，您会发现每个源表都有两个目标表，其中一个带有后缀“_log ”,其中附加了所有更改，并且每个记录都包含有关它所代表的更改类型的信息，即它是插入、更新还是删除。您可以通过配置参数指示数据流作业定期将新的更改合并到最终目标表中。每个合并操作都会在 BigQuery 上产生开销，因此您需要平衡开销和数据延迟。我强烈推荐下面这篇文章，它很好地解释了这种权衡:[https://cloud . Google . com/architecture/database-replication-to-big query-using-change-data-capture](https://cloud.google.com/architecture/database-replication-to-bigquery-using-change-data-capture)

![](img/b15dd23f3c1eecdd4b9c13d5602a6aa6.png)

数据流作业将把变更事件传递给 BigQuery。与数据流类似，数据流作业需要首先从源获取变更事件(对于数据流作业，源是 Google 云存储)，因此数据新鲜度和系统延迟的概念也适用于这一步。

数据流模板定义了一个表示逻辑执行计划的任务图。

![](img/2fc7e90730e593fad2f0eed50227064c.png)

当运行该图时，数据流会将这个逻辑计划编译成物理计划，并将任务分解成执行阶段。它们的名称(F142、F145、…)无助于理解它们对应于哪个任务，但是从本文的角度来看，需要注意的是，每个这样的阶段都有自己的数据新鲜度。

![](img/ab9a92e144e863dadf7069f63900b529.png)

在图表上监控数据流作业指标更加方便。这里我们有按阶段划分的数据新鲜度:

![](img/5314802ac59d69a11e643519471c51f5.png)

这里，我们汇总了所有阶段的最大和平均数据新鲜度:

![](img/3cf47678673438228c7fda826e886378.png)

每个阶段都需要一些时间来处理我们的更改，因此这是系统延迟的一个来源。同样，数据流有助于我们分阶段了解系统延迟:

![](img/e8a25b6223663c0bc2dad64fb20b6fee.png)

我们还可以跟踪所有阶段的最大值和平均值:

![](img/2fbd5144629c1c36ce26056024180ee9.png)

**数据新鲜度** + **系统延迟**定义数据流作业引入的**总延迟**。

**我们能否控制数据流带来的延迟？**

配置数据流作业时，您可以指定要为此作业分配的计算资源。这些资源由数据流工作者使用的 VM 的类型和工作者的数量来表示。您还可以启用工作线程的自动缩放，并通过设置此作业可以使用的最小和最大工作线程数来指定自动缩放边界。也许不太明显，但是这些设置对延迟有影响。怎么会？想象一下，在源和数据流上有大量的变化，它们将具体化为 Google 云存储上的文件。数据流工作者将努力尽快处理这些文件，但这在很大程度上取决于有哪些资源可用。

因此，Dataflow recommender 可能会向您显示一条消息，指示在当前最大工作线程数和要处理的更改数的情况下，CPU 利用率相当高，添加额外的工作线程应该会提高性能和数据新鲜度。

![](img/b419d784566a33ddc29ea63dd7334d56.png)

请记住，尽管增加额外的工作人员也会增加成本，因此调整数据流作业的总延迟是延迟和成本之间的权衡。

**数据流作业的总系统延迟:几秒钟，但也可能需要几分钟**

# BigQuery

对于复制到 BigQuery 的每个表，数据流作业将相应的更改事件流式传输到具有以下命名模式的辅助 BigQuery 日志表中: <table_name>_log</table_name>

![](img/31c4e08e92f868142c1d2f52be1ed057.png)

这些是仅追加表，每个 _log 表都有一个名为***_ metadata _ change _ type***的列，它描述了更改的类型(插入、更新、删除):

![](img/f6a95f56460d10238629c823632a8b0f.png)

如果您的用户确实需要尽快访问新数据，您可以让他们访问这些日志表。您还可以稍微取悦您的用户，用视图覆盖这些表，这些视图负责动态地将更改与 final table 合并，以便在用户查询中使用时产生表的最新状态。否则，用户将不得不在他们的 SQL 查询中显式添加这个逻辑。这种方法不会给系统带来任何额外的延迟(除了计算表状态所花费的时间)，但这带来了额外的成本，当您的用户运行许多引用这些视图的 SQL 查询时，这些成本就会累积起来。

有一种替代方法可能更加经济高效，但会增加端到端复制延迟。也就是说，我们为将 Datastream 在 Google 云存储上暂存的更改移动到 BigQuery 而配置的相同数据流作业也可以配置为执行 SQL Merge 命令，该命令每隔 X 分钟将 _log 表中的更改合并到最终表中。x 由名为**mergefrequencyments 的数据流作业配置参数控制。X 还描述了在讨论端到端复制延迟时会增加多少延迟:只能访问最终表的用户需要等待 X 分钟，然后最新的更改才会合并到这些表中。**

从延迟的角度来看，您希望增加合并的频率。但是另一方面，在 BigQuery 上更频繁的合并操作会产生更多的 BigQuery 开销。

**big query 上的总系统延迟:**此阶段的延迟完全取决于您的需求，是可配置的，可能低至几分钟，但也可能需要几个小时。

# 摘要

数据流和数据流将帮助您在 Oracle 和 BigQuery 之间建立近乎实时的复制。然而，术语“接近实时”并不一定指毫秒。您更应该期待长达 30 分钟的端到端延迟，其中大部分价值可归因于 Oracle LogMiner 如何使源更改可供下游使用。

![](img/c2cda3ebf2935b0d828002def4b2441b.png)

对总延迟的另一个有意义的贡献来自于这样一个事实，即首先存放在仅附加 BigQuery 日志表中的更改事件不会立即合并到最终表中，而是以可配置的时间间隔合并。根据您的要求，此阶段的延迟可能低至几分钟，但也可能需要几个小时。

> ***本文由***[***Lukasz Olejniczak***](https://www.linkedin.com/in/lukasz-olejniczak-1a75a613/)***和***[***Tomasz szaankiewicz***](https://www.linkedin.com/in/tomasz-sza%C5%82ankiewicz-529b82113/)***合著。所表达的观点是作者的观点，不一定反映谷歌的观点。***

如果你喜欢这篇文章，请为它鼓掌。有关基于 google 云的数据科学、数据工程和 AI/ML 主题的更多详细信息，请关注我的[***LinkedIn***](https://www.linkedin.com/in/lukasz-olejniczak-1a75a613/)***。***