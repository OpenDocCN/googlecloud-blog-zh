<html>
<head>
<title>Calling Google Cloud Machine Learning APIs from Batch and Stream ETL pipelines</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">从批处理和流ETL管道调用Google Cloud机器学习API</h1>
<blockquote>原文：<a href="https://medium.com/google-cloud/calling-google-cloud-machine-learning-apis-from-batch-and-stream-etl-pipelines-9a789ac6f972?source=collection_archive---------1-----------------------#2020-04-28">https://medium.com/google-cloud/calling-google-cloud-machine-learning-apis-from-batch-and-stream-etl-pipelines-9a789ac6f972?source=collection_archive---------1-----------------------#2020-04-28</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="51bf" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">Apache Beam 2.20包括一些方便的PTransforms</h2></div><p id="018e" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">Google Cloud AI有一些非常方便的“构建块”API，用于自然语言处理、视觉(例如OCR、图像分类、徽标识别等。)，以及视频智能。</p><p id="15f7" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">你将经常需要在一堆文档、图像或视频上调用这些API。有时，这是基于已经收集的数据(“批处理”)，有时，这是基于流数据。从批处理和流管道中一次一个地调用在线API需要非常小心，这样才不会触及网络、吞吐量或节流限制。</p><h2 id="b7e4" class="jt ju hi bd jv jw jx jy jz ka kb kc kd jg ke kf kg jk kh ki kj jo kk kl km kn bi translated">使用Apache Beam调用云自然语言API</h2><p id="b5d7" class="pw-post-body-paragraph ix iy hi iz b ja ko ij jc jd kp im jf jg kq ji jj jk kr jm jn jo ks jq jr js hb bi translated">幸运的是，Apache Beam 2.20现在提供了一个方便的PTransform，可以为您完成所有繁重的工作。要使用它，首先安装Apache Beam:</p><pre class="kt ku kv kw fd kx ky kz la aw lb bi"><span id="e32f" class="jt ju hi ky b fi lc ld l le lf">pip install --upgrade --quiet apache-beam[gcp]</span></pre><figure class="kt ku kv kw fd lh er es paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="er es lg"><img src="../Images/4b0bca3f948c7c2a4ec8063fc34dd033.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ktBZstRBbs86lzzg7xRo2g.jpeg"/></div></div><figcaption class="lo lp et er es lq lr bd b be z dx translated">明白了吗？图片来自<a class="ae ls" href="https://pixabay.com/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=3105954" rel="noopener ugc nofollow" target="_blank">皮克斯拜</a>的<a class="ae ls" href="https://pixabay.com/users/Peter-Lomas-5966639/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=3105954" rel="noopener ugc nofollow" target="_blank">彼得·洛马斯</a></figcaption></figure><p id="0561" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">下面是一个完整的程序，它将在本地对三个句子运行Apache Beam:</p><pre class="kt ku kv kw fd kx ky kz la aw lb bi"><span id="cd20" class="jt ju hi ky b fi lc ld l le lf">import apache_beam as beam<br/>from apache_beam.ml.gcp import naturallanguageml as nlp</span><span id="1e6c" class="jt ju hi ky b fi lt ld l le lf">def <strong class="ky hj">parse_nlp_result</strong>(response):<br/>    return [<br/>       response.sentences[0].text.content, # first sentence<br/>       [entity.name for entity in response.entities], # all entities<br/>       [entity.metadata['wikipedia_url'] for entity in response.entities], # urls<br/>       response.language,<br/>       response.document_sentiment.score<br/>    ]</span><span id="90f3" class="jt ju hi ky b fi lt ld l le lf"><strong class="ky hj">features</strong> = nlp.types.AnnotateTextRequest.Features(<br/>    extract_entities=True,<br/>    extract_document_sentiment=True,<br/>    extract_syntax=False<br/>)</span><span id="1ffb" class="jt ju hi ky b fi lt ld l le lf">p = beam.Pipeline()<br/>(p <br/> | beam.Create(['Has President Obama been to Paris?', 'Sophie loves walking along the Seine.', "C'est terrible"])<br/> | beam.Map(lambda x : nlp.<strong class="ky hj">Document</strong>(x, type='PLAIN_TEXT'))<br/> | nlp.<strong class="ky hj">AnnotateText</strong>(features)<br/> | beam.Map(<strong class="ky hj">parse_nlp_result</strong>)<br/> | beam.io.WriteToText('output.txt')<br/>)<br/>result = p.run()<br/>result.wait_until_finish()</span></pre><p id="72d7" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">以上管道中的步骤如下:</p><ol class=""><li id="02e6" class="lu lv hi iz b ja jb jd je jg lw jk lx jo ly js lz ma mb mc bi translated">创建内存中的集合</li><li id="83b6" class="lu lv hi iz b ja md jd me jg mf jk mg jo mh js lz ma mb mc bi translated">将每个句子更改为NLP文档对象</li><li id="be6c" class="lu lv hi iz b ja md jd me jg mf jk mg jo mh js lz ma mb mc bi translated"><a class="ae ls" href="https://beam.apache.org/releases/pydoc/2.20.0/apache_beam.ml.gcp.naturallanguageml.html" rel="noopener ugc nofollow" target="_blank">调用NLP API </a>来注释文档。在这里(看看传入的特性)，我们正在提取实体和文档情感。</li><li id="8d4e" class="lu lv hi iz b ja md jd me jg mf jk mg jo mh js lz ma mb mc bi translated">解析NLP API的输出(见下文)</li><li id="f22a" class="lu lv hi iz b ja md jd me jg mf jk mg jo mh js lz ma mb mc bi translated">将输出写入文本文件</li></ol><p id="6891" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">NLP API的输出如下所示:</p><pre class="kt ku kv kw fd kx ky kz la aw lb bi"><span id="ea61" class="jt ju hi ky b fi lc ld l le lf"><strong class="ky hj">sentences</strong> {<br/>  <strong class="ky hj">text</strong> {<br/>    <strong class="ky hj">content</strong>: "I love walking along the Seine."<br/>  }<br/>  sentiment {<br/>    magnitude: 0.699999988079071<br/>    score: 0.699999988079071<br/>  }<br/>}<br/>entities {<br/>  name: "Seine"<br/>  type: LOCATION<br/>  metadata {<br/>    key: "mid"<br/>    value: "/m/0f3vz"<br/>  }<br/>  metadata {<br/>    key: "wikipedia_url"<br/>    value: "<a class="ae ls" href="https://en.wikipedia.org/wiki/Seine" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Seine</a>"<br/>  }<br/>  salience: 1.0<br/>  mentions {<br/>    text {<br/>      content: "Seine"<br/>      begin_offset: 25<br/>    }<br/>    type: PROPER<br/>  }<br/>}<br/><strong class="ky hj">document_sentiment</strong> {<br/>  magnitude: 0.699999988079071<br/>  <strong class="ky hj">score</strong>: 0.699999988079071<br/>}<br/>language: "en"</span></pre><p id="2c23" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这就是为什么我能够提取出我想要的片段作为<em class="mi">response . sentences[0]. text . content</em>和<em class="mi">response . document _ sensation . score</em>。下面是管道的输出:</p><pre class="kt ku kv kw fd kx ky kz la aw lb bi"><span id="bef3" class="jt ju hi ky b fi lc ld l le lf">['Has President Obama been to Paris?', ['Obama', 'Paris'], ['<a class="ae ls" href="https://en.wikipedia.org/wiki/Barack_Obama'" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Barack_Obama'</a>, '<a class="ae ls" href="https://en.wikipedia.org/wiki/Paris'" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Paris'</a>], 'en', 0.0]<br/>["C'est terrible", [], [], 'fr', -0.8999999761581421]<br/>['Sophie loves walking along the Seine.', ['Sophie', 'Seine'], ['', '<a class="ae ls" href="https://en.wikipedia.org/wiki/Seine'" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Seine'</a>], 'en', 0.800000011920929]</span></pre><h2 id="b26e" class="jt ju hi bd jv jw jx jy jz ka kb kc kd jg ke kf kg jk kh ki kj jo kk kl km kn bi translated">将输入更改为BigQuery并在云上运行</h2><p id="2fa1" class="pw-post-body-paragraph ix iy hi iz b ja ko ij jc jd kp im jf jg kq ji jj jk kr jm jn jo ks jq jr js hb bi translated">在上面的代码片段中，我对内存中的一组句子运行了管道，并使用了DirectRunner，它在本地运行。让我们将输入更改为BigQuery，并在云数据流中运行它:</p><p id="8123" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><a class="ae ls" href="https://gist.github.com/lakshmanok/a07d488a0b8006c26bdee0a7effd6245" rel="noopener ugc nofollow" target="_blank">https://gist . github . com/lakshmanok/a07d 488 a0b 8006 c 26 bdee 0 a 7 effd 6245</a></p><p id="67d2" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">管道现在运行在BigQuery中hackernews注释表的数据流上:</p><figure class="kt ku kv kw fd lh er es paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="er es mj"><img src="../Images/34849fe5a1fb8f0f0a396a00115359cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VwnfLxIJCAJVE17blYfp-w.png"/></div></div></figure><p id="7cf6" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">结果看起来像这样:</p><figure class="kt ku kv kw fd lh er es paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="er es mk"><img src="../Images/8a5ce33e7463324cabade6e135f44f5b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*z2npc4ruEXXeK3nip-ZdMw.png"/></div></div></figure><p id="a5ec" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">获得一船评论的情绪有多容易？</p><p id="f6dd" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">尽情享受吧！</p><h2 id="0a2b" class="jt ju hi bd jv jw jx jy jz ka kb kc kd jg ke kf kg jk kh ki kj jo kk kl km kn bi translated">后续步骤:</h2><ul class=""><li id="4b17" class="lu lv hi iz b ja ko jd kp jg ml jk mm jo mn js mo ma mb mc bi translated">启动一个Jupyter笔记本，在<a class="ae ls" href="https://console.cloud.google.com/ai-platform/notebooks" rel="noopener ugc nofollow" target="_blank"> AI平台上笔记本</a></li><li id="9b33" class="lu lv hi iz b ja md jd me jg mf jk mg jo mh js mo ma mb mc bi translated">在GitHub上运行我的<a class="ae ls" href="https://github.com/GoogleCloudPlatform/ml-design-patterns/blob/master/05_resilience/nlp_api.ipynb" rel="noopener ugc nofollow" target="_blank">完整笔记本</a></li></ul></div></div>    
</body>
</html>