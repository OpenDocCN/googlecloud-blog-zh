<html>
<head>
<title>Using a GPU &amp; TensorFlow on Google Cloud Platform</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在Google云平台上使用GPU &amp; TensorFlow</h1>
<blockquote>原文：<a href="https://medium.com/google-cloud/using-a-gpu-tensorflow-on-google-cloud-platform-1a2458f42b0?source=collection_archive---------0-----------------------#2017-07-22">https://medium.com/google-cloud/using-a-gpu-tensorflow-on-google-cloud-platform-1a2458f42b0?source=collection_archive---------0-----------------------#2017-07-22</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/></div><div class="ab cl if ig gp ih" role="separator"><span class="ii bw bk ij ik il"/><span class="ii bw bk ij ik il"/><span class="ii bw bk ij ik"/></div><div class="hb hc hd he hf"><p id="a4cb" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">阅读此文之前的警告:我很高兴这个博客对很多人有用。因为它已经有一年多的历史了，一些命令是基于旧版本的软件。为了简化设置，您现在可能需要使用谷歌云优化计算映像:</p><figure class="jk jl jm jn fd jo"><div class="bz dy l di"><div class="jp jq l"/></div></figure><p id="9a1a" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">我推荐阅读维亚切斯拉夫·科瓦列夫斯基的<a class="ae jr" href="https://blog.kovalevskyi.com/deep-learning-images-for-google-cloud-engine-the-definitive-guide-bc74f5fb02bc" rel="noopener ugc nofollow" target="_blank">这篇博客，而不是继续看这篇。</a></p></div><div class="ab cl if ig gp ih" role="separator"><span class="ii bw bk ij ik il"/><span class="ii bw bk ij ik il"/><span class="ii bw bk ij ik"/></div><div class="hb hc hd he hf"><p id="e95a" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><em class="js">这篇博客的作者:</em></p><ul class=""><li id="347f" class="jt ju hi io b ip iq it iu ix jv jb jw jf jx jj jy jz ka kb bi translated"><em class="js"> Ubuntu 16.04 </em></li><li id="d8a5" class="jt ju hi io b ip kc it kd ix ke jb kf jf kg jj jy jz ka kb bi translated"><em class="js"> CUDA 8 </em></li><li id="a487" class="jt ju hi io b ip kc it kd ix ke jb kf jf kg jj jy jz ka kb bi translated"><em class="js"> TensorFlow 1.4.0 </em></li></ul><p id="d5a0" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">谷歌有一些很好的文档<a class="ae jr" href="https://cloud.google.com/compute/docs/gpus/add-gpus#install-gpu-driver" rel="noopener ugc nofollow" target="_blank">在这里</a>但是我需要采取一些额外的步骤。所以，让我们从头开始:</p><h2 id="6dae" class="kh ki hi bd kj kk kl km kn ko kp kq kr ix ks kt ku jb kv kw kx jf ky kz la lb bi translated">GPU实例</h2><p id="c999" class="pw-post-body-paragraph im in hi io b ip lc ir is it ld iv iw ix le iz ja jb lf jd je jf lg jh ji jj hb bi translated">有两种方法来设置实例:1)使用Google Cloud提供的命令行界面，或者2)使用他们非常友好的web ui来帮助你。因为我是谷歌云网络界面的忠实粉丝，这就是我要做的。设置服务器非常简单。</p><figure class="jk jl jm jn fd jo er es paragraph-image"><div class="er es lh"><img src="../Images/acd12db56b6ebfef447a76c605e34f1a.png" data-original-src="https://miro.medium.com/v2/resize:fit:944/format:webp/1*pBxYHWrzvqzOk878RsfSiQ.png"/></div><figcaption class="lk ll et er es lm ln bd b be z dx translated">指向并单击以设置GPU实例</figcaption></figure><p id="1973" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">在谷歌云平台中，确保您已经创建了一个项目，然后导航到<strong class="io hj">计算引擎。</strong>系统会询问您是否要创建一个新实例，一旦您看到左侧所示的弹出对话框，您可以配置内核数量、内存(RAM)和一个小选项“GPU”。点击这个和额外的选项显示出来，这将允许你指出是否和多少GPU你想使用。然后我选择<strong class="io hj"> Ubuntu 16.04 </strong>作为启动盘，其他选项保持不变，然后点击<em class="js"> Create </em>启动实例。</p><p id="578f" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">一旦实例准备好了，你就可以通过使用Google Cloud提供的web-shell或者从你自己的命令行复制<em class="js"> gcloud </em>命令来连接它。</p><h2 id="722e" class="kh ki hi bd kj kk kl km kn ko kp kq kr ix ks kt ku jb kv kw kx jf ky kz la lb bi translated">安装CUDA</h2><p id="f97e" class="pw-post-body-paragraph im in hi io b ip lc ir is it ld iv iw ix le iz ja jb lf jd je jf lg jh ji jj hb bi translated">现在我们在我们需要为GPU安装一些驱动程序。Google Cloud上的GPU都是NVIDIA卡，需要安装CUDA。为了安装CUDA 8.0，我对Ubuntu 16.04使用了以下命令(摘自<a class="ae jr" href="https://cloud.google.com/compute/docs/gpus/add-gpus#install-gpu-driver" rel="noopener ugc nofollow" target="_blank">谷歌云文档</a>):</p><pre class="jk jl jm jn fd lo lp lq lr aw ls bi"><span id="970f" class="kh ki hi lp b fi lt lu l lv lw">sudo su</span><span id="a077" class="kh ki hi lp b fi lx lu l lv lw">#!/bin/bash<br/>echo "Checking for CUDA and installing."<br/># Check for CUDA and try to install.<br/>if ! dpkg-query -W cuda; then<br/>  # The 16.04 installer works with 16.10.<br/>  curl -O <a class="ae jr" href="http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64/cuda-repo-ubuntu1604_8.0.61-1_amd64.deb" rel="noopener ugc nofollow" target="_blank">http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64/cuda-repo-ubuntu1604_8.0.61-1_amd64.deb</a><br/>  dpkg -i ./cuda-repo-ubuntu1604_8.0.61-1_amd64.deb<br/>  apt-get update<br/>  # apt-get install cuda -y<br/>  sudo apt-get install cuda-8-0<br/>fi</span></pre><p id="92db" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">要验证其工作是否正常，请运行下面的命令，这将显示GPU已被识别并正确设置。</p><pre class="jk jl jm jn fd lo lp lq lr aw ls bi"><span id="bef9" class="kh ki hi lp b fi lt lu l lv lw">nvidia-smi</span></pre><figure class="jk jl jm jn fd jo er es paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="er es ly"><img src="../Images/7e152ec3bff62d67c441052a00134840.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1VoaAWqNsHCP9QSEoDD-qQ.png"/></div></div></figure><p id="a765" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">耶！它是存在的，并且正在得到承认。我们还需要为CUDA设置一些环境变量:</p><pre class="jk jl jm jn fd lo lp lq lr aw ls bi"><span id="6062" class="kh ki hi lp b fi lt lu l lv lw">echo 'export CUDA_HOME=/usr/local/cuda' &gt;&gt; ~/.bashrc<br/>echo 'export PATH=$PATH:$CUDA_HOME/bin' &gt;&gt; ~/.bashrc<br/>echo 'export LD_LIBRARY_PATH=$CUDA_HOME/lib64' &gt;&gt; ~/.bashrc</span><span id="aed6" class="kh ki hi lp b fi lx lu l lv lw">source ~/.bashrc</span></pre><h2 id="a09c" class="kh ki hi bd kj kk kl km kn ko kp kq kr ix ks kt ku jb kv kw kx jf ky kz la lb bi translated">安装cuDNN</h2><p id="d6d3" class="pw-post-body-paragraph im in hi io b ip lc ir is it ld iv iw ix le iz ja jb lf jd je jf lg jh ji jj hb bi translated">NVIDIA提供了<strong class="io hj"> cuDNN </strong>库来优化他们卡上的神经网络计算。他们将其描述为:</p><blockquote class="md me mf"><p id="be10" class="im in js io b ip iq ir is it iu iv iw mg iy iz ja mh jc jd je mi jg jh ji jj hb bi translated">NVIDIA CUDA深度神经网络库(cuDNN)是一个针对<a class="ae jr" href="https://developer.nvidia.com/deep-learning" rel="noopener ugc nofollow" target="_blank">深度神经网络</a>的GPU加速原语库。cuDNN为标准例程提供了高度优化的实现，例如前向和后向卷积、池化、规范化和激活层。cuDNN是<a class="ae jr" href="https://developer.nvidia.com/deep-learning-sdk" rel="noopener ugc nofollow" target="_blank">英伟达深度学习SDK </a>的一部分。</p><p id="1827" class="im in js io b ip iq ir is it iu iv iw mg iy iz ja mh jc jd je mi jg jh ji jj hb bi translated">全球深度学习研究人员和框架开发人员依赖cuDNN进行高性能GPU加速。这使得他们可以专注于训练神经网络和开发软件应用程序，而不是花时间在低级别的GPU性能调优上。</p></blockquote><p id="778c" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">总结:他们做了很多工作来让你的生活变得更容易…你需要注册<a class="ae jr" href="https://developer.nvidia.com/developer-program" rel="noopener ugc nofollow" target="_blank"> NVIDIA开发者计划</a>，然后你就可以下载最新版本的软件了。在这种情况下，我下载了CUDA 8.0的5.1版本(我刚刚注意到一个更新的6.0版本也可用)。下载完成后，使用SCP或通过Google云存储将其转移到实例中。</p><p id="81bc" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">一旦它在实例上，使用以下命令安装它:</p><pre class="jk jl jm jn fd lo lp lq lr aw ls bi"><span id="a735" class="kh ki hi lp b fi lt lu l lv lw">cd $HOME</span><span id="3476" class="kh ki hi lp b fi lx lu l lv lw">tar xzvf cudnn-8.0-linux-x64-v5.1.tgz</span><span id="c095" class="kh ki hi lp b fi lx lu l lv lw">sudo cp cuda/lib64/* /usr/local/cuda/lib64/<br/>sudo cp cuda/include/cudnn.h /usr/local/cuda/include/</span><span id="1b05" class="kh ki hi lp b fi lx lu l lv lw">rm -rf ~/cuda<br/>rm cudnn-8.0-linux-x64-v5.1.tgz</span></pre><h2 id="0e5a" class="kh ki hi bd kj kk kl km kn ko kp kq kr ix ks kt ku jb kv kw kx jf ky kz la lb bi translated">安装TensorFlow</h2><p id="3b5d" class="pw-post-body-paragraph im in hi io b ip lc ir is it ld iv iw ix le iz ja jb lf jd je jf lg jh ji jj hb bi translated">因此，GPU实例正在运行，驱动程序也已就绪，剩下的工作就是安装TensorFlow来运行GPU。你可以看到，谷歌正试图让这一切变得超级简单，因为你真的需要行来完成这最后一步:</p><pre class="jk jl jm jn fd lo lp lq lr aw ls bi"><span id="58bc" class="kh ki hi lp b fi lt lu l lv lw">sudo apt-get install python-dev python-pip libcupti-dev<br/>sudo pip install --upgrade tensorflow-gpu==1.4.0</span></pre><p id="dc8e" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">安装<em class="js"> tensorflow-gpu </em>可以确保它在需要的地方默认使用gpu进行操作。只要你愿意，你仍然可以手动将某些东西转移到CPU中。让我们测试一下是否一切正常…</p><h2 id="a88a" class="kh ki hi bd kj kk kl km kn ko kp kq kr ix ks kt ku jb kv kw kx jf ky kz la lb bi translated">测试设置</h2><p id="caa9" class="pw-post-body-paragraph im in hi io b ip lc ir is it ld iv iw ix le iz ja jb lf jd je jf lg jh ji jj hb bi translated">现在，要测试是否全部成功，您可以使用下面的python代码。它将两个变量和一个操作分配给cpu，将另外两个变量和一个操作分配给GPU。当启动会话时，我们通过ConfigProto告诉它记录变量/操作的位置，您应该看到它在放置变量/操作的命令行打印出来。</p><pre class="jk jl jm jn fd lo lp lq lr aw ls bi"><span id="b090" class="kh ki hi lp b fi lt lu l lv lw">import tensorflow as tf<br/></span><span id="017a" class="kh ki hi lp b fi lx lu l lv lw">with tf.device('/cpu:0'):<br/>    a_c = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a-cpu')<br/>    b_c = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b-cpu')<br/>    c_c = tf.matmul(a_c, b_c, name='c-cpu')</span><span id="3504" class="kh ki hi lp b fi lx lu l lv lw"><br/>with tf.device('/gpu:0'):<br/>    a_g = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a-gpu')<br/>    b_g = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b-gpu')<br/>    c_g = tf.matmul(a_g, b_g, name='c-gpu')</span><span id="b148" class="kh ki hi lp b fi lx lu l lv lw"><br/>with tf.Session(config=tf.ConfigProto(log_device_placement=True)) as sess:<br/>    print (sess.run(c_c))<br/>    print (sess.run(c_g))</span><span id="034d" class="kh ki hi lp b fi lx lu l lv lw"><br/>print 'DONE!'</span></pre><p id="ca84" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">就这些…</p><h2 id="130f" class="kh ki hi bd kj kk kl km kn ko kp kq kr ix ks kt ku jb kv kw kx jf ky kz la lb bi translated">***更新(2018年3月7日)</h2><p id="a6ab" class="pw-post-body-paragraph im in hi io b ip lc ir is it ld iv iw ix le iz ja jb lf jd je jf lg jh ji jj hb bi translated">根据ChrisAMancuso的反馈，我已经替换了这条线</p><pre class="jk jl jm jn fd lo lp lq lr aw ls bi"><span id="db6d" class="kh ki hi lp b fi lt lu l lv lw">apt-get install cuda -y</span></pre><p id="8fb3" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">随着</p><pre class="jk jl jm jn fd lo lp lq lr aw ls bi"><span id="d905" class="kh ki hi lp b fi lt lu l lv lw">sudo apt-get install cuda-8–0</span></pre><p id="26bb" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">以确保其安装CUDA 8.0(tensor flow支持/不支持CUDA 9.0)。</p></div></div>    
</body>
</html>