<html>
<head>
<title>Building a client-side web app which streams audio from a browser microphone to a server. (Part II)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">构建一个客户端web应用程序，将音频从浏览器麦克风传输到服务器。(第二部分)</h1>
<blockquote>原文：<a href="https://medium.com/google-cloud/building-a-client-side-web-app-which-streams-audio-from-a-browser-microphone-to-a-server-part-ii-df20ddb47d4e?source=collection_archive---------0-----------------------#2020-04-14">https://medium.com/google-cloud/building-a-client-side-web-app-which-streams-audio-from-a-browser-microphone-to-a-server-part-ii-df20ddb47d4e?source=collection_archive---------0-----------------------#2020-04-14</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><h1 id="c1a7" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated"><strong class="ak">将音频从浏览器麦克风流式传输到Dialogflow的最佳实践&amp;谷歌云语音转文本。</strong></h1><p id="5309" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">这是该系列的第二篇博客:</p><p id="7910" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated"><strong class="jf hj">将音频从浏览器麦克风流式传输到Dialogflow的最佳实践&amp;谷歌云语音转文本。</strong></p><p id="75d9" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated"><a class="ae kg" rel="noopener" href="/google-cloud/building-your-own-conversational-voice-ai-with-dialogflow-speech-to-text-in-web-apps-part-i-b92770bd8b47"> <strong class="jf hj">在这第一篇博客中，我已经介绍了所有的对话组件，并解释了为什么客户会集成他们自己的对话式人工智能，而不是为谷歌助手</strong> </a> <strong class="jf hj">构建。</strong></p><p id="7dee" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">今天，我将首先构建一个客户端web应用程序，它使用带有WebRTC的HTML5麦克风，将音频字节流传输到Node.js后端。</p><p id="bbd2" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">在这个博客系列的后面，我将向您展示如何使用Google Cloud对话式AI APIs来转录文本或通过文本到语音返回答案。</p><p id="48d1" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">这些博客<a class="ae kg" href="https://github.com/dialogflow/selfservicekiosk-audio-streaming/tree/master/examples" rel="noopener ugc nofollow" target="_blank">包含简单的代码片段</a>和一个演示应用程序；<a class="ae kg" href="https://github.com/dialogflow/selfservicekiosk-audio-streaming/" rel="noopener ugc nofollow" target="_blank">机场自助服务亭</a>，将用作参考架构。</p><p id="6cc2" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">让我们从客户端HTML &amp; JavaScript代码的创建开始。无论你是想把语音转录成文字(STT)，还是用语音触发一个聊天机器人代理来回答(Dialogflow)，客户端的代码库都是非常相似的。</p><figure class="ki kj kk kl fd km er es paragraph-image"><div role="button" tabindex="0" class="kn ko di kp bf kq"><div class="er es kh"><img src="../Images/21b50fc798824c2fdae4b7c79490f77a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*A0K0liWr_UXsz5mb.png"/></div></div></figure><h1 id="a4ae" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">客户端WebRTC实现</h1><p id="a101" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">这里有一些代码片段，您可以运行它们来体验一下。</p><p id="168b" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">您可以通过克隆这个存储库来运行这些示例。<a class="ae kg" href="https://github.com/dialogflow/selfservicekiosk-audio-streaming/tree/master/examples" rel="noopener ugc nofollow" target="_blank">说明写在这里</a>。</p><ul class=""><li id="82a8" class="kt ku hi jf b jg kb jk kc jo kv js kw jw kx ka ky kz la lb bi translated"><a class="ae kg" href="https://github.com/dialogflow/selfservicekiosk-audio-streaming/tree/master/examples/example1.html" rel="noopener ugc nofollow" target="_blank">客户端代码:DetectIntent </a> — Dialogflow</li><li id="dcb8" class="kt ku hi jf b jg lc jk ld jo le js lf jw lg ka ky kz la lb bi translated"><a class="ae kg" href="https://github.com/dialogflow/selfservicekiosk-audio-streaming/tree/master/examples/example4.html" rel="noopener ugc nofollow" target="_blank">客户端代码:转录</a> — STT</li></ul><p id="574f" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">这些示例利用了以下JavaScript库:</p><ul class=""><li id="3d88" class="kt ku hi jf b jg kb jk kc jo kv js kw jw kx ka ky kz la lb bi translated"><a class="ae kg" href="https://www.npmjs.com/package/socket.io" rel="noopener ugc nofollow" target="_blank"> Socket.io </a> — Socket。IO支持基于事件的实时双向通信。</li><li id="2c70" class="kt ku hi jf b jg lc jk ld jo le js lf jw lg ka ky kz la lb bi translated"><a class="ae kg" href="https://www.npmjs.com/package/socket.io-stream" rel="noopener ugc nofollow" target="_blank"> Socket.io-Stream </a> —用于通过Socket.io进行二进制流传输</li><li id="2abe" class="kt ku hi jf b jg lc jk ld jo le js lf jw lg ka ky kz la lb bi translated"><a class="ae kg" href="https://github.com/muaz-khan/RecordRTC" rel="noopener ugc nofollow" target="_blank"> RecordRTC </a> — RecordRTC是WebRTC JavaScript库，用于音频/视频以及屏幕活动记录。</li></ul><p id="ac63" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">在这些演示中，我使用了两个按钮，一个开始录制和一个停止录制按钮。</p><p id="574c" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">我还创建了一个textarea字段，稍后将显示结果。</p><pre class="ki kj kk kl fd lh li lj lk aw ll bi"><span id="8486" class="lm ig hi li b fi ln lo l lp lq">&lt;div&gt;</span><span id="d004" class="lm ig hi li b fi lr lo l lp lq">&lt;button id=”start-recording” disabled&gt;Start Recording&lt;/button&gt;</span><span id="44b5" class="lm ig hi li b fi lr lo l lp lq">&lt;button id=”stop-recording” disabled&gt;Stop Recording&lt;/button&gt;</span><span id="b9e0" class="lm ig hi li b fi lr lo l lp lq">&lt;/div&gt;</span><span id="619b" class="lm ig hi li b fi lr lo l lp lq">&lt;textarea id=”results” style=”width: 800px; height: 300px;”&gt;&lt;/textarea&gt;</span></pre><p id="240e" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">如果您想查看端到端示例，请查看<a class="ae kg" href="https://github.com/dialogflow/selfservicekiosk-audio-streaming/tree/master/client/src" rel="noopener ugc nofollow" target="_blank">机场自助服务亭演示</a>。这是一个有棱角的网络应用程序，它包含一个需要按一次的录制按钮，以录制音频流。它会在屏幕中间显示结果。</p><figure class="ki kj kk kl fd km er es paragraph-image"><div role="button" tabindex="0" class="kn ko di kp bf kq"><div class="er es ls"><img src="../Images/1db231982ca2e64ec2406f245c0cfa6f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*9SMQBhZrVflHYnHS"/></div></div><figcaption class="lt lu et er es lv lw bd b be z dx translated">前端代码:机场自助服务亭演示</figcaption></figure><p id="cef5" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">我写了一些JavaScript代码，嵌入在HTML简单示例中:</p><figure class="ki kj kk kl fd km"><div class="bz dy l di"><div class="lx ly l"/></div></figure><ol class=""><li id="30dc" class="kt ku hi jf b jg kb jk kc jo kv js kw jw kx ka lz kz la lb bi translated">首先，我将创建一些指向开始和停止按钮的指针。</li><li id="8ea0" class="kt ku hi jf b jg lc jk ld jo le js lf jw lg ka lz kz la lb bi translated">接下来，我将实例化socket.io，并打开一个连接。</li><li id="f7a3" class="kt ku hi jf b jg lc jk ld jo le js lf jw lg ka lz kz la lb bi translated">我已经创建了两个事件监听器来开始和停止记录。开始按钮onclick事件，将禁用开始按钮，所以你不能按下按钮两次，因此记录音频两次。</li><li id="ab03" class="kt ku hi jf b jg lc jk ld jo le js lf jw lg ka lz kz la lb bi translated"><a class="ae kg" href="https://www.html5rocks.com/en/tutorials/getusermedia/intro/" rel="noopener ugc nofollow" target="_blank"> navigator.getUserMedia() </a>是代码的重要组成部分。它是一组WebRTC APIs的一部分，提供了访问用户本地摄像头/麦克风流的方法。在我们的例子中，我们只使用麦克风(<strong class="jf hj"> audio: true </strong>)。这给了我们进入溪流的机会。</li><li id="05f6" class="kt ku hi jf b jg lc jk ld jo le js lf jw lg ka lz kz la lb bi translated">现在，我正在利用图书馆的记录。我本来可以选择自己写这部分代码的。但是RecordRTC解决了很多复杂的问题。比如转换缓冲区(从Float32到Int16)，跨浏览器支持等。</li><li id="f76a" class="kt ku hi jf b jg lc jk ld jo le js lf jw lg ka lz kz la lb bi translated">RecordRTC有两个参数。第一个参数是来自getUserMedia()调用的MediaStream。第二个参数是一个配置对象，带有优化流的设置。我正在进行一些重要的设置，这些设置应该与您的设置一致，稍后在服务器端代码中(Dialogflow中的<a class="ae kg" href="https://cloud.google.com/dialogflow/docs/reference/rpc/google.cloud.dialogflow.v2beta1#google.cloud.dialogflow.v2beta1.InputAudioConfig" rel="noopener ugc nofollow" target="_blank"> InputAudioConfig </a>或STT的<a class="ae kg" href="https://cloud.google.com/speech-to-text/docs/reference/rpc/google.cloud.speech.v1?hl=nl#recognitionconfig" rel="noopener ugc nofollow" target="_blank"> RecognitionConfig </a>的文档):</li></ol><ul class=""><li id="ac4a" class="kt ku hi jf b jg kb jk kc jo kv js kw jw kx ka ky kz la lb bi translated">mimetype设置为<strong class="jf hj">AUDIO/webm</strong>——当使用<strong class="jf hj"> AUDIO_ENCODING_LINEAR_16 </strong>或<strong class="jf hj"> LINEAR16 </strong>作为Dialogflow或STT中的音频编码配置时，这将是一个很好的设置。</li><li id="2fb6" class="kt ku hi jf b jg lc jk ld jo le js lf jw lg ka ky kz la lb bi translated">采样率是输入采样频率，单位为赫兹。我将其重采样为16000Hz (desiredSampleRate ),这样网络上的消息大小将会更小，并且与我的Dialogflow或STT调用中的herz设置样本相匹配。</li><li id="bf25" class="kt ku hi jf b jg lc jk ld jo le js lf jw lg ka ky kz la lb bi translated">此外，Dialogflow &amp; STT需要单声道声音，这意味着，我应该将音频通道的数量设置为1。recorder type stereo audio recorder允许我将音频通道的数量从2个改为1个。</li></ul><h1 id="ff0d" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">记录单个话语</h1><p id="7108" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">简短话语/探测意图。这意味着您的最终用户按下录音按钮，说话，当他们按下停止，我们收集音频流返回结果。在您的代码中，这意味着一旦客户端web应用程序收集了完整的音频记录，它就将其发送到服务器，这样服务器就可以调用Dialogflow或语音到文本API。对于这个用例，神奇之处在于停止按钮onclick事件监听器:</p><figure class="ki kj kk kl fd km"><div class="bz dy l di"><div class="lx ly l"/></div></figure><ol class=""><li id="0e9e" class="kt ku hi jf b jg kb jk kc jo kv js kw jw kx ka lz kz la lb bi translated">当你点击停止，它将首先重置按钮，然后停止录制。当停止记录时，在回调函数中，它将请求audioDataURL，它是<a class="ae kg" href="https://recordrtc.org/" rel="noopener ugc nofollow" target="_blank"> RecordRTC API </a>的一部分。这将返回一个字符串dataURL，带有包含音频流的Base64字符串。这一长串是这样的:<strong class="jf hj">数据:audio/wav；base64，uklgrirgagbxqvzfzm 10 ibaaaaaaaaaaearkwaa</strong></li><li id="0005" class="kt ku hi jf b jg lc jk ld jo le js lf jw lg ka lz kz la lb bi translated">我们可以从中创建一个对象，这个对象也设置了音频类型，然后我们正在把它发送给服务器，用socket io:<strong class="jf hj">socket io . emit(' message '，files)；</strong>我们将设置一个名称。一旦服务器与这个套接字建立了连接，它将寻找“消息”事件名称，并对其进行响应。它将接收文件对象。</li><li id="4e41" class="kt ku hi jf b jg lc jk ld jo le js lf jw lg ka lz kz la lb bi translated">一旦服务器调用Dialogflow / Speech API并对服务器进行websockets调用以返回结果，该脚本的最后一部分将运行。在这个例子中，我只是在一个文本框中打印结果。对于Dialogflow，<strong class="jf hj"> fulfillmentText </strong>是queryResult的一部分。当使用STT时，您想要打印来自<strong class="jf hj">备选项</strong>数组的<strong class="jf hj">副本</strong>字符串。</li></ol><h1 id="67dc" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">录制音频流</h1><p id="3c9a" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">记录流意味着您的最终用户按下记录按钮，说话，将看到结果的飞行。当使用Dialogflow检测意图时，这可能意味着一旦你说得更多，它将检测到更好的匹配，或者它可以收集多个结果。在您的代码中，这意味着客户端开始创建一个双向流，并将数据块传输到服务器，这样服务器就可以通过事件侦听器对传入的数据进行调用，因此它是实时的。</p><p id="5a97" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">您可能会选择这种方法，因为您期望的音频很长。或者在Dialogflow的情况下，您可能希望在说话的同时在屏幕上实时显示中间结果。在这种情况下，您不需要stopRecording回调函数，它将base64 URL字符串发送到服务器。相反，它会将流实时发送到服务器！</p><p id="beb7" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">看看下面的例子:</p><p id="3dd9" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">客户端代码:<a class="ae kg" href="https://github.com/dialogflow/selfservicekiosk-audio-streaming/blob/master/examples/example2.html" rel="noopener ugc nofollow" target="_blank"> DetectStreamingIntent </a> —您可以通过克隆这个存储库来运行这些示例。<a class="ae kg" href="https://github.com/dialogflow/selfservicekiosk-audio-streaming/tree/master/examples" rel="noopener ugc nofollow" target="_blank">说明写在这里</a>。</p><figure class="ki kj kk kl fd km"><div class="bz dy l di"><div class="lx ly l"/></div></figure><p id="01d9" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">本例中的神奇之处在于RecordRTC对象和<strong class="jf hj"> ondataavailable </strong>事件监听器:</p><ol class=""><li id="ece7" class="kt ku hi jf b jg kb jk kc jo kv js kw jw kx ka lz kz la lb bi translated">首先，你需要设置一个<strong class="jf hj">时间片。</strong>时间片设定创建音频块的时间间隔。在Dialogflow的情况下，您可能不想每秒都检测意图(因为您可能没有说完一个句子)，而是内置一个计时器。timeSlice设置为<strong class="jf hj">毫秒</strong>，所以我用的是4000 (4秒)。</li><li id="6436" class="kt ku hi jf b jg lc jk ld jo le js lf jw lg ka lz kz la lb bi translated">然后是<strong class="jf hj"> ondataavailable </strong>事件监听器，一旦有数据就会被触发，它将包含大量的blobs(音频缓冲区)，在我的例子中是每4秒一次。</li><li id="b796" class="kt ku hi jf b jg lc jk ld jo le js lf jw lg ka lz kz la lb bi translated">这就是<strong class="jf hj"> socketio-stream </strong>的用武之地。我正在利用双向流(我每4秒发送一个包含块的流，但是我也可能希望在中间接收来自服务器的结果)。所以我正在创建流，它将临时存储在我的本地驱动器上。带<strong class="jf hj"> ss(插座)。emit() </strong>我将它流式传输到服务器，在这样做的同时，我将音频缓冲区通过管道传输到流中。<strong class="jf hj"> stream.pipe() </strong>的目的是将数据缓冲限制在可接受的水平，这样不同速度的源和目的地就不会淹没可用内存。</li></ol><p id="7ed7" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">如果您想查看端到端示例，请查看<a class="ae kg" href="https://github.com/dialogflow/selfservicekiosk-audio-streaming/blob/master/client/src/app/microphone/microphone.component.ts" rel="noopener ugc nofollow" target="_blank">机场自助服务亭演示话筒课程</a>。它是用TypeScript编写的，实现了HTML5麦克风。</p><h1 id="1c77" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">在iOS上运行您的应用</h1><p id="d2d2" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">在iOS设备上运行应用程序时，您可能会遇到各种问题。首先，iOS不支持除Safari之外的任何其他移动浏览器中的JavaScript<strong class="jf hj">getuser media</strong>和WebRTC方法。</p><p id="8abd" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">在我的应用程序中，<a class="ae kg" href="https://github.com/dialogflow/selfservicekiosk-audio-streaming/blob/master/client/src/app/app.component.ts" rel="noopener ugc nofollow" target="_blank">当它在iOS浏览器而不是mobile Safari </a>上打开时，我会显示一个弹出窗口。</p><p id="67da" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">要使用getUserMedia() WebRTC方法，您需要允许权限弹出窗口，它只在从<strong class="jf hj"> HTTPS </strong>运行时才会出现。</p><p id="59c5" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">iOS仍然存在一个重要的限制:在用户激活之前，网络音频实际上是静音的。要在iOS中播放和录制音频，需要用户交互(如触摸开始)。</p><p id="3858" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">暂时就这样了。<a class="ae kg" rel="noopener" href="/google-cloud/building-a-web-server-which-receives-a-browser-microphone-stream-and-uses-dialogflow-or-the-speech-62b47499fc71">在本系列的下一篇博客中，我将在服务器端接收音频字节，因此我可以使用它来使Dialogflow检测意图或语音到文本转录呼叫！</a></p></div></div>    
</body>
</html>