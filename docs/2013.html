<html>
<head>
<title>Boost up a Helpdesk Chatbot with Dialogflow CX, TFX and Vertex AI</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用对话流CX，TFX和顶点人工智能增强一个服务台聊天机器人</h1>
<blockquote>原文：<a href="https://medium.com/google-cloud/boost-up-a-helpdesk-chatbot-with-dialogflow-cx-tfx-and-vertex-ai-4999c26eef13?source=collection_archive---------4-----------------------#2021-11-22">https://medium.com/google-cloud/boost-up-a-helpdesk-chatbot-with-dialogflow-cx-tfx-and-vertex-ai-4999c26eef13?source=collection_archive---------4-----------------------#2021-11-22</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="7e71" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jd">与</em> <a class="je jf ge" href="https://medium.com/u/8f61f3a4e09c?source=post_page-----4999c26eef13--------------------------------" rel="noopener" target="_blank">合作撰写<em class="jd">加布里埃</em>合作撰写</a></p><figure class="jh ji jj jk fd jl er es paragraph-image"><div role="button" tabindex="0" class="jm jn di jo bf jp"><div class="er es jg"><img src="../Images/31408a31851534f95061aaa2409f7681.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BOFZ69ay_3_8z3AyhfpkQg.png"/></div></div><figcaption class="js jt et er es ju jv bd b be z dx translated">图一。团队和文章的内容</figcaption></figure><h2 id="40d1" class="jw jx hi bd jy jz ka kb kc kd ke kf kg iq kh ki kj iu kk kl km iy kn ko kp kq bi translated">好吧，你说，我听！</h2><p id="18e0" class="pw-post-body-paragraph if ig hi ih b ii kr ik il im ks io ip iq kt is it iu ku iw ix iy kv ja jb jc hb bi translated">关于Google Cloud  上的<a class="ae kw" href="https://cloud.google.com/data-science" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj">数据科学你有什么想看的想法吗？请填写这张表格</strong> </a>让我知道。这将对我以后的博客帖子有所帮助=)</p></div><div class="ab cl kx ky gp kz" role="separator"><span class="la bw bk lb lc ld"/><span class="la bw bk lb lc ld"/><span class="la bw bk lb lc"/></div><div class="hb hc hd he hf"><h2 id="248c" class="jw jx hi bd jy jz ka kb kc kd ke kf kg iq kh ki kj iu kk kl km iy kn ko kp kq bi translated">放弃</h2><p id="8d63" class="pw-post-body-paragraph if ig hi ih b ii kr ik il im ks io ip iq kt is it iu ku iw ix iy kv ja jb jc hb bi translated">本文假设了一些关于TFX、顶点人工智能和对话流的先验知识。我建议观看谷歌云开发人员宣传团队的这些视频，快速更新主要概念:</p><ul class=""><li id="e10b" class="le lf hi ih b ii ij im in iq lg iu lh iy li jc lj lk ll lm bi translated"><a class="ae kw" href="https://www.youtube.com/watch?v=Mxk4qmO_1B4&amp;list=PLQY2H8rRoyvxR15n04JiW0ezF5HQRs_8F&amp;index=3" rel="noopener ugc nofollow" target="_blank">这个TFX到底是什么东西？(TensorFlow Extended) </a>和<a class="ae kw" href="https://www.youtube.com/watch?v=iVKa8SZQdPI&amp;list=PLQY2H8rRoyvxR15n04JiW0ezF5HQRs_8F&amp;index=3" rel="noopener ugc nofollow" target="_blank">TFX管道是如何工作的？(TensorFlow Extended) </a>作者<a class="ae kw" href="https://twitter.com/robert_crowe?lang=en" rel="noopener ugc nofollow" target="_blank">罗伯特·克罗</a></li><li id="f222" class="le lf hi ih b ii ln im lo iq lp iu lq iy lr jc lj lk ll lm bi translated"><a class="ae kw" href="https://www.youtube.com/watch?v=Jrh-QLrVCvM" rel="noopener ugc nofollow" target="_blank">MLOps和顶点流水线介绍</a>和<a class="ae kw" href="https://www.youtube.com/watch?v=6_Gilug2QYw" rel="noopener ugc nofollow" target="_blank">什么是Dialogflow CX？</a>作者<a class="ae kw" href="https://twitter.com/pvergadia" rel="noopener ugc nofollow" target="_blank">普里扬卡·韦尔加迪亚</a></li></ul><h2 id="2905" class="jw jx hi bd jy jz ka kb kc kd ke kf kg iq kh ki kj iu kk kl km iy kn ko kp kq bi translated">前提</h2><p id="538d" class="pw-post-body-paragraph if ig hi ih b ii kr ik il im ks io ip iq kt is it iu ku iw ix iy kv ja jb jc hb bi translated">最近，我和Gabriele Randelli讨论了将Vertex AI与谷歌云的其他服务整合的想法。我们都提出了不同的场景(我们希望在接下来的文章中讨论),但最终我们都提出了这个问题</p><blockquote class="ls"><p id="a2d3" class="lt lu hi bd lv lw lx ly lz ma mb jc dx translated">用基于Vertex AI训练的ML模型来增强一个用Dialogflow CX构建的简单聊天机器人不是很棒吗？</p></blockquote><p id="e394" class="pw-post-body-paragraph if ig hi ih b ii md ik il im me io ip iq mf is it iu mg iw ix iy mh ja jb jc hb bi translated">在本文中，我们将说明如何形式化张量流模型训练，以便通过顶点管道上的TFX来运行它。然后，我们将使用<a class="ae kw" href="https://cloud.google.com/dialogflow/cx/docs/basics" rel="noopener ugc nofollow" target="_blank"> Dialogflow CX </a>描述一个简单的聊天机器人，我们将学习如何将训练好的模型与它集成，以便在用户与聊天机器人交互时为他/她提供预测。</p><h2 id="7fa7" class="jw jx hi bd jy jz ka kb kc kd ke kf kg iq kh ki kj iu kk kl km iy kn ko kp kq bi translated">我们的场景</h2><p id="9917" class="pw-post-body-paragraph if ig hi ih b ii kr ik il im ks io ip iq kt is it iu ku iw ix iy kv ja jb jc hb bi translated">作为我在上一篇文章的<a class="ae kw" rel="noopener" href="/google-cloud/sparkling-vertex-ai-pipeline-cfe6e19334f7">中描述的数据科学团队的成员之一，贵公司提供了一个云原生应用程序来帮助其客户。但是，过了一段时间，客户给了<strong class="ih hj">不好的反馈，说要等很长时间才能得到呼叫中心的帮助。</strong></a></p><figure class="jh ji jj jk fd jl er es paragraph-image"><div role="button" tabindex="0" class="jm jn di jo bf jp"><div class="er es mi"><img src="../Images/d42b941c2e5c4bdc4231a1401553436b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*jaGBDt7xTdPxV5gL"/></div></div><figcaption class="js jt et er es ju jv bd b be z dx translated">图二。客户反馈</figcaption></figure><p id="9eb3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">由于投资巨大，<strong class="ih hj">公司决定释放更多资源，利用ML功能来改善客户服务</strong>。特别是，他们认为聊天机器人和NLP技术已经达到了构建商业应用程序的成熟水平。这就是为什么他们最近雇佣了一名会话科学家和一名会话工程师。但是，与此同时，他们指望你用人工智能聊天机器人来建立一个概念证明。</p><p id="7020" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">作为KPI </strong>，<strong class="ih hj">企业希望提高遏制率</strong>，从而减少等待时间，改善整体客户服务。幸运的是，由于Dialogflow和Vertex AI，您迁移到的云平台Google Cloud可以帮助他们锁定KPI目标。</p><p id="ccd0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">通过<strong class="ih hj"> Dialogflow CX，对话团队获得了一个设计、构建和测试聊天机器人和语音机器人的综合平台</strong>。除了所有关键功能，他们还欣赏它具有可视化的流程构建器，并且集成了最新的基于BERT的自然语言理解(NLU)模型。通过这种方式，他们可以合作并专注于提供最佳的对话体验，因为这将是在更复杂的用例中准确有效地识别意图和上下文的模型。</p><p id="2ff2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">同时，<strong class="ih hj">您需要一个ML管道框架，允许您轻松地大规模部署高级Tensorflow模型</strong>。<a class="ae kw" href="https://www.tensorflow.org/tfx/guide" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj"> Tensorflow Extended </strong>(简称TFX)</a>平台使您能够在测试和生产环境中部署自动化管道。它为常见步骤(如数据接收、数据验证和培训)提供了预构建的组件。每一步都有明确的定义，它有一组清晰的输入和输出，并且是专为可扩展的高性能机器学习任务而设计的。你知道吗，Vertex AI Pipeline原生支持其TFX SDK。您可以使用Python和TFX来定义ML管道，然后在Vertex AI上以无服务器的方式执行管道。</p><h2 id="3b94" class="jw jx hi bd jy jz ka kb kc kd ke kf kg iq kh ki kj iu kk kl km iy kn ko kp kq bi translated">我们的数据集</h2><p id="ce59" class="pw-post-body-paragraph if ig hi ih b ii kr ik il im ks io ip iq kt is it iu ku iw ix iy kv ja jb jc hb bi translated"><strong class="ih hj">为了模拟场景</strong>，我们决定使用<strong class="ih hj">服务台问题</strong>数据集。数据集由几个变量组成，如支持人员的资历和经验级别以及问题的类别或类型。目标变量由解决时间表示，即解决特定问题所需的时间。下面您可以看到我们使用的帮助台问题数据集的视图。</p><figure class="jh ji jj jk fd jl"><div class="bz dy l di"><div class="mj mk l"/></div></figure><h2 id="a992" class="jw jx hi bd jy jz ka kb kc kd ke kf kg iq kh ki kj iu kk kl km iy kn ko kp kq bi translated">当TFX遇到对话流CX:我们的ML系统的服务台聊天机器人</h2><p id="de81" class="pw-post-body-paragraph if ig hi ih b ii kr ik il im ks io ip iq kt is it iu ku iw ix iy kv ja jb jc hb bi translated">我们开始评估架构和组件，如果有人需要在现实生活中实现这样的系统，我们会使用这些组件。我们假设</p><ul class=""><li id="7f14" class="le lf hi ih b ii ij im in iq lg iu lh iy li jc lj lk ll lm bi translated"><strong class="ih hj">张量流模型不具备生产质量</strong></li></ul><p id="36a5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们真的想重点了解数据科学家是否以及如何需要创建一个TF预处理和训练任务，以便在相应的TFX组件中使用它。</p><ul class=""><li id="ec36" class="le lf hi ih b ii ij im in iq lg iu lh iy li jc lj lk ll lm bi translated"><strong class="ih hj">TFX管道将尽可能干燥</strong></li></ul><p id="87ef" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们假设ML工程师第一次采用该框架，我们真的希望在像这样的POC场景中保持简单。</p><ul class=""><li id="490c" class="le lf hi ih b ii ij im in iq lg iu lh iy li jc lj lk ll lm bi translated"><strong class="ih hj">这个场景不是关于构建一个机器人。</strong></li></ul><p id="530c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这就是为什么我们要重用<a class="ae kw" href="https://github.com/gmikels/cloud-dialogflow-bqml" rel="noopener ugc nofollow" target="_blank">一个带有Dialogflow的帮助台聊天机器人&amp; BigQuery ML </a> Dialogflow项目。但我们修改了履行代码，以便使用部署在顶点人工智能端点的模型生成的预测。</p><p id="a1d3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">说到这里，让我们深入研究一下我们实现的ML系统的细节。</p><h2 id="cbe4" class="jw jx hi bd jy jz ka kb kc kd ke kf kg iq kh ki kj iu kk kl km iy kn ko kp kq bi translated">预处理。改造，训练。验证。用力。重复一遍。</h2><p id="25f4" class="pw-post-body-paragraph if ig hi ih b ii kr ik il im ks io ip iq kt is it iu ku iw ix iy kv ja jb jc hb bi translated">正如我们之前提到的，我们实施的TFX管道具有关键组件:</p><ul class=""><li id="8eb2" class="le lf hi ih b ii ij im in iq lg iu lh iy li jc lj lk ll lm bi translated">an<strong class="ih hj"><em class="jd">example _ gen</em></strong>消费csv文件，生成训练和评估拆分为tf。基于我们设置的output_config的示例消息(⅔培训，⅓评估)。</li><li id="5876" class="le lf hi ih b ii ln im lo iq lp iu lq iy lr jc lj lk ll lm bi translated">A <strong class="ih hj"> <em class="jd"> statistics_gen </em> </strong>生成训练和服务数据的特征统计，这允许我们验证样本的变量分布，并查看一些计算出的统计，以便进行数据处理和数据分析。</li></ul><figure class="jh ji jj jk fd jl er es paragraph-image"><div role="button" tabindex="0" class="jm jn di jo bf jp"><div class="er es ml"><img src="../Images/a09c68b6ea9a6d435b3b2125bf88b6e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*w4YTXcaeCS2l58zsiMtGTw.png"/></div></div></figure><figure class="jh ji jj jk fd jl er es paragraph-image"><div role="button" tabindex="0" class="jm jn di jo bf jp"><div class="er es mm"><img src="../Images/d4dbe1ddd9f91d9bf6cecbc63f3848ed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*F60mHLaXqw9At6XBSi7c0w.png"/></div></div><figcaption class="js jt et er es ju jv bd b be z dx translated">图3。统计生成训练和评估样本的输出统计</figcaption></figure><ul class=""><li id="c67f" class="le lf hi ih b ii ij im in iq lg iu lh iy li jc lj lk ll lm bi translated"><strong class="ih hj"> <em class="jd"> schema_gen </em> </strong>使用<em class="jd"> statistics_gen </em>组件的输出来推断模式，即与dataset⁴.相关联的特征值、值范围和其他属性的数据类型</li><li id="e34e" class="le lf hi ih b ii ln im lo iq lp iu lq iy lr jc lj lk ll lm bi translated"><strong class="ih hj"> <em class="jd">转换</em> </strong>允许我们应用缺失插补逻辑，生成词汇并将其应用于分类插补，并将数值变量缩放至范围[0，1]。为了做到这一点，我们需要提供一个用户定义的<em class="jd">预处理_fn </em>。这是两个组件中的一个(另一个是<em class="jd">训练器</em>)，数据科学家需要将他的实验代码调整到TFX组件所要求的格式。</li></ul><pre class="jh ji jj jk fd mn mo mp mq aw mr bi"><span id="4ae9" class="jw jx hi mo b fi ms mt l mu mv">def preprocessing_fn(inputs):<br/>    """tf.transform's callback function for preprocessing inputs.<br/>    We assume not using feature store in this example<br/>  Args:<br/>    inputs: map from feature keys to raw not-yet-transformed features.<br/>  Returns:<br/>    Map from string feature key to transformed feature operations.<br/>  """<br/><br/>    outputs = {}<br/><br/>    # generate the vocabulary and apply it for categorical imputation<br/>    for key in _CATEGORICAL_VARIABLES:<br/>        outputs[key] = \<br/>            tft.compute_and_apply_vocabulary(_fill_in_missing(inputs[key]))<br/><br/>    # scale numerical variables to have range [0,1]<br/>    for key in _NUMERICAL_VARIABLES:<br/>        outputs[key] = tft.scale_to_0_1(_fill_in_missing(inputs[key]))</span></pre><ul class=""><li id="f8a7" class="le lf hi ih b ii ij im in iq lg iu lh iy li jc lj lk ll lm bi translated">与前面的组件一样，<strong class="ih hj"> <em class="jd">训练器</em> </strong>需要一个用户自定义的、符合组件需求的训练模块文件。例如，在我们的例子中，我们构建一个定制的Keras模型，并使用<em class="jd"> custom_executor_spec </em>中的<em class="jd"> GenericExecutor </em>在TFX内部对其进行本地训练。然后，<a class="ae kw" href="https://www.tensorflow.org/tfx/guide/trainer" rel="noopener ugc nofollow" target="_blank">根据文档</a>，需要一个<em class="jd"> run_fn </em>函数。您可以在下面找到我们在培训模块中定义的内容:</li></ul><pre class="jh ji jj jk fd mn mo mp mq aw mr bi"><span id="cd5c" class="jw jx hi mo b fi ms mt l mu mv"># TFX will call this function<br/>def run_fn(fn_args):<br/>    """A function to train the model based on given args.<br/>    Args:<br/>      fn_args: training args as name/value pairs.<br/>    """<br/>    train_batch_size = 100<br/>    eval_batch_size = 100<br/><br/>    # read the preprocessing data in order to speed up training process<br/>    tf_transform_output = \<br/>        tft.TFTransformOutput(fn_args.transform_output)<br/><br/>    # ingest the transformed data and prepare training and evaluation dataset<br/>    train_input_fn = _input_fn(fn_args.train_files,<br/>                               fn_args.data_accessor,      tf_transform_output,<br/>                               batch_size=train_batch_size)  # pylint: disable=g-long-lambda<br/><br/>    eval_input_fn = _input_fn(fn_args.eval_files,<br/>                              fn_args.data_accessor, tf_transform_output,<br/>                              batch_size=eval_batch_size)  # pylint: disable=g-long-lambda<br/><br/>    # build the model<br/>    model = _build_simple_dnn_regressor()<br/><br/>    # define callback for TensorBoard<br/>    tensorboard_callback = tf.keras.callbacks.TensorBoard(<br/>        log_dir=fn_args.model_run_dir, update_freq='batch')<br/><br/>    # fit the model<br/>    model.fit(<br/>        train_input_fn,<br/>        steps_per_epoch=fn_args.train_steps,<br/>        validation_data=eval_input_fn,<br/>        validation_steps=fn_args.eval_steps,<br/>        callbacks=[tensorboard_callback])<br/><br/>    # read the feature spec to integrate in the serving function<br/>    feature_spec = tf_transform_output.raw_feature_spec()<br/>    features_input_signature = {<br/>        feature_name:<br/>            tf.TensorSpec(<br/>                shape=(None, 1), dtype=spec.dtype, name=feature_name<br/>            )<br/>        for feature_name, spec in feature_spec.items()<br/>        if feature_name in _FEATURE_NAMES<br/>    }<br/>    # define the signature<br/>    signatures = {<br/>        'serving_default':<br/>            _get_serve_tf_fn(model,<br/>                             tf_transform_output).get_concrete_function(<br/>                features_input_signature)<br/>    }<br/>    # save the model<br/>    model.save(fn_args.serving_model_dir, save_format='tf', signatures=signatures)</span></pre><p id="8752" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在哪里</p><ul class=""><li id="942d" class="le lf hi ih b ii ij im in iq lg iu lh iy li jc lj lk ll lm bi translated"><em class="jd"> _input_fn </em>生成特征和标签</li><li id="6037" class="le lf hi ih b ii ln im lo iq lp iu lq iy lr jc lj lk ll lm bi translated"><em class="jd">_ build _ simple _ dnn _ regressor</em>定义特征列并建立模型</li><li id="20fc" class="le lf hi ih b ii ln im lo iq lp iu lq iy lr jc lj lk ll lm bi translated"><em class="jd"> _get_serve_tf_fn </em>解析一个序列化的tf。示例和应用TFT</li></ul><p id="bb09" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">请注意</p><ul class=""><li id="5aa5" class="le lf hi ih b ii ij im in iq lg iu lh iy li jc lj lk ll lm bi translated">在训练过程中，我们使用预处理数据<em class="jd"> tf_transform_output </em>来减少训练时间。</li><li id="d879" class="le lf hi ih b ii ln im lo iq lp iu lq iy lr jc lj lk ll lm bi translated">因为我们希望将模型提供给顶点端点，所以我们还提供了一个定制的<em class="jd"> serving_default </em>签名，它将集成转换图，并允许模型正确得分。</li></ul><p id="15bb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">最后，组件使用带有训练和评估示例的模块、训练参数和评估参数的Protobuf定义、由<em class="jd"> schema_gen </em>组件创建的模式和由上游<em class="jd">转换</em>组件生成的转换图，并训练模型。</p><ul class=""><li id="7cfa" class="le lf hi ih b ii ij im in iq lg iu lh iy li jc lj lk ll lm bi translated"><strong class="ih hj"> <em class="jd">评估器</em> </strong>利用来自<em class="jd"> example_gen </em>的数据、来自训练器的训练模型以及<em class="jd"> EvalConfig </em>配置计算模型性能指标，并返回性能结果和验证结果。关于<em class="jd"> EvalConfig </em>，我们明确了<em class="jd"> model_spec </em>来表示目标变量和服务签名。我们还设置了<em class="jd"> metrics_specs </em>在Keras<em class="jd">mean _ absolute _ error</em>指标上设置了<em class="jd"> GenericValueThreshold </em>。最后，我们将<em class="jd"> slicing_specs </em>留空以考虑整个数据集。一旦您运行它，因为模型的准确性满足评估标准，模型是“受祝福的”,也就是说它可以被部署</li></ul><figure class="jh ji jj jk fd jl er es paragraph-image"><div role="button" tabindex="0" class="jm jn di jo bf jp"><div class="er es mw"><img src="../Images/1d4073757ce264b15e56976444aa83b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pZ4NqNKGZZ0EV_Ne91-arg.png"/></div></div><figcaption class="js jt et er es ju jv bd b be z dx translated">图4。该模型是“有福的”</figcaption></figure><ul class=""><li id="1109" class="le lf hi ih b ii ij im in iq lg iu lh iy li jc lj lk ll lm bi translated"><strong class="ih hj"> <em class="jd">推进器</em> </strong>是TFX管道的最后一步。它只是检查模型是否通过了验证，然后将模型导出到<em class="jd"> _serving_model_dir </em>。</li></ul><p id="19e6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">下面你可以看到我用<strong class="ih hj"> <em class="jd"> run </em> </strong>方法定义的<strong class="ih hj"> <em class="jd">管道</em> </strong>类，它允许我在本地和顶点AI管道上运行它</p><pre class="jh ji jj jk fd mn mo mp mq aw mr bi"><span id="df70" class="jw jx hi mo b fi ms mt l mu mv">class Pipeline:<br/>    """<br/>    The Pipeline class generalizes a pipeline definition in order to run it<br/>    both on prem and on cloud.<br/>    """<br/><br/>    def __init__(self,<br/>                 runner: str,<br/>                 pipeline_name: str,<br/>                 pipeline_root: str,<br/>                 data_root: str,<br/>                 modules_path: str,<br/>                 serving_model_dir: str,<br/>                 metadata_path: str,<br/>                 project_id=None,<br/>                 region=None,<br/>                 pipeline_definition=None):<br/><br/>        self.pipeline = None<br/>        self.runner = runner<br/>        self.pipeline_name = pipeline_name<br/>        self.pipeline_root = pipeline_root<br/>        self.data_root = data_root<br/>        self.modules_path = modules_path<br/>        self.serving_model_dir = serving_model_dir<br/>        self.metadata_path = metadata_path<br/>        self.transform_filepath = f'{self.modules_path}/{TRANSFORM_MODULE}'<br/>        self.trainer_filepath = f'{self.modules_path}/{TRAINER_MODULE}'<br/>        self.train_num_steps = 2000<br/>        self.eval_num_steps = 1000<br/>        self.components = []<br/>        if self.runner == 'KubeflowRunner':<br/>            self.project_id = project_id<br/>            self.region = region<br/>            self.pipeline_definition = pipeline_definition<br/><br/>        # ExampleGen<br/>        example_gen = tfx.components.CsvExampleGen(input_base=self.data_root,<br/>                                                   output_config=EXAMPLE_GEN_OUTPUT_CONFIG)<br/><br/>        # StatisticsGen<br/>        statistics_gen = tfx.components.StatisticsGen(<br/>            examples=example_gen.outputs['examples']<br/>        )<br/><br/>        # SchemaGen<br/>        schema_gen = tfx.components.SchemaGen(<br/>            statistics=statistics_gen.outputs['statistics'],<br/>            infer_feature_shape=True)<br/><br/>        # Transform<br/>        transform = tfx.components.Transform(<br/>            examples=example_gen.outputs['examples'],<br/>            schema=schema_gen.outputs['schema'],<br/>            module_file=self.transform_filepath)<br/><br/>        # Trainer<br/>        trainer = tfx.components.Trainer(<br/>            module_file=self.trainer_filepath,<br/>            examples=transform.outputs['transformed_examples'],<br/>            schema=schema_gen.outputs['schema'],<br/>            transform_graph=transform.outputs['transform_graph'],<br/>            train_args=tfx.proto.TrainArgs(num_steps=self.train_num_steps),<br/>            eval_args=tfx.proto.EvalArgs(num_steps=self.eval_num_steps))<br/><br/>        # Evaluator<br/>        evaluator = tfx.components.Evaluator(<br/>            examples=example_gen.outputs['examples'],<br/>            model=trainer.outputs['model'],<br/>            eval_config=EVALUATOR_CONFIG)<br/><br/>        with conditional.Cond(evaluator.outputs['blessing'].future()<br/>                              [0].custom_property('blessed') == 1):<br/><br/>            # Pusher<br/>            pusher = tfx.components.Pusher(<br/>                model=trainer.outputs['model'],<br/>                model_blessing=evaluator.outputs['blessing'],<br/>                push_destination=tfx.proto.PushDestination(<br/>                    filesystem=tfx.proto.PushDestination.Filesystem(<br/>                        base_directory=self.serving_model_dir)))<br/><br/>        # prepare components<br/>        self.components = [example_gen,<br/>                           statistics_gen,<br/>                           schema_gen,<br/>                           transform,<br/>                           trainer,<br/>                           evaluator,<br/>                           pusher]<br/><br/>        # build pipeline<br/>        if self.runner == 'KubeflowRunner':<br/>            self.pipeline = tfx.dsl.Pipeline(<br/>                pipeline_name=self.pipeline_name,<br/>                pipeline_root=self.pipeline_root,<br/>                components=self.components)<br/>        else:<br/>            self.pipeline = tfx.dsl.Pipeline(<br/>                pipeline_name=self.pipeline_name,<br/>                pipeline_root=self.pipeline_root,<br/>                components=self.components,<br/>                metadata_connection_config=tfx.orchestration.metadata<br/>                    .sqlite_metadata_connection_config(self.metadata_path),<br/>                beam_pipeline_args=BEAM_PIPELINE_ARGS_RUNNER[self.runner])<br/><br/>    def run(self):<br/>        if self.runner == 'KubeflowRunner':<br/>            self.runner_instance = tfx.orchestration.experimental.KubeflowV2DagRunner(<br/>                config=tfx.orchestration.experimental.KubeflowV2DagRunnerConfig(),<br/>                output_filename=self.pipeline_definition)<br/>            _ = self.runner_instance.run(self.pipeline)<br/>            vertex_ai.init(project=self.project_id, location=self.region)<br/>            pipeline_job = vertex_ai.PipelineJob(<br/>                          display_name=self.pipeline_name,<br/>                          template_path=self.pipeline_definition,<br/>                          pipeline_root=self.pipeline_root<br/>                      )<br/>            pipeline_job.run(sync=False)<br/>        else:<br/>            self.runner_instance = tfx.orchestration.LocalDagRunner()<br/>            _ = self.runner_instance.run(self.pipeline)</span></pre><p id="be0a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这是当你把管道提交给顶点AI时，执行图的样子</p><figure class="jh ji jj jk fd jl er es paragraph-image"><div role="button" tabindex="0" class="jm jn di jo bf jp"><div class="er es mx"><img src="../Images/8c04c012d17ab8aca05baf74f283371d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*63FAbTnss8SQO_FP"/></div></div><figcaption class="js jt et er es ju jv bd b be z dx translated">图5。顶点人工智能管道的执行图</figcaption></figure><p id="c0e2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">最后，一旦我们训练了模型，我们可以使用<a class="ae kw" href="https://cloud.google.com/vertex-ai/docs/predictions/deploy-model-api" rel="noopener ugc nofollow" target="_blank"> Vertex Python SDK </a>轻松部署。然后，它将能够对任何来源传递的实例进行评分，甚至包括来自Dialogflow CX聊天机器人的实例。</p><h2 id="476b" class="jw jx hi bd jy jz ka kb kc kd ke kf kg iq kh ki kj iu kk kl km iy kn ko kp kq bi translated">“嗨，我有一个技术问题”</h2><figure class="jh ji jj jk fd jl er es paragraph-image"><div role="button" tabindex="0" class="jm jn di jo bf jp"><div class="er es mi"><img src="../Images/79335af40ab896cf44b2613dc41d12e6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*nMg56EQv2ZzsUY0P"/></div></div><figcaption class="js jt et er es ju jv bd b be z dx translated">图6。服务台聊天机器人</figcaption></figure><p id="7cb6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如前所述，本文的目的不是设计一个复杂和专业的虚拟代理，因此它的结构刻意保持简单。</p><p id="924f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">我们的虚拟代理代表了一个典型的面向客户的一级(L1)支持代理</strong>，其范围是收集客户的支持请求，获取关于问题的基本描述，最终提交支持单并提供关于解决时间的估计。特别是，在这个特定的场景中，问题的类别是虚拟代理要求什么(例如，性能、计费、技术、认证)。</p><p id="c186" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">使用Dialogflow CX，我们可以通过设计对话流来轻松构建企业级对话代理，每个对话流都由多个对话回合组成。客户的每一句话都被自动分类到一个可能的意图列表中，这些意图是在Dialogflow CX GUI中定义的，无需编写任何代码。</p><p id="9665" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在我们的具体示例中，代理被构造为单个对话流，由以下几轮组成:</p><ol class=""><li id="2e88" class="le lf hi ih b ii ij im in iq lg iu lh iy li jc my lk ll lm bi translated">问候(虚拟代理)和票证请求(客户)</li><li id="aff4" class="le lf hi ih b ii ln im lo iq lp iu lq iy lr jc my lk ll lm bi translated">问题信息的收集。特别是，虚拟代理仅询问问题类别</li><li id="28d6" class="le lf hi ih b ii ln im lo iq lp iu lq iy lr jc my lk ll lm bi translated"><strong class="ih hj">确认收集的信息和提交的票据，并报告预计的解决时间。</strong></li><li id="e12b" class="le lf hi ih b ii ln im lo iq lp iu lq iy lr jc my lk ll lm bi translated">对话结束</li></ol><p id="bce7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这听起来很容易，但是<strong class="ih hj">虚拟代理如何推断估计的解决时间？</strong></p><p id="107d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了满足这个请求，虚拟代理需要与我们的后端系统交互，以获得每个特定问题的估计解决时间，并将其返回给客户。<strong class="ih hj">使用Dialogflow CX，这是由</strong><a class="ae kw" href="https://cloud.google.com/dialogflow/cx/docs/concept/webhook" rel="noopener ugc nofollow" target="_blank"><strong class="ih hj">web hooks</strong></a><strong class="ih hj">启用的。</strong></p><p id="d3ef" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Webhooks使用Dialogflow CX的自然语言处理提取的数据来生成动态响应，验证收集的数据，或触发后端的操作。简而言之，webhook是一种向后端系统触发HTTPS请求的服务。</p><figure class="jh ji jj jk fd jl er es paragraph-image"><div role="button" tabindex="0" class="jm jn di jo bf jp"><div class="er es mz"><img src="../Images/fff6e915d7466763667c7f9ed1223903.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nFV7akqZpwJT_3Gj1sAaMA.png"/></div></div><figcaption class="js jt et er es ju jv bd b be z dx translated">图7。Dialogflow CX中的webhook视图</figcaption></figure><p id="e34f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">后端是如何通过webhooks处理来自Dialogflow CX的请求的？</strong></p><p id="cf6e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">一个直截了当的方法是用谷歌的</strong> <a class="ae kw" href="https://cloud.google.com/functions" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj">云功能</strong> </a>，我们的功能即服务(FaaS)框架，实现所有的业务逻辑来服务推理阶段。这种架构的一个主要好处是确保业务逻辑本身和使用Vertex AI部署的机器学习服务之间的解耦。举个例子，将来我们可以增加相同的云功能，在不影响ML端点的情况下从我们的CRM系统获取额外的信息。</p><p id="40a2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在所有支持的编程语言中，我们选择了Node.js。做出这一选择的一个重要原因是Vertex AI提供了一个非常灵活的Node.js API 。</p><p id="5645" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">云功能的架构由</strong>以下组件组成:</p><ul class=""><li id="dac8" class="le lf hi ih b ii ij im in iq lg iu lh iy li jc lj lk ll lm bi translated"><strong class="ih hj"><em class="jd">index . js</em></strong>:<em class="jd"/>node . js中的功能实现</li><li id="4417" class="le lf hi ih b ii ln im lo iq lp iu lq iy lr jc lj lk ll lm bi translated"><strong class="ih hj"> <em class="jd"> package.json </em> </strong>:包装函数依赖关系的元数据文件，用<a class="ae kw" href="https://docs.npmjs.com/" rel="noopener ugc nofollow" target="_blank"> <em class="jd"> npm </em> </a>管理</li></ul><p id="f4e1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jd"> package.json </em>记录了我们的两个依赖项:Vertex AI，用于调用估计解析时间的预测；dialog flow CX，用于解析和管理来自虚拟代理的webhook的请求:</p><pre class="jh ji jj jk fd mn mo mp mq aw mr bi"><span id="f0d1" class="jw jx hi mo b fi ms mt l mu mv">"dependencies": {<br/>   "@google-cloud/dialogflow-cx": "^2.4.0",<br/>   "@google-cloud/aiplatform": "^1.12.0"<br/> }</span></pre><p id="6206" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">至于函数本身，有几个方面值得澄清:</p><ul class=""><li id="8755" class="le lf hi ih b ii ij im in iq lg iu lh iy li jc lj lk ll lm bi translated">为了保持虚拟代理的简单性，以及不要用多个问题来打扰客户，虚拟代理只收集问题类别(例如，技术、计费等)。ML端点所需的所有其他特征(资历、优先级、经验等)都已硬编码。将来，最好的方法是通过查询公司的后端系统来获取这些附加功能</li><li id="299c" class="le lf hi ih b ii ln im lo iq lp iu lq iy lr jc lj lk ll lm bi translated">为了将请求提交给预测端点，我们依靠助手来正确格式化请求负载。帮助器对于摆脱表示转换非常有用，这在Node.js中可能很棘手</li><li id="e097" class="le lf hi ih b ii ln im lo iq lp iu lq iy lr jc lj lk ll lm bi translated">功能实现最重要的方面是负责在线预测和可解释请求的<a class="ae kw" href="https://cloud.google.com/vertex-ai/docs/reference/rpc/google.cloud.aiplatform.v1#predictionservice" rel="noopener ugc nofollow" target="_blank"> <em class="jd">预测服务</em> </a></li></ul><p id="1d76" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">下面我们报告云函数实现的预测片段:</p><pre class="jh ji jj jk fd mn mo mp mq aw mr bi"><span id="c60c" class="jw jx hi mo b fi ms mt l mu mv">async function getPredictionRequest(category) {<br/>    // Configure the parent resource<br/>    const endpoint = `projects/${projectId}/locations/${location}/endpoints/${endpointId}`;<br/>    // Set empty parameters <br/>    const parameters = {<br/>      structValue: {</span><span id="48f4" class="jw jx hi mo b fi na mt l mu mv">// TODO<br/>        // fields: {category: {stringValue: category}}} <br/>      },<br/>    };</span><span id="1bac" class="jw jx hi mo b fi na mt l mu mv">// Set the instance value. For simplicity, we pass one input (category). <br/>    // In the real world, you can pass multiple inputs. <br/>    // In case of caller inputs, they would be collected from <br/>    // Bigtable. In case of ticket inputs, they would be passed by the Dialogflow agent.<br/>    const instanceValue = {<br/>      seniority: [12],<br/>      experience: ['3-Advanced'],<br/>      category: [category],<br/>      type: ['Request'],<br/>      impact: ['4-Critical'],<br/>      priority: ['P1']<br/>    };<br/><br/>    const instance = helpers.toValue(instanceValue);<br/><br/>    const instances = [instance];<br/>    const request = {<br/>      endpoint,<br/>      instances,<br/>      parameters,<br/>    };<br/><br/>    return request;<br/>}<br/><br/>async function getResolutionTime(request) {<br/><br/>    // Declare the ResolutionTime constant.<br/>    var resolutionTime = 1;<br/><br/>    // Specifies the location of the api endpoint<br/>    const clientOptions = {<br/>        apiEndpoint: 'us-central1-aiplatform.googleapis.com',<br/>    };<br/><br/>    // Instantiates a client<br/>    const predictionServiceClient = new PredictionServiceClient(clientOptions);<br/><br/>    // Predict request<br/>    const [response] = await predictionServiceClient.predict(request);<br/><br/>    console.log('Predict custom trained model response');<br/>    console.log(`\tDeployed model id : ${response.deployedModelId}`);<br/>    const predictions = response.predictions;<br/>    console.log('\tPredictions :');<br/>    for (const prediction of predictions) {<br/>      resolutionTime = JSON.stringify(prediction.listValue.values[0].numberValue);<br/>      console.log(`\t\tPrediction : ${resolutionTime}`);<br/>    }<br/>    return parseInt(resolutionTime);<br/>  }</span></pre><p id="994f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">最后，在您成功部署完成后，虚拟代理将票据信息传递给端点，收集解决时间估计值并将其提供给客户。为了更好地理解，下面你会看到我们用Dialogflow CX模拟器模拟的一段对话。</p><figure class="jh ji jj jk fd jl er es paragraph-image"><div class="er es nb"><img src="../Images/8f23a8651692045aae88a7f8090f876d.png" data-original-src="https://miro.medium.com/v2/resize:fit:876/1*EUNsYoAWDBpNd4tcjMsMVg.gif"/></div><figcaption class="js jt et er es ju jv bd b be z dx translated">图8。Dialogflow CX模拟器中的模拟对话</figcaption></figure><h2 id="77f1" class="jw jx hi bd jy jz ka kb kc kd ke kf kg iq kh ki kj iu kk kl km iy kn ko kp kq bi translated">MLOps优势:通过简单的云构建管道实现模型服务自动化</h2><p id="ee66" class="pw-post-body-paragraph if ig hi ih b ii kr ik il im ks io ip iq kt is it iu ku iw ix iy kv ja jb jc hb bi translated">在真实的场景中，一旦您用管道训练了模型，并将其版本化到模型注册中心，就应该部署它了。现在，<strong class="ih hj">模型部署需要大量的测试和验证步骤，在模型到达服务环境之前需要一次又一次地重复</strong>。出于这个原因，您将构建一个<strong class="ih hj"> CI/CD管道系统</strong>。使用该系统，您可以验证、测试、集成模型和服务，并最终部署它们(运行时和模型)。</p><figure class="jh ji jj jk fd jl er es paragraph-image"><div role="button" tabindex="0" class="jm jn di jo bf jp"><div class="er es mi"><img src="../Images/96c83a2742d63d9f7ab4a93d202eba92.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*WLcaBPzLz7bNqOSg"/></div></div><figcaption class="js jt et er es ju jv bd b be z dx translated">图9。服务于Process⁵.的模型的高级概述</figcaption></figure><p id="cb62" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">也就是说，作为本文的额外部分，我实现了<strong class="ih hj">一个具有云功能和云构建的CI/CD模型部署管道的简单示例。</strong></p><p id="9505" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">特别是，云构建管道将</p><ol class=""><li id="1a96" class="le lf hi ih b ii ij im in iq lg iu lh iy li jc my lk ll lm bi translated">从谷歌云存储中下载模型人工制品</li><li id="4cf8" class="le lf hi ih b ii ln im lo iq lp iu lq iy lr jc my lk ll lm bi translated">为测试构建运行时环境</li><li id="442c" class="le lf hi ih b ii ln im lo iq lp iu lq iy lr jc my lk ll lm bi translated">运行预测单元测试</li><li id="f181" class="le lf hi ih b ii ln im lo iq lp iu lq iy lr jc my lk ll lm bi translated">使用临时顶点AI端点运行集成</li><li id="b846" class="le lf hi ih b ii ln im lo iq lp iu lq iy lr jc my lk ll lm bi translated">将模型部署到目标顶点AI端点</li></ol><p id="0cb3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">请注意，为了简单起见，我使用staging作为生产环境。此外，这只是一个简单的例子，没有虚饰。正如“<a class="ae kw" href="https://cloud.google.com/resources/mlops-whitepaper" rel="noopener ugc nofollow" target="_blank">MLOps实践者指南:机器学习的连续交付和自动化框架</a>中所述，这些CI/CD模式可能需要一个复杂的渐进交付过程来验证兼容性、延迟和吞吐量，这意味着还要进行几次测试。</p><p id="df28" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">下面你可以找到我创建的get_build函数，它使用<a class="ae kw" href="https://googleapis.dev/python/cloudbuild/latest/index.html" rel="noopener ugc nofollow" target="_blank"><em class="jd">Google-Cloud-Build</em></a>Python SDK来构建云构建的模型部署管道:</p><pre class="jh ji jj jk fd mn mo mp mq aw mr bi"><span id="537b" class="jw jx hi mo b fi ms mt l mu mv">def get_build(project_id, region, bucket, source, model_uri, model_path, serving_signature, model_name, serving_image_uri,<br/>endpoint_name, timeout):<br/>    """<br/>    An utility function to get a build object <br/>    Args:<br/>        project_id: The name of the project<br/>        region: The name of the region<br/>        bucket: The name of the bucket<br/>        source: The GCS uri of the source code <br/>        model_uri: The GCS uri of the model <br/>        model_path: The path of the model <br/>        serving_signature: The default signature to deploy the model<br/>        model_name: The model name <br/>        serving_image_uri: The serving image uri<br/>        endpoint_name: The name of endpoint<br/>        timeout: The timeout of cloud build<br/><br/>    Returns: build object<br/><br/>    """<br/>    build = cloudbuild_v1.Build()<br/>    build.source = Source(storage_source=StorageSource(bucket=bucket,<br/>                                                       object_=source))<br/>    build.steps = [<br/><br/>        {"name": 'gcr.io/google.com/cloudsdktool/cloud-sdk',<br/>         "args": ['gsutil', '-m', 'cp', '-r', '${_MODEL_URI}', '.'],<br/>         "id": 'Download model'},<br/><br/>        {"name": 'gcr.io/deeplearning-platform-release/tf-cpu.2-7:latest',<br/>         "entrypoint": "pip",<br/>         "args": ["install", "-r", "build/deployment/requirements.txt", "--user"],<br/>         "id": 'Install requirements',<br/>         "wait_for": ['Download model']},<br/><br/>        {"name": 'gcr.io/deeplearning-platform-release/tf-cpu.2-7:latest',<br/>         "entrypoint": "python",<br/>         "args": ["-m", "pytest", 'build/deployment/src/test_model.py'],<br/>         "env": ['MODEL_PATH=${_MODEL_PATH}', 'SERVING_SIGNATURE=${_SERVING_SIGNATURE}'],<br/>         "id": 'Run unit test',<br/>         "wait_for": ['Install requirements']<br/>         },<br/><br/>        {<br/>            "name": 'gcr.io/deeplearning-platform-release/tf-cpu.2-7:latest',<br/>            "entrypoint": "python",<br/>            "args": ["-m", "pytest", 'build/deployment/src/test_endpoint.py'],<br/>            "env": ['PROJECT_ID=${_PROJECT_ID}', 'REGION=${_REGION}',<br/>                    'MODEL_NAME=${_MODEL_NAME}', 'ARTIFACT_URI=${_MODEL_URI}',<br/>                    'SERVING_IMAGE_URI=${_SERVING_IMAGE_URI}', 'ENDPOINT_NAME=${_ENDPOINT_NAME}'],<br/>            "id": 'Run integration test',<br/>            "wait_for": ['Run unit test']<br/>        },<br/><br/>        {<br/>            "name": 'gcr.io/deeplearning-platform-release/tf-cpu.2-7:latest',<br/>            "entrypoint": "python",<br/>            "args": ['build/deployment/src/deploy.py'],<br/>            "env": ['PROJECT_ID=${_PROJECT_ID}', 'REGION=${_REGION}',<br/>                    'MODEL_NAME=${_MODEL_NAME}', 'ARTIFACT_URI=${_MODEL_URI}',<br/>                    'SERVING_IMAGE_URI=${_SERVING_IMAGE_URI}', 'ENDPOINT_NAME=${_ENDPOINT_NAME}'],<br/>            "id": 'Deploy the validated model',<br/>            "wait_for": ['Run integration test']<br/>        }<br/><br/>    ]<br/>    build.substitutions = {'_PROJECT_ID': project_id,<br/>                           '_REGION': region,<br/>                           '_MODEL_URI': model_uri,<br/>                           '_MODEL_PATH': model_path,<br/>                           '_SERVING_SIGNATURE': serving_signature,<br/>                           '_MODEL_NAME': model_name,<br/>                           '_SERVING_IMAGE_URI': serving_image_uri,<br/>                           '_ENDPOINT_NAME': endpoint_name<br/>                           }<br/>    build.timeout = Duration(seconds=timeout)<br/>    return build</span></pre><p id="d092" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">然后，每次新的模型将被构建并存储在目标存储桶路径中时，云函数将触发一个新的构建管道实例。</p><p id="0afc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">下面您可以看到部署成功运行后的结果。</p><figure class="jh ji jj jk fd jl er es paragraph-image"><div role="button" tabindex="0" class="jm jn di jo bf jp"><div class="er es nc"><img src="../Images/d4e59a303af3336dbbd4f877f55aa5a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eRHweRNYmTbEp0hPKZfEnw.png"/></div></div><figcaption class="js jt et er es ju jv bd b be z dx translated">图10。成功建模部署的云构建视图</figcaption></figure><h2 id="7a99" class="jw jx hi bd jy jz ka kb kc kd ke kf kg iq kh ki kj iu kk kl km iy kn ko kp kq bi translated">下一步是什么</h2><p id="55a6" class="pw-post-body-paragraph if ig hi ih b ii kr ik il im ks io ip iq kt is it iu ku iw ix iy kv ja jb jc hb bi translated">在本文中，我们探索了如何使用顶点管道上训练的ML模型来增强用Dialogflow CX构建的简单聊天机器人。</p><p id="e906" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">出于学习目的，我们决定使用Tensorflow来训练模型，并使用Tensorflow Extended(又名TFX)框架来操作它。</p><p id="f7fc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们都从这次经历中学到了很多。</p><p id="076f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">首先，我们理解了在混合模式下工作的重要性，为了成功地交付一个模型，模型实验和模型工程需要合作。关于这个话题，你可以在这里找到一篇来自谷歌的有趣文章。</p><p id="7d08" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">第二，我个人喜欢TFX。我发现它是一致的，并体验了它在加速张量流模型的MLOps过程中的潜在价值。它与Vertex AI的集成几乎是免费的。因此，我将继续对它进行试验，以探索其他组件和功能。</p><p id="c1de" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">第三，我们不知道VertexAI NodeJS SDK。多亏了这个演示，我们现在=)</p><p id="f057" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">当然，这并不是故事的结尾</strong>。正如你所想象的，这是一个完美的用例，可以实现一个可靠的再培训过程。</p><blockquote class="nd ne nf"><p id="6097" class="if ig jd ih b ii ij ik il im in io ip ng ir is it nh iv iw ix ni iz ja jb jc hb bi translated">您部署虚拟代理。它有效地支持客户节省时间和改善客户体验。收集请求所节省的时间会影响解决特定问题的时间，从而影响模型的性能。则因此需要触发新的模型训练管道。最后，一旦你得到这个模型，你将有一个从A版本到B版本的过渡期。</p></blockquote><p id="98b0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">到目前为止，我的描述引发了许多问题，例如</p><ul class=""><li id="cd46" class="le lf hi ih b ii ij im in iq lg iu lh iy li jc lj lk ll lm bi translated"><strong class="ih hj">我们如何设计再培训管道流程？</strong></li><li id="f51f" class="le lf hi ih b ii ln im lo iq lp iu lq iy lr jc lj lk ll lm bi translated"><strong class="ih hj">我们如何在模型服务中实现流量分割？</strong></li><li id="c130" class="le lf hi ih b ii ln im lo iq lp iu lq iy lr jc lj lk ll lm bi translated"><strong class="ih hj">我们如何衡量和管理</strong> <a class="ae kw" href="https://developers.google.com/machine-learning/guides/rules-of-ml#rule_36_avoid_feedback_loops_with_positional_features" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj">反馈循环效应</strong> </a>的效果？</li></ul><p id="b851" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">所有有趣的挑战都需要用适当的解决方案来解决。不是吗？</p><p id="0017" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，我希望你喜欢这篇文章。如果有，就鼓掌或者留言评论。如果你想知道以上问题的答案，就在<a class="ae kw" href="https://www.linkedin.com/in/ivan-nardini/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>或<a class="ae kw" href="https://twitter.com/IlNardo92" rel="noopener ugc nofollow" target="_blank"> Twitter </a>上告诉我们，让我们一起讨论。</p><p id="dd52" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">直到下一个帖子…</p><p id="ab32" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jd">感谢Camus Ma和Hussain Chinoy的宝贵反馈。</em></p><h2 id="882e" class="jw jx hi bd jy jz ka kb kc kd ke kf kg iq kh ki kj iu kk kl km iy kn ko kp kq bi translated"><strong class="ak">参考文献</strong></h2><ol class=""><li id="a682" class="le lf hi ih b ii kr im ks iq nj iu nk iy nl jc my lk ll lm bi translated"><a class="ae kw" href="https://www.tensorflow.org/guide" rel="noopener ugc nofollow" target="_blank">https://www.tensorflow.org/guide</a></li><li id="d4c5" class="le lf hi ih b ii ln im lo iq lp iu lq iy lr jc my lk ll lm bi translated"><a class="ae kw" href="https://www.tensorflow.org/tfx/guide" rel="noopener ugc nofollow" target="_blank">https://www.tensorflow.org/tfx/guide</a></li><li id="d9d7" class="le lf hi ih b ii ln im lo iq lp iu lq iy lr jc my lk ll lm bi translated"><a class="ae kw" href="https://cloud.google.com/vertex-ai/docs/start/introduction-unified-platform" rel="noopener ugc nofollow" target="_blank">https://cloud . Google . com/vertex-ai/docs/start/简介-统一-平台</a></li><li id="fcaa" class="le lf hi ih b ii ln im lo iq lp iu lq iy lr jc my lk ll lm bi translated"><a class="ae kw" href="https://cloud.google.com/dialogflow/cx/docs/basics" rel="noopener ugc nofollow" target="_blank">https://cloud.google.com/dialogflow/cx/docs/basics</a></li></ol></div><div class="ab cl kx ky gp kz" role="separator"><span class="la bw bk lb lc ld"/><span class="la bw bk lb lc ld"/><span class="la bw bk lb lc"/></div><div class="hb hc hd he hf"><p id="f934" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们决定使用张量流和TFX进行学习。当然，同样的方法可以推广到其他使用KFP的ML框架。</p><p id="dbe1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jd">包容率是指与虚拟助手进行交互，但未与人工代理交谈就离开的用户的百分比。高容纳率是一件好事，因为“被容纳”的电话可以防止客户浪费时间，并节省客户服务的宝贵资源。</em></p><p id="b825" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jd">对于https://www.tensorflow.org/tfx/guide组件文档:</em><a class="ae kw" href="https://www.tensorflow.org/tfx/guide" rel="noopener ugc nofollow" target="_blank"><em class="jd"/></a></p><p id="78b4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jd"> ⁴Notice，您可以手动定义模式并添加关于您的数据集的信息。通过这种方式，您可以定义自己的数据验证策略。更多关于TFDV的信息，</em><a class="ae kw" href="https://www.tensorflow.org/tfx/guide/tfdv" rel="noopener ugc nofollow" target="_blank"><em class="jd">https://www.tensorflow.org/tfx/guide/tfdv</em></a></p><p id="26db" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jd"> ⁵The图像是MLOps实践者指南中数字8的个人再现:机器学习的连续交付和自动化的框架</em></p></div></div>    
</body>
</html>