<html>
<head>
<title>Data Mesh Self Service — Ingestion Pattern from GCS(Google Cloud Storage) to BigQuery (Data Store for Mesh)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">数据网格自助服务—从GCS(Google云存储)到BigQuery(网格数据存储)的摄取模式</h1>
<blockquote>原文：<a href="https://medium.com/google-cloud/data-mesh-self-service-ingestion-pattern-from-gcs-google-cloud-storage-to-bigquery-data-store-609aa4bedd8c?source=collection_archive---------1-----------------------#2022-12-31">https://medium.com/google-cloud/data-mesh-self-service-ingestion-pattern-from-gcs-google-cloud-storage-to-bigquery-data-store-609aa4bedd8c?source=collection_archive---------1-----------------------#2022-12-31</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="6429" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Google Cloud中最常用的摄取用例之一是将文件从GCS(Google Cloud Storage)加载到BigQuery。围绕这一点已经有了很多模板，每一个都有不同的用途。在这篇博客中，我们将讨论各种用例以及要应用的特定工具/模板。此外，我们还将了解如何在一个模板中迎合各种文件格式。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/805e61e9ffe71a1b3135b7740635687f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*GSm3qpGyItCysbS_"/></div></div></figure><h1 id="71ba" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">负载类型:</h1><ol class=""><li id="fbb2" class="kn ko hi ih b ii kp im kq iq kr iu ks iy kt jc ku kv kw kx bi translated"><strong class="ih hj">基于时间表:</strong>如果GCS中的文件有固定的到达时间，或者负载预计在特定时间运行，则可以使用基于时间表的方法。文件大小、成本、性能等各种因素都会影响工具/服务的选择。</li></ol><ul class=""><li id="1590" class="kn ko hi ih b ii ij im in iq ky iu kz iy la jc lb kv kw kx bi translated">Cloud Composer:在GCP，每当我们想到基于时间表的负载时，首先想到的就是Composer。Composer是一个基于Apache Airflow的完全托管的工作流编排服务。它有各种内置的操作符，如<a class="ae lc" href="https://airflow.apache.org/docs/apache-airflow-providers-google/stable/_api/airflow/providers/google/cloud/transfers/gcs_to_bigquery/index.html" rel="noopener ugc nofollow" target="_blank"> gcs_to_bigquery操作符</a>，可以用来将文件直接从gcs加载到bigquery。如果我们需要编写任何自定义逻辑或转换，可以用python编写脚本，并使用<a class="ae lc" href="https://airflow.apache.org/docs/apache-airflow/stable/howto/operator/python.html" rel="noopener ugc nofollow" target="_blank"> Python操作符</a>运行。Composer提供了一个非常好的UI，可以用来查看不同日期的负载和日志。它提供了从UI为特定负载重新运行作业的能力。但是由于所有这些特性，Composer非常昂贵，这是选择这个工具的主要因素。</li><li id="14fa" class="kn ko hi ih b ii ld im le iq lf iu lg iy lh jc lb kv kw kx bi translated">云工作流:GCP提供的另一个轻量级编排服务是云工作流。与Composer相比，它们相当便宜，但也有一些限制。例如，我们可以在特定日期从UI重新运行Composer中的DAG，但是工作流不提供这种灵活性。它们也没有像Composer中那样的内置操作符。</li></ul></div><div class="ab cl li lj gp lk" role="separator"><span class="ll bw bk lm ln lo"/><span class="ll bw bk lm ln lo"/><span class="ll bw bk lm ln"/></div><div class="hb hc hd he hf"><ul class=""><li id="0d2c" class="kn ko hi ih b ii ij im in iq ky iu kz iy la jc lb kv kw kx bi translated">除此之外，还有Cloud Scheduler，它可以与各种GCS服务结合使用，将文件从GCS加载到BigQuery。</li></ul><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/4896f49c684e210c5f2356dcd461a44c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*TepS6m_Lbt1kFKQD"/></div></div><figcaption class="lp lq et er es lr ls bd b be z dx translated">使用编排工具调度基于负载</figcaption></figure><p id="3a87" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 2。基于事件:</strong>如果文件到达时间不固定，需要在文件到达时加载，可以使用基于事件的方式。云功能是能够在文件到达事件上执行任务的服务。我们可以编写一个定制的包装器来将文件加载到BigQuery。云功能可以调用其他GCP服务来高效地执行文件加载任务。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/d80e77471df211155daabeb44355fdf8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*3WpM78fVVUf4WF08"/></div></div><figcaption class="lp lq et er es lr ls bd b be z dx translated">使用云函数的基于事件的负载</figcaption></figure><h1 id="9601" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">迎合多种文件格式:</h1><p id="d81f" class="pw-post-body-paragraph if ig hi ih b ii kp ik il im kq io ip iq lt is it iu lu iw ix iy lv ja jb jc hb bi translated">其中一个用例可能是为相同的负载使用不同类型的文件格式。假设一个表需要加载一个CSV和一个Avro文件。现在，两种格式是不同的，所以像模式检查和头检查这样的验证也应该是不同的。然后，为了最终在BigQuery中加载文件，加载作业也应该根据具体的文件格式而有所不同。</p><p id="4d1b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了让一个模板能够加载各种文件格式，我们可以编写一个定制的包装器(比如用Python)。它可以检查文件扩展名，并执行与扩展名对应的验证和加载。因此，可以增强相同的代码，为各种文件格式添加逻辑。入口点可以是相同的，然后基于格式，它可以执行特定于格式的加载。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/abd56cfc50577973d9c0046775bb0dc8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*SQjtMYeZqu4lTzJV"/></div></div><figcaption class="lp lq et er es lr ls bd b be z dx translated">用单个模板加载多种文件格式</figcaption></figure><h1 id="b5bf" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">使用转换加载:</h1><p id="220c" class="pw-post-body-paragraph if ig hi ih b ii kp ik il im kq io ip iq lt is it iu lu iw ix iy lv ja jb jc hb bi translated">在某些情况下，数据需要在加载到BigQuery之前从文件中转换出来。转换可能需要来自处理工具/服务的一定量的计算和内存。</p><p id="af8a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">GCP提供的一个这样的工具是数据流。数据流是一个统一的流和批量数据处理，无服务器，快速，经济高效。它可以用于使用beam transformations和load in BigQuery来转换数据。它可以根据文件大小和处理要求自动缩放。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="ab fe cl lw"><img src="../Images/fc1dad48ac1495cff39ba6e90fc930b8.png" data-original-src="https://miro.medium.com/v2/0*eKmcIu5bPXgwkfCA"/></div><figcaption class="lp lq et er es lr ls bd b be z dx translated">通过转换加载文件的云数据流</figcaption></figure><h1 id="5f1c" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">总结:</h1><p id="68ba" class="pw-post-body-paragraph if ig hi ih b ii kp ik il im kq io ip iq lt is it iu lu iw ix iy lv ja jb jc hb bi translated">在本系列的前一部分<a class="ae lc" rel="noopener" href="/google-cloud/mesh-self-service-data-ingestion-template-for-moving-data-from-spanner-to-bigquery-data-store-94186c0f13e5"> Data Mesh Self Service —从Spanner到BigQuery(Mesh的数据存储)的摄取模式</a>中，我们讨论了Spanner到BigQuery的模式，以及如何针对Spanner中的任何模式更改处理big query中的<a class="ae lc" rel="noopener" href="/google-cloud/automatic-schema-evolution-in-bigquery-for-any-change-in-spanner-using-spanner-change-stream-d44710880855">自动模式演变</a>。</p><p id="b750" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这一部分中，我们讨论了将文件从GCS加载到BigQuery的各种方法(基于时间表的和基于事件的)。我们还看到了加载文件的各种GCP服务。除此之外，我们还讨论了如何通过创建自定义包装器在一个模板中满足各种文件格式的需求。然后我们讨论了使用数据流加载文件，这需要一些数据转换。</p><p id="18cc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在本系列的下一部分中，我们将介绍如何在BigQuery中处理自动模式进化，以防文件中出现额外的列，而无需任何手动干预。</p></div></div>    
</body>
</html>