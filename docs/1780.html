<html>
<head>
<title>Data operation with Cloud Spanner using Mercari Dataflow Template</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Mercari数据流模板使用云扳手进行数据操作</h1>
<blockquote>原文：<a href="https://medium.com/google-cloud/data-operation-with-cloud-spanner-using-mercari-dataflow-template-dcc095e9a8f3?source=collection_archive---------0-----------------------#2021-01-29">https://medium.com/google-cloud/data-operation-with-cloud-spanner-using-mercari-dataflow-template-dcc095e9a8f3?source=collection_archive---------0-----------------------#2021-01-29</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/></div><div class="ab cl if ig gp ih" role="separator"><span class="ii bw bk ij ik il"/><span class="ii bw bk ij ik il"/><span class="ii bw bk ij ik"/></div><div class="hb hc hd he hf"><p id="b0bb" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><a class="ae jk" href="https://github.com/mercari/DataflowTemplate" rel="noopener ugc nofollow" target="_blank">Mercari data flow Template</a>(MDT)是一款OSS工具，使用GCP的分布式数据处理服务<a class="ae jk" href="https://cloud.google.com/dataflow" rel="noopener ugc nofollow" target="_blank">云Dataflow </a>轻松处理数据。<br/>它在<a class="ae jk" href="https://www.merpay.com/" rel="noopener ugc nofollow" target="_blank"> Merpay，Inc. </a>中用于组合、处理和存储各种数据源之间的数据。<br/>在本文中，我将介绍使用MDT向/从Cloud Spanner输入/输出和处理数据的例子。</p></div><div class="ab cl if ig gp ih" role="separator"><span class="ii bw bk ij ik il"/><span class="ii bw bk ij ik il"/><span class="ii bw bk ij ik"/></div><div class="hb hc hd he hf"><h1 id="bcff" class="jl jm hi bd jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki bi translated">如何使用Mercari数据流模板？</h1><p id="413a" class="pw-post-body-paragraph im in hi io b ip kj ir is it kk iv iw ix kl iz ja jb km jd je jf kn jh ji jj hb bi translated">首先，您需要部署MDT。之后，描述配置文件(称为管道文件)，该文件以JSON格式定义了您想要执行的流程。将该文件上传到GCS，并使用<a class="ae jk" href="https://cloud.google.com/sdk/gcloud/reference/dataflow/flex-template/run" rel="noopener ugc nofollow" target="_blank"> gcloud命令</a>或<a class="ae jk" href="https://cloud.google.com/dataflow/docs/reference/rest/v1b3/projects.locations.templates/launch" rel="noopener ugc nofollow" target="_blank"> Dataflow的REST API </a>启动它。<br/>在本节中，我们将向您展示如何使用MDT部署、定义和执行数据处理。(有关如何使用MDT的更多信息，请参考<a class="ae jk" href="https://github.com/mercari/DataflowTemplate/tree/master/docs" rel="noopener ugc nofollow" target="_blank">文档</a>)</p><h2 id="b6d7" class="ko jm hi bd jn kp kq kr jr ks kt ku jv ix kv kw jz jb kx ky kd jf kz la kh lb bi translated">部署管道</h2><p id="087e" class="pw-post-body-paragraph im in hi io b ip kj ir is it kk iv iw ix kl iz ja jb km jd je jf kn jh ji jj hb bi translated">首先，您需要从<a class="ae jk" href="https://github.com/mercari/DataflowTemplate" rel="noopener ugc nofollow" target="_blank"> GitHub </a>存储库中克隆MDT代码，并使用以下命令部署它。(你需要安装Java 11和maven 3)</p><pre class="lc ld le lf fd lg lh li lj aw lk bi"><span id="9f7a" class="ko jm hi lh b fi ll lm l ln lo">mvn clean package -DskipTests -Dimage=gcr.io/{deploy_project}/{template_repo_name}</span></pre><p id="129a" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">MDT在云数据流中使用了一个名为<a class="ae jk" href="https://cloud.google.com/dataflow/docs/guides/templates/using-flex-templates" rel="noopener ugc nofollow" target="_blank"> FlexTemplate </a>的特性，允许用户在不编写程序的情况下定义和执行数据处理。<br/>使用上面的命令，MDT管道代码将作为Docker映像打包并部署到您指定的云容器注册中心(GCR)。<br/>此外，通过执行以下命令，用于从在GCR中注册的映像启动云数据流作业的模板文件将在GCS中注册。</p><pre class="lc ld le lf fd lg lh li lj aw lk bi"><span id="e83e" class="ko jm hi lh b fi ll lm l ln lo">gcloud dataflow flex-template build gs://{path/to/template_file} \<br/>  --image "gcr.io/{deploy_project}/{template_repo_name}" \<br/>  --sdk-language "JAVA"</span></pre><p id="a285" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">这就完成了MDT的部署。接下来，我们将看到如何定义我们想要在MDT中执行的数据处理。</p><h2 id="eac6" class="ko jm hi bd jn kp kq kr jr ks kt ku jv ix kv kw jz jb kx ky kd jf kz la kh lb bi translated">定义管道</h2><p id="61a2" class="pw-post-body-paragraph im in hi io b ip kj ir is it kk iv iw ix kl iz ja jb km jd je jf kn jh ji jj hb bi translated">如前所述，数据处理在JSON格式中被定义为管道文件。管道文件主要由源、转换和接收器组成。这些字段描述了定义数据读取源的源模块、定义如何处理输入的转换模块以及定义数据写入目的地的接收模块。</p><pre class="lc ld le lf fd lg lh li lj aw lk bi"><span id="71cd" class="ko jm hi lh b fi ll lm l ln lo">{<br/>  "<strong class="lh hj">sources</strong>": [<br/>    { <br/>      "name": "input1",<br/>      "module": "bigquery",<br/>      "parameters":    {...}<br/>    },<br/>    ...<br/>  ],<br/>  "<strong class="lh hj">transforms</strong>": [<br/>    {<br/>      "name": "trans1",<br/>      "module": "beamsql",<br/>      "inputs": ["input1"],<br/>      "parameters": {...}<br/>    },<br/>    ...<br/>  ],<br/>  "<strong class="lh hj">sinks</strong>": [<br/>    {<br/>      "name": "output1",<br/>      "module": "spanner",<br/>      "input": "trans1",<br/>      "parameters": {...}<br/>    },<br/>    ...<br/>  ]<br/>}</span></pre><p id="d125" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">在源、转换和接收模块中，<strong class="io hj"> <em class="lp">名称</em> </strong>和<strong class="io hj"> <em class="lp">模块</em> </strong>字段是必需的。<strong class="io hj"> <em class="lp">模块</em> </strong>字段指定流程的适当模块名称(可用模块列表见<a class="ae jk" href="https://github.com/mercari/DataflowTemplate/blob/master/docs/config/module/README.md" rel="noopener ugc nofollow" target="_blank"> GitHub </a>)。<strong class="io hj"> <em class="lp">名称</em> </strong>字段指定管道中步骤的名称，在管道文件中应该是唯一的。<br/>每个转换步骤可以有几个<strong class="io hj"><em class="lp"/></strong>，从一个源或其他转换步骤获取数据，而接收器只接受一个<strong class="io hj"> <em class="lp">输入</em> </strong>。通过在输入或输入字段中指定要用作每个步骤的输入的步骤名称，可以将步骤链接在一起以创建管道。<br/>在<strong class="io hj"> <em class="lp">参数</em> </strong>字段中，您可以指定针对每个模块的配置项。</p><figure class="lc ld le lf fd lr er es paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="er es lq"><img src="../Images/2be0eecdd4d5490d05d84e3fada14a69.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FCqFyXkxCfsZ05CLWwbOhw.png"/></div></div></figure><h2 id="408e" class="ko jm hi bd jn kp kq kr jr ks kt ku jv ix kv kw jz jb kx ky kd jf kz la kh lb bi translated">执行管道</h2><p id="39cd" class="pw-post-body-paragraph im in hi io b ip kj ir is it kk iv iw ix kl iz ja jb km jd je jf kn jh ji jj hb bi translated">使用以下gcloud命令，您可以从部署为FlexTemplate的MDT和您定义的管道文件启动云数据流作业。</p><pre class="lc ld le lf fd lg lh li lj aw lk bi"><span id="9b3a" class="ko jm hi lh b fi ll lm l ln lo">gcloud dataflow flex-template run bigquery-to-spanner \<br/>   --project=myproject \<br/>   --region=us-central1 \<br/>   --template-file-gcs-location=gs://example/template \<br/>   --parameters=config=gs://example/pipeline.json</span></pre><p id="832b" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">另一种启动作业的方法是直接调用<a class="ae jk" href="https://cloud.google.com/dataflow/docs/reference/rest/v1b3/projects.locations.templates/launch" rel="noopener ugc nofollow" target="_blank"> REST API </a>。(gcloud命令也使用REST API)<br/>如果要从云调度程序或程序中执行作业，可以使用REST API。<br/>以下是使用curl命令从REST API执行作业的示例。</p><pre class="lc ld le lf fd lg lh li lj aw lk bi"><span id="c342" class="ko jm hi lh b fi ll lm l ln lo">PROJECT_ID=[PROJECT_ID]<br/>REGION=us-central1</span><span id="9713" class="ko jm hi lh b fi ly lm l ln lo">curl -X POST -H "Content-Type: application/json"  -H "Authorization: Bearer $(gcloud auth print-access-token)" "https://dataflow.googleapis.com/v1b3/projects/${PROJECT_ID}/locations/${REGION}/templates:launch"`<br/>   `"?dynamicTemplate.gcsPath=gs://example/template" -d "{<br/>     'parameters': {<br/>       'config': 'gs://example/pipeline.json'<br/>     }<br/>     'jobName':'myJobName',<br/>   }"</span></pre><p id="2bc8" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">#注意gcloud和REST API的<a class="ae jk" href="https://github.com/mercari/DataflowTemplate/blob/master/docs/deploy/README.md" rel="noopener ugc nofollow" target="_blank">部署方法</a>略有不同。</p></div><div class="ab cl if ig gp ih" role="separator"><span class="ii bw bk ij ik il"/><span class="ii bw bk ij ik il"/><span class="ii bw bk ij ik"/></div><div class="hb hc hd he hf"><h1 id="dff3" class="jl jm hi bd jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki bi translated">基于MDT的云扳手数据操作</h1><p id="06c9" class="pw-post-body-paragraph im in hi io b ip kj ir is it kk iv iw ix kl iz ja jb km jd je jf kn jh ji jj hb bi translated">在本节中，我将介绍使用MDT向Cloud Spanner实际输入/输出数据并对其进行处理的示例。</p><h2 id="dc37" class="ko jm hi bd jn kp kq kr jr ks kt ku jv ix kv kw jz jb kx ky kd jf kz la kh lb bi translated">1.将BigQuery查询结果插入云扳手</h2><p id="bde2" class="pw-post-body-paragraph im in hi io b ip kj ir is it kk iv iw ix kl iz ja jb km jd je jf kn jh ji jj hb bi translated">让我们从一个将BigQuery的查询结果插入Spanner的简单例子开始。<br/>首先如下图定义管道文件，上传到GCS(谷歌云存储)。<br/>在管道文件中，<strong class="io hj"> <em class="lp"> bigquery </em> </strong>被指定为数据源，<strong class="io hj"> <em class="lp">扳手</em> </strong>被指定为目的地。</p><pre class="lc ld le lf fd lg lh li lj aw lk bi"><span id="6c13" class="ko jm hi lh b fi ll lm l ln lo">{<br/>  "sources": [<br/>     {<br/>       "name": "bigqueryInput",<br/>       "module": "<strong class="lh hj">bigquery</strong>",<br/>       "parameters": {<br/>         "query": "SELECT * FROM `myproject.mydataset.mytable`"<br/>       }<br/>     }<br/>   ],<br/>   "sinks": [<br/>     {<br/>       "name": "spannerOutput",<br/>       "module": "<strong class="lh hj">spanner</strong>",<br/>       "input": "bigqueryInput",<br/>       "parameters": {<br/>         "projectId": "myproject",<br/>         "instanceId": "myinstance",<br/>         "databaseId": "mydatabase",<br/>         "table": "mytable"<br/>       }<br/>     }<br/>   ]<br/> }</span></pre><p id="db26" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">接下来，执行以下命令。<br/>(假设您已经将MDT部署到<strong class="io hj"><em class="lp">GS://example/template</em></strong>，并将管道文件保存到<strong class="io hj"><em class="lp">GS://example/pipeline . JSON</em></strong>)</p><pre class="lc ld le lf fd lg lh li lj aw lk bi"><span id="cc8f" class="ko jm hi lh b fi ll lm l ln lo">gcloud dataflow flex-template run bigquery-to-spanner \<br/>   --project=myproject \<br/>   --template-file-gcs-location=gs://example/template \<br/>   --parameters=config=gs://example/pipeline.json</span></pre><p id="0ecb" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">过了一会儿，数据流作业应该启动，流程按照管道文件中的定义执行。</p><figure class="lc ld le lf fd lr er es paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="er es lz"><img src="../Images/025ae7312b01b8116a71abea7f50ec12.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ute_h71g9ONUoXPFiRdvEQ.png"/></div></div></figure><h2 id="e37c" class="ko jm hi bd jn kp kq kr jr ks kt ku jv ix kv kw jz jb kx ky kd jf kz la kh lb bi translated">2.将云扳手查询结果插入BigQuery</h2><p id="ce5c" class="pw-post-body-paragraph im in hi io b ip kj ir is it kk iv iw ix kl iz ja jb km jd je jf kn jh ji jj hb bi translated">与前一个例子相反，这里有一个将Spanner的查询结果插入BigQuery的例子。<br/>可以看到，<strong class="io hj"> <em class="lp"> bigquery </em> </strong>被交换为汇，<strong class="io hj"> <em class="lp">扳手</em> </strong>为源。</p><pre class="lc ld le lf fd lg lh li lj aw lk bi"><span id="733b" class="ko jm hi lh b fi ll lm l ln lo">{<br/>  "sources": [<br/>    {<br/>      "name": "spanner",<br/>      "module": "spanner",<br/>      "parameters": {<br/>        "projectId": "myproject",<br/>        "instanceId": "myinstance",<br/>        "databaseId": "mydatabase",<br/>        "query": "SELECT * FROM mytable"<br/>      }<br/>    }<br/>  ],<br/>  "sinks": [<br/>    {<br/>      "name": "bigquery",<br/>      "module": "bigquery",<br/>      "input": "spanner",<br/>      "parameters": {<br/>        "table": "myproject.mydataset.mytable",<br/>        "createDisposition": "CREATE_IF_NEEDED",<br/>        "writeDisposition": "WRITE_TRUNCATE"<br/>      }<br/>    }<br/>  ]<br/>}</span></pre><p id="9eb5" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">作业执行方法与前面的示例相同。</p><h2 id="997a" class="ko jm hi bd jn kp kq kr jr ks kt ku jv ix kv kw jz jb kx ky kd jf kz la kh lb bi translated">3.用SQL结合不同资源的数据</h2><p id="c39f" class="pw-post-body-paragraph im in hi io b ip kj ir is it kk iv iw ix kl iz ja jb km jd je jf kn jh ji jj hb bi translated">在前面的例子中，我们只是简单地移动了数据，但是您也可以使用<a class="ae jk" href="https://beam.apache.org/documentation/dsls/sql/overview/" rel="noopener ugc nofollow" target="_blank"> Beam SQL </a>来执行SQL连接和处理数据。<br/>以下管道文件示例使用SQL将扳手表与BigQuery的查询结果连接起来，并将结果存储在另一个扳手表中。<br/>在这个例子中，除了源模块和接收模块之外，<strong class="io hj"> <em class="lp"> beamsql </em> </strong>被指定为转换模块来处理sql中的数据。<br/>在转换模块中，在<strong class="io hj"> <em class="lp">输入</em> </strong>中指定你想要处理的数据的名称。用<strong class="io hj"> <em class="lp"> sql </em> </strong>参数指定要处理的SQL。表名可以通过输入中指定的名称来引用。</p><pre class="lc ld le lf fd lg lh li lj aw lk bi"><span id="17e6" class="ko jm hi lh b fi ll lm l ln lo">{<br/>   "sources": [<br/>     {<br/>       "name": "<strong class="lh hj">BigQueryInput</strong>",<br/>       "module": "bigquery",<br/>       "parameters": {<br/>         "query": "SELECT BField1, BField2 FROM `myproject.mydataset.mytable`"<br/>       }<br/>     },<br/>     {<br/>       "name": "<strong class="lh hj">SpannerInput</strong>",<br/>       "module": "spanner",<br/>       "parameters": {<br/>         "projectId": "myproject",<br/>         "instanceId": "myinstance",<br/>         "databaseId": "mydatabase",<br/>         "table": "mytable",<br/>         "fields": ["SField1","SField2"]<br/>       }<br/>     }<br/>   ],<br/>   "<strong class="lh hj">transforms</strong>": [<br/>     {<br/>       "name": "BeamsqlTransform",<br/>       "module": "<strong class="lh hj">beamsql</strong>",<br/>       "<strong class="lh hj">inputs</strong>": [<br/>         "<strong class="lh hj">BigQueryInput</strong>",<br/>         "<strong class="lh hj">SpannerInput</strong>"<br/>       ],<br/>       "parameters": {<br/>         "<strong class="lh hj">sql</strong>": "<strong class="lh hj">SELECT BigQueryInput.BField1 AS Field1, IF(BigQueryInput.BField2 IS NULL, SpannerInput.SField2, BigQueryInput.BField2) AS Field2 FROM BigQueryInput LEFT JOIN SpannerInput ON BigQueryInput.BField1 = SpannerInput.SField1</strong>"<br/>       }<br/>     }<br/>   ],<br/>   "sinks": [<br/>     {<br/>       "name": "SpannerOutput",<br/>       "module": "spanner",<br/>       "input": "BeamsqlTransform",<br/>       "parameters": {<br/>         "projectId": "anotherproject",<br/>         "instanceId": "anotherinstance",<br/>         "databaseId": "anotherdatabase",<br/>         "table": "anothertable"<br/>       }<br/>     }<br/>   ]<br/> }</span></pre><p id="6f12" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">如果您运行与上一个示例相同的命令，将会启动以下数据流作业。</p><figure class="lc ld le lf fd lr er es paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="er es ma"><img src="../Images/f04d73d1ddcf35b195e68282acc141b4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ag5iHEDmcd_Wc_UaskcXqA.png"/></div></div></figure><h2 id="8f4f" class="ko jm hi bd jn kp kq kr jr ks kt ku jv ix kv kw jz jb kx ky kd jf kz la kh lb bi translated">4.从Spanner加载数据，并以微批处理方式保存到BigQuery</h2><p id="82e0" class="pw-post-body-paragraph im in hi io b ip kj ir is it kk iv iw ix kl iz ja jb km jd je jf kn jh ji jj hb bi translated">在某些情况下，您可能想要接近实时地使用来自Spanner的最新数据。MDT支持通过微批处理执行查询从Spanner获取数据。<br/>以下配置是一个微批处理的示例，该微批处理定期执行一个查询，以指定的频率扳手来检索数据并将其插入到BigQuery中。</p><pre class="lc ld le lf fd lg lh li lj aw lk bi"><span id="9aa1" class="ko jm hi lh b fi ll lm l ln lo">{<br/>  "sources": [<br/>    {<br/>      "name": "spanner",<br/>      "module": "spanner",<br/>      "<strong class="lh hj">microbatch</strong>": <strong class="lh hj"><em class="lp">true</em></strong>,<br/>      "parameters": {<br/>        "projectId": "myproject",<br/>        "instanceId": "myinstance",<br/>        "databaseId": "mydatabase",<br/>        "query": "SELECT * FROM MyTable@{FORCE_INDEX=MyTableCreatedAtDesc} WHERE ShardCreatedAt = 1 AND CreatedAt &gt;= TIMESTAMP_SECONDS(<strong class="lh hj">${__EVENT_EPOCH_SECOND_PRE__}</strong>) AND CreatedAt &lt; TIMESTAMP_SECONDS(<strong class="lh hj">${__EVENT_EPOCH_SECOND__}</strong>)",<br/>        "<strong class="lh hj">startDatetime</strong>": "2021-01-01T00:00:00Z",<br/>        "<strong class="lh hj">intervalSecond</strong>": 60,<br/>        "<strong class="lh hj">gapSecond</strong>": 30,<br/>        "<strong class="lh hj">maxDurationMinute</strong>": 60,<br/>        "<strong class="lh hj">catchupIntervalSecond</strong>": 60<br/>      }<br/>    }<br/>  ],<br/>  "sinks": [<br/>    {<br/>      "name": "bigquery",<br/>      "module": "bigquery",<br/>      "input": "spanner",<br/>      "parameters": {<br/>        "table": "myproject:mydataset.mytable",<br/>        "createDisposition": "CREATE_IF_NEEDED",<br/>        "writeDisposition": "WRITE_APPEND"<br/>      }<br/>    }<br/>  ]<br/>}</span></pre><p id="e7f3" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">为了在微批次中运行扳手查询，在扳手源模块中将<strong class="io hj"> <em class="lp">微批次</em> </strong>参数设置为真。<br/>在上面的例子中，对Spanner的查询是为微批处理执行准备的。<br/>在微批处理执行的查询中，使用名为<strong class="io hj">_ _ EVENT _ EPOCH _ SECOND _ PRE _ _</strong>和<strong class="io hj"> __EVENT_EPOCH_SECOND__ </strong>的变量指定过滤条件。这些变量将根据配置中指定的频率和间隔在查询执行时嵌入。<br/>查询执行的频率和间隔由<strong class="io hj"> <em class="lp"> startDatetime、</em></strong><strong class="io hj"><em class="lp">intervalSecond</em></strong>、<strong class="io hj"> <em class="lp"> gapSecond </em> </strong>、<strong class="io hj"><em class="lp">maxDurationMinute</em></strong>、<strong class="io hj"><em class="lp">catchupIntervalSecond</em></strong>等参数指定。这些参数与查询执行时间和过滤条件的关系如下图所示。<br/>(关于微批处理执行的详细说明，参见<a class="ae jk" href="https://github.com/mercari/DataflowTemplate/blob/master/docs/config/module/source/microbatch.md" rel="noopener ugc nofollow" target="_blank"> GitHub </a>。)</p><figure class="lc ld le lf fd lr er es paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="er es mb"><img src="../Images/21117bb78a936cee7575f9c9dd2cffdf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kWdR367-k4Oob_rU48vy2Q.png"/></div></div></figure><p id="8927" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">要在微批处理中运行管道，请在流模式下使用如下所示的流参数运行数据流。</p><pre class="lc ld le lf fd lg lh li lj aw lk bi"><span id="821d" class="ko jm hi lh b fi ll lm l ln lo">gcloud dataflow flex-template run spanner-microbatch-to-bigquery \<br/>   --project=myproject \<br/>   --region=us-central1 \<br/>   --template-file-gcs-location=gs://example/template \<br/>   --parameters=config=gs://example/pipeline.json \<br/>   <strong class="lh hj">--</strong><strong class="lh hj">parameters=streaming=true</strong></span></pre><figure class="lc ld le lf fd lr er es paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="er es mc"><img src="../Images/83d47e4010b70f116572c787f746d613.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xxmtoqMMScbQEvBX2Wd5lw.png"/></div></div></figure><p id="0d07" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj"/></p></div><div class="ab cl if ig gp ih" role="separator"><span class="ii bw bk ij ik il"/><span class="ii bw bk ij ik il"/><span class="ii bw bk ij ik"/></div><div class="hb hc hd he hf"><p id="d823" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">正如本文所介绍的，使用MDT，您可以将想要执行的数据处理定义为管道文件，并在云数据流中执行。<br/>其他管道文件的例子可以在<a class="ae jk" href="https://github.com/mercari/DataflowTemplate/tree/master/examples" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上找到，所以如果你有兴趣，请找一个和你想做的数据处理类似的文件。<br/> MDT还是一个刚刚发布的开发中的OSS。如果您发现任何错误、功能请求或问题，请随时在<a class="ae jk" href="https://github.com/mercari/DataflowTemplate" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上告诉我们。</p></div></div>    
</body>
</html>