<html>
<head>
<title>Migrate Oracle to Big Query using Dataproc and Sqoop</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Dataproc和Sqoop将Oracle迁移到大查询</h1>
<blockquote>原文：<a href="https://medium.com/google-cloud/migrate-oracle-data-to-bigquery-using-dataproc-and-sqoop-cd3863adde7b?source=collection_archive---------0-----------------------#2020-08-26">https://medium.com/google-cloud/migrate-oracle-data-to-bigquery-using-dataproc-and-sqoop-cd3863adde7b?source=collection_archive---------0-----------------------#2020-08-26</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/813ff0689cb0e1abb5dd3ebda221fb23.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*j4blirD8wkgvhw2n"/></div></div></figure><blockquote class="iq"><p id="c549" class="ir is hi bd it iu iv iw ix iy iz ja dx translated">想把Oracle数据库迁移到大查询？不知道如何将数据从Oracle迁移到Big Query？想用GCP本地工具做这件事吗？</p><p id="96ff" class="ir is hi bd it iu jb jc jd je jf ja dx translated">继续读，你在正确的岗位上！</p></blockquote><p id="3195" class="pw-post-body-paragraph jg jh hi ji b jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc ja hb bi translated">下面是使用Dataproc和Sqoop进行Oracle迁移的一些优势；</p><ol class=""><li id="6ebd" class="kd ke hi ji b jj kf jn kg jr kh jv ki jz kj ja kk kl km kn bi translated">几分钟后Dataproc就可以使用了</li><li id="f814" class="kd ke hi ji b jj ko jn kp jr kq jv kr jz ks ja kk kl km kn bi translated">有内置的GCS连接器，所以数据将保存在GCS中，以备大查询使用。只需使用“gs://”，而不是“hdfs://”</li><li id="3d98" class="kd ke hi ji b jj ko jn kp jr kq jv kr jz ks ja kk kl km kn bi translated">Sqoop支持许多关系数据库和大型机</li><li id="802e" class="kd ke hi ji b jj ko jn kp jr kq jv kr jz ks ja kk kl km kn bi translated">Sqoop具有强大的可扩展性，例如配置分割和并行性。</li></ol><p id="d264" class="pw-post-body-paragraph jg jh hi ji b jj kf jl jm jn kg jp jq jr kt jt ju jv ku jx jy jz kv kb kc ja hb bi translated">Cloud Composer或云数据融合也可用于Oracle到大型查询的迁移。我将在下一篇博文中讨论这些内容。</p><h1 id="6131" class="kw kx hi bd ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">1.创建Dataproc集群</h1><p id="ab69" class="pw-post-body-paragraph jg jh hi ji b jj lu jl jm jn lv jp jq jr lw jt ju jv lx jx jy jz ly kb kc ja hb bi translated">首先创建一个dataproc集群。您可以使用单节点dataproc集群。我们不需要很多节点，因为我们在这里不做大数据分析。</p><p id="91da" class="pw-post-body-paragraph jg jh hi ji b jj kf jl jm jn kg jp jq jr kt jt ju jv ku jx jy jz kv kb kc ja hb bi translated"><strong class="ji hj">性能提示；</strong>大概网络带宽或者Oracle服务器(CPU/IO)会是瓶颈。dataproc集群的CPU数量可能无关紧要，但是应该与期望的并行性成比例。为dataproc、GCS存储桶和BQ数据集仔细选择区域，它应该靠近您的Oracle数据库位置，以提供更好的网络延迟。</p><p id="eb08" class="pw-post-body-paragraph jg jh hi ji b jj kf jl jm jn kg jp jq jr kt jt ju jv ku jx jy jz kv kb kc ja hb bi translated"><strong class="ji hj">哈提示；</strong>如果这不是生产关键(即停机时间不是那么关键)，您就不需要HA (3个主节点)</p><p id="b419" class="pw-post-body-paragraph jg jh hi ji b jj kf jl jm jn kg jp jq jr kt jt ju jv ku jx jy jz kv kb kc ja hb bi translated"><strong class="ji hj">账单提示；</strong> E2实例比N2实例便宜。我们不需要附加GPU或其他N2功能，所以您可以使用E2。</p><p id="ce2a" class="pw-post-body-paragraph jg jh hi ji b jj kf jl jm jn kg jp jq jr kt jt ju jv ku jx jy jz kv kb kc ja hb bi translated"><strong class="ji hj">上浆提示；</strong>数据将被写入GCS，HDFS大小无关紧要。</p><figure class="ma mb mc md fd ij er es paragraph-image"><div class="er es lz"><img src="../Images/cc60e49e8e3c4344254b8d664ea36b47.png" data-original-src="https://miro.medium.com/v2/resize:fit:932/0*IzStuYX74x1EqmoX"/></div></figure><pre class="ma mb mc md fd me mf mg mh aw mi bi"><span id="a9f3" class="mj kx hi mf b fi mk ml l mm mn">gcloud dataproc clusters create sqoop-cluster — enable-component-gateway — region europe-west4 — subnet default — zone europe-west4-b — single-node — master-machine-type e2-standard-8 — master-boot-disk-size 500 — image-version 1.3-debian10 — project &lt;project-id&gt;</span></pre><h1 id="df5d" class="kw kx hi bd ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">2.获取Oracle JDBC驱动程序</h1><p id="f637" class="pw-post-body-paragraph jg jh hi ji b jj lu jl jm jn lv jp jq jr lw jt ju jv lx jx jy jz ly kb kc ja hb bi translated">下载<a class="ae mo" href="https://www.oracle.com/database/technologies/appdev/jdbc-downloads.html" rel="noopener ugc nofollow" target="_blank">甲骨文JDBC驱动</a>。</p><p id="ea6c" class="pw-post-body-paragraph jg jh hi ji b jj kf jl jm jn kg jp jq jr kt jt ju jv ku jx jy jz kv kb kc ja hb bi translated">出于本教程的目的，下载<a class="ae mo" href="https://download.oracle.com/otn-pub/otn_software/jdbc/ojdbc8.jar" rel="noopener ugc nofollow" target="_blank"> ojdbc8.jar </a>或ojdbc7.jar版本</p><h1 id="9afc" class="kw kx hi bd ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">3.将Oracle JDBC驱动程序上传到GCS</h1><p id="3e77" class="pw-post-body-paragraph jg jh hi ji b jj lu jl jm jn lv jp jq jr lw jt ju jv lx jx jy jz ly kb kc ja hb bi translated">在GCS中创建一个存储桶，并将文件上传到GCS；</p><p id="98b8" class="pw-post-body-paragraph jg jh hi ji b jj kf jl jm jn kg jp jq jr kt jt ju jv ku jx jy jz kv kb kc ja hb bi translated">从cloudshell(或者您的终端，如果您在中安装了gsutil</p><pre class="ma mb mc md fd me mf mg mh aw mi bi"><span id="b94f" class="mj kx hi mf b fi mk ml l mm mn">gsutil mb -l europe-west4 gs://my-sqoop-jar-bucket<br/>wget <a class="ae mo" href="https://download.oracle.com/otn-pub/otn_software/jdbc/ojdbc8.jar" rel="noopener ugc nofollow" target="_blank">https://download.oracle.com/otn-pub/otn_software/jdbc/ojdbc8.jar</a><br/>gsutil cp ojdbc8.jar gs://my-sqoop-jar-bucket/</span></pre><h1 id="a3d2" class="kw kx hi bd ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">4.下载和上传sqoop jars</h1><p id="32fb" class="pw-post-body-paragraph jg jh hi ji b jj lu jl jm jn lv jp jq jr lw jt ju jv lx jx jy jz ly kb kc ja hb bi translated">在供应期间，可以使用<a class="ae mo" href="https://github.com/GoogleCloudDataproc/initialization-actions/tree/master/sqoop" rel="noopener ugc nofollow" target="_blank">这个初始化操作</a>安装Sqoop。但是出于本教程的目的，我们将手动下载sqoop jars并上传到GCS。</p><p id="b426" class="pw-post-body-paragraph jg jh hi ji b jj kf jl jm jn kg jp jq jr kt jt ju jv ku jx jy jz kv kb kc ja hb bi translated">从<a class="ae mo" href="http://www.apache.org/dyn/closer.lua/sqoop/" rel="noopener ugc nofollow" target="_blank">这里</a>下载sqoop jars。从任意镜像中选择sqoop-1 . 4 . 7 . bin _ _ Hadoop-2 . 6 . 0 . tar . gz。例如；<a class="ae mo" href="http://apache.cs.uu.nl/sqoop/1.4.7/sqoop-1.4.7.bin__hadoop-2.6.0.tar.gz" rel="noopener ugc nofollow" target="_blank">http://Apache . cs . uu . nl/sqoop/1 . 4 . 7/sqoop-1 . 4 . 7 . bin _ _ Hadoop-2 . 6 . 0 . tar . gz</a></p><pre class="ma mb mc md fd me mf mg mh aw mi bi"><span id="1f00" class="mj kx hi mf b fi mk ml l mm mn">BUCKET=gs://my-sqoop-jar-bucket<br/>wget <a class="ae mo" href="https://apache.belnet.be/sqoop/1.4.7/sqoop-1.4.7.bin__hadoop-2.6.0.tar.gz" rel="noopener ugc nofollow" target="_blank">https://apache.belnet.be/sqoop/1.4.7/sqoop-1.4.7.bin__hadoop-2.6.0.tar.gz</a><br/>tar xvfz sqoop*<br/>gsutil cp sqoop-1.4.7.bin__hadoop-2.6.0/sqoop-1.4.7.jar $BUCKET/<br/>gsutil cp sqoop-1.4.7.bin__hadoop-2.6.0/lib/* $BUCKET/</span></pre><h1 id="f12f" class="kw kx hi bd ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">5.从Oracle数据库中提取一个表并加载到GCS中</h1><p id="e186" class="pw-post-body-paragraph jg jh hi ji b jj lu jl jm jn lv jp jq jr lw jt ju jv lx jx jy jz ly kb kc ja hb bi translated">我们将使用带分隔符的文件类型(文本文件),因为在加载到大查询时，AVRO格式的日期和数字列可能会有问题。</p><p id="5b53" class="pw-post-body-paragraph jg jh hi ji b jj kf jl jm jn kg jp jq jr kt jt ju jv ku jx jy jz kv kb kc ja hb bi translated">创建一个GCS bucket来存储提取文件，并提交您的Sqoop作业；</p><pre class="ma mb mc md fd me mf mg mh aw mi bi"><span id="d3e4" class="mj kx hi mf b fi mk ml l mm mn">gsutil mb -l europe-west4 gs://my-oracle-extract</span><span id="23c6" class="mj kx hi mf b fi mp ml l mm mn">JAR_BUCKET=gs://my-sqoop-jar-bucket<br/>STAGING_BUCKET=gs://my-oracle-extract<br/>libs=`gsutil ls $JAR_BUCKET | paste -sd, — `<br/>JDBC_STR=jdbc:oracle:thin:&lt;username&gt;/&lt;password&gt;@&lt;IP&gt;:1521/&lt;SERVICE&gt;<br/>TABLE=EMPLOYEES<br/>SCHEMA=HR</span><span id="ee90" class="mj kx hi mf b fi mp ml l mm mn">gcloud dataproc jobs submit hadoop — cluster=sqoop-cluster — region=europe-west4 — class=org.apache.sqoop.Sqoop — jars=$libs — import -Dmapreduce.job.user.classpath.first=true -Dorg.apache.sqoop.splitter.allow_text_splitter=true — connect=$JDBC_STR — target-dir=$STAGING_BUCKET/$TABLE — table=$SCHEMA.$TABLE — enclosed-by ‘\”’ — escaped-by \” — fields-terminated-by ‘|’ — null-string ‘’ — null-non-string ‘’ — as-textfile</span></pre><p id="0a92" class="pw-post-body-paragraph jg jh hi ji b jj kf jl jm jn kg jp jq jr kt jt ju jv ku jx jy jz kv kb kc ja hb bi translated">Sqoop有一个<a class="ae mo" href="https://issues.apache.org/jira/browse/SQOOP-3480" rel="noopener ugc nofollow" target="_blank">错误</a>，当“字符既用作封闭字符又用作转义字符”时会导致重复的双引号在大查询中，需要作为引号终止字段的转义字符。一种解决方法是在加载后更新BQ，用单双引号替换双双引号。Sqoop获取Oracle的“日期”类型作为“时间戳”类型。所以目标大查询表应该有“时间戳”列而不是“日期”列。初始加载后，可以很容易地转换到使用CTAS日期。</p><h1 id="349d" class="kw kx hi bd ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">6.在大查询中创建数据集和表</h1><p id="4fad" class="pw-post-body-paragraph jg jh hi ji b jj lu jl jm jn lv jp jq jr lw jt ju jv lx jx jy jz ly kb kc ja hb bi translated">如果您还没有创建数据集，请创建一个。</p><p id="c434" class="pw-post-body-paragraph jg jh hi ji b jj kf jl jm jn kg jp jq jr kt jt ju jv ku jx jy jz kv kb kc ja hb bi translated">在大查询中创建表。您需要将数字类型转换为数值，并将其他Oracle类型转换为相应的BQ类型。</p><blockquote class="mq mr ms"><p id="984f" class="jg jh mt ji b jj kf jl jm jn kg jp jq mu kt jt ju mv ku jx jy mw kv kb kc ja hb bi translated">好消息；自动Oracle到BQ模式转换器将在下一篇博文中发布，敬请关注。</p></blockquote><h1 id="51f9" class="kw kx hi bd ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">7.将数据从GCS加载到大查询</h1><p id="145e" class="pw-post-body-paragraph jg jh hi ji b jj lu jl jm jn lv jp jq jr lw jt ju jv lx jx jy jz ly kb kc ja hb bi translated">从GCS加载大查询表；</p><pre class="ma mb mc md fd me mf mg mh aw mi bi"><span id="2442" class="mj kx hi mf b fi mk ml l mm mn">bq load -source_format=CSV — allow_quoted_newlines — field_delimiter=’|’ BQ_DATASET.$TABLE “$STAGING_BUCKET/$TABLE/part-*”</span></pre><h1 id="6a75" class="kw kx hi bd ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">8.导出模式中的所有表</h1><pre class="ma mb mc md fd me mf mg mh aw mi bi"><span id="edc2" class="mj kx hi mf b fi mk ml l mm mn">gcloud dataproc jobs submit hadoop — cluster=sqoop — region=europe-west4 — class=org.apache.sqoop.Sqoop — jars=$libs — import-all-tables -Dmapreduce.job.user.classpath.first=true -Dorg.apache.sqoop.splitter.allow_text_splitter=true — connect=$JDBC_STR — warehouse-dir=$STAGING_BUCKET/$SCHEMA — enclosed-by ‘\”’ — escaped-by \” — fields-terminated-by ‘|’ — null-string ‘’ — null-non-string ‘’ — as-textfile</span></pre><h1 id="f07c" class="kw kx hi bd ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">9.将所有表格导入BQ</h1><p id="4c6a" class="pw-post-body-paragraph jg jh hi ji b jj lu jl jm jn lv jp jq jr lw jt ju jv lx jx jy jz ly kb kc ja hb bi translated">首先，你需要在BQ中创建所有的表(好消息；会是下一篇博文)。然后，您可以使用下面的shell脚本来自动加载所有的表。</p><pre class="ma mb mc md fd me mf mg mh aw mi bi"><span id="bd3b" class="mj kx hi mf b fi mk ml l mm mn">FILTER_DS=$1<br/>FILTER_TABLE=$2<br/>mkdir -p .schemas<br/>files=`gsutil ls -r gs://my-oracle-extract/ | grep "\:$"  `</span><span id="17df" class="mj kx hi mf b fi mp ml l mm mn">for f in $files<br/>do<br/>  dataset=`echo $f | cut -d/ -f4`<br/>  dataset="${dataset//c_lew/p_lew}"<br/>  table=`echo $f | cut -d/ -f5`<br/>  colon=`echo $f | cut -d/ -f6`<br/>  if [[ ! -z $FILTER_DS ]] &amp;&amp; [[ $FILTER_DS != $dataset ]] ; then<br/>    echo "skipping " $dataset<br/>    continue<br/>  fi<br/>  <br/>  if [[ ! -z $FILTER_TABLE ]] &amp;&amp; [[ $FILTER_TABLE != $table ]] ; then<br/>    echo "skipping " $table<br/>    continue<br/>  fi<br/>  if [[ ":" == "$colon" ]] ; then<br/>    bq show --format=prettyjson  $dataset.$table | jq '.schema.fields' &gt; .schemas/$dataset.$table.json 2&gt;/dev/null<br/>    OUT=$?<br/>    if [ $OUT -eq 0 ];then<br/>      f_with_wildcard="${f//\/\://*}"<br/>      echo "Loading $dataset.$table"<br/>      bq load  --field_delimiter='|' --source_format=CSV $dataset.$table $f_with_wildcard .schemas/$dataset.$table.json<br/>    else<br/>      echo "No table definition for $dataset.$table"<br/>    fi<br/>  fi</span><span id="9a78" class="mj kx hi mf b fi mp ml l mm mn">done</span></pre><p id="6db3" class="pw-post-body-paragraph jg jh hi ji b jj kf jl jm jn kg jp jq jr kt jt ju jv ku jx jy jz kv kb kc ja hb bi translated">希望这篇文章对你有用，感谢你的评论和反馈！</p></div></div>    
</body>
</html>