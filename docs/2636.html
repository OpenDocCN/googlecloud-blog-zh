<html>
<head>
<title>Connect your Scala Application from HBase to Bigtable</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">将您的Scala应用程序从HBase连接到Bigtable</h1>
<blockquote>原文：<a href="https://medium.com/google-cloud/connect-your-scala-application-from-hbase-to-bigtable-668945511d31?source=collection_archive---------2-----------------------#2022-12-15">https://medium.com/google-cloud/connect-your-scala-application-from-hbase-to-bigtable-668945511d31?source=collection_archive---------2-----------------------#2022-12-15</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="7548" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">将Scala代码和数据一起从HBase迁移到Google Cloud Bigtable</p><p id="657f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在将本地基础设施迁移到Google Cloud之后，通常会迁移连接到该基础设施并从中使用数据的应用程序代码。代码可以是不同的语言，因此涉及基于基础设施和应用程序语言的相应变化。因此，我们将访问一个这样的常见需求，迁移连接到<a class="ae jd" href="https://hbase.apache.org/" rel="noopener ugc nofollow" target="_blank"> Apache Hbase </a>的Scala应用程序，以连接和使用来自<a class="ae jd" href="https://cloud.google.com/bigtable" rel="noopener ugc nofollow" target="_blank"> Google Cloud Bigtable </a>的数据。</p><p id="9e46" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">假设我们有一个HBase集群，其中一个表为“employee ”,还有一个Bigtable集群，其中一个表的名称相同，如下所示。两个表都有2行，行键分别为1和2。</p><blockquote class="je jf jg"><p id="00c7" class="if ig jh ih b ii ij ik il im in io ip ji ir is it jj iv iw ix jk iz ja jb jc hb bi translated">HBase:</p></blockquote><pre class="jl jm jn jo fd jp jq jr bn js jt bi"><span id="85bf" class="ju jv hi jq b be jw jx l jy jz">scan 'employee'</span></pre><figure class="jl jm jn jo fd kb er es paragraph-image"><div role="button" tabindex="0" class="kc kd di ke bf kf"><div class="er es ka"><img src="../Images/1305668c2096b449cd54f40a064d22a0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*IQpKmPISBKvnLlTO"/></div></div></figure><blockquote class="je jf jg"><p id="4895" class="if ig jh ih b ii ij ik il im in io ip ji ir is it jj iv iw ix jk iz ja jb jc hb bi translated">谷歌云Bigtable:</p></blockquote><pre class="jl jm jn jo fd jp jq jr bn js jt bi"><span id="bd33" class="ju jv hi jq b be jw jx l jy jz">cbt read employee</span></pre><figure class="jl jm jn jo fd kb er es paragraph-image"><div role="button" tabindex="0" class="kc kd di ke bf kf"><div class="er es ka"><img src="../Images/6a03d04be1c97c1f613841be78ddb096.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*eSWdm7gx08dfdkkL"/></div></div></figure><h2 id="cff2" class="ki jv hi bd kj kk kl km kn ko kp kq kr iq ks kt ku iu kv kw kx iy ky kz la lb bi translated">连接HBase的Scala应用程序</h2><p id="499a" class="pw-post-body-paragraph if ig hi ih b ii lc ik il im ld io ip iq le is it iu lf iw ix iy lg ja jb jc hb bi translated">我们有一个Scala应用程序，它连接到上面的HBase集群，从行键为1的employee表中读取数据。应用程序中包含的文件有:</p><ul class=""><li id="3427" class="lh li hi ih b ii ij im in iq lj iu lk iy ll jc lm ln lo lp bi translated">App.scala(从HBase集群读取数据的应用程序代码)</li><li id="ed47" class="lh li hi ih b ii lq im lr iq ls iu lt iy lu jc lm ln lo lp bi translated">Connection.scala(建立与HBase集群连接的代码，该集群将由App.scala使用)</li><li id="840a" class="lh li hi ih b ii lq im lr iq ls iu lt iy lu jc lm ln lo lp bi translated">Pom.xml(项目依赖、插件、版本等的配置。包括HBase连接、配置)</li></ul><p id="6bf9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">注意:对应用程序代码进行了简化，以关注从HBase迁移到Bigtable所需的更改。</p><blockquote class="je jf jg"><p id="52bf" class="if ig jh ih b ii ij ik il im in io ip ji ir is it jj iv iw ix jk iz ja jb jc hb bi translated">App.scala</p></blockquote><pre class="jl jm jn jo fd jp jq jr bn js jt bi"><span id="0b2a" class="ju jv hi jq b be jw jx l jy jz">package com.example<br/><br/>import org.apache.hadoop.hbase.client._<br/>import org.apache.hadoop.hbase.util.Bytes<br/>import org.apache.hadoop.hbase.{CellUtil, HBaseConfiguration, TableName}<br/>import org.apache.hadoop.conf.Configuration<br/>import scala.collection.JavaConverters._<br/><br/>/**<br/> * @author anjalichimnani<br/> */<br/>object App {<br/><br/>  /**<br/>   * Read data in the cluster connected to connection object from table name specified and for row key requested<br/>   */<br/>  def readTable(connection: Connection, tableName: String, rowKey: String) {<br/>    println("Within readTable:")<br/>    val table = connection.getTable(TableName.valueOf( Bytes.toBytes(tableName) ) )<br/><br/>    var get = new Get(Bytes.toBytes(rowKey))<br/>    var result = table.get(get)<br/><br/>    println(result)<br/><br/>    table.close()<br/>  }<br/><br/>  /**<br/>   * Main function where the code execution initiates.<br/>   * It sets the variable values for cluster, table name and row key to be read<br/>   * Requests for a connection to cluster<br/>   * Calls readTable method to get data from the cluster.<br/>   *<br/>   * To run the code, specify HBase Cluster host/hosts<br/>   */<br/>  def main(args : Array[String]) {<br/><br/>    println( "Within Main Method:")<br/>    val zookeeper_quorum = "&lt;HBase-cluster&gt;"<br/>    val tableName = "employee"<br/>    val rowKey = "1"<br/><br/>    val connection = Connection.connect(zookeeper_quorum)<br/>    readTable(connection, tableName, rowKey)<br/><br/>    connection.close()<br/><br/>  }<br/><br/>}</span></pre><blockquote class="je jf jg"><p id="aa6a" class="if ig jh ih b ii ij ik il im in io ip ji ir is it jj iv iw ix jk iz ja jb jc hb bi translated">Connection.scala</p></blockquote><pre class="jl jm jn jo fd jp jq jr bn js jt bi"><span id="6930" class="ju jv hi jq b be jw jx l jy jz">package com.example<br/><br/>import org.apache.hadoop.hbase.client._<br/>import org.apache.hadoop.hbase.util.Bytes<br/>import org.apache.hadoop.hbase.{CellUtil, HBaseConfiguration, TableName}<br/>import org.apache.hadoop.conf.Configuration<br/>import scala.collection.JavaConverters._<br/><br/>object Connection {<br/><br/>  /**<br/>   * Connect Method to take the cluster details, create a Hbase configuration and consequently a connection<br/>   * The method returns a Connection object which could be used to read/write/update data from the cluster which it is connected to.<br/>   */<br/>  def connect(zookeeper_quorum: String): Connection = {<br/>    println("Within Connection:")<br/>    val conf : Configuration = HBaseConfiguration.create()<br/>    conf.set("hbase.zookeeper.quorum", zookeeper_quorum)<br/><br/>    val connection = ConnectionFactory.createConnection(conf)<br/><br/>    return connection<br/>  }<br/><br/>}</span></pre><blockquote class="je jf jg"><p id="8977" class="if ig jh ih b ii ij ik il im in io ip ji ir is it jj iv iw ix jk iz ja jb jc hb bi translated">pom.xml</p></blockquote><pre class="jl jm jn jo fd jp jq jr bn js jt bi"><span id="e084" class="ju jv hi jq b be jw jx l jy jz">&lt;project  xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd"&gt;<br/>  &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;<br/>  &lt;groupId&gt;com.example&lt;/groupId&gt;<br/>  &lt;artifactId&gt;employee&lt;/artifactId&gt;<br/>  &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;<br/>  &lt;name&gt;${project.artifactId}&lt;/name&gt;<br/>  &lt;description&gt;My wonderfull scala app&lt;/description&gt;<br/>  &lt;inceptionYear&gt;2018&lt;/inceptionYear&gt;<br/>  &lt;licenses&gt;<br/>    &lt;license&gt;<br/>      &lt;name&gt;My License&lt;/name&gt;<br/>      &lt;url&gt;http://....&lt;/url&gt;<br/>      &lt;distribution&gt;repo&lt;/distribution&gt;<br/>    &lt;/license&gt;<br/>  &lt;/licenses&gt;<br/><br/>  &lt;properties&gt;<br/>    &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt;<br/>    &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt;<br/>    &lt;encoding&gt;UTF-8&lt;/encoding&gt;<br/>    &lt;scala.version&gt;2.12.6&lt;/scala.version&gt;<br/>    &lt;spark.version&gt;2.4.8&lt;/spark.version&gt;<br/>    &lt;hbase.version&gt;2.4.9&lt;/hbase.version&gt;<br/>    &lt;scala.compat.version&gt;2.12&lt;/scala.compat.version&gt;<br/>    &lt;spec2.version&gt;4.2.0&lt;/spec2.version&gt;<br/>  &lt;/properties&gt;<br/><br/>  &lt;dependencies&gt;<br/><br/>    &lt;dependency&gt;<br/>      &lt;groupId&gt;org.scala-lang&lt;/groupId&gt;<br/>      &lt;artifactId&gt;scala-library&lt;/artifactId&gt;<br/>      &lt;version&gt;${scala.version}&lt;/version&gt;<br/>    &lt;/dependency&gt;<br/><br/>    &lt;dependency&gt;<br/>      &lt;groupId&gt;org.apache.hbase&lt;/groupId&gt;<br/>      &lt;artifactId&gt;hbase-server&lt;/artifactId&gt;<br/>      &lt;version&gt;${hbase.version}&lt;/version&gt;<br/>    &lt;/dependency&gt;<br/><br/>    &lt;dependency&gt;<br/>      &lt;groupId&gt;org.apache.spark&lt;/groupId&gt;<br/>      &lt;artifactId&gt;spark-core_2.12&lt;/artifactId&gt;<br/>      &lt;version&gt;${spark.version}&lt;/version&gt;<br/>      &lt;scope&gt;provided&lt;/scope&gt;<br/>    &lt;/dependency&gt;<br/><br/>    &lt;!-- Test --&gt;<br/>    &lt;dependency&gt;<br/>      &lt;groupId&gt;junit&lt;/groupId&gt;<br/>      &lt;artifactId&gt;junit&lt;/artifactId&gt;<br/>      &lt;version&gt;4.12&lt;/version&gt;<br/>      &lt;scope&gt;test&lt;/scope&gt;<br/>    &lt;/dependency&gt;<br/>    &lt;dependency&gt;<br/>      &lt;groupId&gt;org.scalatest&lt;/groupId&gt;<br/>      &lt;artifactId&gt;scalatest_${scala.compat.version}&lt;/artifactId&gt;<br/>      &lt;version&gt;3.0.5&lt;/version&gt;<br/>      &lt;scope&gt;test&lt;/scope&gt;<br/>    &lt;/dependency&gt;<br/>    &lt;dependency&gt;<br/>      &lt;groupId&gt;org.specs2&lt;/groupId&gt;<br/>      &lt;artifactId&gt;specs2-core_${scala.compat.version}&lt;/artifactId&gt;<br/>      &lt;version&gt;${spec2.version}&lt;/version&gt;<br/>      &lt;scope&gt;test&lt;/scope&gt;<br/>    &lt;/dependency&gt;<br/>    &lt;dependency&gt;<br/>      &lt;groupId&gt;org.specs2&lt;/groupId&gt;<br/>      &lt;artifactId&gt;specs2-junit_${scala.compat.version}&lt;/artifactId&gt;<br/>      &lt;version&gt;${spec2.version}&lt;/version&gt;<br/>      &lt;scope&gt;test&lt;/scope&gt;<br/>    &lt;/dependency&gt;<br/>  &lt;/dependencies&gt;<br/><br/>  &lt;build&gt;<br/>    &lt;sourceDirectory&gt;src/main/scala&lt;/sourceDirectory&gt;<br/>    &lt;testSourceDirectory&gt;src/test/scala&lt;/testSourceDirectory&gt;<br/>    &lt;plugins&gt;<br/>      &lt;plugin&gt;<br/>        &lt;!-- see http://davidb.github.com/scala-maven-plugin --&gt;<br/>        &lt;groupId&gt;net.alchim31.maven&lt;/groupId&gt;<br/>        &lt;artifactId&gt;scala-maven-plugin&lt;/artifactId&gt;<br/>        &lt;version&gt;3.3.2&lt;/version&gt;<br/>        &lt;executions&gt;<br/>          &lt;execution&gt;<br/>            &lt;goals&gt;<br/>              &lt;goal&gt;compile&lt;/goal&gt;<br/>              &lt;goal&gt;testCompile&lt;/goal&gt;<br/>            &lt;/goals&gt;<br/>            &lt;configuration&gt;<br/>              &lt;args&gt;<br/>                &lt;arg&gt;-dependencyfile&lt;/arg&gt;<br/>                &lt;arg&gt;${project.build.directory}/.scala_dependencies&lt;/arg&gt;<br/>              &lt;/args&gt;<br/>            &lt;/configuration&gt;<br/>          &lt;/execution&gt;<br/>        &lt;/executions&gt;<br/>      &lt;/plugin&gt;<br/>      &lt;plugin&gt;<br/>        &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;<br/>        &lt;artifactId&gt;maven-surefire-plugin&lt;/artifactId&gt;<br/>        &lt;version&gt;2.21.0&lt;/version&gt;<br/>        &lt;configuration&gt;<br/>          &lt;!-- Tests will be run with scalatest-maven-plugin instead --&gt;<br/>          &lt;skipTests&gt;true&lt;/skipTests&gt;<br/>        &lt;/configuration&gt;<br/>      &lt;/plugin&gt;<br/>      &lt;plugin&gt;<br/>        &lt;groupId&gt;org.scalatest&lt;/groupId&gt;<br/>        &lt;artifactId&gt;scalatest-maven-plugin&lt;/artifactId&gt;<br/>        &lt;version&gt;2.0.0&lt;/version&gt;<br/>        &lt;configuration&gt;<br/>          &lt;reportsDirectory&gt;${project.build.directory}/surefire-reports&lt;/reportsDirectory&gt;<br/>          &lt;junitxml&gt;.&lt;/junitxml&gt;<br/>          &lt;filereports&gt;TestSuiteReport.txt&lt;/filereports&gt;<br/>          &lt;!-- Comma separated list of JUnit test class names to execute --&gt;<br/>          &lt;jUnitClasses&gt;samples.AppTest&lt;/jUnitClasses&gt;<br/>        &lt;/configuration&gt;<br/>        &lt;executions&gt;<br/>          &lt;execution&gt;<br/>            &lt;id&gt;test&lt;/id&gt;<br/>            &lt;goals&gt;<br/>              &lt;goal&gt;test&lt;/goal&gt;<br/>            &lt;/goals&gt;<br/>          &lt;/execution&gt;<br/>        &lt;/executions&gt;<br/>       &lt;/plugin&gt;<br/>       &lt;plugin&gt;<br/>        &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;<br/>        &lt;artifactId&gt;maven-assembly-plugin&lt;/artifactId&gt;<br/>        &lt;version&gt;2.4&lt;/version&gt;<br/>                &lt;configuration&gt;<br/>                    &lt;descriptorRefs&gt;<br/>                        &lt;descriptorRef&gt;jar-with-dependencies&lt;/descriptorRef&gt;<br/>                    &lt;/descriptorRefs&gt;<br/>                    &lt;archive&gt;<br/>                        &lt;manifest&gt;<br/>                            &lt;mainClass&gt;com.example.App&lt;/mainClass&gt;<br/>                        &lt;/manifest&gt;<br/>                    &lt;/archive&gt;<br/>                &lt;/configuration&gt;<br/>                &lt;executions&gt;<br/>                    &lt;execution&gt;<br/>                        &lt;phase&gt;package&lt;/phase&gt;<br/>                        &lt;goals&gt;<br/>                            &lt;goal&gt;single&lt;/goal&gt;<br/>                        &lt;/goals&gt;<br/>                    &lt;/execution&gt;<br/>                &lt;/executions&gt;<br/>       &lt;/plugin&gt;<br/><br/>    &lt;/plugins&gt;<br/>  &lt;/build&gt;<br/>&lt;/project&gt;</span></pre><p id="ed52" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">应用程序执行的输出如下:</p><figure class="jl jm jn jo fd kb er es paragraph-image"><div role="button" tabindex="0" class="kc kd di ke bf kf"><div class="er es ka"><img src="../Images/dcfb8011b07bab7c0baf7e8e9675092f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*tCo3MJmxqee3Omfu"/></div></div></figure><h2 id="c5cc" class="ki jv hi bd kj kk kl km kn ko kp kq kr iq ks kt ku iu kv kw kx iy ky kz la lb bi translated">迁移应用程序以连接到Google Cloud Bigtable</h2><p id="b0f3" class="pw-post-body-paragraph if ig hi ih b ii lc ik il im ld io ip iq le is it iu lf iw ix iy lg ja jb jc hb bi translated">要迁移应用程序，我们只需在connect方法中进行更改，以使用Bigtable配置而不是HBase配置，传入适当的连接参数，并在pom.xml中用适当的版本指定Bigtable依赖项。</p><blockquote class="je jf jg"><p id="025b" class="if ig jh ih b ii ij ik il im in io ip ji ir is it jj iv iw ix jk iz ja jb jc hb bi translated">对Connection.class的首次更改</p></blockquote><p id="7baf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">将连接更改为使用BigtableConfiguration connect方法来创建连接。因此，移除较早的HBase配置和连接。</p><p id="ff34" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">要使用BigtableConfiguration类，请使用com . Google . cloud . bigtable . h base . bigtable configuration导入它</p><pre class="jl jm jn jo fd jp jq jr bn js jt bi"><span id="a309" class="ju jv hi jq b be jw jx l jy jz">package com.example<br/><br/>import org.apache.hadoop.hbase.client._<br/>import org.apache.hadoop.hbase.util.Bytes<br/>import org.apache.hadoop.hbase.{CellUtil, HBaseConfiguration, TableName}<br/>import org.apache.hadoop.conf.Configuration<br/>import scala.collection.JavaConverters._<br/>import com.google.cloud.bigtable.hbase.BigtableConfiguration;<br/><br/>object Connection {<br/><br/>  /**<br/>   * Connect Method to take the cluster details, create a Hbase configuration and consequently a connection<br/>   * The method returns a Connection object which could be used to read/write/update data from the cluster which it is connected to.<br/>   */<br/>  def connect(project_id: String, instance_id: String): Connection = {<br/><br/>    println("Within Connection:")<br/>    <br/>    val connection = BigtableConfiguration.connect(BigtableConfiguration.configure(project_id, instance_id))<br/><br/>    return connection<br/>  }<br/><br/>}</span></pre><blockquote class="je jf jg"><p id="1841" class="if ig jh ih b ii ij ik il im in io ip ji ir is it jj iv iw ix jk iz ja jb jc hb bi translated">App.scala中的变化</p></blockquote><p id="efdd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因为连接配置已经从HBase中的cluster list更改为Bigtable中的project_id和instance_id，所以更改对connect方法的调用。</p><p id="45e3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">当Bigtable中存在与HBase中相同的表名和行键时，读取数据不需要进行其他更改</p><pre class="jl jm jn jo fd jp jq jr bn js jt bi"><span id="ef4d" class="ju jv hi jq b be jw jx l jy jz">package com.example<br/><br/>import org.apache.hadoop.hbase.client._<br/>import org.apache.hadoop.hbase.util.Bytes<br/>import org.apache.hadoop.hbase.{CellUtil, HBaseConfiguration, TableName}<br/>import org.apache.hadoop.conf.Configuration<br/>import scala.collection.JavaConverters._<br/><br/>/**<br/> * @author anjalichimnani<br/> */<br/>object App {<br/><br/>  /**<br/>   * Read data in the cluster connected to connection object from table name specified and for row key requested<br/>   */<br/>  def readTable(connection: Connection, tableName: String, rowKey: String) {<br/>    println("Within readTable:")<br/>    val table = connection.getTable(TableName.valueOf( Bytes.toBytes(tableName) ) )<br/><br/>    var get = new Get(Bytes.toBytes(rowKey))<br/>    var result = table.get(get)<br/><br/>    println(result)<br/><br/>    table.close()<br/>  }<br/><br/>  /**<br/>   * Main function where the code execution initiates.<br/>   * It sets the variable values for cluster, table name and row key to be read<br/>   * Requests for a connection to cluster<br/>   * Calls readTable method to get data from the cluster.<br/>   *<br/>   * To run the code, specify Bigtable Project ID and Instance ID <br/>   */<br/>  def main(args : Array[String]) {<br/><br/>    println( "Within Main Method:")<br/>    val tableName = "employee"<br/>    val rowKey = "1"<br/>    val project_id = "&lt;google-cloud-project-name&gt;"<br/>    val instance_id = "&lt;bigtable-instance-id&gt;"<br/><br/>    val connection = Connection.connect(project_id, instance_id)<br/>    readTable(connection, tableName, rowKey)<br/><br/>    connection.close()<br/><br/>  }<br/><br/>}</span></pre><blockquote class="je jf jg"><p id="e6c0" class="if ig jh ih b ii ij ik il im in io ip ji ir is it jj iv iw ix jk iz ja jb jc hb bi translated">pom.xml中的最终更改</p></blockquote><p id="d1cf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因为我们需要com . Google . cloud . bigtable . h base . bigtable configuration类，所以我们需要指定各自的依赖项和版本。它们被添加如下:</p><pre class="jl jm jn jo fd jp jq jr bn js jt bi"><span id="6b64" class="ju jv hi jq b be jw jx l jy jz">&lt;project  xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd"&gt;<br/>  &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;<br/>  &lt;groupId&gt;com.example&lt;/groupId&gt;<br/>  &lt;artifactId&gt;employee&lt;/artifactId&gt;<br/>  &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;<br/>  &lt;name&gt;${project.artifactId}&lt;/name&gt;<br/>  &lt;description&gt;My wonderfull scala app&lt;/description&gt;<br/>  &lt;inceptionYear&gt;2018&lt;/inceptionYear&gt;<br/>  &lt;licenses&gt;<br/>    &lt;license&gt;<br/>      &lt;name&gt;My License&lt;/name&gt;<br/>      &lt;url&gt;http://....&lt;/url&gt;<br/>      &lt;distribution&gt;repo&lt;/distribution&gt;<br/>    &lt;/license&gt;<br/>  &lt;/licenses&gt;<br/><br/>  &lt;properties&gt;<br/>    &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt;<br/>    &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt;<br/>    &lt;encoding&gt;UTF-8&lt;/encoding&gt;<br/>    &lt;scala.version&gt;2.12.6&lt;/scala.version&gt;<br/>    &lt;spark.version&gt;2.4.8&lt;/spark.version&gt;<br/>    &lt;hbase.version&gt;2.4.9&lt;/hbase.version&gt;<br/>    &lt;scala.compat.version&gt;2.12&lt;/scala.compat.version&gt;<br/>    &lt;spec2.version&gt;4.2.0&lt;/spec2.version&gt;<br/>    &lt;bigtable.version&gt;1.26.3&lt;/bigtable.version&gt;<br/>  &lt;/properties&gt;<br/><br/>  &lt;dependencies&gt;<br/>    &lt;dependency&gt;<br/>       &lt;groupId&gt;com.google.cloud.bigtable&lt;/groupId&gt;<br/>       &lt;artifactId&gt;bigtable-hbase-2.x-hadoop&lt;/artifactId&gt;<br/>       &lt;version&gt;${bigtable.version}&lt;/version&gt;<br/>    &lt;/dependency&gt;<br/><br/>    &lt;dependency&gt;<br/>      &lt;groupId&gt;org.scala-lang&lt;/groupId&gt;<br/>      &lt;artifactId&gt;scala-library&lt;/artifactId&gt;<br/>      &lt;version&gt;${scala.version}&lt;/version&gt;<br/>    &lt;/dependency&gt;<br/><br/>    &lt;dependency&gt;<br/>      &lt;groupId&gt;org.apache.hbase&lt;/groupId&gt;<br/>      &lt;artifactId&gt;hbase-server&lt;/artifactId&gt;<br/>      &lt;version&gt;${hbase.version}&lt;/version&gt;<br/>    &lt;/dependency&gt;<br/><br/>    &lt;dependency&gt;<br/>      &lt;groupId&gt;org.apache.spark&lt;/groupId&gt;<br/>      &lt;artifactId&gt;spark-core_2.12&lt;/artifactId&gt;<br/>      &lt;version&gt;${spark.version}&lt;/version&gt;<br/>      &lt;scope&gt;provided&lt;/scope&gt;<br/>    &lt;/dependency&gt;<br/><br/>    &lt;!-- Test --&gt;<br/>    &lt;dependency&gt;<br/>      &lt;groupId&gt;junit&lt;/groupId&gt;<br/>      &lt;artifactId&gt;junit&lt;/artifactId&gt;<br/>      &lt;version&gt;4.12&lt;/version&gt;<br/>      &lt;scope&gt;test&lt;/scope&gt;<br/>    &lt;/dependency&gt;<br/>    &lt;dependency&gt;<br/>      &lt;groupId&gt;org.scalatest&lt;/groupId&gt;<br/>      &lt;artifactId&gt;scalatest_${scala.compat.version}&lt;/artifactId&gt;<br/>      &lt;version&gt;3.0.5&lt;/version&gt;<br/>      &lt;scope&gt;test&lt;/scope&gt;<br/>    &lt;/dependency&gt;<br/>    &lt;dependency&gt;<br/>      &lt;groupId&gt;org.specs2&lt;/groupId&gt;<br/>      &lt;artifactId&gt;specs2-core_${scala.compat.version}&lt;/artifactId&gt;<br/>      &lt;version&gt;${spec2.version}&lt;/version&gt;<br/>      &lt;scope&gt;test&lt;/scope&gt;<br/>    &lt;/dependency&gt;<br/>    &lt;dependency&gt;<br/>      &lt;groupId&gt;org.specs2&lt;/groupId&gt;<br/>      &lt;artifactId&gt;specs2-junit_${scala.compat.version}&lt;/artifactId&gt;<br/>      &lt;version&gt;${spec2.version}&lt;/version&gt;<br/>      &lt;scope&gt;test&lt;/scope&gt;<br/>    &lt;/dependency&gt;<br/>  &lt;/dependencies&gt;<br/><br/>  &lt;build&gt;<br/>    &lt;sourceDirectory&gt;src/main/scala&lt;/sourceDirectory&gt;<br/>    &lt;testSourceDirectory&gt;src/test/scala&lt;/testSourceDirectory&gt;<br/>    &lt;plugins&gt;<br/>      &lt;plugin&gt;<br/>        &lt;!-- see http://davidb.github.com/scala-maven-plugin --&gt;<br/>        &lt;groupId&gt;net.alchim31.maven&lt;/groupId&gt;<br/>        &lt;artifactId&gt;scala-maven-plugin&lt;/artifactId&gt;<br/>        &lt;version&gt;3.3.2&lt;/version&gt;<br/>        &lt;executions&gt;<br/>          &lt;execution&gt;<br/>            &lt;goals&gt;<br/>              &lt;goal&gt;compile&lt;/goal&gt;<br/>              &lt;goal&gt;testCompile&lt;/goal&gt;<br/>            &lt;/goals&gt;<br/>            &lt;configuration&gt;<br/>              &lt;args&gt;<br/>                &lt;arg&gt;-dependencyfile&lt;/arg&gt;<br/>                &lt;arg&gt;${project.build.directory}/.scala_dependencies&lt;/arg&gt;<br/>              &lt;/args&gt;<br/>            &lt;/configuration&gt;<br/>          &lt;/execution&gt;<br/>        &lt;/executions&gt;<br/>      &lt;/plugin&gt;<br/>      &lt;plugin&gt;<br/>        &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;<br/>        &lt;artifactId&gt;maven-surefire-plugin&lt;/artifactId&gt;<br/>        &lt;version&gt;2.21.0&lt;/version&gt;<br/>        &lt;configuration&gt;<br/>          &lt;!-- Tests will be run with scalatest-maven-plugin instead --&gt;<br/>          &lt;skipTests&gt;true&lt;/skipTests&gt;<br/>        &lt;/configuration&gt;<br/>      &lt;/plugin&gt;<br/>      &lt;plugin&gt;<br/>        &lt;groupId&gt;org.scalatest&lt;/groupId&gt;<br/>        &lt;artifactId&gt;scalatest-maven-plugin&lt;/artifactId&gt;<br/>        &lt;version&gt;2.0.0&lt;/version&gt;<br/>        &lt;configuration&gt;<br/>          &lt;reportsDirectory&gt;${project.build.directory}/surefire-reports&lt;/reportsDirectory&gt;<br/>          &lt;junitxml&gt;.&lt;/junitxml&gt;<br/>          &lt;filereports&gt;TestSuiteReport.txt&lt;/filereports&gt;<br/>          &lt;!-- Comma separated list of JUnit test class names to execute --&gt;<br/>          &lt;jUnitClasses&gt;samples.AppTest&lt;/jUnitClasses&gt;<br/>        &lt;/configuration&gt;<br/>        &lt;executions&gt;<br/>          &lt;execution&gt;<br/>            &lt;id&gt;test&lt;/id&gt;<br/>            &lt;goals&gt;<br/>              &lt;goal&gt;test&lt;/goal&gt;<br/>            &lt;/goals&gt;<br/>          &lt;/execution&gt;<br/>        &lt;/executions&gt;<br/>       &lt;/plugin&gt;<br/>       &lt;plugin&gt;<br/>        &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;<br/>        &lt;artifactId&gt;maven-assembly-plugin&lt;/artifactId&gt;<br/>        &lt;version&gt;2.4&lt;/version&gt;<br/>                &lt;configuration&gt;<br/>                    &lt;descriptorRefs&gt;<br/>                        &lt;descriptorRef&gt;jar-with-dependencies&lt;/descriptorRef&gt;<br/>                    &lt;/descriptorRefs&gt;<br/>                    &lt;archive&gt;<br/>                        &lt;manifest&gt;<br/>                            &lt;mainClass&gt;com.example.App&lt;/mainClass&gt;<br/>                        &lt;/manifest&gt;<br/>                    &lt;/archive&gt;<br/>                &lt;/configuration&gt;<br/>                &lt;executions&gt;<br/>                    &lt;execution&gt;<br/>                        &lt;phase&gt;package&lt;/phase&gt;<br/>                        &lt;goals&gt;<br/>                            &lt;goal&gt;single&lt;/goal&gt;<br/>                        &lt;/goals&gt;<br/>                    &lt;/execution&gt;<br/>                &lt;/executions&gt;<br/>       &lt;/plugin&gt;<br/><br/>    &lt;/plugins&gt;<br/>  &lt;/build&gt;<br/>&lt;/project&gt;</span></pre><p id="597c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">完成所有更改后，迁移后的代码成功运行，如下所示:</p><figure class="jl jm jn jo fd kb er es paragraph-image"><div role="button" tabindex="0" class="kc kd di ke bf kf"><div class="er es ka"><img src="../Images/86f601fdb56630bbae0153c552800906.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*5H6GHuzD6Yw2Oj9n"/></div></div></figure><p id="f06d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">注意:要运行代码，您必须提供代码中“&lt;&gt;”中指定的HBase集群和Bigtable集群详细信息，例如:</p><pre class="jl jm jn jo fd jp jq jr bn js jt bi"><span id="0f8d" class="ju jv hi jq b be jw jx l jy jz">//For HBase<br/>val zookeeper_quorum = "&lt;HBase-cluster&gt;"<br/><br/>//For Google Cloud Bigtable<br/>val project_id = "&lt;google-cloud-project-name&gt;"<br/>val instance_id = "&lt;bigtable-instance-id&gt;"</span></pre><p id="3b65" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">要构建和执行jar，请在pom.xml所在的目录中运行以下命令:</p><pre class="jl jm jn jo fd jp jq jr bn js jt bi"><span id="de95" class="ju jv hi jq b be jw jx l jy jz">mvn package<br/><br/>java -jar target/employee-1.0-SNAPSHOT-jar-with-dependencies.jar</span></pre><p id="cc08" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">那都是乡亲们！！您成功地迁移了Scala代码，从HBase连接到Google Cloud Bigtable并从中读取数据。</p><h2 id="3481" class="ki jv hi bd kj kk kl km kn ko kp kq kr iq ks kt ku iu kv kw kx iy ky kz la lb bi translated">参考资料:</h2><ul class=""><li id="9fb0" class="lh li hi ih b ii lc im ld iq lv iu lw iy lx jc lm ln lo lp bi translated">拥有Maven的Scala:<a class="ae jd" href="https://docs.scala-lang.org/tutorials/scala-with-maven.html" rel="noopener ugc nofollow" target="_blank">https://docs.scala-lang.org/tutorials/scala-with-maven.html</a></li><li id="7a8b" class="lh li hi ih b ii lq im lr iq ls iu lt iy lu jc lm ln lo lp bi translated">h基本文档:<a class="ae jd" href="https://hbase.apache.org/" rel="noopener ugc nofollow" target="_blank">https://hbase.apache.org/</a></li><li id="1ccf" class="lh li hi ih b ii lq im lr iq ls iu lt iy lu jc lm ln lo lp bi translated">Bigtable依赖项的Maven存储库:<a class="ae jd" href="https://mvnrepository.com/artifact/com.google.cloud.bigtable" rel="noopener ugc nofollow" target="_blank">https://mvn Repository . com/artifact/com . Google . cloud . Bigtable</a></li></ul><h2 id="5ed9" class="ki jv hi bd kj kk kl km kn ko kp kq kr iq ks kt ku iu kv kw kx iy ky kz la lb bi translated">Google Cloud Bigtable的更多信息:</h2><ul class=""><li id="cd5c" class="lh li hi ih b ii lc im ld iq lv iu lw iy lx jc lm ln lo lp bi translated"><a class="ae jd" href="https://cloud.google.com/bigtable/docs/overview" rel="noopener ugc nofollow" target="_blank">https://cloud.google.com/bigtable/docs/overview</a></li><li id="4462" class="lh li hi ih b ii lq im lr iq ls iu lt iy lu jc lm ln lo lp bi translated"><a class="ae jd" href="https://github.com/GoogleCloudPlatform/cloud-bigtable-examples" rel="noopener ugc nofollow" target="_blank">https://github . com/Google cloud platform/cloud-bigtable-examples</a></li></ul><p id="2869" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">感谢您的阅读。欢迎分享您对该主题的评论和进一步的兴趣！！</p></div></div>    
</body>
</html>