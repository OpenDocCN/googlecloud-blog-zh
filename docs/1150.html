<html>
<head>
<title>How to improve the performance of BigQuery queries by optimizing the schema of your tables</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何通过优化表的模式来提高BigQuery查询的性能</h1>
<blockquote>原文：<a href="https://medium.com/google-cloud/how-to-improve-the-performance-of-bigquery-queries-by-optimizing-the-schema-of-your-tables-e4c36077fa2d?source=collection_archive---------0-----------------------#2019-09-21">https://medium.com/google-cloud/how-to-improve-the-performance-of-bigquery-queries-by-optimizing-the-schema-of-your-tables-e4c36077fa2d?source=collection_archive---------0-----------------------#2019-09-21</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="f155" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">提高存储级BigQuery性能的三个技巧:嵌套字段、地理类型和聚类</h2></div><p id="b228" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在本文中，我采用了一个真实的表，并以无损的方式更改了它的模式，以提高该表上的查询性能。</p><figure class="ju jv jw jx fd jy er es paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><div class="er es jt"><img src="../Images/54d65c80c0d9538ebbb7762e707743b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*920bYZr5qdeU1x6pf0jpow.jpeg"/></div></div><figcaption class="kf kg et er es kh ki bd b be z dx translated">优化数据的存储方式，以获得更好的查询性能。安妮·斯普拉特在<a class="ae kj" href="https://unsplash.com/search/photos/beehive?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</figcaption></figure><h2 id="3014" class="kk kl hi bd km kn ko kp kq kr ks kt ku jg kv kw kx jk ky kz la jo lb lc ld le bi translated">要优化的查询</h2><p id="a3fe" class="pw-post-body-paragraph ix iy hi iz b ja lf ij jc jd lg im jf jg lh ji jj jk li jm jn jo lj jq jr js hb bi translated">为了说明表模式得到了改进，我们必须测量真实数据集上真实查询的性能。我将使用美国环境保护署(EPA)对可吸入颗粒物(PM10)的观测数据。<a class="ae kj" href="https://console.cloud.google.com/bigquery?p=bigquery-public-data&amp;d=epa_historical_air_quality&amp;t=pm10_hourly_summary&amp;page=table" rel="noopener ugc nofollow" target="_blank"> EPA PM10每小时数据集</a>作为BigQuery公共数据集程序的一部分可用。</p><p id="4bad" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这原本是一个扁平的表—基本上，每个小时的观察都有一行。数据集相对较小(1.4 GB，40m行)，因此查询应该非常适合每月的免费配额(1 TB)。因为它是一张小桌子，所以改进不会像在大桌子上那样显著。</p><p id="3a93" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">假设我们想知道2017年每个县有多少台PM10观测仪器。该查询是:</p><pre class="ju jv jw jx fd lk ll lm ln aw lo bi"><span id="1446" class="kk kl hi ll b fi lp lq l lr ls">SELECT<br/> pm10.county_name,<br/> COUNT(DISTINCT pm10.site_num) AS num_instruments<br/>FROM <br/>  `bigquery-public-data`.epa_historical_air_quality.pm10_hourly_summary as pm10<br/>WHERE <br/>  EXTRACT(YEAR from pm10.date_local) = 2017 AND<br/>  pm10.state_name = 'Ohio'<br/>GROUP BY pm10.county_name</span></pre><p id="e538" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">该查询耗时2.4秒，处理了1.3 GB。</p><p id="43d1" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">对于第二个查询，假设我们想找到俄亥俄州哥伦布市每年的最大PM10读数。城市多边形位于另一个公共数据集中，因此我们将连接它们:</p><pre class="ju jv jw jx fd lk ll lm ln aw lo bi"><span id="b146" class="kk kl hi ll b fi lp lq l lr ls">SELECT<br/>  MIN(EXTRACT(YEAR from pm10.date_local)) AS year<br/>  , MAX(pm10.sample_measurement) AS PM10<br/>FROM <br/>  `bigquery-public-data`.epa_historical_air_quality.pm10_hourly_summary as pm10<br/>CROSS JOIN<br/>  `bigquery-public-data`.utility_us.us_cities_area as city<br/>WHERE<br/>  pm10.state_name = 'Ohio' AND<br/>  city.name = 'Columbus, OH' AND<br/>  ST_Within( ST_GeogPoint(pm10.longitude, pm10.latitude), <br/>             city.city_geom )<br/>GROUP BY EXTRACT(YEAR from pm10.date_local)<br/>ORDER BY year ASC</span></pre><p id="f206" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这花费了大约4分钟，处理了1.4 GB，并产生了哥伦布这些年的PM10读数。</p><p id="ef7a" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这是我将用来演示优化的两个查询。</p><h2 id="f394" class="kk kl hi bd km kn ko kp kq kr ks kt ku jg kv kw kx jk ky kz la jo lb lc ld le bi translated">技巧1:使用嵌套字段</h2><p id="18c5" class="pw-post-body-paragraph ix iy hi iz b ja lf ij jc jd lg im jf jg lh ji jj jk li jm jn jo lj jq jr js hb bi translated">EPA每小时的数据在一个表中，表中的每一行都是每小时的观察值。这意味着现在有许多关于车站等的重复数据。让我们将同一天来自同一个传感器的所有观察值组合成一个数组(参见下面的ARRAY_AGG ),并将它写入一个新表(首先创建一个名为advdata的新数据集):</p><pre class="ju jv jw jx fd lk ll lm ln aw lo bi"><span id="21f1" class="kk kl hi ll b fi lp lq l lr ls">CREATE OR REPLACE TABLE advdata.epa AS</span><span id="58e8" class="kk kl hi ll b fi lt lq l lr ls">SELECT<br/>  state_code<br/>  , county_code<br/>  , site_num<br/>  , parameter_code<br/>  , poc<br/>  , MIN(latitude) as latitude<br/>  , MIN(longitude) as longitude<br/>  , MIN(datum) as datum<br/>  , MIN(parameter_name) as parameter_name<br/>  , date_local<br/>  , <strong class="ll hj">ARRAY_AGG</strong>(STRUCT(time_local, date_gmt, sample_measurement, uncertainty, qualifier, date_of_last_change) ORDER BY time_local ASC) AS obs<br/>  , STRUCT(MIN(units_of_measure) as units_of_measure<br/>         , MIN(mdl) as mdl<br/>         , MIN(method_type) as method_type<br/>         , MIN(method_code) as method_code<br/>         , MIN(method_name) as method_name) AS method<br/>  , MIN(state_name) as state_name<br/>  , MIN(county_name) as county_name<br/>FROM `bigquery-public-data.epa_historical_air_quality.pm10_hourly_summary`<br/>GROUP BY state_code, county_code, site_num, parameter_code, poc, date_local</span></pre><p id="5d6b" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">新表的行数更少(170万)，但仍然是1.41 GB，因为我们没有丢失任何数据！不同之处在于，我们将观察到的值存储为一行中的数组。因此，行数减少到了原来的1/24。</p><p id="188b" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">按县查询仪器现在是:</p><pre class="ju jv jw jx fd lk ll lm ln aw lo bi"><span id="30b0" class="kk kl hi ll b fi lp lq l lr ls">SELECT<br/> pm10.county_name,<br/> COUNT(DISTINCT pm10.site_num) AS num_instruments<br/>FROM <br/>  advdata.epa as pm10<br/>WHERE <br/>  EXTRACT(YEAR from pm10.date_local) = 2017 AND<br/>  pm10.state_name = 'Ohio'<br/>GROUP BY pm10.county_name</span></pre><p id="0271" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在，查询耗时0.7秒(速度提高了3倍)，处理量仅为56 MB(成本降低了24倍)。为什么不那么贵？因为少了24行(还记得我们将每小时的测量值聚集成一行)，所以表扫描需要处理的数据少了24行。查询速度更快，因为它需要处理的行数更少。</p><p id="5492" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">但是如果你真的需要处理每小时的数据呢？由于使用数组的转换没有损失，我们仍然可以查询哥伦布这些年来每小时最大的PM10观测值。该查询现在在FROM子句中需要一个UNNEST，但在其他方面是相同的:</p><pre class="ju jv jw jx fd lk ll lm ln aw lo bi"><span id="5918" class="kk kl hi ll b fi lp lq l lr ls">SELECT<br/>  MIN(EXTRACT(YEAR from pm10.date_local)) AS year<br/>  , MAX(<strong class="ll hj">pm10obs.</strong>sample_measurement) AS PM10<br/>FROM <br/>  advdata.epa as pm10,<br/>  <strong class="ll hj">UNNEST(obs) as pm10obs</strong><br/>CROSS JOIN<br/>  `bigquery-public-data`.utility_us.us_cities_area as city<br/>WHERE <br/>  city.name = 'Columbus, OH' AND<br/>  ST_Within( ST_GeogPoint(pm10.longitude, pm10.latitude), <br/>             city.city_geom )<br/>GROUP BY EXTRACT(YEAR from pm10.date_local)<br/>ORDER BY year ASC</span></pre><p id="ed43" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这个查询仍然需要4分钟，但是它只处理537 MB。换句话说，将数据存储为嵌套字段(数组)使查询成本降低了3倍！这很奇怪。为什么读取的数据会下降？因为有些行(Columbus之外的行)不需要读取数组数据。但是计算(max，extract year，ST_Within)是这个查询的大部分开销，并且执行的行数是相同的，所以查询速度没有变化。</p><h2 id="7c78" class="kk kl hi bd km kn ko kp kq kr ks kt ku jg kv kw kx jk ky kz la jo lb lc ld le bi translated">技巧2:地理类型</h2><p id="2851" class="pw-post-body-paragraph ix iy hi iz b ja lf ij jc jd lg im jf jg lh ji jj jk li jm jn jo lj jq jr js hb bi translated">我们能通过更好地存储数据来改进计算吗？是啊！</p><p id="4f44" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">与其每次都从经纬度构造地理点，不如将经纬度存储为地理类型。原因在于，使用ST_GeogPoint()创建地理点实际上是一项开销较大的操作，需要查找包含该点的S2像元(如果您试图创建更复杂的形状，如多边形，则开销会更大):</p><pre class="ju jv jw jx fd lk ll lm ln aw lo bi"><span id="acaf" class="kk kl hi ll b fi lp lq l lr ls">CREATE OR REPLACE TABLE advdata.epageo AS</span><span id="dcca" class="kk kl hi ll b fi lt lq l lr ls">SELECT <br/>  * except(latitude, longitude)<br/>  , ST_GeogPoint(longitude, latitude) AS location<br/>FROM advdata.epa</span></pre><p id="1e61" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">第一个查询是相同的，因为我们在查询中不使用纬度和经度。第二个查询现在可以避免创建ST_GeogPoint:</p><pre class="ju jv jw jx fd lk ll lm ln aw lo bi"><span id="7437" class="kk kl hi ll b fi lp lq l lr ls">SELECT<br/>  MIN(EXTRACT(YEAR from pm10.date_local)) AS year<br/>  , MAX(pm10obs.sample_measurement) AS PM10<br/>FROM <br/>  advdata.<strong class="ll hj">epageo</strong> as pm10,<br/>  UNNEST(obs) as pm10obs<br/>CROSS JOIN<br/>  `bigquery-public-data`.utility_us.us_cities_area as city<br/>WHERE <br/>  city.name = 'Columbus, OH' AND<br/>  ST_Within( <strong class="ll hj">pm10.location</strong>, city.city_geom )<br/>GROUP BY EXTRACT(YEAR from pm10.date_local)<br/>ORDER BY year ASC</span></pre><p id="041b" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">它耗时3.5分钟，处理576 MB，也就是说，在12.5%的查询性能加速下，多了6%的数据(一个点的geography类型使用的数据比两个floats多)。</p><h2 id="1443" class="kk kl hi bd km kn ko kp kq kr ks kt ku jg kv kw kx jk ky kz la jo lb lc ld le bi translated">技巧#3:集群</h2><p id="94c0" class="pw-post-body-paragraph ix iy hi iz b ja lf ij jc jd lg im jf jg lh ji jj jk li jm jn jo lj jq jr js hb bi translated">请注意，我们非常广泛地使用时间。如果我们要求BigQuery以这样一种方式存储它的表，即该字段的所有相等值都保存在相邻的行中，会怎么样呢？这样，如果我们的查询在某个时间点进行过滤，BigQuery就不必进行全表扫描。相反，它只能读取表的一部分。</p><p id="36b4" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">因为您一次只能创建2000个分区，所以我决定通过一个虚拟日期字段进行分区(这没问题，因为通过集群，我们强制查询使用分区):</p><pre class="ju jv jw jx fd lk ll lm ln aw lo bi"><span id="179e" class="kk kl hi ll b fi lp lq l lr ls">CREATE OR REPLACE TABLE advdata.epaclustered <br/>PARTITION BY dummy_month<br/>CLUSTER BY state_name, date_local<br/>AS <br/>SELECT <br/>*, <br/>CAST(<br/>CONCAT(CAST(EXTRACT(YEAR from date_local) AS STRING), "-", <br/>       CAST(EXTRACT(MONTH from date_local) AS STRING), "-01") AS DATE) AS dummy_month<br/>FROM advdata.epageo</span></pre><p id="a107" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在，让我们来看第一个查询:</p><pre class="ju jv jw jx fd lk ll lm ln aw lo bi"><span id="0a43" class="kk kl hi ll b fi lp lq l lr ls">SELECT<br/> pm10.county_name,<br/> COUNT(DISTINCT pm10.site_num) AS num_instruments<br/>FROM <br/>  advdata.epaclustered as pm10<br/>WHERE <br/>  pm10.state_name = 'Ohio'<br/>GROUP BY pm10.county_name</span></pre><p id="60db" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">0.8秒，43MB！没有区别。</p><p id="9516" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">第二个呢？</p><pre class="ju jv jw jx fd lk ll lm ln aw lo bi"><span id="2ea7" class="kk kl hi ll b fi lp lq l lr ls">SELECT<br/>  MIN(EXTRACT(YEAR from pm10.date_local)) AS year<br/>  , MAX(pm10obs.sample_measurement) AS PM10<br/>FROM <br/>  advdata.epaclustered as pm10,<br/>  UNNEST(obs) as pm10obs<br/>CROSS JOIN<br/>  `bigquery-public-data`.utility_us.us_cities_area as city<br/>WHERE <br/>  pm10.state_name = 'Ohio' AND<br/>  city.name = 'Columbus, OH' AND<br/>  ST_Within( pm10.location, city.city_geom )<br/>GROUP BY EXTRACT(YEAR from pm10.date_local)<br/>ORDER BY year ASC</span></pre><p id="7c08" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在，查询只需20秒，处理576.4 MB，速度提高了10倍。这是因为我们按月对表进行了聚类，并按月进行了筛选，这使得BigQuery能够更有效地组织数据。</p><p id="7313" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">尽情享受吧！</p></div></div>    
</body>
</html>