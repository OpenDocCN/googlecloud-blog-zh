<html>
<head>
<title>How to do time series prediction using RNNs, TensorFlow and Cloud ML Engine</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何用RNNs，TensorFlow，Cloud ML引擎做时间序列预测</h1>
<blockquote>原文：<a href="https://medium.com/google-cloud/how-to-do-time-series-prediction-using-rnns-and-tensorflow-and-cloud-ml-engine-2ad2eeb189e8?source=collection_archive---------0-----------------------#2017-04-01">https://medium.com/google-cloud/how-to-do-time-series-prediction-using-rnns-and-tensorflow-and-cloud-ml-engine-2ad2eeb189e8?source=collection_archive---------0-----------------------#2017-04-01</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="cdb8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">tf.contrib.learn中的Estimators API是开始使用TensorFlow的一种非常方便的方式。从我的角度来看，估算器API真正酷的地方在于，使用它是创建<strong class="ih hj">分布式</strong>张量流模型的一种非常简单的方式。您在互联网上看到的许多TensorFlow示例都不是分布式的，它们假设您将在一台机器上运行代码。人们从这样的代码开始，然后发现低级的TensorFlow代码实际上并不能在他们的完整数据集上工作，这让他们感到非常难过。然后，他们必须做大量的工作，在原始样本周围添加分布式训练代码，谁想编辑别人的代码呢？</p><blockquote class="jd je jf"><p id="559e" class="if ig jg ih b ii ij ik il im in io ip jh ir is it ji iv iw ix jj iz ja jb jc hb bi translated">N <!-- -->注:评估者现在已经进入核心张量流。<a class="ae jk" href="https://github.com/GoogleCloudPlatform/training-data-analyst/tree/master/courses/machine_learning/deepdive/09_sequence/sinemodel" rel="noopener ugc nofollow" target="_blank">使用tf.estimator而非tf.contrib.learn.estimator的更新代码现已在GitHub </a>上发布——使用更新后的代码作为起点。</p></blockquote><p id="cdfc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">所以，请，请，请，如果你看到一个TensorFlow样本，不使用估计API，忽略它。要让它在您的生产(大型)数据集上工作，需要做大量的工作——将会有监视器、协调器、参数服务器和各种您不想深入其中的系统编程狂热。从估计器API开始，使用实验类。(免责声明:我的观点，不是我雇主的观点)。</p><h1 id="011e" class="jl jm hi bd jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki bi translated">时间序列预测需要一个定制的估计器</h1><p id="3318" class="pw-post-body-paragraph if ig hi ih b ii kj ik il im kk io ip iq kl is it iu km iw ix iy kn ja jb jc hb bi translated">估计器API带有深度神经网络分类器和回归器。如果你有典型的结构化数据，遵循上面链接的教程或参加谷歌云的这个<a class="ae jk" href="https://cloud.google.com/training/courses/data-engineering" rel="noopener ugc nofollow" target="_blank">培训课程</a>(很快将在Coursera上提供)，你将开始创建机器学习模型，这些模型在你的关系数据仓库中的真实世界、大型数据集上工作。但是如果没有典型的结构化数据问题呢？在这种情况下，您通常需要创建一个定制的评估器。在这篇博文中，我将向你展示如何做到这一点。</p><p id="2be1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">您想要对其进行机器学习的一种常见数据类型是时序数据。本质上，您的输入是一组数字，您希望预测该序列中的下一个数字。在本文中，我将把它变得更一般一些，并假设您想要预测序列的最后两个<em class="jg">数字。正如计算机科学谚语所说，如果你能做两件事，你就能做n件事。</em></p><p id="ebe2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">用于序列间预测的传统神经网络结构被称为递归神经网络(RNN)。参见这篇<a class="ae jk" href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/" rel="noopener ugc nofollow" target="_blank">文章</a>和<a class="ae jk" href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/" rel="noopener ugc nofollow" target="_blank">这篇</a>文章，了解RNNs的简单介绍。但是你不需要知道如何实现一个RNN来使用它，所以一旦那些文章比你想要的更深入，退出。</p><p id="200d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了跟踪这篇文章，让<a class="ae jk" href="https://github.com/GoogleCloudPlatform/training-data-analyst/blob/master/blogs/timeseries/rnn_cloudmle.ipynb" rel="noopener ugc nofollow" target="_blank">在另一个浏览器窗口中打开我的Jupyter笔记本</a>。我在这里只展示了关键的代码片段。笔记本(和<a class="ae jk" href="https://github.com/GoogleCloudPlatform/training-data-analyst/tree/master/courses/machine_learning/deepdive/09_sequence/" rel="noopener ugc nofollow" target="_blank"> GitHub文件夹</a>)包含了所有的代码。</p><h1 id="5be9" class="jl jm hi bd jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki bi translated">模拟一些时间序列数据</h1><p id="09aa" class="pw-post-body-paragraph if ig hi ih b ii kj ik il im kk io ip iq kl is it iu km iw ix iy kn ja jb jc hb bi translated">用一个小的玩具数据集来学习通常更容易，你可以想生成多少就生成多少。真实的数据会有自己的怪癖！所以，让我们生成一组时间序列数据。每个序列将由10个数字组成。我们将使用前八个作为输入，后两个作为<em class="jg">标签</em>(即要预测的内容):</p><figure class="kp kq kr ks fd kt er es paragraph-image"><div class="er es ko"><img src="../Images/8e8d975a732ad79ec421b5e43035184f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1100/format:webp/1*heIQAa4sV1M-YaMvjXSc7g.png"/></div></figure><p id="11e9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">使用numpy (np)生成这些时序序列的代码:</p><pre class="kp kq kr ks fd kw kx ky kz aw la bi"><span id="9b3a" class="lb jm hi kx b fi lc ld l le lf">SEQ_LEN = 10<br/>def create_time_series():<br/>  freq = (np.random.random()*0.5) + 0.1  # 0.1 to 0.6<br/>  ampl = np.random.random() + 0.5  # 0.5 to 1.5<br/>  x = np.sin(np.arange(0,SEQ_LEN) * freq) * ampl<br/>  return x</span></pre><p id="cfd8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">把一堆这样的时序序列写成CSV文件(train.csv和valid.csv)我们就入行了。我们有数据。</p><h1 id="d805" class="jl jm hi bd jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki bi translated">输入函数</h1><p id="4012" class="pw-post-body-paragraph if ig hi ih b ii kj ik il im kk io ip iq kl is it iu km iw ix iy kn ja jb jc hb bi translated">TensorFlow中估算器API的工作方式是，您需要提供一个input_fn来读取您的数据。你没有提供x和y值。相反，您提供了一个返回输入和标签的函数。输入是所有输入的字典(张量的输入名),标签是张量。</p><p id="7f7b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在我们的例子中，我们的CSV文件只包含10个浮点数。默认值用于指定张量的数据类型。我们希望一次读取20行数据；这就是BATCH_SIZE。批次是执行梯度下降的样本数。你需要试验这个数字——如果太大，你的训练会很慢，如果太小，你的训练会反弹，不会收敛。因为我们只有输入，所以您给输入起的名字并不重要。我们称之为原始数据。</p><pre class="kp kq kr ks fd kw kx ky kz aw la bi"><span id="88e3" class="lb jm hi kx b fi lc ld l le lf">DEFAULTS = [[0.0] for x in xrange(0, SEQ_LEN)]<br/>BATCH_SIZE = 20<br/>TIMESERIES_COL = 'rawdata'<br/>N_OUTPUTS = 2  # in each sequence, 1-8 are features, and 9-10 is label<br/>N_INPUTS = SEQ_LEN - N_OUTPUTS</span></pre><p id="82a2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">估计器API想要的input_fn应该不带参数。然而，我们确实希望能够提供在命令行上读取的文件名。所以，让我们写一个read_dataset()函数，返回一个input_fn。</p><pre class="kp kq kr ks fd kw kx ky kz aw la bi"><span id="7f00" class="lb jm hi kx b fi lc ld l le lf"># read data and convert to needed format<br/>def read_dataset(filename, mode=tf.contrib.learn.ModeKeys.TRAIN):<br/>  def _input_fn():<br/>    num_epochs = 100 if mode == tf.contrib.learn.ModeKeys.TRAIN else 1</span></pre><p id="a913" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们要做的第一件事是决定历元的数量。这是我们需要浏览数据集的次数。如果我们是在训练，我们会浏览数据集100次，但是如果我们是在评估，我们只会浏览一次。</p><p id="1b7b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">接下来，我们将进行通配符扩展。很多时候，大数据程序会生成分片文件，如train.csv-0001-of-0036，因此，我们希望只提供train.csv*作为输入。我们使用它来填充文件名队列，然后使用TextLineReader来读取数据:</p><pre class="kp kq kr ks fd kw kx ky kz aw la bi"><span id="8f12" class="lb jm hi kx b fi lc ld l le lf"># could be a path to one file or a file pattern.<br/>input_file_names = tf.train.match_filenames_once(filename)<br/>filename_queue = tf.train.string_input_producer(<br/>        input_file_names, num_epochs=num_epochs, shuffle=True)</span><span id="1ad3" class="lb jm hi kx b fi lg ld l le lf">reader = tf.TextLineReader()<br/>    _, value = reader.read_up_to(filename_queue, num_records=BATCH_SIZE)</span><span id="8c09" class="lb jm hi kx b fi lg ld l le lf">value_column = tf.expand_dims(value, -1)</span></pre><p id="ae76" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">之后，我们对数据进行解码，将前8个数字作为输入，后两个数字作为标签。当我们读取它时，输入是一个8个张量的列表，每个张量的大小为1。使用tf.concat使其成为单个8xbatchsize张量。这很重要，因为估算者API想要张量而不是列表。</p><pre class="kp kq kr ks fd kw kx ky kz aw la bi"><span id="4387" class="lb jm hi kx b fi lc ld l le lf"># all_data is a list of tensors<br/>all_data = tf.decode_csv(value_column, record_defaults=DEFAULTS)<br/>inputs = all_data[:len(all_data)-N_OUTPUTS]  # first few values<br/>label = all_data[len(all_data)-N_OUTPUTS : ] # last few values<br/>   <br/># from list of tensors to tensor with one more dimension<br/>inputs = tf.concat(inputs, axis=1)<br/>label = tf.concat(label, axis=1)<br/>print 'inputs={}'.format(inputs)<br/>   <br/>return {TIMESERIES_COL: inputs}, label   # dict of features, label</span></pre><h1 id="ad22" class="jl jm hi bd jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki bi translated">定义RNN</h1><p id="dbbb" class="pw-post-body-paragraph if ig hi ih b ii kj ik il im kk io ip iq kl is it iu km iw ix iy kn ja jb jc hb bi translated">如果我们使用线性回归器、dnn回归器、DNNLinearCombinedRegressor等。，我们可以简单地使用现有的类。但是因为我们做的是序列到序列的预测，所以我们必须自己写模型函数。至少现在，估算器API还没有现成的RNNRegressor。因此，让我们使用低级张量流函数推出我们自己的RNN模型。</p><pre class="kp kq kr ks fd kw kx ky kz aw la bi"><span id="40ea" class="lb jm hi kx b fi lc ld l le lf">LSTM_SIZE = 3  <em class="jg"># number of hidden layers in each of the LSTM cells</em><br/><br/><em class="jg"># create the inference model</em><br/><strong class="kx hj">def</strong> simple_rnn(features, targets, mode):<br/>  <em class="jg"># 0. Reformat input shape to become a sequence</em><br/>  x = tf.split(features[TIMESERIES_COL], N_INPUTS, 1)<br/>  <em class="jg">#print 'x={}'.format(x)</em><br/>    <br/>  <em class="jg"># 1. configure the RNN</em><br/>  lstm_cell = rnn.BasicLSTMCell(LSTM_SIZE, forget_bias=1.0)<br/>  outputs, _ = rnn.static_rnn(lstm_cell, x, dtype=tf.float32)<br/><br/>  <em class="jg"># slice to keep only the last cell of the RNN</em><br/>  outputs = outputs[-1]<br/>  <em class="jg">#print 'last outputs={}'.format(outputs)</em><br/>  <br/>  <em class="jg"># output is result of linear activation of last layer of RNN</em><br/>  weight = tf.Variable(tf.random_normal([LSTM_SIZE, N_OUTPUTS]))<br/>  bias = tf.Variable(tf.random_normal([N_OUTPUTS]))<br/>  predictions = tf.matmul(outputs, weight) + bias<br/>    <br/>  <em class="jg"># 2. Define the loss function for training/evaluation</em><br/>  <em class="jg">#print 'targets={}'.format(targets)</em><br/>  <em class="jg">#print 'preds={}'.format(predictions)</em><br/>  loss = tf.losses.mean_squared_error(targets, predictions)<br/>  eval_metric_ops = {<br/>      "rmse": tf.metrics.root_mean_squared_error(targets, predictions)<br/>  }<br/>  <br/>  <em class="jg"># 3. Define the training operation/optimizer</em><br/>  train_op = tf.contrib.layers.optimize_loss(<br/>      loss=loss,<br/>      global_step=tf.contrib.framework.get_global_step(),<br/>      learning_rate=0.01,<br/>      optimizer="SGD")<br/><br/>  <em class="jg"># 4. Create predictions</em><br/>  predictions_dict = {"predicted": predictions}<br/>  <br/>  <em class="jg"># 5. return ModelFnOps</em><br/>  <strong class="kx hj">return</strong> tflearn.ModelFnOps(<br/>      mode=mode,<br/>      predictions=predictions_dict,<br/>      loss=loss,<br/>      train_op=train_op,<br/>      eval_metric_ops=eval_metric_ops)</span></pre><p id="ee49" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">回想一下，我们必须将输入打包成单个张量，然后将它作为特征从input_fn传递出去。步骤0简单地颠倒了这个过程，并得到张量的列表。</p><p id="d1be" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">递归神经网络由一个BasicLSTMLCell组成，您可以将输入传递给它。您会得到输出和状态。对其进行切片，仅保留RNN的最后一个像元—我们不使用任何先前的状态。其他架构也是可能的。例如，我可以训练网络总是只有一个输出，并使用滚动窗口。在本文的最后，我将讨论如何修改我的示例来做到这一点。</p><p id="7d91" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">关于其他步骤，上面代码中的注释是不言自明的。我们在那里没有做任何令人惊讶的事情。这是一个回归问题，所以我用RMSE。</p><h1 id="adc0" class="jl jm hi bd jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki bi translated">创造一个实验</h1><p id="0f6e" class="pw-post-body-paragraph if ig hi ih b ii kj ik il im kk io ip iq kl is it iu km iw ix iy kn ja jb jc hb bi translated">实验类是估计器API中的智能类。它知道如何采用模型函数、用于训练和验证的输入函数，并做关于分配、提前停止等合理的事情。所以，让我们把我们的作品交给它:</p><pre class="kp kq kr ks fd kw kx ky kz aw la bi"><span id="9ef3" class="lb jm hi kx b fi lc ld l le lf"><strong class="kx hj">def</strong> get_train():<br/>  <strong class="kx hj">return</strong> read_dataset('train.csv', mode=tf.contrib.learn.ModeKeys.TRAIN)<br/><br/><strong class="kx hj">def</strong> get_valid():<br/>  <strong class="kx hj">return</strong> read_dataset('valid.csv', mode=tf.contrib.learn.ModeKeys.EVAL)<br/><br/><strong class="kx hj">def</strong> experiment_fn(output_dir):<br/>    <em class="jg"># run experiment</em><br/>    <strong class="kx hj">return</strong> tflearn.Experiment(<br/>        tflearn.Estimator(model_fn=simple_rnn, model_dir=output_dir),<br/>        train_input_fn=get_train(),<br/>        eval_input_fn=get_valid(),<br/>        eval_metrics={<br/>            'rmse': tflearn.MetricSpec(<br/>                metric_fn=metrics.streaming_root_mean_squared_error<br/>            )<br/>        }<br/>    )<br/><br/>shutil.rmtree('outputdir', ignore_errors=True) <em class="jg"># start fresh each time</em><br/>learn_runner.run(experiment_fn, 'outputdir')</span></pre><h1 id="353e" class="jl jm hi bd jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki bi translated">云上培训</h1><p id="d7bf" class="pw-post-body-paragraph if ig hi ih b ii kj ik il im kk io ip iq kl is it iu km iw ix iy kn ja jb jc hb bi translated">上面的代码在单台机器上工作，如果您将其打包到Python模块中，您还可以将其提交到Cloud ML Engine，以无服务器的方式对其进行训练:</p><pre class="kp kq kr ks fd kw kx ky kz aw la bi"><span id="50e4" class="lb jm hi kx b fi lc ld l le lf">OUTDIR=gs://${BUCKET}/simplernn/model_trained<br/>JOBNAME=simplernn_$(date -u +%y%m%d_%H%M%S)<br/>REGION=us-central1<br/>gsutil -m rm -rf $OUTDIR<br/>gcloud ml-engine jobs submit training $JOBNAME \<br/>   --region=$REGION \<br/>   --module-name=trainer.task \<br/>   --package-path=${REPO}/simplernn/trainer \<br/>   --job-dir=$OUTDIR \<br/>   --staging-bucket=gs://$BUCKET \<br/>   --scale-tier=BASIC \<br/>   --runtime-version=1.0 \<br/>   -- \<br/>   --train_data_paths="gs://${BUCKET}/train.csv*" \<br/>   --eval_data_paths="gs://${BUCKET}/valid.csv*"  \<br/>   --output_dir=$OUTDIR \<br/>   --num_epochs=100</span></pre><h1 id="34f9" class="jl jm hi bd jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki bi translated">一个常见的变体:非常长的时间序列</h1><p id="2dc6" class="pw-post-body-paragraph if ig hi ih b ii kj ik il im kk io ip iq kl is it iu km iw ix iy kn ja jb jc hb bi translated">在本文中，我假设您有数千个短(10个元素)序列。如果你有一个很长的序列呢？例如，您可能有股票的价格或来自传感器的温度读数。在这种情况下，你能做的就是把你的长序列分解成固定长度的滚动序列。这个长度显然是任意的，但是可以把它想象成RNN的“回望”间隔。下面是TensorFlow代码，它将一个长序列分解成更小的固定长度的重叠序列:</p><pre class="kp kq kr ks fd kw kx ky kz aw la bi"><span id="ed53" class="lb jm hi kx b fi lc ld l le lf">import tensorflow as tf<br/>import numpy as np</span><span id="a6d6" class="lb jm hi kx b fi lg ld l le lf">def breakup(sess, x, lookback_len):<br/>  N = sess.run(tf.size(x))<br/>  windows = [tf.slice(x, [b], [lookback_len]) for b in xrange(0, N-lookback_len)]<br/>  windows = tf.stack(windows)<br/>  return windows</span></pre><p id="e59d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">例如:</p><pre class="kp kq kr ks fd kw kx ky kz aw la bi"><span id="23cf" class="lb jm hi kx b fi lc ld l le lf">x = tf.constant(np.arange(1,11, dtype=np.float32))<br/>with tf.Session() as sess:<br/>    print 'input=', x.eval()<br/>    seqx = breakup(sess, x, 5)<br/>    print 'output=', seqx.eval()</span></pre><p id="535a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">将导致:</p><pre class="kp kq kr ks fd kw kx ky kz aw la bi"><span id="9945" class="lb jm hi kx b fi lc ld l le lf">input= [  1.   2.   3.   4.   5.   6.   7.   8.   9.  10.]<br/>output= [[ 1.  2.  3.  4.  5.]<br/> [ 2.  3.  4.  5.  6.]<br/> [ 3.  4.  5.  6.  7.]<br/> [ 4.  5.  6.  7.  8.]<br/> [ 5.  6.  7.  8.  9.]]</span></pre><p id="f961" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">一旦你有了这些固定长度的序列，一切都和以前一样了。</p><p id="8566" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">编码快乐！</p></div></div>    
</body>
</html>