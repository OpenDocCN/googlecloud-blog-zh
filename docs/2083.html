<html>
<head>
<title>Aggregate Vertex AI model training logs in a BigQuery Table</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在BigQuery表中聚集顶点AI模型训练日志</h1>
<blockquote>原文：<a href="https://medium.com/google-cloud/aggregate-vertex-ai-model-training-job-logs-into-a-single-bigquery-table-6e074b90b5c2?source=collection_archive---------4-----------------------#2022-02-01">https://medium.com/google-cloud/aggregate-vertex-ai-model-training-job-logs-into-a-single-bigquery-table-6e074b90b5c2?source=collection_archive---------4-----------------------#2022-02-01</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="b9d1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Vertex AI将构建ML的谷歌云服务汇集在一个统一的UI和<a class="ae jd" href="https://googleapis.dev/python/aiplatform/latest/index.html" rel="noopener ugc nofollow" target="_blank"> API </a>之下。在Vertex AI中，您现在可以使用AutoML或自定义代码训练来轻松训练和比较模型，并且您的所有模型都存储在一个中央模型库中。这些模型现在可以部署到Vertex AI上的相同端点。</p><p id="5495" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果您正在编写自己的培训代码，而不是使用AutoML，那么有多种方式可以考虑进行定制培训。您可以创建三种类型的顶点AI资源来进行训练——自定义作业、超参数调整作业和训练管道。这些资源在执行时会生成资源类型为<strong class="ih hj"><em class="je">【ml _ job】</em></strong>的日志条目。</p><h1 id="6f85" class="jf jg hi bd jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc bi translated"><strong class="ak">挑战— </strong></h1><p id="f663" class="pw-post-body-paragraph if ig hi ih b ii kd ik il im ke io ip iq kf is it iu kg iw ix iy kh ja jb jc hb bi translated">云日志记录通过云日志记录API接收这些ML作业日志条目，在那里它们通过日志路由器。日志路由器中的接收器根据现有的包含过滤器(严重性、资源类型)和排除过滤器检查每个日志条目，这些过滤器确定日志条目应该发送到哪些目的地，包括云日志记录桶。接收器控制云日志记录路由日志的方式。使用接收器，您可以将部分或全部日志路由到受支持的目的地，BigQuery是受支持的目的地之一。我们可以创建如下所示的接收器，并将日志推送到提供的BigQuery数据集——</p><figure class="kj kk kl km fd kn er es paragraph-image"><div class="er es ki"><img src="../Images/6416c153c6daf548821c5bd41a98e763.png" data-original-src="https://miro.medium.com/v2/resize:fit:912/format:webp/1*FLL689oaXqnbbW7gJWDXKw.png"/></div><figcaption class="kq kr et er es ks kt bd b be z dx translated">将日志条目直接聚合到BQ的接收器详细信息</figcaption></figure><p id="a739" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">但是，对于新的作业id，在所选的BigQuery数据集中创建了一个新的表，连接多个表以对各种类似的训练作业进行聚合分析变得很麻烦，因为该接收器为每个作业id创建了新的表，如下所示</p><figure class="kj kk kl km fd kn er es paragraph-image"><div class="er es ku"><img src="../Images/4e7e9bc9a8f80e48ca284efff9ca96c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:964/format:webp/1*iMOAAuxZv101q1wsz4XP2g.png"/></div><figcaption class="kq kr et er es ks kt bd b be z dx translated">为每个作业id创建一个新表</figcaption></figure><h1 id="dafb" class="jf jg hi bd jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc bi translated">解决方案—</h1><p id="9e27" class="pw-post-body-paragraph if ig hi ih b ii kd ik il im ke io ip iq kf is it iu kg iw ix iy kh ja jb jc hb bi translated">另一个支持路由日志的目的地是Pub/Sub，它支持与其他服务的集成，如<strong class="ih hj">数据流</strong>，Splunk等。我们可以创建如下所示的接收器，将这些日志条目推送到发布/订阅服务器</p><figure class="kj kk kl km fd kn er es paragraph-image"><div class="er es kv"><img src="../Images/6fb77aae82ebd371a643b169a403134d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1132/format:webp/1*damR4tjFsdVLj6i5d6h5-w.png"/></div><figcaption class="kq kr et er es ks kt bd b be z dx translated">将日志条目聚合到发布/订阅的接收器详细信息</figcaption></figure><p id="34c1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Dataflow是一种统一的流和批处理数据处理服务，无服务器、快速且经济高效。它能够以更低的数据延迟实现快速、简化的流数据管道开发。使用Google提供的数据流模板(BigQuery的发布/订阅)，我们可以近乎实时地将日志条目推送到BQ。</p><p id="04c1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">BigQuery模板的发布/订阅是一个流管道，它从发布/订阅中读取JSON格式的消息，并将它们写入BigQuery表。您可以使用模板作为将发布/订阅数据移动到BigQuery的快速解决方案。该模板从Pub/Sub读取JSON格式的消息，并将它们转换成BigQuery元素。</p><p id="3c3e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">下面提到的流程使我们能够将所有ML培训工作的日志汇总到同一个BQ表中</p><figure class="kj kk kl km fd kn er es paragraph-image"><div class="er es kw"><img src="../Images/2ea29ea0b0019d378e227c1188e5baa5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1328/format:webp/1*6_C8iI2Waf0SZdHDPFUQrw.png"/></div><figcaption class="kq kr et er es ks kt bd b be z dx translated">将数据移动到BQ表的架构流程</figcaption></figure><p id="f5d3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">但是在ml作业创建的日志条目中，某些日志字段不符合BQ列命名约定(BQ列名只能包含' _ '或字母数字字符，而ml_job日志字段的名称类似于“ml.googleapis.com/job_state”)。</p><p id="9a2d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此，我们必须使用UDF来转换日志字段名，将所有特殊字符都改为“_”，这样它就符合BQ列命名约定，然后将数据移动到BQ表中。UDF(用户定义的函数)帮助客户使用他们的自定义逻辑扩展某些数据流模板，以动态转换记录。</p><p id="61ba" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">用于将日志字段更改为BQ兼容列名的UDF函数—</p><pre class="kj kk kl km fd kx ky kz la aw lb bi"><span id="542f" class="lc jg hi ky b fi ld le l lf lg">/**<br/> * User-defined function (UDF) to transform events<br/> * as part of a Dataflow template job.<br/> *<br/> * @param {string} inJson input Pub/Sub JSON message (stringified)<br/> * @return {string} outJson output JSON message (stringified)<br/> */<br/>function process(inJson) {<br/>  var obj = JSON.parse(inJson);<br/>  var keys = Object.keys(obj);<br/>  for each (var key in keys ) {<br/>      print(key);<br/>      if(key.indexOf("labels")!== -1)<br/>      {<br/>         for each (var item in Object.keys(obj[key]))<br/>         {<br/>             var newitem = item.replace(/([./!,])/g, "_")<br/>             //print(newitem)<br/>             obj[key][newitem] = obj[key][item]<br/>             delete obj[key][item]<br/>         }<br/>      }<br/>    //if(key.includes('.') || key.includes('/'))<br/>     //  {<br/>     //       var newkey = key.replace(['.','/']/g,'_')<br/>     //       obj[newkey] = obj[key]<br/>    //        delete obj[key]<br/>   //    }<br/>  };<br/>  if (!obj.hasOwnProperty('jsonPayload')) {<br/>      obj.hasOwnProperty('')<br/>    return JSON.stringify(obj);  }<br/>  }</span></pre><p id="0180" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">数据流作业管道选项，其中我们必须描述输出表规范，即BQ输出表(该表的模式必须与输入JSON对象相匹配)和UDF脚本路径</p><figure class="kj kk kl km fd kn er es paragraph-image"><div class="er es lh"><img src="../Images/d1aed95bdafd5d8e5718e44e10b4df10.png" data-original-src="https://miro.medium.com/v2/resize:fit:1176/format:webp/1*8nONYKdVxWsSqVmMLZJ4qw.png"/></div><figcaption class="kq kr et er es ks kt bd b be z dx translated">javascriptTextTransformGcsPath是UDF脚本在GCS中所处的路径</figcaption></figure><p id="a36b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">数据流作业的图形视图—</p><figure class="kj kk kl km fd kn er es paragraph-image"><div class="er es li"><img src="../Images/e56cc1cda98aeb030ea0d1ae2eaf1dba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1244/format:webp/1*Y7SHvO8LFfHY-RYvzO_wAA.png"/></div><figcaption class="kq kr et er es ks kt bd b be z dx translated">图表视图-数据流作业</figcaption></figure><p id="63d9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">上述过程将所有ML作业日志条目移动到单个BQ表中，从该表中可以很容易地对其进行分析。下图显示了多个作业的日志条目如何出现在同一个表中——</p><figure class="kj kk kl km fd kn er es paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="er es lj"><img src="../Images/c569f7644c59b46ade0eebe8b3a2eeaa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ABYzWtNx35-kSDP7bi7dOw.png"/></div></div><figcaption class="kq kr et er es ks kt bd b be z dx translated">多个作业的日志条目</figcaption></figure><h1 id="465e" class="jf jg hi bd jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc bi translated">总结一下-</h1><p id="33ae" class="pw-post-body-paragraph if ig hi ih b ii kd ik il im ke io ip iq kf is it iu kg iw ix iy kh ja jb jc hb bi translated">如果过滤器的聚合不是在开箱即用的单个BQ表中进行的，则该过程可以以通用方式用于任何资源类型或过滤器的聚合。如果需要，您只需修改UDF脚本来处理日志字段的更新转换。</p><h1 id="776e" class="jf jg hi bd jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc bi translated">参考文献-</h1><div class="lo lp ez fb lq lr"><a href="https://cloud.google.com/dataflow/docs/guides/templates/provided-streaming#pubsub-subscription-to-bigquery" rel="noopener  ugc nofollow" target="_blank"><div class="ls ab dw"><div class="lt ab lu cl cj lv"><h2 class="bd hj fi z dy lw ea eb lx ed ef hh bi translated">谷歌提供的流模板|云数据流|谷歌云</h2><div class="ly l"><h3 class="bd b fi z dy lw ea eb lx ed ef dx translated">对BigQuery模板的发布/订阅是一个流管道，它从发布/订阅中读取JSON格式的消息…</h3></div><div class="lz l"><p class="bd b fp z dy lw ea eb lx ed ef dx translated">cloud.google.com</p></div></div><div class="ma l"><div class="mb l mc md me ma mf ko lr"/></div></div></a></div><div class="lo lp ez fb lq lr"><a href="https://cloud.google.com/blog/topics/developers-practitioners/extend-your-dataflow-template-with-udfs" rel="noopener  ugc nofollow" target="_blank"><div class="ls ab dw"><div class="lt ab lu cl cj lv"><h2 class="bd hj fi z dy lw ea eb lx ed ef hh bi translated">使用UDF |谷歌云博客扩展您的数据流模板</h2><div class="ly l"><h3 class="bd b fi z dy lw ea eb lx ed ef dx translated">要配置的相关参数:gcs-location:数据流模板的gcs位置路径…</h3></div><div class="lz l"><p class="bd b fp z dy lw ea eb lx ed ef dx translated">cloud.google.com</p></div></div><div class="ma l"><div class="mg l mc md me ma mf ko lr"/></div></div></a></div></div></div>    
</body>
</html>