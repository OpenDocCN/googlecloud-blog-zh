<html>
<head>
<title>Airflow for Google Cloud: Part 1 — BigQuery</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Google Cloud的气流:第1部分— BigQuery</h1>
<blockquote>原文：<a href="https://medium.com/google-cloud/airflow-for-google-cloud-part-1-d7da9a048aa4?source=collection_archive---------0-----------------------#2017-01-20">https://medium.com/google-cloud/airflow-for-google-cloud-part-1-d7da9a048aa4?source=collection_archive---------0-----------------------#2017-01-20</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="61e0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">你知道大数据…这是一个肮脏的行业。所有的文献都向您展示了所有这些数据处理器和查询引擎有多么强大，但这一切都假设所有的数据都已准备好供消费。实际上，很多自动化数据流、Spark和BigQuery ETL流程都是用bash或Python粘在一起的。</p><p id="6421" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">好吧，是时候改变这一点了…看看<a class="ae jd" href="https://airflow.incubator.apache.org/" rel="noopener ugc nofollow" target="_blank">阿帕奇气流</a>。Airflow是一个工作流引擎，它将确保您的所有转换、处理和查询作业都能在正确的时间、顺序以及所需数据可供使用的时间运行。不再需要编写大量脆弱的样板代码来调度、重试和等待:只需关注工作流。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es je"><img src="../Images/0c9860fe96c2c8cac00e22acaaa9c489.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*27PLaAr2RH1UVWRARmctLg.jpeg"/></div></div><figcaption class="jq jr et er es js jt bd b be z dx translated"><a class="ae jd" href="https://unsplash.com/@jeisblack?photo=stLXUcN2Dac" rel="noopener ugc nofollow" target="_blank">https://unsplash.com/@jeisblack?photo=stLXUcN2Dac</a></figcaption></figure><p id="0df5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">2016年，大量工作被注入到气流中，使其成为谷歌云的一流工作流引擎。这个Medium系列将解释如何使用Airflow来自动化许多Google Cloud产品，并使数据从一个引擎平滑地过渡到另一个引擎。我不会深入研究如何将DAG构建到气流中，你应该阅读相关的文档。基本上所有的DAG都是通过Python对象构建的…我将把重点放在谷歌云集成上。</p><h1 id="1f2e" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">BigQuery集成</h1><p id="91db" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">在第一部分中，我们将解释如何从Airflow中自动化BigQuery任务。</p><pre class="jf jg jh ji fd kx ky kz la aw lb bi"><span id="4653" class="lc jv hi ky b fi ld le l lf lg"><strong class="ky hj"><em class="lh">Note</em></strong>: The series talks about the upcoming <strong class="ky hj">Airflow 1.8</strong>, make sure you have the latest verion. You can now pip install airflow.</span></pre><p id="a30b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">BigQuery是非常流行的交互式查询大型数据集的工具，但我也喜欢用它来存储大量临时数据。比起云存储上的文件，我更喜欢它，因为你可以在它上面做一些特别的探索性查询。因此，让我们开始使用Airflow将数据输入和输出BigQuery。</p><h2 id="477f" class="lc jv hi bd jw li lj lk ka ll lm ln ke iq lo lp ki iu lq lr km iy ls lt kq lu bi translated">问题</h2><p id="426a" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">第一个BigQuery集成是执行一个查询并将输出存储在一个新表中，这是通过<code class="du lv lw lx ky b">BigQueryOperator</code>完成的。操作符接受一个查询(或对查询文件的引用)和一个输出表。</p><figure class="jf jg jh ji fd jj"><div class="bz dy l di"><div class="ly lz l"/></div></figure><p id="4ce1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果你看一下<code class="du lv lw lx ky b"><strong class="ih hj">destination_dataset_table</strong></code>，你会注意到模板参数。Airflow使用jinja模板的强大功能，使您的工作流程更加动态和具有上下文意识。在我们的例子中，它将在<code class="du lv lw lx ky b"><strong class="ih hj">ds_nodash</strong></code>中填入当前的执行日期。气流中的执行日期是数据的上下文日期。例如，如果您计算7月4日的一些指标，<code class="du lv lw lx ky b"><strong class="ih hj">execution_date</strong></code>将是<code class="du lv lw lx ky b">2017–07–04T00:00:00+0</code>。</p><p id="c6d8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">您甚至可以在引用的查询中使用jinja模板。这是一个强大的工具，因为通常BigQuery API不支持参数，但是使用模板引擎可以模拟这种情况。</p><p id="bcc4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">关于什么是可能的以及什么类型的参数在上下文中可用的完整列表，请查看气流宏文档。</p><figure class="jf jg jh ji fd jj"><div class="bz dy l di"><div class="ly lz l"/></div></figure><p id="21d6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在我们的示例中，上述查询文件位于示例DAG旁边的文件系统中。</p><h2 id="b0e7" class="lc jv hi bd jw li lj lk ka ll lm ln ke iq lo lp ki iu lq lr km iy ls lt kq lu bi translated">提取到存储</h2><p id="ea2d" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">除了查询之外，您还想从BigQuery中获取数据。让我们从提取到云存储开始。</p><figure class="jf jg jh ji fd jj"><div class="bz dy l di"><div class="ly lz l"/></div></figure><p id="0d82" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">提取是一个非常常见的场景，用<code class="du lv lw lx ky b">BigQueryToCloudStorageOperator</code>来完成。熟悉BigQuery API的人会认识到许多参数，但基本上您必须指定源表和目标存储对象模式。但是指定一个模式很重要(例如:<code class="du lv lw lx ky b">…/part-.avro</code>)。该模式将确保如果您有大型表，那么每次提取都有多个存储对象。</p><p id="9225" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">再次注意jinja模板参数的使用。在这种情况下，我们读取气流中定义的变量，这对于区分不同环境非常有用，如<em class="lh">生产</em>或<em class="lh">测试</em>。</p><h2 id="751b" class="lc jv hi bd jw li lj lk ka ll lm ln ke iq lo lp ki iu lq lr km iy ls lt kq lu bi translated">从仓库装载</h2><p id="2a68" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">但是在进行查询和提取之前，您需要将数据放入BigQuery。<code class="du lv lw lx ky b">GoogleCloudStorageToBigQueryOperator</code>已经完成了。</p><figure class="jf jg jh ji fd jj"><div class="bz dy l di"><div class="ly lz l"/></div></figure><p id="45a7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">与提取相比，加载操作符确实有更多的参数。原因是您需要告诉BigQuery导入对象的一些元数据，比如模式和格式。通过指定<code class="du lv lw lx ky b">schema_fields</code>和<code class="du lv lw lx ky b">source_format</code>可以做到这一点。</p><p id="37ad" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">另一个需要指定的重要参数是<code class="du lv lw lx ky b">create_disposition</code>和<code class="du lv lw lx ky b">write_disposition</code>。我喜欢我的操作是可重复的，这样你就可以一次又一次地运行它们，所以<code class="du lv lw lx ky b"><strong class="ih hj">CREATE_IF_NEEDED</strong></code>和<code class="du lv lw lx ky b"><strong class="ih hj">WRITE_TRUNCATE</strong></code>是很好的默认值。只要确保您的表能够处理它，那么就使用分区表。现在，您必须使用名称中带有日期后缀的传统分区。在Airflow的下一个版本中，我们将添加对新的BigQuery分区的完全支持。</p><p id="5c42" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这个系列的下一篇文章中，我们将会看到气流驱动的Dataproc，到时候见。</p></div><div class="ab cl ma mb gp mc" role="separator"><span class="md bw bk me mf mg"/><span class="md bw bk me mf mg"/><span class="md bw bk me mf"/></div><div class="hb hc hd he hf"><p id="e609" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">示例摘自《谷歌云集成测试与示例的气流:<a class="ae jd" href="https://github.com/alexvanboxel/airflow-gcp-examples" rel="noopener ugc nofollow" target="_blank">https://github.com/alexvanboxel/airflow-gcp-examples</a></p></div></div>    
</body>
</html>