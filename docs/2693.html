<html>
<head>
<title>HBase to Bigtable Migration Strategy using Snapshots - Lab</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用快照的HBase到Bigtable迁移策略—实验室</h1>
<blockquote>原文：<a href="https://medium.com/google-cloud/hbase-to-bigtable-migration-strategy-using-snapshots-lab-37d3e6569def?source=collection_archive---------11-----------------------#2022-12-27">https://medium.com/google-cloud/hbase-to-bigtable-migration-strategy-using-snapshots-lab-37d3e6569def?source=collection_archive---------11-----------------------#2022-12-27</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/f5084270123c31caed5a0c8c99d2e542.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xHN5cMimctKTyRFbOWJq0w.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">Hbase到Bigtable迁移</figcaption></figure><p id="6555" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">HBase到云Bigtable的迁移包括从本地HBase表GCP云Bigtable中移动数据。在将数据从内部Hbase迁移到云时，Bigtable是首选，因为它是一个完全托管的、基于云的NoSQL数据库，还具有HBase兼容客户端，从而最大限度地减少了应用程序更改。</p><p id="62c0" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">虽然有许多关于HBase到BigTable迁移的参考资料，如<a class="ae js" href="https://cloud.google.com/architecture/hadoop/hadoop-gcp-migration-data-hbase-to-bigtable" rel="noopener ugc nofollow" target="_blank">将数据从HBase迁移到云Bigtable |将Hadoop迁移到GCP | Google Cloud </a>，但本博客的目的是提供详细的实施指南和样本数据集。</p><h1 id="160c" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">实验操作的先决条件:</h1><ol class=""><li id="ba35" class="kr ks hi iw b ix kt jb ku jf kv jj kw jn kx jr ky kz la lb bi translated">用HBase和Zookeeper WebUI创建一个<a class="ae js" href="https://cloud.google.com/dataproc/docs/tutorials/spark-hbase#create_a_cluster" rel="noopener ugc nofollow" target="_blank"> Dataproc集群</a>。</li><li id="0e86" class="kr ks hi iw b ix lc jb ld jf le jj lf jn lg jr ky kz la lb bi translated">为演示在Google云存储上创建一个样本<a class="ae js" href="https://cloud.google.com/storage/docs/creating-buckets#create_a_new_bucket" rel="noopener ugc nofollow" target="_blank">桶</a>。</li><li id="b49e" class="kr ks hi iw b ix lc jb ld jf le jj lf jn lg jr ky kz la lb bi translated">创建一个<a class="ae js" href="https://cloud.google.com/bigtable/docs/creating-instance#creating-instance" rel="noopener ugc nofollow" target="_blank">大表</a>实例。</li><li id="2e55" class="kr ks hi iw b ix lc jb ld jf le jj lf jn lg jr ky kz la lb bi translated">下载<a class="ae js" href="https://search.maven.org/artifact/com.google.cloud.bigtable/bigtable-beam-import/2.0.0/jar" rel="noopener ugc nofollow" target="_blank"> beam导入jar </a>和<a class="ae js" href="https://repo1.maven.org/maven2/com/google/cloud/bigtable/bigtable-hbase-1.x-tools/2.0.0/" rel="noopener ugc nofollow" target="_blank"> HBase到Bigtable模式转换jar </a>。</li><li id="af27" class="kr ks hi iw b ix lc jb ld jf le jj lf jn lg jr ky kz la lb bi translated">对于本实验，使用了样本数据文件<a class="ae js" href="https://github.com/avittala03/data-sample/blob/main/emp_data.csv" rel="noopener ugc nofollow" target="_blank"> emp_data </a>，可以下载并用于测试。</li></ol><h1 id="7977" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">概述和实施:</h1><p id="1cc6" class="pw-post-body-paragraph iu iv hi iw b ix kt iz ja jb ku jd je jf lh jh ji jj li jl jm jn lj jp jq jr hb bi translated">为了复制HBase到Bigtable迁移的场景，设置了一个预安装了Hbase的Dataproc集群。Hbase的配置细节可以在Dataproc上Hbase的WebUI中找到。</p><p id="11c9" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">由于从HBase区域服务器读取数据会直接影响实时HBase集群的性能，因此可以使用以下方法来捕获HBase中的数据并迁移到云Bigtable:</p><ol class=""><li id="4401" class="kr ks hi iw b ix iy jb jc jf lk jj ll jn lm jr ky kz la lb bi translated">从HBase集群获取表的快照</li><li id="cf3b" class="kr ks hi iw b ix lc jb ld jf le jj lf jn lg jr ky kz la lb bi translated">将快照导出到云存储桶</li><li id="e567" class="kr ks hi iw b ix lc jb ld jf le jj lf jn lg jr ky kz la lb bi translated">启动一个数据流作业来读取云存储桶中的快照，并将数据导入复制集群中的云Bigtable表。</li></ol><p id="085c" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">下图显示了迁移所需的详细步骤。</p><figure class="lo lp lq lr fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ln"><img src="../Images/4d8123123b5dcc90bf3a865c43e4e25f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4k_SkLxOKALbeuvLRo2wjg.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated"><em class="ls">云大表初始加载策略图</em></figcaption></figure><p id="74e3" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">下面是参考上图的详细步骤。</p><p id="2718" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hj">步骤1:迁移前状态</strong></p><p id="3846" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">在初始加载到BigTable之前，我们需要在GCP项目中准备和创建一些先决条件，如前面的先决条件步骤中所提到的。对于典型的客户环境，下面是在初始加载之前要做的关键事情。</p><ul class=""><li id="6916" class="kr ks hi iw b ix iy jb jc jf lk jj ll jn lm jr lt kz la lb bi translated">创建<a class="ae js" href="https://cloud.google.com/resource-manager/docs/creating-managing-projects#creating_a_project" rel="noopener ugc nofollow" target="_blank"> GCP项目</a></li><li id="63bf" class="kr ks hi iw b ix lc jb ld jf le jj lf jn lg jr lt kz la lb bi translated">创建GCP服务，如<a class="ae js" href="https://cloud.google.com/storage/docs/creating-buckets#create_a_new_bucket" rel="noopener ugc nofollow" target="_blank">桶</a>、<a class="ae js" href="https://cloud.google.com/compute/docs/instances/create-start-instance" rel="noopener ugc nofollow" target="_blank"> GCE </a></li><li id="8799" class="kr ks hi iw b ix lc jb ld jf le jj lf jn lg jr lt kz la lb bi translated">创建<a class="ae js" href="https://cloud.google.com/iam/docs/creating-managing-service-accounts#creating" rel="noopener ugc nofollow" target="_blank">服务帐户</a>和所需的IAM角色和权限</li><li id="b0a1" class="kr ks hi iw b ix lc jb ld jf le jj lf jn lg jr lt kz la lb bi translated">通过使用VM实例获得<a class="ae js" href="https://repo1.maven.org/maven2/com/google/cloud/bigtable/bigtable-hbase-1.x-tools/2.0.0/" rel="noopener ugc nofollow" target="_blank">模式转换工具</a></li><li id="117a" class="kr ks hi iw b ix lc jb ld jf le jj lf jn lg jr lt kz la lb bi translated">使用虚拟机实例获取<a class="ae js" href="https://search.maven.org/artifact/com.google.cloud.bigtable/bigtable-beam-import/2.0.0/jar" rel="noopener ugc nofollow" target="_blank">导入工具</a></li></ul><p id="67dd" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hj">步骤2:从Hbase服务器导出模式</strong></p><p id="f108" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">对于本实验，从<a class="ae js" href="https://github.com/avittala03/data-sample/blob/main/emp_data.csv" rel="noopener ugc nofollow" target="_blank"> emp_data </a>示例数据文件创建一个示例表。</p><pre class="lo lp lq lr fd lu lv lw bn lx ly bi"><span id="af40" class="lz ju hi lv b be ma mb l mc md">create 'emp_data',{NAME =&gt; 'cf'}</span></pre><p id="6e5d" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">将样本数据从csv加载到hbase表中</p><pre class="lo lp lq lr fd lu lv lw bn lx ly bi"><span id="ff0a" class="lz ju hi lv b be ma mb l mc md">hbase org.apache.hadoop.hbase.mapreduce.ImportTsv -Dimporttsv.separator=',' <br/>-Dimporttsv.columns='HBASE_ROW_KEY,cf:ename,cf:designation,cf:manager,cf:hire_date,cf:sal,cf:deptno' emp_data /user/aparnavittala/emp_data.csv</span></pre><p id="ad22" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">列出表的内容，以验证数据是否已加载。</p><pre class="lo lp lq lr fd lu lv lw bn lx ly bi"><span id="74ae" class="lz ju hi lv b be ma mb l mc md">scan 'emp_data'</span></pre><p id="9ba4" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">注意:在Hbase中，我们有类似于模式/数据库的名称空间。在这个例子中，为了简单起见，我们使用了默认的名称空间。</p><p id="2978" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">根据需要定义环境变量。</p><pre class="lo lp lq lr fd lu lv lw bn lx ly bi"><span id="2539" class="lz ju hi lv b be ma mb l mc md">PROJECT_ID=&lt;PROJECT_ID&gt;<br/>INSTANCE_ID=&lt;INSTANCE_ID&gt;<br/>TABLE_NAME_REGEX=&lt;TABLE_NAME&gt;<br/>ZOOKEEPER_QUORUM=&lt;ZOOKEEPER_QUORUM&gt;<br/>ZOOKEEPER_PORT=&lt;ZOOKEEPER_PORT&gt;</span></pre><p id="2cb3" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hj">步骤2:从Hbase表中获取快照。</strong></p><p id="1fec" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">通过从内部部署的边缘节点在hbase shell中执行以下命令来拍摄表快照。对于实验室，我们使用我们刚刚使用dataproc Hbase集群创建的表。</p><pre class="lo lp lq lr fd lu lv lw bn lx ly bi"><span id="d4ae" class="lz ju hi lv b be ma mb l mc md">hbase&gt; snapshot '&lt;tableName&gt;', '&lt;snapshotName&gt;'<br/>hbase&gt; snapshot 'emp_data', 'emp_data_snapshot'</span></pre><p id="608a" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">注意:确保hbase-site.xml中的“<em class="me">h base . snapshot . master . time out . millis</em>”和“<em class="me">h base . snapshot . region . time out</em>”属性设置为足够大的数字，以避免拍摄快照时超时。如果出于备份目的定期拍摄快照，这些属性应该会得到适当的调整。</p><p id="3b22" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hj">步骤3:创建用于验证的哈希</strong></p><p id="8167" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">接下来，在迁移完成后，创建用于验证的哈希。HashTable是HBase提供的一个验证工具，它计算行范围的散列并将它们导出到文件中。您可以在目标表上运行同步表作业，以匹配哈希值并增强对迁移数据完整性的信心。</p><p id="e653" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">对我们刚刚导出的表运行以下命令:</p><pre class="lo lp lq lr fd lu lv lw bn lx ly bi"><span id="e08f" class="lz ju hi lv b be ma mb l mc md">hbase org.apache.hadoop.hbase.mapreduce.HashTable - batchsize=32000 - numhashfiles=20 \<br/>emp_data /user/hbase/emp_data</span></pre><p id="ec7c" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hj">步骤4:安装GCS连接器</strong></p><p id="3f2b" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">本实验不需要此步骤。但是，对于典型的迁移场景，请确保按照如下所述安装GCS连接器。</p><p id="de33" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">云存储连接器库将安装在HBase集群上，并进行一些配置更改。可以在Hadoop集群(例如边缘节点)上执行以下步骤来配置对云存储的访问:</p><ol class=""><li id="df5a" class="kr ks hi iw b ix iy jb jc jf lk jj ll jn lm jr ky kz la lb bi translated"><a class="ae js" href="https://search.maven.org/search?q=g:com.google.cloud.bigdataoss%20AND%20a:gcs-connector%20AND%20v:hadoop2-*" rel="noopener ugc nofollow" target="_blank">下载云存储连接器</a>(<em class="me">GCS-connector-Hadoop 2–2 . 1 . 3-shaded . jar</em>)。确保阴影jar具有<em class="me"> -shaded.jar </em>后缀。</li><li id="c9c2" class="kr ks hi iw b ix lc jb ld jf le jj lf jn lg jr ky kz la lb bi translated">为云存储连接器JAR文件创建一个包，并将该包分发到集群中的所有主机。</li><li id="96ce" class="kr ks hi iw b ix lc jb ld jf le jj lf jn lg jr ky kz la lb bi translated">创建一个服务帐户(如果尚未创建)，并下载JSON格式的私钥。</li></ol><p id="75f8" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hj">步骤5:设置GCS连接器</strong></p><p id="7934" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">修改core-site.xml的以下属性，并将其分发给集群中的所有节点</p><ul class=""><li id="c034" class="kr ks hi iw b ix iy jb jc jf lk jj ll jn lm jr lt kz la lb bi translated"><em class="me"> fs。AbstractFileSystem.gs.impl </em></li><li id="8a50" class="kr ks hi iw b ix lc jb ld jf le jj lf jn lg jr lt kz la lb bi translated"><em class="me"> fs.gs.project.id </em></li><li id="9549" class="kr ks hi iw b ix lc jb ld jf le jj lf jn lg jr lt kz la lb bi translated"><em class="me">fs . GS . auth . service . account . enable</em></li><li id="db17" class="kr ks hi iw b ix lc jb ld jf le jj lf jn lg jr lt kz la lb bi translated"><em class="me">Google . cloud . auth . service . account . JSON . keyfile</em></li><li id="68a5" class="kr ks hi iw b ix lc jb ld jf le jj lf jn lg jr lt kz la lb bi translated"><em class="me">fs . GS . http . transport . type</em></li><li id="5a2f" class="kr ks hi iw b ix lc jb ld jf le jj lf jn lg jr lt kz la lb bi translated"><em class="me"> fs.gs.proxy.address(如果需要)</em></li><li id="25f1" class="kr ks hi iw b ix lc jb ld jf le jj lf jn lg jr lt kz la lb bi translated"><em class="me"> fs.gs.proxy.username(如果需要)</em></li><li id="95ec" class="kr ks hi iw b ix lc jb ld jf le jj lf jn lg jr lt kz la lb bi translated"><em class="me"> fs.gs.proxy.password(如果需要)</em></li></ul><p id="3bbf" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">修改Hadoop类路径以指向包中的云存储连接器jar文件。</p><pre class="lo lp lq lr fd lu lv lw bn lx ly bi"><span id="09d0" class="lz ju hi lv b be ma mb l mc md">export HADOOP_CLASSPATH=$HADOOP_CLASSPATH:/usr/lib/hadoop/lib/&lt;gcs-connector-jar-file&gt;</span></pre><p id="514a" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">验证对云存储桶的访问。</p><pre class="lo lp lq lr fd lu lv lw bn lx ly bi"><span id="d6b0" class="lz ju hi lv b be ma mb l mc md">hadoop fs -ls gs://&lt;GCS-BUCKET&gt;</span></pre><p id="5713" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hj">步骤6:运行Hbase导出快照作业</strong></p><p id="45b1" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">在Hadoop集群上的边缘节点上执行以下命令，将快照导出到云存储桶。</p><pre class="lo lp lq lr fd lu lv lw bn lx ly bi"><span id="d697" class="lz ju hi lv b be ma mb l mc md">hbase org.apache.hadoop.hbase.snapshot.ExportSnapshot -snapshot 'emp_hbase_snapshot' -copy-to gs://&lt;snapshot-bucket-name&gt; -mappers 3 -bandwidth 40</span></pre><ul class=""><li id="d857" class="kr ks hi iw b ix iy jb jc jf lk jj ll jn lm jr lt kz la lb bi translated">使用<em class="me">-映射器</em>选项控制导出作业中的映射器数量</li><li id="805f" class="kr ks hi iw b ix lc jb ld jf le jj lf jn lg jr lt kz la lb bi translated">使用<em class="me">-带宽</em>选项限制要使用的带宽</li><li id="4369" class="kr ks hi iw b ix lc jb ld jf le jj lf jn lg jr lt kz la lb bi translated">或者，也可以通过使用<em class="me">-dsnapshot . export . default . map . group</em>属性为每个映射器分配一定数量的HFiles来控制映射器的数量</li></ul><p id="ccf5" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">完成客户表导出的预期时间取决于网络带宽和映射器将底层HFiles复制到云存储的并行性。</p><p id="2ec1" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hj">步骤7: </strong> <a class="ae js" href="https://cloud.google.com/bigtable/docs/creating-instance#creating-instance" rel="noopener ugc nofollow" target="_blank"> <strong class="iw hj">从控制台或命令行创建一个大表实例</strong> </a> <strong class="iw hj">。</strong></p><p id="995c" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hj">步骤8:导入表模式</strong></p><p id="ec4f" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">我们可以使用模式转换器工具，或者使用导入和导出模式文件的替代方法。</p><p id="c0c4" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">如果您的HBase master位于私有VPC中或者无法连接到互联网，您可以将HBase模式导出到一个文件中，并使用该文件在Cloud Bigtable中创建表。否则，我们可以使用模式转换器工具。</p><p id="3501" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hj">使用模式转换器:</strong></p><p id="83a7" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">在可以连接到HBase的主机上，定义模式文件的导出位置。</p><pre class="lo lp lq lr fd lu lv lw bn lx ly bi"><span id="abcd" class="lz ju hi lv b be ma mb l mc md">HBASE_EXPORT_PATH=gs://hbase_test_load/output/hbase-schema.json</span></pre><p id="13fe" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">从主机运行导出工具。</p><pre class="lo lp lq lr fd lu lv lw bn lx ly bi"><span id="683d" class="lz ju hi lv b be ma mb l mc md">java \<br/>-Dgoogle.bigtable.table.filter=emp_data\<br/>-Dgoogle.bigtable.output.filepath=/home/aparnavittala/hbase-schema.json \<br/>-Dhbase.zookeeper.quorum=hive-hbase-test-m:2181 \<br/>-Dhbase.zookeeper.property.clientPort=2181 \<br/>-jar bigtable-hbase-1.x-tools-2.0.0-jar-with-dependencies.jar</span></pre><p id="d980" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">将模式文件复制到可以连接到Google Cloud的主机上。</p><pre class="lo lp lq lr fd lu lv lw bn lx ly bi"><span id="8abf" class="lz ju hi lv b be ma mb l mc md">gsutil cp /home/aparnavittala/hbase-schema.json gs://hbase_test_load/output/hbase-schema.json</span></pre><p id="1f3c" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">使用模式文件在云Bigtable中创建表</p><pre class="lo lp lq lr fd lu lv lw bn lx ly bi"><span id="9a1c" class="lz ju hi lv b be ma mb l mc md">gsutil cp gs://hbase_test_load/output/hbase-schema.json .<br/>java \<br/>-Dgoogle.bigtable.project.id=&lt;PROJECT-ID&gt; \<br/>-Dgoogle.bigtable.instance.id=&lt;BIGTABLE-INSTANCE-ID&gt; \<br/>-Dgoogle.bigtable.input.filepath=gs://hbase_test_load/output/hbase-schema.json \<br/>-jar bigtable-hbase-1.x-tools-2.0.0-jar-with-dependencies.jar</span></pre><p id="bf81" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">通过检查日志中的以下两条消息，验证模式转换器是否已成功运行。</p><p id="9b0a" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><em class="me">19:09:19.520[main]INFO c . g . c . b . h . t . hbaseschematranslator—读取包含1个表的模式。</em></p><p id="d035" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><em class="me">19:09:23.533[main]INFO c . g . c . b . h . t . hbaseschematranslator—在Bigtable中创建了表emp_data。</em></p><p id="c2dd" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hj">或者</strong>，我们可以按照<a class="ae js" href="http://If your HBase master is in a private VPC or can't connect to internet, you can export the HBase schema to a file and use that to create tables in Cloud Bigtable." rel="noopener ugc nofollow" target="_blank">这个</a>来导出和导入模式。</p><p id="6bcf" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hj">第9步:运行数据流作业</strong></p><p id="3234" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">准备好要将数据迁移到的表后，就可以导入和验证数据了。</p><ul class=""><li id="6049" class="kr ks hi iw b ix iy jb jc jf lk jj ll jn lm jr lt kz la lb bi translated">BigTable导入作业</li></ul><pre class="lo lp lq lr fd lu lv lw bn lx ly bi"><span id="7d94" class="lz ju hi lv b be ma mb l mc md">IMPORT_JAR="bigtable-beam-import-2.0.0-shaded.jar"<br/>java -jar $IMPORT_JAR importsnapshot \<br/> - runner=DataflowRunner \<br/> - project=&lt;PROJECT_ID&gt; \<br/> - bigtableInstanceId=&lt;BIGTABLE-INSTANCE-ID&gt; \<br/> - bigtableTableId=emp_data \<br/> - hbaseSnapshotSourceDir=gs://&lt;HBASE-SNAPSHOT-BUCKET&gt; \<br/> - snapshotName=emp_hbase_snapshot \<br/> - stagingLocation=gs://&lt;HBASE-SNAPSHOT-STAGING-BUCKET&gt;/staging \<br/> - tempLocation=gs://&lt;HBASE-SNAPSHOT-STAGING-BUCKET&gt;/staging/temp \<br/> - maxNumWorkers=3 \<br/> - region=us-central1</span></pre><figure class="lo lp lq lr fd ij er es paragraph-image"><div class="er es mf"><img src="../Images/c58b1e549c887e814b6425d6a0f8514f.png" data-original-src="https://miro.medium.com/v2/resize:fit:568/format:webp/1*fNZ-m71X_0sR_yD2mtdM_g.jpeg"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">数据流加载作业的屏幕截图</figcaption></figure><ul class=""><li id="0200" class="kr ks hi iw b ix iy jb jc jf lk jj ll jn lm jr lt kz la lb bi translated">数据验证作业</li></ul><pre class="lo lp lq lr fd lu lv lw bn lx ly bi"><span id="5cd1" class="lz ju hi lv b be ma mb l mc md">java -jar bigtable-beam-import-2.0.0-shaded.jar sync-table \<br/> - runner=dataflow \<br/> - project=&lt;PROJECT_ID&gt; \<br/> - bigtableInstanceId=&lt;BIGTABLE-INSTANCE-ID&gt; \<br/> - bigtableTableId=emp_data \<br/> - outputPrefix=gs://&lt;HBASE-LOAD-BUCKET&gt;/output-emp_data-$(date +"%s") \<br/> - stagingLocation=gs://&lt;HBASE-LOAD-BUCKET&gt;/sync-table/sync-table/staging \<br/> - hashTableOutputDir=gs://&lt;HBASE-LOAD-BUCKET&gt;/hashtable/emp_data \<br/> - tempLocation=gs:gs://&lt;HBASE-LOAD-BUCKET&gt;/temp \<br/> - region=us-central1</span></pre><figure class="lo lp lq lr fd ij er es paragraph-image"><div class="er es mg"><img src="../Images/2322eb1899c083192b52d436aa9aa4b6.png" data-original-src="https://miro.medium.com/v2/resize:fit:874/format:webp/1*lnIi9MZ1JCr9H1i1YeA16A.jpeg"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">验证作业的屏幕截图</figcaption></figure><p id="2ca2" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">在数据被导入和验证之后，初始加载活动就被认为完成了。</p><h2 id="1937" class="mh ju hi bd jv mi mj mk jz ml mm mn kd jf mo mp kh jj mq mr kl jn ms mt kp mu bi translated"><strong class="ak">常见问题:</strong></h2><ol class=""><li id="dd96" class="kr ks hi iw b ix kt jb ku jf kv jj kw jn kx jr ky kz la lb bi translated"><strong class="iw hj"> GCS连接器无法安装在Hbase集群上<br/>缓解措施:</strong>在HBase集群上安装GCS连接器。Hbase快照导出的推送机制是最常用且经过验证的方法。如果存在阻塞，请从DataProc Hbase中选择拉机制，这需要从身份验证和网络中进行额外的配置。</li><li id="e8fd" class="kr ks hi iw b ix lc jb ld jf le jj lf jn lg jr ky kz la lb bi translated"><strong class="iw hj">导出快照耗时太长<br/>缓解:</strong>与其他操作相比，此步骤将运行更长时间。有许多因素会影响将数据从内部Hbase导出到GCS所需的时间。如果需要，我们可能需要将快照分成多个批次。减少对生产系统影响的另一个缓解措施是在低时段运行该操作。</li><li id="065e" class="kr ks hi iw b ix lc jb ld jf le jj lf jn lg jr ky kz la lb bi translated"><strong class="iw hj">从GCS到BigTable的数据加载花费太长时间<br/>缓解:</strong>如果发生这种情况，根据监控中发现的瓶颈，考虑增加数据流节点或BigTable节点。</li><li id="3124" class="kr ks hi iw b ix lc jb ld jf le jj lf jn lg jr ky kz la lb bi translated"><strong class="iw hj">数据验证失败<br/>缓解:</strong>如果在BigTable加载后立即运行验证作业，它可能会失败。在触发验证作业之前，请等待几分钟(~5分钟)。如果作业仍然失败，请参考此处的<a class="ae js" href="https://cloud.google.com/architecture/hadoop/hadoop-gcp-migration-data-hbase-to-bigtable#verify-hbase-data" rel="noopener ugc nofollow" target="_blank">和</a>。</li><li id="4e98" class="kr ks hi iw b ix lc jb ld jf le jj lf jn lg jr ky kz la lb bi translated"><strong class="iw hj">h base与bitable中的表名不同<br/>缓解:</strong>有时我们可能想要更改BigTable上的表名。在这个场景中，我们可以使用<a class="ae js" href="https://github.com/googleapis/java-bigtable-hbase/tree/main/bigtable-hbase-1.x-parent/bigtable-hbase-1.x-tools#table-name-renaming" rel="noopener ugc nofollow" target="_blank"> this </a>文档并映射Hbase和Big Table的表名。</li></ol></div></div>    
</body>
</html>