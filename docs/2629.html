<html>
<head>
<title>Using Dataproc Serverless to migrate your Dataplex GCS data to Bigquery</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Dataproc Serverless将Dataplex GCS数据迁移到Bigquery</h1>
<blockquote>原文：<a href="https://medium.com/google-cloud/using-dataproc-serverless-to-migrate-your-dataplex-gcs-data-to-bigquery-1e47bc8de74c?source=collection_archive---------2-----------------------#2022-12-14">https://medium.com/google-cloud/using-dataproc-serverless-to-migrate-your-dataplex-gcs-data-to-bigquery-1e47bc8de74c?source=collection_archive---------2-----------------------#2022-12-14</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="a6aa" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi jd translated"><span class="l je jf jg bm jh ji jj jk jl di">我们</span>可以使用Dataproc Serverless来运行Spark batch工作负载，而无需配置和管理我们自己的集群。我们可以指定工作负载参数，然后将工作负载提交给Dataproc无服务器服务。</p><p id="6d06" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><a class="ae jm" href="https://cloud.google.com/dataproc-serverless/docs" rel="noopener ugc nofollow" target="_blank"> <em class="jn"> Dataproc无服务器</em> </a> <em class="jn">帮助用户完成整个基础设施管理工作—执行他们的</em><a class="ae jm" href="http://spark.apache.org/" rel="noopener ugc nofollow" target="_blank"><em class="jn">Apache Spark</em></a><em class="jn">工作负载用户是</em> <strong class="ih hj"> <em class="jn">而不是</em> </strong> <em class="jn"> </em> <strong class="ih hj"> <em class="jn">需要</em> </strong> <em class="jn">先创建一个集群才能执行任何操作。用户只需根据自己的使用情况选择一个模板，只需点击几下鼠标和几个命令，即可完成各自的工作。</em></p><figure class="jp jq jr js fd jt er es paragraph-image"><div role="button" tabindex="0" class="ju jv di jw bf jx"><div class="er es jo"><img src="../Images/885342a90ea4ef27340233261b49e778.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jPnJVWmWcaTPcDYiV_1Ogg.png"/></div></div></figure></div><div class="ab cl ka kb gp kc" role="separator"><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf"/></div><div class="hb hc hd he hf"><h2 id="62fa" class="kh ki hi bd kj kk kl km kn ko kp kq kr iq ks kt ku iu kv kw kx iy ky kz la lb bi translated">目标</h2><p id="d7cd" class="pw-post-body-paragraph if ig hi ih b ii lc ik il im ld io ip iq le is it iu lf iw ix iy lg ja jb jc hb bi translated">这篇博客文章将分享关于如何使用“<a class="ae jm" href="https://github.com/GoogleCloudPlatform/dataproc-templates/blob/main/java/src/main/java/com/google/cloud/dataproc/templates/dataplex/README.md" rel="noopener ugc nofollow" target="_blank">data plex GCS to big query</a>data proc无服务器模板”进行数据迁移的完整细节。该模板将数据从Dataplex GCS表中逐渐转移到BigQuery中。它将识别Dataplex GCS中的新分区，并将它们加载到BigQuery中。</p><p id="8c9a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jn">注意:如果Dataplex GCS表没有分区，那么将从GCS中读取整个表，并且目标BigQuery表将被覆盖。</em></p></div><div class="ab cl ka kb gp kc" role="separator"><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf"/></div><div class="hb hc hd he hf"><h2 id="3323" class="kh ki hi bd kj kk kl km kn ko kp kq kr iq ks kt ku iu kv kw kx iy ky kz la lb bi translated">设置您的GCP项目和基础设施</h2><ol class=""><li id="8181" class="lh li hi ih b ii lc im ld iq lj iu lk iy ll jc lm ln lo lp bi translated">登录到您的GCP项目并启用Dataproc API(如果它被禁用的话)</li><li id="ce89" class="lh li hi ih b ii lq im lr iq ls iu lt iy lu jc lm ln lo lp bi translated">确保子网启用了私有Google访问，如果您要使用GCP生成的“默认”VPC网络，那么也必须启用私有访问，如下所示:</li></ol><figure class="jp jq jr js fd jt er es paragraph-image"><div role="button" tabindex="0" class="ju jv di jw bf jx"><div class="er es lv"><img src="../Images/1d96118efc365e205a42ee7736e81987.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LPcitxbKUL7HHL3-fib42w.png"/></div></div></figure><pre class="jp jq jr js fd lw lx ly bn lz ma bi"><span id="3e9b" class="mb ki hi lx b be mc md l me mf">gcloud compute networks subnets update default --region=us-central1 --enable-private-ip-google-access</span></pre><p id="2a92" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">3.为jar文件创建一个GCS存储桶和暂存位置。</p><pre class="jp jq jr js fd lw lx ly bn lz ma bi"><span id="d4b0" class="mb ki hi lx b be mc md l me mf">export GCS_STAGING_BUCKET=”my-gcs-staging-bucket”<br/>gsutil mb gs://$GCS_STAGING_BUCKET</span></pre><p id="67ce" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">4.要配置Dataproc无服务器作业，您需要导出以下变量</p><p id="414b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du mg mh mi lx b">GCP_PROJECT</code>:运行Dataproc无服务器的GCP项目id。</p><p id="0cf9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du mg mh mi lx b">REGION</code>:运行Dataproc无服务器的区域。</p><p id="23c8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du mg mh mi lx b">GCS_STAGING_LOCATION</code> : GCS暂存桶位置，Dataproc将在此存储暂存资产(参见步骤3)。</p></div><div class="ab cl ka kb gp kc" role="separator"><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf"/></div><div class="hb hc hd he hf"><h2 id="c894" class="kh ki hi bd kj kk kl km kn ko kp kq kr iq ks kt ku iu kv kw kx iy ky kz la lb bi translated">执行Dataproc模板的步骤</h2><ol class=""><li id="ec11" class="lh li hi ih b ii lc im ld iq lj iu lk iy ll jc lm ln lo lp bi translated">克隆Dataproc模板库并导航到Java模板文件夹。</li></ol><pre class="jp jq jr js fd lw lx ly bn lz ma bi"><span id="6369" class="mb ki hi lx b be mc md l me mf">git clone https://github.com/GoogleCloudPlatform/dataproc-templates.git<br/>cd dataproc-templates/java</span></pre><p id="e509" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">2.获取身份验证凭据(以提交作业)。</p><pre class="jp jq jr js fd lw lx ly bn lz ma bi"><span id="297e" class="mb ki hi lx b be mc md l me mf">gcloud auth application-default login</span></pre><p id="5256" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">3.通过导出提交所需的变量来配置Dataproc无服务器作业(如下面<em class="jn">“设置您的GCP项目&amp;”</em>的步骤4中所述)。</p><pre class="jp jq jr js fd lw lx ly bn lz ma bi"><span id="4af9" class="mb ki hi lx b be mc md l me mf">export GCP_PROJECT=&lt;project_id&gt; # your Google Cloud project<br/>export REGION=&lt;region&gt; # your region for ex: us-central1<br/>export SUBNET=&lt;subnet&gt; # optional if you are using default<br/># export GCS_STAGING_LOCATION=&lt;gcs-staging-bucket-folder&gt; # already done at step 3(Under Setup your GCP Project &amp; Infra)</span></pre><p id="76b6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">4.下载Jar和属性文件。</p><pre class="jp jq jr js fd lw lx ly bn lz ma bi"><span id="79f8" class="mb ki hi lx b be mc md l me mf">export GCS_STAGING_LOCATION=gs://bucket/path/to/staging/folder/<br/>gsutil -u &lt;billing-project-id&gt; cp gs://dataplex-dataproc-templates-artifacts/dataproc-templates-1.0-SNAPSHOT.jar ${GCS_STAGING_LOCATION}<br/>gsutil -u &lt;billing-project-id&gt; cp gs://dataplex-dataproc-templates-artifacts/log4j-spark-driver-template.properties ${GCS_STAGING_LOCATION}</span></pre><p id="2a0e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">5.收集以下参数的值:</p><p id="e107" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du mg mh mi lx b">project.id</code>:目标BigQuery数据集和自定义SQL文件所在的GCP项目的Id。</p><p id="9f3f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du mg mh mi lx b">dataplex.gcs.bq.target.dataset</code>:data plex GCS资产将被迁移到的目标BigQuery数据集的名称。</p><p id="a927" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du mg mh mi lx b">gcs.bigquery.temp.bucket.name</code>:在数据装载到BigQuery之前临时保存数据的GCS桶。</p><p id="890f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du mg mh mi lx b">dataplex.gcs.bq.save.mode</code>:指定如何处理BigQuery中的现有数据(如果存在)。可以是以下任意一种:<code class="du mg mh mi lx b">errorifexists</code>、<code class="du mg mh mi lx b">append</code>、<code class="du mg mh mi lx b">overwrite</code>、<code class="du mg mh mi lx b">ignore</code>。默认为<code class="du mg mh mi lx b">errorifexists</code></p><p id="ec04" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du mg mh mi lx b">dataplex.gcs.bq.incremental.partition.copy</code>:指定模板是只复制新分区还是复制所有分区。如果设置为<code class="du mg mh mi lx b">no</code>现有分区，并且如果找到那么它将被覆盖。可以是以下任意一种<code class="du mg mh mi lx b">yes</code>、<code class="du mg mh mi lx b">no</code>。默认为<code class="du mg mh mi lx b">yes</code></p><p id="e2b4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">6.提供正确的论据:</p><p id="62bf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du mg mh mi lx b">--dataplexEntity</code>:要加载到BigQuery的Dataplex GCS表<br/>示例:<code class="du mg mh mi lx b">--dataplexEntityList "projects/{project_number}/locations/{location_id}/lakes/{lake_id}/zones/{zone_id}/entities/{entity_id_1}"</code></p><p id="d439" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du mg mh mi lx b">--partitionField</code>:如果该字段与<code class="du mg mh mi lx b">partitionType</code>一起指定，则该表按该字段分区。该字段应该是顶级时间戳或日期字段。</p><p id="5af1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du mg mh mi lx b">--partitionType</code>:支持的类型有:<code class="du mg mh mi lx b">HOUR</code>、<code class="du mg mh mi lx b">DAY</code>、<code class="du mg mh mi lx b">MONTH</code>、<code class="du mg mh mi lx b">YEAR</code></p><p id="a2a1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du mg mh mi lx b">--targetTableName</code>:指定要写入数据的表的名称。如果未指定此参数，实体的名称将用作表名。</p><p id="2558" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">7.执行以下命令:</p><pre class="jp jq jr js fd lw lx ly bn lz ma bi"><span id="57ea" class="mb ki hi lx b be mc md l me mf">gcloud dataplex tasks create &lt;task-id&gt; \<br/>    --project=&lt;project-id&gt; \<br/>    --location=&lt;region&gt; \<br/>    --vpc-sub-network-name=&lt;subnet&gt; \<br/>    --lake=&lt;dataplex-lake&gt; \<br/>    --trigger-type=ON_DEMAND \<br/>    --execution-service-account=&lt;execution service account&gt; \<br/>    --spark-main-class="com.google.cloud.dataproc.templates.main.DataProcTemplate" \<br/>    --spark-file-uris="${GCS_STAGING_LOCATION}log4j-spark-driver-template.properties" \<br/>    --container-image-java-jars="${GCS_STAGING_LOCATION}dataproc-templates-1.0-SNAPSHOT.jar" \<br/>    --execution-args=^::^TASK_ARGS="--template=DATAPLEXGCSTOBQ,\<br/>        --templateProperty=project.id=&lt;project-id&gt;,\<br/>        --templateProperty=dataplex.gcs.bq.target.dataset=&lt;dataset_name&gt;,\<br/>        --templateProperty=gcs.bigquery.temp.bucket.name=&lt;temp-bucket-name&gt;,\<br/>        --templateProperty=dataplex.gcs.bq.save.mode=append,\<br/>        --templateProperty=dataplex.gcs.bq.incremental.partition.copy=yes,\<br/>        --dataplexEntity=projects/{project_number}/locations/{location_id}/lakes/{lake_id}/zones/{zone_id}/entities/{entity_id_1},\<br/>        --partitionField=&lt;partition_field&gt;,\<br/>        --partitionType=&lt;DAY&gt;,\<br/>        --targetTableName=&lt;table_name&gt;,\<br/>        --customSqlGcsPath=&lt;gs://bucket/path/to/custom_sql.sql&gt;"</span></pre><p id="09df" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jn">注意:-可选地，可以提供一个自定义SQL来过滤将被复制到BigQuery的数据。<br/>模板将从一个GCS文件中读取一个定制的sql字符串。该文件的路径必须提供选项</em> <code class="du mg mh mi lx b">--customSqlGcsPath</code> <em class="jn">。自定义SQL必须引用FROM子句中的</em> <code class="du mg mh mi lx b">__table__</code> <em class="jn">，如下例所示:</em></p><pre class="jp jq jr js fd lw lx ly bn lz ma bi"><span id="38b4" class="mb ki hi lx b be mc md l me mf">SELECT <br/>    col1, col2<br/>FROM<br/>    __table__<br/>WHERE <br/>    id &gt; 100</span></pre><p id="3c26" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jn">此外，如果您需要</em> <a class="ae jm" href="https://cloud.google.com/dataproc-serverless/docs/concepts/properties" rel="noopener ugc nofollow" target="_blank"> <em class="jn">指定Dataproc无服务器支持的spark属性</em> </a> <em class="jn">，例如:调整驱动程序、内核、执行器等的数量，您可以编辑start.sh文件中的OPT_PROPERTIES值。</em></p><p id="67fb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">6.监控Spark批处理作业</p><p id="eb9b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">提交作业后，我们将能够在<a class="ae jm" href="https://console.cloud.google.com/dataproc/batches" rel="noopener ugc nofollow" target="_blank"> Dataproc批处理UI </a>中看到它。从那里，我们可以查看作业的指标和日志。</p></div><div class="ab cl ka kb gp kc" role="separator"><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf"/></div><div class="hb hc hd he hf"><h2 id="68ea" class="kh ki hi bd kj kk kl km kn ko kp kq kr iq ks kt ku iu kv kw kx iy ky kz la lb bi translated">参考</h2><ul class=""><li id="87f5" class="lh li hi ih b ii lc im ld iq lj iu lk iy ll jc mj ln lo lp bi translated"><a class="ae jm" href="https://cloud.google.com/dataproc-serverless/docs/overview" rel="noopener ugc nofollow" target="_blank"> Dataproc无服务器</a></li><li id="19fa" class="lh li hi ih b ii lq im lr iq ls iu lt iy lu jc mj ln lo lp bi translated"><a class="ae jm" href="https://github.com/GoogleCloudPlatform/dataproc-templates" rel="noopener ugc nofollow" target="_blank"> Dataproc模板库</a></li></ul><p id="b280" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如有任何疑问/建议，请联系:dataproc-templates-support-external@googlegroups.com</p></div></div>    
</body>
</html>