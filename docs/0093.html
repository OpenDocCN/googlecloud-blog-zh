<html>
<head>
<title>A to Z of Google Cloud Platform a personal selection -S- Streaming</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">谷歌云平台的a到Z个人精选-S流</h1>
<blockquote>原文：<a href="https://medium.com/google-cloud/a-to-z-of-google-cloud-platform-a-personal-selection-s-streaming-740428b77f9d?source=collection_archive---------0-----------------------#2016-04-24">https://medium.com/google-cloud/a-to-z-of-google-cloud-platform-a-personal-selection-s-streaming-740428b77f9d?source=collection_archive---------0-----------------------#2016-04-24</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="ca22" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我将主要谈论流式传输，我的意思是我不是指处理无界数据集，而是将数据作为从源到接收器的连续数据流进行馈送的过程。</p><p id="0e66" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果您有一个生成数据的过程，并且您不希望在上传数据之前在本地缓冲它，或者如果您希望将结果从计算管道直接发送到Google云存储中，那么流式传输非常有用。</p><p id="449a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">GCP有很多产品可以让你直接向他们传输数据流，也就是说，接受持续的数据流</p><p id="8509" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Pub/Sub —是GCP的工作平台，足够灵活，可以从各种来源接收数据，如遥测数据、游戏数据等，然后可以从Pub/Sub中删除数据，并将其传递到BigQuery、云存储、BigTable等接收器。管道是一个关键的部分。我在这里谈到了Pub/Sub <a class="ae jd" rel="noopener" href="/google-cloud/a-to-z-of-google-cloud-platform-a-personal-selection-p-pub-sub-130538dab6e5#.v2mudj5uc">，所以我不会在这篇文章中花更多的时间。</a></p><p id="c2ae" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">云存储——基于HTTP分块传输编码，使用gsutil工具或boto库支持<a class="ae jd" href="https://cloud.google.com/storage/docs/streaming" rel="noopener ugc nofollow" target="_blank">流传输</a>。流式数据允许您在云存储帐户可用时立即将数据传入传出，而无需先将数据保存到单独的文件中。许多场景要求数据最终存储在云存储中，例如，如果你想将计算管道的结果直接发送到谷歌云存储中，那么流式传输就是实现这一点的方法。</p><p id="b4ca" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">文档中的例子在这方面很棒，所以使用那里的例子来说明如何使用gsutil或boto。</p><p id="50f0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">使用gsutil将数据传输到管道中使用gsutil cp命令，并用破折号替换要复制的文件。以下示例显示了一个名为collect_measurements的流程，其输出被传输到一个名为data_measurements的Google云存储对象:</p><pre class="je jf jg jh fd ji jj jk jl aw jm bi"><span id="e213" class="jn jo hi jj b fi jp jq l jr js">collect_measurements | gsutil cp -gs://my_app_bucket/data_measurements</span></pre><p id="e634" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">使用boto传输数据流时，您可以使用以下命令:</p><pre class="je jf jg jh fd ji jj jk jl aw jm bi"><span id="1d58" class="jn jo hi jj b fi jp jq l jr js">dst_uri = boto.storage_uri(<em class="jt">&lt;bucket&gt;</em> + ‘/’ + <em class="jt">&lt;object&gt;</em>, ‘gs’)<br/>dst_uri.new_key().set_contents_from_stream(<em class="jt">&lt;stream object&gt;</em>)</span></pre><p id="06df" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此，用法示例如下:</p><pre class="je jf jg jh fd ji jj jk jl aw jm bi"><span id="dc5c" class="jn jo hi jj b fi jp jq l jr js">filename = ‘data_file’<br/>MY_BUCKET = ‘my_app_bucket’<br/>my_data = open(filename, ‘rb’)<br/>dst_uri = boto.storage_uri(MY_BUCKET + ‘/’ + filename, ‘gs’)<br/>dst_uri.new_key().set_contents_from_stream(my_data)</span></pre><p id="55a4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这会将名为data_file的文件流式上载到同名的对象:</p><p id="a7d1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">虽然这个例子演示了打开一个文件来获取输入流，但是您可以使用任何流对象来代替上面的my_data。</p><p id="876e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">你也可以在云存储源的地方进行流媒体下载</p><p id="d0e7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">大查询——通过使用tabledata()，您可以<a class="ae jd" href="https://cloud.google.com/bigquery/streaming-data-into-bigquery" rel="noopener ugc nofollow" target="_blank">将数据一次一条记录地流入大查询</a>。insertAll()方法。这种方法支持查询数据，而没有运行加载作业的延迟。</p><p id="15d2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">使用Python下面是一个示例代码片段，摘自说明如何使用Python的文档:</p><pre class="je jf jg jh fd ji jj jk jl aw jm bi"><span id="0399" class="jn jo hi jj b fi jp jq l jr js">def stream_row_to_bigquery(bigquery, project_id, dataset_id, table_name, row,</span><span id="3201" class="jn jo hi jj b fi ju jq l jr js">num_retries=5):</span><span id="33a6" class="jn jo hi jj b fi ju jq l jr js">insert_all_data = {</span><span id="8497" class="jn jo hi jj b fi ju jq l jr js">‘rows’: [{</span><span id="b84a" class="jn jo hi jj b fi ju jq l jr js">‘json’: row,</span><span id="6fc5" class="jn jo hi jj b fi ju jq l jr js"># Generate a unique id for each row so retries don’t accidentally</span><span id="1217" class="jn jo hi jj b fi ju jq l jr js"># duplicate insert</span><span id="9d43" class="jn jo hi jj b fi ju jq l jr js">‘insertId’: str(uuid.uuid4()),</span><span id="24bc" class="jn jo hi jj b fi ju jq l jr js">}]</span><span id="e99c" class="jn jo hi jj b fi ju jq l jr js">}</span><span id="f118" class="jn jo hi jj b fi ju jq l jr js">return bigquery.tabledata().insertAll(</span><span id="9623" class="jn jo hi jj b fi ju jq l jr js">projectId=project_id,</span><span id="1dce" class="jn jo hi jj b fi ju jq l jr js">datasetId=dataset_id,</span><span id="1bb1" class="jn jo hi jj b fi ju jq l jr js">tableId=table_name,</span><span id="3910" class="jn jo hi jj b fi ju jq l jr js">body=insert_all_data).execute(num_retries=num_retries)</span></pre><p id="44f8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">注意以下限制适用于<a class="ae jd" href="https://cloud.google.com/bigquery/streaming-data-into-bigquery" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj">将数据流式传输到BigQuery </strong> </a>。(直接取自文档)</p><ul class=""><li id="cde7" class="jv jw hi ih b ii ij im in iq jx iu jy iy jz jc ka kb kc kd bi translated"><strong class="ih hj">最大行大小:</strong> 1 MB</li><li id="4d05" class="jv jw hi ih b ii ke im kf iq kg iu kh iy ki jc ka kb kc kd bi translated"><strong class="ih hj"> HTTP请求大小限制:</strong> 10 MB</li><li id="c619" class="jv jw hi ih b ii ke im kf iq kg iu kh iy ki jc ka kb kc kd bi translated"><strong class="ih hj">每秒最大行数:</strong>每个表每秒100，000行。超过此数量将导致quota_exceeded错误。</li><li id="1114" class="jv jw hi ih b ii ke im kf iq kg iu kh iy ki jc ka kb kc kd bi translated"><strong class="ih hj">每个请求的最大行数:</strong> 500</li><li id="9f63" class="jv jw hi ih b ii ke im kf iq kg iu kh iy ki jc ka kb kc kd bi translated"><strong class="ih hj">每秒最大字节数:</strong>每个表每秒100 MB。超过此数量将导致quota_exceeded错误</li></ul><p id="f897" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我知道我说过我主要是要谈论流传输，但是那些一直在阅读本系列的人知道，我对没有真正在数据流上花费任何时间感到有点内疚(我在我的发布/订阅帖子的末尾快速打了个招呼)，所以我将在这里添加一篇关于流处理的文章。我们这样说是什么意思？我们正在讨论的<em class="jt">是一个</em>数据处理引擎，它是根据无限数据集(未绑定)设计的<em class="jt">。</em>来自Dataflow/ Apache Beam团队的Tyler在这个伟大的<a class="ae jd" href="http://radar.oreilly.com/2015/08/the-world-beyond-batch-streaming-101.html" rel="noopener ugc nofollow" target="_blank"> 101 </a>中很好地讨论了这个概念。</p><p id="e009" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">数据流需要与发布/订阅结合使用，以接受来自设备的数据流。</p><p id="20d8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在你的数据流代码中，你指定了一个发布/订阅，并使用<a class="ae jd" href="https://cloud.google.com/dataflow/model/pubsub-io" rel="noopener ugc nofollow" target="_blank">发布订阅</a>来读取主题。读取转换</p><p id="794e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">公共汽车。Read transform不断从Pub/Sub流中读取数据，并返回一个表示流中数据的无界字符串集合</p><p id="498a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">设置它只需要几行代码，下面是文档中的一个例子:</p><pre class="je jf jg jh fd ji jj jk jl aw jm bi"><span id="9ec1" class="jn jo hi jj b fi jp jq l jr js">PipelineOptions options = PipelineOptionsFactory.create();</span><span id="71e7" class="jn jo hi jj b fi ju jq l jr js">Pipeline p = Pipeline.create(options);</span><span id="7146" class="jn jo hi jj b fi ju jq l jr js">// streamData is Unbounded; apply windowing afterward.</span><span id="801f" class="jn jo hi jj b fi ju jq l jr js">PCollection&lt;String&gt; streamData =</span><span id="8f43" class="jn jo hi jj b fi ju jq l jr js">p.apply(PubsubIO.Read.named(“ReadFromPubsub”)</span><span id="6972" class="jn jo hi jj b fi ju jq l jr js">.topic(“/topics/my-topic”));</span></pre><p id="d7cf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我对设置如此简单印象深刻。</p></div></div>    
</body>
</html>