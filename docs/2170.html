<html>
<head>
<title>Serving a Spark ML model on Vertex AI using a CI/CD Pipeline with Cloud Build and Cloud Function</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用具有云构建和云功能的CI/CD管道在Vertex AI上提供Spark ML模型</h1>
<blockquote>原文：<a href="https://medium.com/google-cloud/serving-a-spark-ml-model-on-vertex-ai-using-a-ci-cd-pipeline-with-cloud-build-and-cloud-function-e659e00dc7c4?source=collection_archive---------1-----------------------#2022-04-27">https://medium.com/google-cloud/serving-a-spark-ml-model-on-vertex-ai-using-a-ci-cd-pipeline-with-cloud-build-and-cloud-function-e659e00dc7c4?source=collection_archive---------1-----------------------#2022-04-27</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="9c5b" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">银行应用程序</h2></div><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ix"><img src="../Images/8df4cc6a47bc62f9233521a7fb17d57f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*NteHROmR-WfHgjU1.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">图一。闪耀顶点AI</figcaption></figure><h2 id="62b4" class="jn jo hi bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">好吧，你说，我听！</h2><p id="f1b9" class="pw-post-body-paragraph kl km hi kn b ko kp ij kq kr ks im kt jy ku kv kw kc kx ky kz kg la lb lc ld hb bi translated">你对Google Cloud 上的<a class="ae le" href="https://cloud.google.com/data-science" rel="noopener ugc nofollow" target="_blank">数据科学有什么想看的想法吗？请通过填写</a><a class="ae le" href="https://forms.gle/H89eNLTVtCdpP1ro6" rel="noopener ugc nofollow" target="_blank">这张表格</a>让我知道。这对我以后的博文会有帮助=)</p><h2 id="2776" class="jn jo hi bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">放弃</h2><p id="eaf6" class="pw-post-body-paragraph kl km hi kn b ko kp ij kq kr ks im kt jy ku kv kw kc kx ky kz kg la lb lc ld hb bi translated">本文有<a class="ae le" href="https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/pipelines/google_cloud_pipelines_dataproc_tabular/google_cloud_pipeline_components_dataproc_tabular.ipynb" rel="noopener ugc nofollow" target="_blank">关于<a class="ae le" href="https://cloud.google.com/blog/topics/developers-practitioners/announcing-serverless-spark-components-vertex-ai-pipelines" rel="noopener ugc nofollow" target="_blank">顶点AI流水线</a>无服务器Spark组件的公告后续内容</a>。它代表了在<a class="ae le" href="https://cloud.google.com/architecture/spark-ml-model-with-vertexai#import-the-model-into-vertex-ai" rel="noopener ugc nofollow" target="_blank">解决方案参考</a>中描述的关于使用顶点AI服务Spark ML模型的应用。</p><p id="c5ba" class="pw-post-body-paragraph kl km hi kn b ko lf ij kq kr lg im kt jy lh kv kw kc li ky kz kg lj lb lc ld hb bi translated">我们假设你熟悉MLeap，顶点AI预测和Docker。如果您不是，请查看以下资源。</p><ul class=""><li id="3354" class="lk ll hi kn b ko lf kr lg jy lm kc ln kg lo ld lp lq lr ls bi translated"><a class="ae le" href="https://combust.github.io/mleap-docs/spark/" rel="noopener ugc nofollow" target="_blank"> MLeap Spark集成</a>将Spark模型序列化为MLeap包</li><li id="ae14" class="lk ll hi kn b ko lt kr lu jy lv kc lw kg lx ld lp lq lr ls bi translated">顶点人工智能预测文档创建一个<a class="ae le" href="https://cloud.google.com/vertex-ai/docs/predictions/use-custom-container" rel="noopener ugc nofollow" target="_blank">定制容器，用于从导出的模型中提供预测</a>。</li></ul><h2 id="f56f" class="jn jo hi bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">你将学到什么</h2><p id="baf1" class="pw-post-body-paragraph kl km hi kn b ko kp ij kq kr ks im kt jy ku kv kw kc kx ky kz kg la lb lc ld hb bi translated">如果你对Google Cloud上的“如何用Pyspark模型实现部署管道”或“MLOps对于MLlib模型是什么样子”有疑问，请继续阅读。</p><blockquote class="ly"><p id="5080" class="lz ma hi bd mb mc md me mf mg mh ld dx translated">如何在Vertex AI上实现部署管道来服务Spark MLlib模型？</p></blockquote><p id="a854" class="pw-post-body-paragraph kl km hi kn b ko mi ij kq kr mj im kt jy mk kv kw kc ml ky kz kg mm lb lc ld hb bi translated">在本文中，我将带您浏览上一篇文章的ML场景，展示如何在Vertex AI上操作Pyspark模型。特别是，我将展示一个持续部署Spark MLlib模型的解决方案，以获得在线和批量预测。</p><p id="ccd5" class="pw-post-body-paragraph kl km hi kn b ko lf ij kq kr lg im kt jy lh kv kw kc li ky kz kg lj lb lc ld hb bi translated">你和我在一起吗？开始吧！</p><h2 id="3992" class="jn jo hi bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">场景</h2><p id="94cc" class="pw-post-body-paragraph kl km hi kn b ko kp ij kq kr ks im kt jy ku kv kw kc kx ky kz kg la lb lc ld hb bi translated">为了设置场景，假设您是一家金融服务机构的数据科学团队的一员，负责支持银行业务。</p><p id="1092" class="pw-post-body-paragraph kl km hi kn b ko lf ij kq kr lg im kt jy lh kv kw kc li ky kz kg lj lb lc ld hb bi translated">您的公司希望使用ML自动确定客户贷款资格。</p><p id="89df" class="pw-post-body-paragraph kl km hi kn b ko lf ij kq kr lg im kt jy lh kv kw kc li ky kz kg lj lb lc ld hb bi translated">理想情况下，利益相关者希望有一个数据驱动的贷款资格引擎，对于每个贷款请求，该引擎根据客户的财务历史和贷款要求来确定客户是否有资格。</p><p id="8ae4" class="pw-post-body-paragraph kl km hi kn b ko lf ij kq kr lg im kt jy lh kv kw kc li ky kz kg lj lb lc ld hb bi translated">根据行业法规，决策必须是可解释的，并监控偏差。该解决方案必须是云本地的，因为该项目是该银行在谷歌云上更广泛的数字化转型之旅中的第一个ML解决方案。</p><p id="07e9" class="pw-post-body-paragraph kl km hi kn b ko lf ij kq kr lg im kt jy lh kv kw kc li ky kz kg lj lb lc ld hb bi translated">为了使该项目取得成功，主要利益相关方希望通过降低与当前手动流程相关的财务风险，更快地做出贷款资格决策并改善结果。</p><p id="df54" class="pw-post-body-paragraph kl km hi kn b ko lf ij kq kr lg im kt jy lh kv kw kc li ky kz kg lj lb lc ld hb bi translated">为了满足这些要求，你和你的团队决定在<a class="ae le" href="https://cloud.google.com/vertex-ai/docs/start/introduction-unified-platform" rel="noopener ugc nofollow" target="_blank"> Vertex AI </a>上实施贷款资格解决方案——谷歌云的托管ML平台，旨在处理所有数据科学&amp; MLOps用例。该平台有几个构建模块，覆盖了整个ML生命周期(从数据接收到模型监控)，允许数据科学团队根据在Google Cloud 上实施ML的<a class="ae le" href="https://cloud.google.com/architecture/ml-on-gcp-best-practices#machine-learning-workflow-orchestration" rel="noopener ugc nofollow" target="_blank">最佳实践构建数据产品。</a></p><h2 id="fd9c" class="jn jo hi bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">贷款资格数据集</h2><p id="56fb" class="pw-post-body-paragraph kl km hi kn b ko kp ij kq kr ks im kt jy ku kv kw kc kx ky kz kg la lb lc ld hb bi translated">在这个场景中，数据集是<a class="ae le" href="https://datasetsearch.research.google.com/search?src=0&amp;query=Loan%20Eligible%20Dataset&amp;docid=L2cvMTFsajJrM3EzcA%3D%3D" rel="noopener ugc nofollow" target="_blank">贷款资格数据集</a>的预处理版本。</p><p id="030b" class="pw-post-body-paragraph kl km hi kn b ko lf ij kq kr lg im kt jy lh kv kw kc li ky kz kg lj lb lc ld hb bi translated">原始数据集的信息模式的详细信息:</p><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="mn mo l"/></div></figure><h2 id="0ed9" class="jn jo hi bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">使用具有云构建的CI/CD部署管道在Vertex AI上提供Spark模型</h2><p id="a79e" class="pw-post-body-paragraph kl km hi kn b ko kp ij kq kr ks im kt jy ku kv kw kc kx ky kz kg la lb lc ld hb bi translated">假设您已经跟随<a class="ae le" href="https://cloud.google.com/blog/topics/developers-practitioners/announcing-serverless-spark-components-vertex-ai-pipelines" rel="noopener ugc nofollow" target="_blank">阅读了原始帖子</a>，让我们假设您已经训练了一个PySpark MLlib随机森林模型，并且您使用顶点AI管道在顶点AI元数据中注册了它。下面是您将在Vertex AI UI中看到的管道定义的执行图示例。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mp"><img src="../Images/dae10fad3e6c37ee29760d9e61e39e81.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*hEvxKCmBCw8KE11pBSk8MA.gif"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">图二。顶点AI UI中管道定义的执行图。</figcaption></figure><p id="fd43" class="pw-post-body-paragraph kl km hi kn b ko lf ij kq kr lg im kt jy lh kv kw kc li ky kz kg lj lb lc ld hb bi translated">为了这篇博文的目的，我们假设团队和利益相关者对模型的结果感到满意，并且已经为生产它开了绿灯。</p><p id="f03b" class="pw-post-body-paragraph kl km hi kn b ko lf ij kq kr lg im kt jy lh kv kw kc li ky kz kg lj lb lc ld hb bi translated">一旦获得批准，下一步就是将你的Spark模型部署到一个<a class="ae le" href="https://cloud.google.com/vertex-ai/docs/predictions/getting-predictions" rel="noopener ugc nofollow" target="_blank">顶点AI端点</a>。并且，根据期望的自动化水平，您和您的团队可以决定实现一个事件驱动的CI/CD模型部署管道，如图2所示。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mq"><img src="../Images/7b849b68b8c058ada708c562b451d416.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VB-k2237rC7b2ssoSSRaEQ.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">图3。云构建ML部署管道(点击放大)。</figcaption></figure><p id="6e73" class="pw-post-body-paragraph kl km hi kn b ko lf ij kq kr lg im kt jy lh kv kw kc li ky kz kg lj lb lc ld hb bi translated">正如博文的<a class="ae le" rel="noopener" href="/google-cloud/boost-up-a-helpdesk-chatbot-with-dialogflow-cx-tfx-and-vertex-ai-4999c26eef13">MLOps奖金部分</a>所述，模型部署在上线前需要一系列测试和验证步骤。这些步骤将由使用webhooks的模型注册中心事件触发。</p><p id="9c90" class="pw-post-body-paragraph kl km hi kn b ko lf ij kq kr lg im kt jy lh kv kw kc li ky kz kg lj lb lc ld hb bi translated">您可以使用一个<a class="ae le" href="https://cloud.google.com/functions" rel="noopener ugc nofollow" target="_blank">云函数</a>来模拟webhook，当一个HTTP请求被发送到这个函数的URL时，这个云函数就会被触发。</p><pre class="iy iz ja jb fd mr ms mt mu aw mv bi"><span id="2c46" class="jn jo hi ms b fi mw mx l my mz">curl -X POST "https://{REGION}-{PROJECT_ID}.cloudfunctions.net/deploy" \<br/>-H "Authorization: bearer $(gcloud auth print-identity-token) Content-Type:application/json" \<br/>--data '{data_str}'</span></pre><p id="e364" class="pw-post-body-paragraph kl km hi kn b ko lf ij kq kr lg im kt jy lh kv kw kc li ky kz kg lj lb lc ld hb bi translated">注意，HTTP POST请求主体中的<em class="na"> data_str </em>包含了CI/CD管道所需的构建参数——比如模型的状态(staged、validated等)。)或顶点AI端点的定义来部署模型。</p><p id="c5ea" class="pw-post-body-paragraph kl km hi kn b ko lf ij kq kr lg im kt jy lh kv kw kc li ky kz kg lj lb lc ld hb bi translated">一旦被触发，云功能提交云构建运行，以覆盖您使用<a class="ae le" href="https://pypi.org/project/google-cloud-build/" rel="noopener ugc nofollow" target="_blank"> google-cloud-build </a> SDK定义的CI/CD步骤。下面是一个构建函数的例子:</p><pre class="iy iz ja jb fd mr ms mt mu aw mv bi"><span id="7097" class="jn jo hi ms b fi mw mx l my mz">def get_build_job(bucket: str, source: str, artifact_uri: str,      project_id: str, mleap_runtime_image: str, image_tag: str, mleap_bundle_file_path: str, region: str, mleap_bundle_name: str,<br/>serving_image_uri: str, predict_route: str, health_route: str, endpoint_name: str, timeout: int):</span><span id="c452" class="jn jo hi ms b fi nb mx l my mz">"""<br/>   An utility function to get a build object<br/>   Args:<br/>       project_id: The name of the project<br/>       region: The name of the region<br/>       bucket: The name of the bucket<br/>       source: The GCS uri of the source code<br/>       model_uri: The GCS uri of the model<br/>       model_path: The path of the model<br/>       serving_signature: The default signature to deploy the model<br/>       model_name: The model name<br/>       serving_image_uri: The serving image uri<br/>       endpoint_name: The name of endpoint<br/>       timeout: The timeout of cloud build<br/><br/>   Returns: The build resource for the Cloud Build job<br/><br/>   """<br/>   build = cloudbuild_v1.Build()<br/>   build.source = Source(storage_source=StorageSource(bucket=bucket,<br/>                                                    object_=source))<br/>   build.steps = [<br/>                 <br/>       # Download target model<br/>       {'name': 'gcr.io/google.com/cloudsdktool/cloud-sdk',<br/>        'args': ['gsutil', '-m', 'cp', '-r', <br/>                 '${_ARTIFACT_URI}',  '.'],<br/>        'dir_': 'serving_bundle',<br/>        'id': 'Download model'},<br/><br/>       # Install dependencies<br/>       {'name': 'gcr.io/${_PROJECT_ID}/${_MLEAP_RUNTIME_IMAGE}:${_IMAGE_TAG}',<br/>        'entrypoint': 'pip',<br/>        'args': ['install', '-r',<br/>        './build_spark_serving_runtime/requirements.txt','--user'],<br/>        'id': 'Install requirements',<br/>        'wait_for': ['Download model']},<br/><br/>       # Run unit test<br/>       {'name': 'gcr.io/${_PROJECT_ID}/${_MLEAP_RUNTIME_IMAGE}:${_IMAGE_TAG}',<br/>        'entrypoint': 'python',<br/>        'args': ['-m', 'pytest', '-s',<br/>        './build_spark_serving_runtime/src/test_model.py'],<br/>        'env':['MLEAP_BUNDLE_FILE_PATH=${_MLEAP_BUNDLE_FILE_PATH}'],<br/>        'id': 'Run unit test',<br/>        'wait_for': ['Install requirements']<br/>        },<br/><br/>       # Integration test with the endpoint<br/>       {'name': 'gcr.io/${_PROJECT_ID}/${_MLEAP_RUNTIME_IMAGE}:${_IMAGE_TAG}',<br/>           'entrypoint': 'python',<br/>           'args': ['-m', 'pytest', './build_spark_serving_runtime/src/test_endpoint.py'],<br/>           'env': ['PROJECT_ID=${_PROJECT_ID}', <br/>                   'REGION=${_REGION}',<br/>                   'MLEAP_BUNDLE_NAME=${_MLEAP_BUNDLE_NAME}',<br/>                   'ARTIFACT_URI=${_ARTIFACT_URI}',         <br/>                   'SERVING_IMAGE_URI=${_SERVING_IMAGE_URI}',<br/>                  'SERVING_PREDICT_ROUTE=${_SERVING_PREDICT_ROUTE}',<br/>                  'SERVING_HEALTH_ROUTE=${_SERVING_HEALTH_ROUTE}',<br/>                  'ENDPOINT_NAME=${_ENDPOINT_NAME}'],<br/>           'id': 'Run integration test',<br/>           'wait_for': ['Run unit test']<br/>       },<br/>      <br/>       # Deploy the model<br/>       {<br/>           'name': 'gcr.io/${_PROJECT_ID}/${_MLEAP_RUNTIME_IMAGE}:${_IMAGE_TAG}',<br/>           'entrypoint': 'python',<br/>           'args': ['./build_spark_serving_runtime/src/deploy.py'],<br/>           'env': ['PROJECT_ID=${_PROJECT_ID}', 'REGION=${_REGION}',<br/>                   'MLEAP_BUNDLE_NAME=${_MLEAP_BUNDLE_NAME}',<br/>                   'ARTIFACT_URI=${_ARTIFACT_URI}',<br/>                   'SERVING_IMAGE_URI=${_SERVING_IMAGE_URI}',<br/>                  'SERVING_PREDICT_ROUTE=${_SERVING_PREDICT_ROUTE}',<br/>                   'SERVING_HEALTH_ROUTE=${_SERVING_HEALTH_ROUTE}',             <br/>                   'ENDPOINT_NAME=${_ENDPOINT_NAME}'],<br/>           'id': 'Deploy the validated model',<br/>           'wait_for': ['Run integration test']<br/>       }<br/><br/>   ]<br/><br/>   build.substitutions = {'_ARTIFACT_URI' : artifact_uri,<br/>                          '_PROJECT_ID': project_id,<br/>                          '_MLEAP_RUNTIME_IMAGE':<br/>                           mleap_runtime_image,<br/>                          '_IMAGE_TAG' : image_tag,<br/>                          '_MLEAP_BUNDLE_FILE_PATH':<br/>                           mleap_bundle_file_path,<br/>                          '_REGION': region,<br/>                          '_MLEAP_BUNDLE_NAME' : mleap_bundle_name,<br/>                          '_SERVING_IMAGE_URI': serving_image_uri,<br/>                          '_SERVING_PREDICT_ROUTE': predict_route,<br/>                          '_SERVING_HEALTH_ROUTE' : health_route,<br/>                          '_ENDPOINT_NAME': endpoint_name}</span><span id="1459" class="jn jo hi ms b fi nb mx l my mz">   build.timeout = Duration(seconds=timeout)<br/>   return build</span></pre><p id="66d9" class="pw-post-body-paragraph kl km hi kn b ko lf ij kq kr lg im kt jy lh kv kw kc li ky kz kg lj lb lc ld hb bi translated">基本上，在您下载了模型工件并安装了需求之后，您已经:</p><ul class=""><li id="e5bd" class="lk ll hi kn b ko lf kr lg jy lm kc ln kg lo ld lp lq lr ls bi translated">验证模型评分能力的单元测试</li><li id="6165" class="lk ll hi kn b ko lt kr lu jy lv kc lw kg lx ld lp lq lr ls bi translated">集成测试，以验证模型部署在顶点人工智能端点</li></ul><p id="014a" class="pw-post-body-paragraph kl km hi kn b ko lf ij kq kr lg im kt jy lh kv kw kc li ky kz kg lj lb lc ld hb bi translated">它将在部署模型之前运行。对于这两个测试场景，您可以使用定制的容器映像<a class="ae le" href="https://cloud.google.com/build/docs/configuring-builds/use-community-and-custom-builders#creating_a_custom_builder" rel="noopener ugc nofollow" target="_blank">作为构建器来重现数据科学团队用于模型实验和形式化的相同Spark运行时环境。在下面的代码块中，有一个docker文件的示例:</a></p><pre class="iy iz ja jb fd mr ms mt mu aw mv bi"><span id="399d" class="jn jo hi ms b fi mw mx l my mz">FROM python:3.7-stretch</span><span id="af2c" class="jn jo hi ms b fi nb mx l my mz"># Set Environment variables<br/>ENV SPARK_VERSION=3.1.2 \<br/>   HADOOP_VERSION=3.2 \<br/>   OPENJDK_VERSION=8</span><span id="8c36" class="jn jo hi ms b fi nb mx l my mz"># Basic Java Installation<br/>RUN apt-get update --yes &amp;&amp; \<br/>   apt-get install --yes --no-install-recommends \<br/>   'openjdk-$OPENJDK_VERSION-jdk-headless' &amp;&amp; \<br/>   apt-get clean &amp;&amp; rm -rf /var/lib/apt/lists/*<br/>ENV JAVA_HOME='/usr/lib/jvm/java-$OPENJDK_VERSION-openjdk-amd64'</span><span id="2763" class="jn jo hi ms b fi nb mx l my mz"># Basic Spark Installation<br/>WORKDIR /tmp<br/>RUN wget -q '<a class="ae le" href="https://archive.apache.org/dist/spark/spark-$SPARK_VERSION/spark-$SPARK_VERSION-bin-hadoop$HADOOP_VERSION.tgz'" rel="noopener ugc nofollow" target="_blank">https://archive.apache.org/dist/spark/spark-$SPARK_VERSION/spark-$SPARK_VERSION-bin-hadoop$HADOOP_VERSION.tgz'</a> &amp;&amp; \<br/>   tar xzf 'spark-$SPARK_VERSION-bin-hadoop$HADOOP_VERSION.tgz' -C /opt &amp;&amp; \<br/>   mv '/opt/spark-$SPARK_VERSION-bin-hadoop$HADOOP_VERSION' /opt/spark &amp;&amp; \<br/>   rm 'spark-$SPARK_VERSION-bin-hadoop$HADOOP_VERSION.tgz'<br/>ENV SPARK_HOME=/opt/spark<br/>ENV PYSPARK_PYTHON=python<br/>ENV PYTHONPATH=$PYTHONPATH:$SPARK_HOME/python</span><span id="36cb" class="jn jo hi ms b fi nb mx l my mz"># Build<br/>WORKDIR build<br/>COPY src src<br/>COPY model model</span><span id="8d9f" class="jn jo hi ms b fi nb mx l my mz"># Define default command for building the MLeap bundle<br/>CMD ['python', './src/build_mleap_bundle.py']</span></pre><p id="a33d" class="pw-post-body-paragraph kl km hi kn b ko lf ij kq kr lg im kt jy lh kv kw kc li ky kz kg lj lb lc ld hb bi translated">对于单元测试，您可以使用如下测试函数:</p><pre class="iy iz ja jb fd mr ms mt mu aw mv bi"><span id="8817" class="jn jo hi ms b fi mw mx l my mz">def test_model():</span><span id="70cd" class="jn jo hi ms b fi nb mx l my mz"># Set logger<br/> logger = set_logger()</span><span id="b14b" class="jn jo hi ms b fi nb mx l my mz"># Initiate spark session<br/> logger.info('Initiate Spark session')<br/> spark = (SparkSession.builder\<br/>       .master('local[*]')\<br/>       .appName('spark go live')\<br/>       .config('spark.jars.packages', <br/>               'ml.combust.mleap:mleap-runtime_2.12:0.19.0') \<br/>       .config('spark.jars.packages',<br/>               'ml.combust.mleap:mleap-base_2.12:0.19.0') \<br/>       .config('spark.jars.packages', <br/>               'ml.combust.mleap:mleap-spark_2.12:0.19.0')\<br/>       .config('spark.jars.packages', <br/>              'ml.combust.mleap:mleap-spark-extension_2.12:0.19.0')\<br/>       .getOrCreate())</span><span id="a443" class="jn jo hi ms b fi nb mx l my mz">  # Create a testing sample<br/> test = spark.createDataFrame(TEST_SAMPLE, DATA_SCHEMA)<br/> test.show(truncate=False)<br/>  # Is the model a pyspark.ml.tuning.CrossValidatorModel instance<br/> logger.info('Test Model instance')<br/> deserializedModel = PipelineModel.deserializeFromBundle(f'jar:file:{MLEAP_BUNDLE_FILE_PATH}')<br/> assert isinstance(deserializedModel, PipelineModel)</span><span id="f48f" class="jn jo hi ms b fi nb mx l my mz"># Are predictions a dataframe<br/> logger.info('Test predictions type')<br/> model_predictions = deserializedModel.transform(test)<br/> assert isinstance(model_predictions, DataFrame)</span><span id="2609" class="jn jo hi ms b fi nb mx l my mz"># Does the model generates predictions<br/> logger.info('Verify predictions')<br/> is_empty = model_predictions.rdd.isEmpty()<br/> assert not is_empty<br/> model_predictions.show(truncate=False)</span></pre><p id="cd41" class="pw-post-body-paragraph kl km hi kn b ko lf ij kq kr lg im kt jy lh kv kw kc li ky kz kg lj lb lc ld hb bi translated">在上面的示例中，您使用一个测试样本来验证spark模型在被正确反序列化后是否会生成预测。</p><p id="491f" class="pw-post-body-paragraph kl km hi kn b ko lf ij kq kr lg im kt jy lh kv kw kc li ky kz kg lj lb lc ld hb bi translated">对于集成测试，测试功能可以使用Vertex AI SDK来:</p><ul class=""><li id="1c5a" class="lk ll hi kn b ko lf kr lg jy lm kc ln kg lo ld lp lq lr ls bi translated">上传顶点人工智能模型</li><li id="450b" class="lk ll hi kn b ko lt kr lu jy lv kc lw kg lx ld lp lq lr ls bi translated">创建顶点AI端点</li><li id="dee5" class="lk ll hi kn b ko lt kr lu jy lv kc lw kg lx ld lp lq lr ls bi translated">将模型部署到端点</li><li id="bf77" class="lk ll hi kn b ko lt kr lu jy lv kc lw kg lx ld lp lq lr ls bi translated">通过传递实例样本来验证模型是否成功地为预测服务</li><li id="d418" class="lk ll hi kn b ko lt kr lu jy lv kc lw kg lx ld lp lq lr ls bi translated">摧毁端点</li><li id="69c3" class="lk ll hi kn b ko lt kr lu jy lv kc lw kg lx ld lp lq lr ls bi translated">删除模型</li></ul><p id="e483" class="pw-post-body-paragraph kl km hi kn b ko lf ij kq kr lg im kt jy lh kv kw kc li ky kz kg lj lb lc ld hb bi translated">在下面的代码示例中，我们将这些任务定义为集成测试的一部分:</p><pre class="iy iz ja jb fd mr ms mt mu aw mv bi"><span id="b84b" class="jn jo hi ms b fi mw mx l my mz">def test_endpoint():<br/>   """<br/>   An utility function to run the integration test<br/>   Returns: None</span><span id="21f7" class="jn jo hi ms b fi nb mx l my mz">"""</span><span id="a404" class="jn jo hi ms b fi nb mx l my mz"># Set logger<br/>   logger = set_logger()</span><span id="e4ab" class="jn jo hi ms b fi nb mx l my mz"># Initiate Vertex AI SDK client<br/>   logger.info('Initiate Vertex AI SDK client.')<br/>   vertex_ai.init(project=PROJECT_ID, location=REGION)</span><span id="bf91" class="jn jo hi ms b fi nb mx l my mz"># Upload the model on Vertex AI<br/>   logger.info('Upload the model on Vertex AI.')<br/>   model = deploy.upload_model(model_name=MLEAP_BUNDLE_NAME, artifact_uri=ARTIFACT_URI, serving_image_uri=SERVING_IMAGE_URI)</span><span id="a46a" class="jn jo hi ms b fi nb mx l my mz"># Create the Vertex AI Endpoint<br/>   logger.info('Create the Vertex AI Endpoint.')<br/>   endpoint = deploy.get_endpoint(endpoint_name=ENDPOINT_NAME, project_id=PROJECT_ID, region=REGION)</span><span id="d624" class="jn jo hi ms b fi nb mx l my mz"># Deploy the model<br/>   logger.info('Deploy the model.')<br/>   deployed_model = deploy.deploy_model(model=model, endpoint=endpoint, deployed_model_name=MLEAP_BUNDLE_NAME)</span><span id="a4f7" class="jn jo hi ms b fi nb mx l my mz"># Submit a prediction request.<br/>   logger.info('Submit a prediction request.')<br/>   predictions = deploy.get_prediction(endpoint=endpoint, instances=INSTANCES)<br/>   assert predictions<br/>   print(predictions)</span><span id="a2f1" class="jn jo hi ms b fi nb mx l my mz"># Delete the Vertex AI endpoint<br/>   logger.info('Delete the Vertex AI endpoint.')<br/>   deploy.delete_endpoint(endpoint=endpoint)</span><span id="329a" class="jn jo hi ms b fi nb mx l my mz"># Delete the Vertex AI model<br/>   logger.info('Delete the Vertex AI model.')<br/>   deploy.delete_model(model=model)</span></pre><p id="a776" class="pw-post-body-paragraph kl km hi kn b ko lf ij kq kr lg im kt jy lh kv kw kc li ky kz kg lj lb lc ld hb bi translated">一旦您触发了部署过程，您就可以使用Cloud Build中的日志来跟踪执行情况(图3)。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es nc"><img src="../Images/578f0990149bf844d27fa766eb09339d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vqaPyVQU4miWaPacI1HB7Q.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">图4。UI中云构建执行的日志(单击可缩放)。</figcaption></figure><p id="7536" class="pw-post-body-paragraph kl km hi kn b ko lf ij kq kr lg im kt jy lh kv kw kc li ky kz kg lj lb lc ld hb bi translated">现在，我们经过验证和测试的模型已经部署到端点，并准备好提供在线预测。在下面的代码示例中，我们可以看到使用Vertex AI SDK的在线预测请求的结果。</p><pre class="iy iz ja jb fd mr ms mt mu aw mv bi"><span id="6901" class="jn jo hi ms b fi mw mx l my mz">endpoint = vertex_ai.Endpoint.list(filter=f'display_name="{ENDPOINT_NAME}"')[0]<br/>endpoint.predict(instances=[[124.0, 'nan', 'Rural', 0.0, 2.41903, 2.09919, 0.0, 0.0, 0.0, 2.83818, 0.0, 0.0, 0.0]])</span><span id="a090" class="jn jo hi ms b fi nb mx l my mz">Prediction(predictions=[[[0.9655723725071873, 0.03442762749281267]]], deployed_model_id='856167714316615680', explanations=None)</span></pre><p id="31a6" class="pw-post-body-paragraph kl km hi kn b ko lf ij kq kr lg im kt jy lh kv kw kc li ky kz kg lj lb lc ld hb bi translated">值得注意的是，虽然我们在这篇文章中关注的是在线预测用例，但我们也可以提供批量预测。在这两种场景中，您都可以通过使用解决方案文章中提供的服务容器映像和Vertex AI端点来利用托管的可伸缩无火花服务环境。在下面的截图中，Vertex AI批量预测的UI显示了关于批量评分作业的一些细节作为示例(图4)。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es nd"><img src="../Images/33274793899bb12990605313db0e490f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_eEHp9CLjCF5T3LRFrkNWg.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">图5。用Spark模型对顶点AI预测进行在线和批量预测(点击可缩放)。</figcaption></figure><p id="b04b" class="pw-post-body-paragraph kl km hi kn b ko lf ij kq kr lg im kt jy lh kv kw kc li ky kz kg lj lb lc ld hb bi translated">最后，这里有一个样本(。jsonl)的批预测:</p><pre class="iy iz ja jb fd mr ms mt mu aw mv bi"><span id="8ac9" class="jn jo hi ms b fi mw mx l my mz">{"instance": [216.0, "360", "Urban", 0.0, 2.41903, 0.0, 0.0, 0.0, 2.09241, 2.83818, 0.0, 0.0, 2.69523], "prediction": [[0.8898546777486088, 0.11014532225139123]]}</span></pre><p id="6559" class="pw-post-body-paragraph kl km hi kn b ko lf ij kq kr lg im kt jy lh kv kw kc li ky kz kg lj lb lc ld hb bi translated">至此，我们的旅程结束了。让我们总结一些考虑事项和一些潜在的后续步骤。</p><h2 id="4974" class="jn jo hi bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">下一步是什么</h2><p id="ca33" class="pw-post-body-paragraph kl km hi kn b ko kp ij kq kr ks im kt jy ku kv kw kc kx ky kz kg la lb lc ld hb bi translated">在本文中，我们使用一个银行贷款资格场景来演示如何在Vertex AI上连续部署Spark MLlib模型进行在线和批量预测。</p><p id="2ed2" class="pw-post-body-paragraph kl km hi kn b ko lf ij kq kr lg im kt jy lh kv kw kc li ky kz kg lj lb lc ld hb bi translated">在撰写本文的过程中，我遇到了一些挑战，需要一些解决方法。一些关键的知识是围绕Spark依赖性和MLeap需求的——例如，当我开始研究这个用例时，MLeap不支持Spark 3 . 1 . 2(【https://github.com/combust/mleap/issues/805】)并且只支持一些允许的转换(<a class="ae le" href="https://github.com/combust/mleap/issues/784" rel="noopener ugc nofollow" target="_blank">【https://github.com/combust/mleap/issues/784】</a>)。这也很棘手，因为当我最初开始研究这个用例时，Vertex AI没有可用的Spark服务图像。</p><p id="93fd" class="pw-post-body-paragraph kl km hi kn b ko lf ij kq kr lg im kt jy lh kv kw kc li ky kz kg lj lb lc ld hb bi translated">我与几位同事合作，我们努力为使用Spark MLlib在Vertex AI上服务其模型的开发人员和从业人员提供这些功能。</p><p id="f2ae" class="pw-post-body-paragraph kl km hi kn b ko lf ij kq kr lg im kt jy lh kv kw kc li ky kz kg lj lb lc ld hb bi translated">可以想象，<strong class="kn hj">这还不是结束。</strong>以下是一些开放点:</p><ul class=""><li id="bf3b" class="lk ll hi kn b ko lf kr lg jy lm kc ln kg lo ld lp lq lr ls bi translated">有没有可能使用<a class="ae le" href="https://cloud.google.com/vertex-ai/docs/explainable-ai/overview" rel="noopener ugc nofollow" target="_blank">顶点可解释AI </a>用Spark模型生成解释？</li><li id="cbc9" class="lk ll hi kn b ko lt kr lu jy lv kc lw kg lx ld lp lq lr ls bi translated">用<a class="ae le" href="https://cloud.google.com/vertex-ai/docs/model-monitoring" rel="noopener ugc nofollow" target="_blank">顶点AI模型监控</a>监控一个Spark模型怎么样？</li></ul><p id="0f0f" class="pw-post-body-paragraph kl km hi kn b ko lf ij kq kr lg im kt jy lh kv kw kc li ky kz kg lj lb lc ld hb bi translated">总的来说，</p><blockquote class="ly"><p id="ebd6" class="lz ma hi bd mb mc md me mf mg mh ld dx translated">如果能有一个端到端的例子来展示整个Spark ML工作流在Vertex AI平台上的样子，岂不是很棒？</p></blockquote><p id="28ca" class="pw-post-body-paragraph kl km hi kn b ko mi ij kq kr mj im kt jy mk kv kw kc ml ky kz kg mm lb lc ld hb bi translated">如果你对以上问题的答案感兴趣，请在<a class="ae le" href="https://www.linkedin.com/in/ivan-nardini/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>、<a class="ae le" href="https://twitter.com/IlNardo92" rel="noopener ugc nofollow" target="_blank"> Twitter </a>上或者在下面留言告诉我。</p><p id="9ef2" class="pw-post-body-paragraph kl km hi kn b ko lf ij kq kr lg im kt jy lh kv kw kc li ky kz kg lj lb lc ld hb bi translated">我希望你喜欢这篇文章，直到下一个帖子…</p><p id="0057" class="pw-post-body-paragraph kl km hi kn b ko lf ij kq kr lg im kt jy lh kv kw kc li ky kz kg lj lb lc ld hb bi translated"><em class="na">感谢</em><a class="nf ng ge" href="https://medium.com/u/2e87ffc46e00?source=post_page-----e659e00dc7c4--------------------------------" rel="noopener" target="_blank"><em class="na">Win Woo</em></a><em class="na">迄今为止我们的合作令人敬畏。以及</em> <a class="nf ng ge" href="https://medium.com/u/6cfe83f12e3?source=post_page-----e659e00dc7c4--------------------------------" rel="noopener" target="_blank"> <em class="na">李</em> </a> <em class="na">对她的宝贵反馈和点评。</em></p><h2 id="9443" class="jn jo hi bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">参考</h2><ol class=""><li id="c272" class="lk ll hi kn b ko kp kr ks jy nh kc ni kg nj ld nk lq lr ls bi translated"><a class="ae le" href="https://spark.apache.org/docs/latest/ml-guide.html" rel="noopener ugc nofollow" target="_blank"> MLlib:主指南— Spark 3.2.1文档</a></li><li id="7430" class="lk ll hi kn b ko lt kr lu jy lv kc lw kg lx ld nk lq lr ls bi translated"><a class="ae le" href="https://combust.github.io/mleap-docs/" rel="noopener ugc nofollow" target="_blank"> MLeap文档手册</a></li><li id="8e8d" class="lk ll hi kn b ko lt kr lu jy lv kc lw kg lx ld nk lq lr ls bi translated"><a class="ae le" href="https://docs.docker.com/" rel="noopener ugc nofollow" target="_blank"> Docker文档</a></li><li id="9a52" class="lk ll hi kn b ko lt kr lu jy lv kc lw kg lx ld nk lq lr ls bi translated"><a class="ae le" href="https://cloud.google.com/functions/docs" rel="noopener ugc nofollow" target="_blank">云函数文档</a></li><li id="e5f4" class="lk ll hi kn b ko lt kr lu jy lv kc lw kg lx ld nk lq lr ls bi translated"><a class="ae le" href="https://cloud.google.com/build/docs" rel="noopener ugc nofollow" target="_blank">云构建文档</a></li><li id="fb82" class="lk ll hi kn b ko lt kr lu jy lv kc lw kg lx ld nk lq lr ls bi translated"><a class="ae le" href="https://cloud.google.com/vertex-ai/docs" rel="noopener ugc nofollow" target="_blank">顶点AI文档|谷歌云</a></li></ol></div><div class="ab cl nl nm gp nn" role="separator"><span class="no bw bk np nq nr"/><span class="no bw bk np nq nr"/><span class="no bw bk np nq"/></div><div class="hb hc hd he hf"><p id="05a2" class="pw-post-body-paragraph kl km hi kn b ko lf ij kq kr lg im kt jy lh kv kw kc li ky kz kg lj lb lc ld hb bi translated">在我写这篇文章的时候，Spark模型在Vertex AI模型注册表中还不被支持。</p></div></div>    
</body>
</html>