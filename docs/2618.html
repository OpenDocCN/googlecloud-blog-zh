<html>
<head>
<title>Data Migration from Snowflake to Bigquery using GCP Dataproc</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用GCP Dataproc从雪花到Bigquery的数据迁移</h1>
<blockquote>原文：<a href="https://medium.com/google-cloud/data-migration-from-snowflake-to-bigquery-using-gcp-dataproc-f10e88f4d51a?source=collection_archive---------2-----------------------#2022-12-12">https://medium.com/google-cloud/data-migration-from-snowflake-to-bigquery-using-gcp-dataproc-f10e88f4d51a?source=collection_archive---------2-----------------------#2022-12-12</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="3217" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在本文中，我将讨论使用Dataproc上的Spark作为ETL处理引擎将数据从雪花迁移到BigQuery。该博客涵盖了历史数据迁移的高级设计、增量批量复制以及使用ETL方法实现CDC的方法。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/ba77e095070d76c090c90e5c32376cb9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DYuAClT-IGDLhTIXI8x7dw.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">雪花到BigQuery</figcaption></figure><p id="3f37" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">雪花是一个全面管理的SaaS工具，为数据仓库解决方案提供了一个单一的平台。雪花是一个云原生工具，可以托管在GCP、AWS和Azure上。雪花在数据治理、工具、服务、sql支持、连接、复制和数据共享方面提供了一系列丰富的功能。</p><h1 id="317e" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">使用外部阶段作为云存储迁移到BQ的通用方法</h1><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es kr"><img src="../Images/100fa603376c067886233c473bd17d3a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QEFekRX8KlfG5U09KaGWgw.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">通过创建外部阶段进行数据迁移</figcaption></figure><p id="ec0b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">雪花提供了从其他来源导入和导出数据的功能。将数据导出到其他接收器最常用的方法之一是创建外部阶段。雪花提供了在AWS S3、Azure storage和Google云存储上创建外部stages的选项。</p><p id="6441" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于与谷歌云存储的集成，雪花使用具有云存储权限的服务帐户进行身份验证，并将数据加载到GCP云存储桶的外部阶段。要在雪花上创建外部存储桶，用户必须是帐户管理员。一旦创建了外部阶段，数据就被直接复制到云存储中。雪花支持多种数据格式，如csv、json、parquet、avro等。</p><p id="f817" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">然后，可以使用BQ数据传输服务将写入云存储的数据加载到BigQuery。该服务需要关于存储位置、BigQuery数据集、BigQuery表和写入模式(追加或覆盖)的输入。</p><p id="e3c3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">尽管这种方法看起来简单且易于实现，但它的局限性很小。</p><ol class=""><li id="3160" class="ks kt hi ih b ii ij im in iq ku iu kv iy kw jc kx ky kz la bi translated">该方法可用于一次性迁移。如果需要定期复制，此方法对于自动执行定期复制没有用。</li><li id="48ef" class="ks kt hi ih b ii lb im lc iq ld iu le iy lf jc kx ky kz la bi translated">为了使这种方法有效，数据用户必须是雪花帐户的所有者，因为它需要一个帐户管理员角色来创建外部存储。如果用户有一个雪花阅读器帐户，这种方法是不可行的。</li><li id="1978" class="ks kt hi ih b ii lb im lc iq ld iu le iy lf jc kx ky kz la bi translated">提取和加载管道是一种手动方法，依赖于Snowflake来导出数据。</li></ol><h1 id="9721" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">使用Dataproc将数据从雪花迁移到BigQuery</h1><p id="f4c0" class="pw-post-body-paragraph if ig hi ih b ii lg ik il im lh io ip iq li is it iu lj iw ix iy lk ja jb jc hb bi translated">正在提出的Dataproc数据迁移方法将克服这些挑战，并提供对ETL管道的更多控制，消除对雪花的所有依赖。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es ll"><img src="../Images/aac8dfec199dbfbf125558cea1ad9c54.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YRS9E0UdMv-Qs-Ylv2bRsA.png"/></div></div></figure><p id="768c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">组件:</p><ol class=""><li id="fadb" class="ks kt hi ih b ii ij im in iq ku iu kv iy kw jc kx ky kz la bi translated">云调度程序—云调度程序是一个完全托管的企业级cron作业调度程序。Cloud scheduler可以调度任何Dataproc批处理作业和基础设施操作。它能够监控作业，并在失败时执行自动重试。</li><li id="828f" class="ks kt hi ih b ii lb im lc iq ld iu le iy lf jc kx ky kz la bi translated">Secret Manager——Secret Manager是一种安全便捷的服务，用于存储API密钥、密码、证书和其他敏感信息。</li><li id="fff8" class="ks kt hi ih b ii lb im lc iq ld iu le iy lf jc kx ky kz la bi translated">data proc——data proc是一个完全托管的、高度可伸缩的服务，用于运行Apache Hadoop和Apache Spark工作负载。</li><li id="2bd6" class="ks kt hi ih b ii lb im lc iq ld iu le iy lf jc kx ky kz la bi translated">GCP数据仓库服务。这是一种用于存储和分析数据的无服务器服务。</li><li id="747e" class="ks kt hi ih b ii lb im lc iq ld iu le iy lf jc kx ky kz la bi translated">日志记录— GCP日志记录服务，用于存储和检索监控日志。</li></ol><p id="cff9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">架构流程</p><ol class=""><li id="a225" class="ks kt hi ih b ii ij im in iq ku iu kv iy kw jc kx ky kz la bi translated">要迁移的数据存储在雪花上。要连接到雪花帐户，需要以下参数-雪花帐户、雪花用户、雪花密码或私钥、数据库和表名称、数据仓库名称(可选)。</li><li id="50b2" class="ks kt hi ih b ii lb im lc iq ld iu le iy lf jc kx ky kz la bi translated">Cloud Scheduler在Dataproc无服务器批处理上提交定制的Spark应用程序。</li><li id="03ee" class="ks kt hi ih b ii lb im lc iq ld iu le iy lf jc kx ky kz la bi translated">Spark应用程序通过使用存储在Secret Manager上的雪花连接凭证来建立到雪花的连接。</li><li id="3fad" class="ks kt hi ih b ii lb im lc iq ld iu le iy lf jc kx ky kz la bi translated">一旦连接建立，spark引擎从Snowflake读取数据，并将数据存储在Dataproc集群的“内存存储”中。</li><li id="9823" class="ks kt hi ih b ii lb im lc iq ld iu le iy lf jc kx ky kz la bi translated">管道是一个“提取&amp;加载”过程，假设不需要转换，spark引擎可以直接将数据加载到BigQuery。如果需要某些转换，如数据类型转换、时间戳转换，spark engine可以转换数据。</li><li id="ff97" class="ks kt hi ih b ii lb im lc iq ld iu le iy lf jc kx ky kz la bi translated">系统日志直接写入云日志。对于自定义日志，云日志代理用于移动日志。</li></ol><h1 id="228c" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">内部工作</h1><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es lm"><img src="../Images/525f23f2d81b3975d504f0949f410a6b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*z436Cm1rJYLcGp0wyUaoxA.png"/></div></div></figure><ol class=""><li id="d9ba" class="ks kt hi ih b ii ij im in iq ku iu kv iy kw jc kx ky kz la bi translated">火花引擎使用JDBC和雪花火花连接器建立到雪花的连接。</li><li id="f06b" class="ks kt hi ih b ii lb im lc iq ld iu le iy lf jc kx ky kz la bi translated">Spark引擎创建优化的逻辑计划、物理计划和sql查询计划。</li><li id="b646" class="ks kt hi ih b ii lb im lc iq ld iu le iy lf jc kx ky kz la bi translated">spark的雪花连接器将spark sql查询计划转换为可执行查询，并将其提交给雪花上的一个数据仓库。</li><li id="cea4" class="ks kt hi ih b ii lb im lc iq ld iu le iy lf jc kx ky kz la bi translated">查询结果被重定向到雪花上的一个内部阶段。</li><li id="a708" class="ks kt hi ih b ii lb im lc iq ld iu le iy lf jc kx ky kz la bi translated">spark应用程序从内部阶段读取数据，并将结果存储为spark数据帧。</li><li id="2013" class="ks kt hi ih b ii lb im lc iq ld iu le iy lf jc kx ky kz la bi translated">使用spark BigQuery连接器将spark数据帧加载到BigQuery。</li></ol><h1 id="8feb" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">批量更新和软删除的变更数据捕获</h1><p id="85d1" class="pw-post-body-paragraph if ig hi ih b ii lg ik il im lh io ip iq li is it iu lj iw ix iy lk ja jb jc hb bi translated">在将数据从雪花数据库增量复制到BigQuery的情况下，可能会出现对雪花数据库进行更新和删除的场景。为了保持BigQuery和Snowflake中的表同步，必须将更改复制到BigQuery表中。</p><p id="81bd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">雪花是一个OLAP数据库，在大多数情况下，它将是一个批量更新和软删除，也将有一个额外的表列来维护上次更新的时间戳。只有在这种情况下，才可以使用下面提到的方法。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es ln"><img src="../Images/eef6c3193c81e45cfc5255fb85a115fa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IA5MdeqV_XV4FlRug3JKrQ.png"/></div></div></figure><p id="1310" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">批量更新和删除的步骤:</p><ol class=""><li id="f088" class="ks kt hi ih b ii ij im in iq ku iu kv iy kw jc kx ky kz la bi translated">每小时/每周/每月的增量数据被加载到分段表中。</li><li id="6bff" class="ks kt hi ih b ii lb im lc iq ld iu le iy lf jc kx ky kz la bi translated">对临时表和主表执行合并操作。新的、更新的记录被向上插入到BigQuery表中。可以从BigQuery表中删除软删除的记录。</li></ol><h1 id="be08" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">用于硬删除和原子更新的CDC</h1><p id="5746" class="pw-post-body-paragraph if ig hi ih b ii lg ik il im lh io ip iq li is it iu lj iw ix iy lk ja jb jc hb bi translated">对于无法跟踪更新和删除的情况，可以选择从雪花到BigQuery覆盖整个表。Dataproc解决方案是可伸缩的，可以处理大量数据。</p><h1 id="78dd" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">使用Dataproc的优势</h1><ol class=""><li id="6259" class="ks kt hi ih b ii lg im lh iq lo iu lp iy lq jc kx ky kz la bi translated">解决方案甚至可以用于雪花读者帐户。</li><li id="9ad2" class="ks kt hi ih b ii lb im lc iq ld iu le iy lf jc kx ky kz la bi translated">解决方案可用于从雪花到BigQuery的数据增量复制。</li><li id="9320" class="ks kt hi ih b ii lb im lc iq ld iu le iy lf jc kx ky kz la bi translated">使用Dataproc的ETL管道是一个独立的解决方案。它不依赖于雪花。</li><li id="1713" class="ks kt hi ih b ii lb im lc iq ld iu le iy lf jc kx ky kz la bi translated">该解决方案可以处理带有覆盖和合并操作的CDC。</li></ol></div></div>    
</body>
</html>