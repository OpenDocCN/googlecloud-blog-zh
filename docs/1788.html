<html>
<head>
<title>Composer, Dataflow and Private IP addresses</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">合成器、数据流和专用IP地址</h1>
<blockquote>原文：<a href="https://medium.com/google-cloud/composer-dataflow-and-private-ip-addresses-c56086f699ea?source=collection_archive---------0-----------------------#2021-02-04">https://medium.com/google-cloud/composer-dataflow-and-private-ip-addresses-c56086f699ea?source=collection_archive---------0-----------------------#2021-02-04</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/40cc5b225c177992132adf82b131b3bc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_H9upWJXHzWXwtHeDWVaFA.png"/></div></div></figure><p id="d89d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">公共IP地址是可从互联网寻址的地址。在GCP环境中，我们可以声明永远不应该为计算引擎分配公共IP地址。这可以在组织级别定义，并成为组织策略。对属于该组织的所有项目实施策略，包括可能由其他GCP产品作为其自身执行的一部分创建的计算引擎。我们可能希望禁用公共IP地址的原因是，这将减少<em class="jo">攻击面</em>。如果GCP的计算引擎不需要从互联网访问，那么将计算引擎定义为简单地不要求访问是正常的。但是，如果出现管理错误，则默认情况下，计算引擎可能会获得一个公共IP地址。组织级别的策略确保<em class="jo">没有</em>计算引擎可以拥有公共IP地址…无论是默认的、意外的还是试图要求一个。</p><p id="f367" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在让我们考虑数据流产品。这将执行分布在多个工作线程中的数据转换管道。默认情况下，这些工作人员使用公共IP地址相互协作。当我们向数据流提交作业时，我们可以传递一个参数，声明我们只使用私有IP地址。我们可以在用于提交数据流作业的<code class="du jp jq jr js b">gcloud</code>命令中看到这个参数:</p><pre class="jt ju jv jw fd jx js jy jz aw ka bi"><span id="0068" class="kb kc hi js b fi kd ke l kf kg">gcloud dataflow jobs run … --disable-public-ips …</span></pre><p id="b161" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><a class="ae kh" href="https://cloud.google.com/sdk/gcloud/reference/dataflow/jobs/run#--disable-public-ips" rel="noopener ugc nofollow" target="_blank"> - disable-public-ips </a>标志用于指示数据流仅使用私有IP。</p><p id="aa32" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">虽然查看<code class="du jp jq jr js b">gcloud</code>命令很有趣，但是大多数数据流调用都是从调用API开始的。<code class="du jp jq jr js b">gcloud</code>命令只是一个为调用这些API而预先构建的命令行工具。如果我们深入查看在数据流中运行工作的API，我们将看到其余的<a class="ae kh" href="https://cloud.google.com/dataflow/docs/reference/rest/v1b3/projects.locations.templates/launch" rel="noopener ugc nofollow" target="_blank">启动</a>请求，该请求具有一个名为<code class="du jp jq jr js b">environment</code>的参数，该参数定义了数据流作业应该运行的环境。在<code class="du jp jq jr js b">environment</code>参数中，有一个名为<code class="du jp jq jr js b">ipConfiguration</code>的参数，它可以取值为<code class="du jp jq jr js b">WORKER_IP_PUBLIC</code>或<code class="du jp jq jr js b">WORKER_IP_PRIVATE</code>。</p><p id="e9fd" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">简单地说，如果我们在一个禁止公共IP地址的环境中运行数据流，那么在数据流中运行作业的请求必须传递一个参数:</p><pre class="jt ju jv jw fd jx js jy jz aw ka bi"><span id="d0e9" class="kb kc hi js b fi kd ke l kf kg">ipConfiguration=WORKER_IP_PRIVATE</span></pre><p id="7f5f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">到目前为止，我们已经讲述了一个关于调用数据流的通用故事，现在我们将注意力转向Composer(气流)。在Composer中，我们可以从DAG调用数据流作业。当我们在DAG中有一个调用数据流的步骤时，DAG作者可以提供传递给数据流进行解释的参数。这意味着我们想要设置并传递刚刚描述的<code class="du jp jq jr js b">ipConfiguration</code>属性。理想情况下，我们需要如下内容:</p><pre class="jt ju jv jw fd jx js jy jz aw ka bi"><span id="106b" class="kb kc hi js b fi kd ke l kf kg">default_args = {<br/>  # Tell airflow to start one day ago, so that it runs as soon as you upload it<br/>  "start_date": days_ago(1),<br/>  "dataflow_default_options": {<br/>    "project": project_id,<br/>    # Set to your region<br/>    "region": gce_region,<br/>    # Set to your zone<br/>    "zone": gce_zone,<br/>    # This is a subfolder for storing temporary files, like the staged pipeline job.<br/>    "temp_location": bucket_path + "/tmp/",    <br/>    # Use private IP addresses<br/>    "ipConfiguration": "WORKER_IP_PRIVATE"<br/>  }<br/>}</span></pre><p id="ed9f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">不幸的是，我们有一个问题。虽然数据流描述了可以设置的所有可能的参数，但气流(以及Composer)产品有一个缺陷。只有数据流认可的可能参数的子集实际上被定义为在气流DAG配置中有效，并且<code class="du jp jq jr js b">ipConfiguration</code>是<strong class="is hj">而不是</strong>其中之一。尽管我们可以在DAG中设置该属性，但它在运行时会被忽略。</p><p id="17fb" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这个问题作为Github问题被追踪到Airflow项目，因为:</p><p id="21ac" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><a class="ae kh" href="https://github.com/apache/airflow/issues/8300" rel="noopener ugc nofollow" target="_blank"> #8300:无法使用私有IP配置创建数据流作业</a></p><p id="6baa" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">幸运的是，这个问题已经解决。然而，正如你可能已经猜到的，我们仍然有一个问题。该解决方案和产生的代码修复是针对Airflow项目的主分支进行的，这意味着它将确保出现在Airflow的v2.x中(我们目前(2021–01)处于1.x)。Composer使用Airflow 1.x，因此Airflow代码库中的解决方案仅适用于将来的某个版本。</p><p id="7c51" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">幸运的是，我们已经测试了一个可行的解决方案，它看起来很有效。为了理解变通方法，您应该对一个叫做<a class="ae kh" href="https://en.wikipedia.org/wiki/Monkey_patch" rel="noopener ugc nofollow" target="_blank">猴子补丁</a>的概念有一个基本的了解。</p><p id="b096" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">假设你正在使用一个叫做<code class="du jp jq jr js b">SomePackage</code>的Python包。现在假设您正在调用该包中一个名为<code class="du jp jq jr js b">someFunction</code>的函数。您可以编写:</p><pre class="jt ju jv jw fd jx js jy jz aw ka bi"><span id="85a5" class="kb kc hi js b fi kd ke l kf kg">SomePackage.someFunction()</span></pre><p id="57fb" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在想象一下，当你调用某个函数时，它失败了或者没有完全按照你想要的去做。如果您可以访问Python包的源代码，您可能会发现其中有一个名为<code class="du jp jq jr js b">_someInternalFunction</code>的内部函数，它包含一个阻碍您实现目标的错误。你想修补<code class="du jp jq jr js b">_someInternalFunction</code>,但是你只是Python包的消费者，你不知道(也不想)如何用你的修改来重建整个包(即使那是可能的)。</p><p id="42af" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">相反，你可以做的是执行一个Monkey补丁，覆盖你想要改变的函数。您的新代码现在变成了:</p><pre class="jt ju jv jw fd jx js jy jz aw ka bi"><span id="f344" class="kb kc hi js b fi kd ke l kf kg">def _myNewInternalFunction:<br/> # New code here</span><span id="09e4" class="kb kc hi js b fi ki ke l kf kg">SomePackage._someInternalFunction = _myNewInternalFunction<br/>SomePackage.someFunction()</span></pre><p id="06f9" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">结果是，当你现在调用<code class="du jp jq jr js b">someFunction()</code>时，该函数的内部将调用<code class="du jp jq jr js b">_someInternalFunction()</code>，但不是调用原始包提供的代码，而是调用你刚刚提供的作为<code class="du jp jq jr js b">_someInternalFunction()</code>的新实现的代码。您已经有效地修补了软件包。这是一个被称为猴子修补技术的例子。</p><p id="2a99" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">考虑到这一背景，有一个Monkey补丁可以与Airflow (Composer)结合使用，这将导致尊重<code class="du jp jq jr js b">ipConfiguration</code>参数。</p><p id="18e9" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在Python DAG中，早期包含以下代码:</p><pre class="jt ju jv jw fd jx js jy jz aw ka bi"><span id="efb0" class="kb kc hi js b fi kd ke l kf kg"># Required for the monkey patch<br/>from airflow.contrib.hooks.gcp_dataflow_hook import DataFlowHook, _DataflowJob</span><span id="69f7" class="kb kc hi js b fi ki ke l kf kg"># We redefine the function that handles the environment keys <br/># that are used to build the RuntimeEnvironment, to include 'ipConfiguration'<br/>def _start_template_dataflow(self, name, variables, parameters,<br/>                             dataflow_template):<br/>    # Builds RuntimeEnvironment from variables dictionary<br/>    # <a class="ae kh" href="https://cloud.google.com/dataflow/docs/reference/rest/v1b3/RuntimeEnvironment" rel="noopener ugc nofollow" target="_blank">https://cloud.google.com/dataflow/docs/reference/rest/v1b3/RuntimeEnvironment</a><br/>    environment = {}<br/>    for key in ['numWorkers', 'maxWorkers', 'zone', 'serviceAccountEmail',<br/>                'tempLocation', 'bypassTempDirValidation', 'machineType',<br/>                'additionalExperiments', 'network', 'subnetwork', 'additionalUserLabels',<br/>                'ipConfiguration']:<br/>        if key in variables:<br/>            environment.update({key: variables[key]})<br/>    body = {"jobName": name,<br/>            "parameters": parameters,<br/>            "environment": environment}<br/>    service = self.get_conn()<br/>    request = service.projects().locations().templates().launch(<br/>        projectId=variables['project'],<br/>        location=variables['region'],<br/>        gcsPath=dataflow_template,<br/>        body=body<br/>    )<br/>    response = request.execute(num_retries=self.num_retries)<br/>    variables = self._set_variables(variables)<br/>    _DataflowJob(self.get_conn(), variables['project'], name, variables['region'],<br/>                 self.poll_sleep, num_retries=self.num_retries).wait_for_done()<br/>    return response</span><span id="2c38" class="kb kc hi js b fi ki ke l kf kg"># Monkey patching<br/>DataFlowHook._start_template_dataflow = _start_template_dataflow</span></pre><p id="b7c9" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">虽然有可能阅读此代码并理解它的作用，但我们的建议是将它视为一个黑盒，并在粘贴后尝试在DAG源文件中忽略它。理想情况下，在将来的某一天，已经在Airflow master Github分支中进行的代码更改将在Composer中可用，并且可以删除Monkey补丁。</p><p id="1827" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">有一个演示这个故事和测试的视频:</p><figure class="jt ju jv jw fd ij"><div class="bz dy l di"><div class="kj kk l"/></div></figure><p id="664a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">注意事项:</p><ul class=""><li id="76a3" class="kl km hi is b it iu ix iy jb kn jf ko jj kp jn kq kr ks kt bi translated">本文没有描述如何定义组织级别的策略，也没有强调用于禁用公共IP地址的特定策略。假设GCP管理员可以查阅有关VPC网络配置和GCP组织政策的文档。还应注意的是，Composer和Dataflow配置使用的VPC网络启用了私有Google访问参数。默认为禁用。</li></ul><p id="1c1c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">另请参见:</p><ul class=""><li id="73ab" class="kl km hi is b it iu ix iy jb kn jf ko jj kp jn kq kr ks kt bi translated"><a class="ae kh" href="https://airflow.apache.org/docs/apache-airflow/1.10.6/_api/airflow/contrib/operators/dataflow_operator/index.html#" rel="noopener ugc nofollow" target="_blank">air flow . contrib . operators . data flow _ operator</a></li><li id="4d80" class="kl km hi is b it ku ix kv jb kw jf kx jj ky jn kq kr ks kt bi translated"><a class="ae kh" href="https://cloud.google.com/dataflow/docs/guides/specifying-networks" rel="noopener ugc nofollow" target="_blank">数据流文档:指定您的网络和子网</a></li></ul></div></div>    
</body>
</html>