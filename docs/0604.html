<html>
<head>
<title>Transcribe Japanese using Go and Machine Learning APIs</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Go和机器学习API转录日语</h1>
<blockquote>原文：<a href="https://medium.com/google-cloud/transcribe-japanese-using-go-and-machine-learning-apis-3ccc74f6c800?source=collection_archive---------0-----------------------#2018-05-14">https://medium.com/google-cloud/transcribe-japanese-using-go-and-machine-learning-apis-3ccc74f6c800?source=collection_archive---------0-----------------------#2018-05-14</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="946b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">学习日语时最难培养的技能之一是扎实的听力理解。一个很好的练习方法是听日语新闻。对于这一点，没有什么比NHK广播新闻，或<a class="ae jd" href="http://www.nhk.or.jp/radionews/" rel="noopener ugc nofollow" target="_blank"><em class="je">rajio nyūsu</em>ラジオニュース</a>更好的了。这个节目中的日本人坚持NHK的清晰标准，该网站允许听众在常规、慢速和快速之间调整音频速度。</p><p id="0935" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">尽管调整播放速度可能会有所帮助，但语言学习者肯定会遇到不熟悉的单词。虽然识别未知单词以便自己查找也是一项同样重要的技能，但是音频的转录在学习速度上有很大的不同。唯一的问题是NHK不提供转录。所以，让我们自己去创造吧！</p><p id="1a66" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为此，我们将使用谷歌云平台的<a class="ae jd" href="https://cloud.google.com/speech-to-text/" rel="noopener ugc nofollow" target="_blank">语音转文本API </a>及其<a class="ae jd" href="https://github.com/googlecloudplatform/google-cloud-go" rel="noopener ugc nofollow" target="_blank"> Go API客户端</a>。有三个步骤。</p><h1 id="e979" class="jf jg hi bd jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc bi translated">下载音频样本</h1><p id="6c6a" class="pw-post-body-paragraph if ig hi ih b ii kd ik il im ke io ip iq kf is it iu kg iw ix iy kh ja jb jc hb bi translated">语音转文本API区分运行时间低于或高于一分钟的短音频文件和长音频文件。如果音频文件长于一分钟，我们需要使用异步API进行<a class="ae jd" href="https://godoc.org/cloud.google.com/go/speech/apiv1#Client.LongRunningRecognize" rel="noopener ugc nofollow" target="_blank">长时间运行识别</a>。对于这个例子，我们将使用<a class="ae jd" href="https://godoc.org/cloud.google.com/go/speech/apiv1#Client.Recognize" rel="noopener ugc nofollow" target="_blank">同步API </a>。API客户端也<a class="ae jd" href="https://godoc.org/google.golang.org/genproto/googleapis/cloud/speech/v1#RecognitionAudio_Uri" rel="noopener ugc nofollow" target="_blank">支持远程URIs </a>，但是为了简单起见，我们将自己上传一个音频样本。</p><p id="69d5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">获取音频文件副本的最简单方法是直接从<a class="ae jd" href="http://www.nhk.or.jp/radionews/" rel="noopener ugc nofollow" target="_blank">广播节目的主页</a>下载。请注意，页面上看不到下载该集的链接。相反，您需要在开始播放某一集后，使用浏览器的开发工具来检查音频播放器的HTML。</p><figure class="kj kk kl km fd kn er es paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="er es ki"><img src="../Images/4fbae571261e8dba1c3787c2f03abad3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XD6afHPrhRmn2Me0hZxYBQ.png"/></div></div></figure><p id="4297" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">然后，找到对应的<code class="du ku kv kw kx b">audio</code>元素，其<code class="du ku kv kw kx b">src</code>属性指向该集的一个MP3文件。下载那个文件。</p><figure class="kj kk kl km fd kn er es paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="er es ky"><img src="../Images/277203657bbe8de3bb8c866cb9e9c46b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1fTx0KLUInxR-CF7x4CBMw.png"/></div></div></figure><h1 id="0267" class="jf jg hi bd jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc bi translated">处理样品以获得最佳结果</h1><p id="a70c" class="pw-post-body-paragraph if ig hi ih b ii kd ik il im ke io ip iq kf is it iu kg iw ix iy kh ja jb jc hb bi translated">现在我们有了一个日本音频样本，我们需要做一些小的处理以确保最佳效果。正如关于最佳实践的<a class="ae jd" href="https://cloud.google.com/speech-to-text/docs/best-practices" rel="noopener ugc nofollow" target="_blank">文档</a>指出的，为了获得最佳结果，我们需要使用FLAC编码和16，000 Hz的采样率。此外，我发现它有助于提交样本混合到单声道，而不是立体声。ffmpeg CLI对于这类工作来说是无价的。</p><p id="2b99" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">首先，我们可以使用以下命令查看文件的各种元数据:</p><pre class="kj kk kl km fd kz kx la lb aw lc bi"><span id="c36e" class="ld jg hi kx b fi le lf l lg lh">ffprobe -v error -show_format -show_streams input.mp3</span></pre><p id="64e5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">接下来，我们需要从MP3转换到FLAC:</p><pre class="kj kk kl km fd kz kx la lb aw lc bi"><span id="312c" class="ld jg hi kx b fi le lf l lg lh">ffmpeg -i input.mp3 output.flac</span></pre><p id="4cbf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了保持我们的样本不超过一分钟，我们将把音频样本调整到30秒的运行时间。对于您的特定剪辑，您需要找到一个好的开始时间和一个好的停止时间。在我正在使用的剪辑中，我想在10秒后开始，30秒后停止:</p><pre class="kj kk kl km fd kz kx la lb aw lc bi"><span id="5e40" class="ld jg hi kx b fi le lf l lg lh">ffmpeg -ss 10 -t 30 input.flac output.flac</span></pre><p id="dd55" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">播出的剧集已经是单声道的了，但是如果您想将立体声样本重新混合到单声道中，命令也很简单:</p><pre class="kj kk kl km fd kz kx la lb aw lc bi"><span id="474f" class="ld jg hi kx b fi le lf l lg lh">ffmpeg -i input.flac -ac 1 output-mono.flac</span></pre><p id="e676" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，处理完成后，我们准备编写一些代码，并将示例提交给语音到文本API。</p><h1 id="ea72" class="jf jg hi bd jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc bi translated">将示例发送到语音转文本API</h1><p id="9691" class="pw-post-body-paragraph if ig hi ih b ii kd ik il im ke io ip iq kf is it iu kg iw ix iy kh ja jb jc hb bi translated">让我们写一些<a class="ae jd" href="https://golang.org" rel="noopener ugc nofollow" target="_blank">围棋</a>。</p><p id="e9cd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">首先，我们将为Go下载一份客户端库:</p><pre class="kj kk kl km fd kz kx la lb aw lc bi"><span id="880a" class="ld jg hi kx b fi le lf l lg lh">go get -u cloud.google.com/go/...</span></pre><p id="2e96" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">然后，在我们的<code class="du ku kv kw kx b">GOPATH</code>内的一个目录中，我们用下面的代码创建一个<code class="du ku kv kw kx b">main.go</code>。我们首先创建一个新的语音客户端。</p><p id="e4ca" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">注意，在下面的代码中，我们没有明确引用API凭证。相反，客户端将从环境中读取<code class="du ku kv kw kx b">GOOGLE_APPLICATION_CREDENTIALS</code>变量来定位提供认证信息的<code class="du ku kv kw kx b">service-account.json</code>文件。有关设置认证的各种方式的更多详细信息，请参见<a class="ae jd" href="https://cloud.google.com/docs/authentication/production" rel="noopener ugc nofollow" target="_blank">文档</a>。此外，GoDoc 中有许多有用的例子。</p><pre class="kj kk kl km fd kz kx la lb aw lc bi"><span id="89f7" class="ld jg hi kx b fi le lf l lg lh">// ~/go/src/github.com/gobuildit/gobuildit/transcribe/main.go</span><span id="aede" class="ld jg hi kx b fi li lf l lg lh">package main</span><span id="02f6" class="ld jg hi kx b fi li lf l lg lh">import (</span><span id="f224" class="ld jg hi kx b fi li lf l lg lh">    "fmt"</span><span id="b720" class="ld jg hi kx b fi li lf l lg lh">    "io/ioutil"</span><span id="5729" class="ld jg hi kx b fi li lf l lg lh">    "log"</span><span id="a784" class="ld jg hi kx b fi li lf l lg lh">    "golang.org/x/net/context"</span><span id="3ff2" class="ld jg hi kx b fi li lf l lg lh">    speech "cloud.google.com/go/speech/apiv1"</span><span id="c0e2" class="ld jg hi kx b fi li lf l lg lh">    speechpb "google.golang.org/genproto/googleapis/cloud/speech/v1"</span><span id="c6cc" class="ld jg hi kx b fi li lf l lg lh">)</span><span id="e978" class="ld jg hi kx b fi li lf l lg lh">func main() {</span><span id="b8a9" class="ld jg hi kx b fi li lf l lg lh">    ctx := context.Background()</span><span id="6508" class="ld jg hi kx b fi li lf l lg lh">    client, err := speech.NewClient(ctx)</span><span id="07bb" class="ld jg hi kx b fi li lf l lg lh">    if err != nil {</span><span id="4354" class="ld jg hi kx b fi li lf l lg lh">        log.Fatalf("failed to create client: %v", err)</span><span id="2706" class="ld jg hi kx b fi li lf l lg lh">    }</span><span id="7fb2" class="ld jg hi kx b fi li lf l lg lh">    // ...</span><span id="262b" class="ld jg hi kx b fi li lf l lg lh">}</span></pre><p id="ae72" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">接下来，我们将音频样本读入内存:</p><pre class="kj kk kl km fd kz kx la lb aw lc bi"><span id="07d6" class="ld jg hi kx b fi le lf l lg lh">// ...</span><span id="2bad" class="ld jg hi kx b fi li lf l lg lh">data, err := ioutil.ReadFile("nhk-radio-news.flac")</span><span id="0eb9" class="ld jg hi kx b fi li lf l lg lh">if err != nil {</span><span id="ea7c" class="ld jg hi kx b fi li lf l lg lh">    log.Fatalf("failed to read file: %v", err)</span><span id="f816" class="ld jg hi kx b fi li lf l lg lh">}</span><span id="16c5" class="ld jg hi kx b fi li lf l lg lh">// ...</span></pre><p id="ef9a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，我们准备创建API请求并发送它:</p><pre class="kj kk kl km fd kz kx la lb aw lc bi"><span id="e9f2" class="ld jg hi kx b fi le lf l lg lh">// ...</span><span id="57a4" class="ld jg hi kx b fi li lf l lg lh">resp, err := client.Recognize(ctx, &amp;speechpb.RecognizeRequest{</span><span id="ebb3" class="ld jg hi kx b fi li lf l lg lh">    Config: &amp;speechpb.RecognitionConfig{</span><span id="b8ee" class="ld jg hi kx b fi li lf l lg lh">        Encoding:        speechpb.RecognitionConfig_FLAC,</span><span id="b9bd" class="ld jg hi kx b fi li lf l lg lh">        SampleRateHertz: int32(16000),</span><span id="b218" class="ld jg hi kx b fi li lf l lg lh">        LanguageCode:    "ja-JP",</span><span id="ed69" class="ld jg hi kx b fi li lf l lg lh">    }, </span><span id="63f3" class="ld jg hi kx b fi li lf l lg lh">    Audio: &amp;speechpb.RecognitionAudio{</span><span id="eaed" class="ld jg hi kx b fi li lf l lg lh">        AudioSource: &amp;speechpb.RecognitionAudio_Content{<br/>            Content: data,<br/>        },</span><span id="689e" class="ld jg hi kx b fi li lf l lg lh">    },</span><span id="b4ab" class="ld jg hi kx b fi li lf l lg lh">})</span><span id="f93f" class="ld jg hi kx b fi li lf l lg lh">if err != nil {</span><span id="7daa" class="ld jg hi kx b fi li lf l lg lh">    log.Fatalf("failed to recognize: %v", err)</span><span id="f7a7" class="ld jg hi kx b fi li lf l lg lh">}</span><span id="1ed0" class="ld jg hi kx b fi li lf l lg lh">// ...</span></pre><p id="44b6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在上面的代码中，我们用音频样本的细节配置了<code class="du ku kv kw kx b">RecognizeRequest</code>。有许多额外的属性值得了解，但我们在这里没有用到。</p><p id="b7fb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">最后，如果我们的请求成功，我们打印出结果:</p><pre class="kj kk kl km fd kz kx la lb aw lc bi"><span id="db21" class="ld jg hi kx b fi le lf l lg lh">// ...</span><span id="9288" class="ld jg hi kx b fi li lf l lg lh">for _, result := range resp.Results {</span><span id="2d1a" class="ld jg hi kx b fi li lf l lg lh">    for _, alt := range result.Alternatives {</span><span id="4105" class="ld jg hi kx b fi li lf l lg lh">        fmt.Printf("\"%v\" (confidence=%3f)\n", alt.Transcript, alt.Confidence)</span><span id="e6d2" class="ld jg hi kx b fi li lf l lg lh">    }</span><span id="6be3" class="ld jg hi kx b fi li lf l lg lh">}</span><span id="5264" class="ld jg hi kx b fi li lf l lg lh">// end of main</span></pre><p id="f75b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">有可能结果会包含一些<code class="du ku kv kw kx b">Alternatives</code>，所以我们会将它们和<code class="du ku kv kw kx b">Confidence</code>值一起打印出来，T1值表示API对抄本正确可能性的估计。注意，<code class="du ku kv kw kx b">Alternatives</code>是按照准确性排序的，最有信心的排在最前面。更多信息，请点击查看<a class="ae jd" href="https://cloud.google.com/speech-to-text/docs/reference/rest/v1/speech/recognize" rel="noopener ugc nofollow" target="_blank">文档。</a></p><p id="1308" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，我们准备转录我们的音频样本。请注意，以下命令可能需要一些时间才能完成。</p><pre class="kj kk kl km fd kz kx la lb aw lc bi"><span id="2b56" class="ld jg hi kx b fi le lf l lg lh">$ GOOGLE_APPLICATION_CREDENTIALS=service-account.json go run main.go</span><span id="ec6b" class="ld jg hi kx b fi li lf l lg lh">ではニュースです # “And now for the news.” (full transcription result omitted)</span></pre><p id="5cf1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">看看那个！我们有音频样本的副本！</p><h1 id="7f8d" class="jf jg hi bd jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc bi translated">可能的后续步骤</h1><p id="4721" class="pw-post-body-paragraph if ig hi ih b ii kd ik il im ke io ip iq kf is it iu kg iw ix iy kh ja jb jc hb bi translated">考虑到获取音频并将其转换成文字稿是多么容易，人们可以很容易地想象将这段代码扩展成一个实时字幕服务<a class="ae jd" href="https://github.com/GoogleCloudPlatform/golang-samples/tree/master/speech/livecaption" rel="noopener ugc nofollow" target="_blank">。给定一个稳定的音频输入，也许可以分成几分钟，我们可以将这些样本提交给自动处理步骤。从那里，经过处理的音频可以被发送到语音转文本API以产生字幕。</a></p><p id="e48b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">当然，它几乎肯定不是现有系统的对手，但随着机器学习在准确性和速度上的不断提高，不难看出像直播字幕这样的系统变得更加容易创建。不过现在，我们有一个强大的工具来帮助语言学习过程。</p><h2 id="c9f2" class="ld jg hi bd jh lj lk ll jl lm ln lo jp iq lp lq jt iu lr ls jx iy lt lu kb lv bi translated">进一步阅读</h2><ul class=""><li id="3bf4" class="lw lx hi ih b ii kd im ke iq ly iu lz iy ma jc mb mc md me bi translated"><a class="ae jd" href="https://cloud.google.com/speech-to-text/docs/" rel="noopener ugc nofollow" target="_blank">云语音转文本文档</a></li><li id="d482" class="lw lx hi ih b ii mf im mg iq mh iu mi iy mj jc mb mc md me bi translated"><a class="ae jd" href="https://github.com/GoogleCloudPlatform/golang-samples/tree/master/speech" rel="noopener ugc nofollow" target="_blank">Go中的示例应用</a></li><li id="74f1" class="lw lx hi ih b ii mf im mg iq mh iu mi iy mj jc mb mc md me bi translated"><a class="ae jd" href="https://www.youtube.com/watch?v=gVz9jKE_9iU" rel="noopener ugc nofollow" target="_blank">谷歌云平台上的机器学习简介</a></li></ul></div></div>    
</body>
</html>