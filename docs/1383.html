<html>
<head>
<title>On-demand small batch predictions with Cloud Run and Embedded-tf</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">利用云运行和嵌入式tf进行按需小批量预测</h1>
<blockquote>原文：<a href="https://medium.com/google-cloud/on-demand-small-batch-predictions-with-cloud-run-and-embedded-tf-469242d66c3b?source=collection_archive---------0-----------------------#2020-04-20">https://medium.com/google-cloud/on-demand-small-batch-predictions-with-cloud-run-and-embedded-tf-469242d66c3b?source=collection_archive---------0-----------------------#2020-04-20</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/abca1233eb2be6060c7f8039bf1f412e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tqVanyyuuWPdD4OcXCuOtg.png"/></div></div></figure><p id="3659" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">机器学习是一个广阔的领域。大多数人都专注于训练、模型和超参数调整。然而，服务部分是重要的，因为没有它，所有之前做的工作都是无用的。</p><p id="cc12" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">您可以<strong class="is hj">以在线或批处理模式</strong>为您的模型提供服务，允许您这样做的无服务器产品或多或少会根据您的要求和您的使用案例进行调整(查看<a class="ae jo" href="https://www.youtube.com/watch?v=0x7gSuJ_Ugk" rel="noopener ugc nofollow" target="_blank">我的演讲</a>)。</p><h1 id="b994" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">数百名训练有素的模特</h1><p id="9fb9" class="pw-post-body-paragraph iq ir hi is b it kn iv iw ix ko iz ja jb kp jd je jf kq jh ji jj kr jl jm jn hb bi translated">对于我的使用案例，我们有一个独特的Tensorflow模型来计算建筑物的能源效率，但每个站点都有一个培训工作，因为<strong class="is hj">我们没有足够的培训数据来对所有不同的情况进行通用培训</strong>。</p><p id="db74" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">该项目始于2年前，今天，<strong class="is hj">我们有超过500个不同的受训模型，预计在未来12个月内将达到3000个</strong>。预测数据每天生成一次，团队要求我在以下方面提供帮助:</p><blockquote class="ks"><p id="a155" class="kt ku hi bd kv kw kx ky kz la lb jn dx translated">如何高效地托管和服务所有这些模型？</p></blockquote><p id="e688" class="pw-post-body-paragraph iq ir hi is b it lc iv iw ix ld iz ja jb le jd je jf lf jh ji jj lg jl jm jn hb bi translated"><em class="lh">当然，而</em> <strong class="is hj"> <em class="lh">限制了对现有项目</em> </strong> <em class="lh">的影响。</em></p><h1 id="3157" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">一个大查询ML解决方案</h1><p id="dad7" class="pw-post-body-paragraph iq ir hi is b it kn iv iw ix ko iz ja jb kp jd je jf kq jh ji jj kr jl jm jn hb bi translated">输入数据已经存储在BigQuery中，模型是用Tensorflow编写的。第一个想法是在<a class="ae jo" href="https://cloud.google.com/bigquery-ml/docs/bigqueryml-intro" rel="noopener ugc nofollow" target="_blank"><strong class="is hj">big query ML</strong></a><strong class="is hj">上<strong class="is hj">主持模特。</strong></strong></p><p id="bbbd" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这是正确的解决方案，但在我们的环境中有两个问题:</p><ul class=""><li id="9f3a" class="li lj hi is b it iu ix iy jb lk jf ll jj lm jn ln lo lp lq bi translated"><strong class="is hj"> BigQuery ML允许</strong> <a class="ae jo" href="https://cloud.google.com/bigquery-ml/quotas" rel="noopener ugc nofollow" target="_blank"> <strong class="is hj">每天只创建1000个模型</strong> </a>。几个月后，根据我们的业务预测，不可能部署所有(重新)训练的模型。</li><li id="7858" class="li lj hi is b it lr ix ls jb lt jf lu jj lv jn ln lo lp lq bi translated"><strong class="is hj"> BigQuery ML对现有项目的影响很多</strong> : <br/> <strong class="is hj"> 1 .</strong>训练结束后，将训练好的模型存入GCS。对于批量预测工作来说，这已经足够了。<br/>使用BigQuery ML，训练后的模型必须在训练后加载到BigQuery ML中。<br/> <strong class="is hj"> 2。</strong>为了启动批量预测作业，执行API调用。<br/>与BigQuery ML一样，这个调用被改变为执行了一个查询<em class="lh">(微小的改变)。</em> <br/> <strong class="is hj"> 3。</strong>流程的其余部分使用以JSON行格式存储在GCS文件中的预测。<br/>使用BigQuery ML，预测结果可以存储:<br/> -存储在表格中(带有<em class="lh"> insert select </em>请求)，然后导出到GCS。<br/> -或者在查询执行后直接存储在GCS上的文件中。<br/>在这两种情况下，文件格式必须与现有格式相同。</li></ul><p id="24c2" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><em class="lh">让我们寻找另一种方式。</em></p><h1 id="29b4" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">人工智能平台解决方案</h1><p id="1369" class="pw-post-body-paragraph iq ir hi is b it kn iv iw ix ko iz ja jb kp jd je jf kq jh ji jj kr jl jm jn hb bi translated"><a class="ae jo" href="https://cloud.google.com/ai-platform" rel="noopener ugc nofollow" target="_blank"> <strong class="is hj"> AI平台</strong> </a> <strong class="is hj">是围绕ML和AI的一套工具、组件和服务。</strong>您托管了笔记本、数据准备组件、培训服务、优化器、(…)以及在线或批处理模式的预测服务。</p><h2 id="a128" class="lw jq hi bd jr lx ly lz jv ma mb mc jz jb md me kd jf mf mg kh jj mh mi kl mj bi translated">在线预测</h2><p id="c9fe" class="pw-post-body-paragraph iq ir hi is b it kn iv iw ix ko iz ja jb kp jd je jf kq jh ji jj kr jl jm jn hb bi translated"><a class="ae jo" href="https://cloud.google.com/ai-platform/prediction/docs/online-predict" rel="noopener ugc nofollow" target="_blank">在线预测</a>是可能的，因为<strong class="is hj">每次预测的数据量很低</strong>。在线请求不会打破每个查询的配额和大小限制。</p><p id="e0f6" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">然而，<strong class="is hj"> AI平台有</strong> <a class="ae jo" href="https://cloud.google.com/ai-platform/training/docs/quotas#resource_quotas" rel="noopener ugc nofollow" target="_blank"> <strong class="is hj">在线模式</strong> </a> <strong class="is hj">部署的100个模型的限制。</strong></p><h2 id="38c9" class="lw jq hi bd jr lx ly lz jv ma mb mc jz jb md me kd jf mf mg kh jj mh mi kl mj bi translated">批量预测</h2><p id="0d96" class="pw-post-body-paragraph iq ir hi is b it kn iv iw ix ko iz ja jb kp jd je jf kq jh ji jj kr jl jm jn hb bi translated"><a class="ae jo" href="https://cloud.google.com/ai-platform/prediction/docs/batch-predict" rel="noopener ugc nofollow" target="_blank">批量预测</a>没有这个限制，因为每一个只为自己的工作创建预测环境，然后全部破坏并停止。</p><p id="000e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这里又有一个限制:<strong class="is hj">只能并行执行25个预测作业</strong>(在文档中找不到<em class="lh">参考)。</em></p></div><div class="ab cl mk ml gp mm" role="separator"><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp"/></div><div class="hb hc hd he hf"><p id="5a38" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">2年前，BigQuery ML才刚刚起步，负责项目的团队<strong class="is hj">选择了批量预测模式</strong>。每天晚上，一个进程创建所有的批量预测作业。当达到25的限制时，AI平台会返回一个<code class="du mr ms mt mu b">429</code> HTTP错误代码，表示超过了配额。<strong class="is hj">进程等待一段时间，稍后再次尝试，希望之前的任务已经完成。</strong></p><p id="d5e1" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">开始时它工作得很好，但是现在，随着每晚超过500批(以及更多即将到来的)每批约6分钟的预测作业，<strong class="is hj">持续时间成为一个问题。</strong>团队寻找另一种经济实惠的解决方案。</p></div><div class="ab cl mk ml gp mm" role="separator"><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp"/></div><div class="hb hc hd he hf"><h1 id="255e" class="jp jq hi bd jr js mv ju jv jw mw jy jz ka mx kc kd ke my kg kh ki mz kk kl km bi translated">面向所有人的云计算</h1><p id="8545" class="pw-post-body-paragraph iq ir hi is b it kn iv iw ix ko iz ja jb kp jd je jf kq jh ji jj kr jl jm jn hb bi translated">我已经写了一篇关于使用Cloud Run和Tensorflow的文章。当前的问题类似，我选择<strong class="is hj">让我的初始解决方案更加模块化和动态化</strong>。</p><p id="f1a2" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">云运行的强大来自于容器的灵活性。你可以在里面做你想做的事情。</p><ul class=""><li id="7b6a" class="li lj hi is b it iu ix iy jb lk jf ll jj lm jn ln lo lp lq bi translated">安装二进制文件和系统库</li><li id="602e" class="li lj hi is b it lr ix ls jb lt jf lu jj lv jn ln lo lp lq bi translated">运行/终止多个进程</li><li id="38b2" class="li lj hi is b it lr ix ls jb lt jf lu jj lv jn ln lo lp lq bi translated">存储本地文件</li></ul><p id="f644" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">…只有一些限制:</p><ul class=""><li id="05ac" class="li lj hi is b it iu ix iy jb lk jf ll jj lm jn ln lo lp lq bi translated"><strong class="is hj">容器必须响应HTTP请求</strong>，实例只有在处理请求时<strong class="is hj">才是活动的。因为实例的vCPU在其余时间是空闲的，<strong class="is hj">您不能执行请求处理之外的处理</strong>。</strong></li><li id="6614" class="li lj hi is b it lr ix ls jb lt jf lu jj lv jn ln lo lp lq bi translated"><strong class="is hj">容器必须是无状态的</strong>:您可以将本地文件存储在内存文件系统中，但是<strong class="is hj">当实例停止时，文件就会丢失。</strong> <br/> <strong class="is hj">你也不能储存大于允许内存的文件。</strong></li></ul><h1 id="48da" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">封装Tensorflow服务器</h1><p id="772c" class="pw-post-body-paragraph iq ir hi is b it kn iv iw ix ko iz ja jb kp jd je jf kq jh ji jj kr jl jm jn hb bi translated">由于这种灵活性，<a class="ae jo" href="https://github.com/guillaumeblaquiere/embedded-tf" rel="noopener ugc nofollow" target="_blank"> <strong class="is hj">我开发了<em class="lh"> Embedded-tf </em> </strong> </a>，一个Go服务器，它执行以下步骤:</p><ul class=""><li id="bf18" class="li lj hi is b it iu ix iy jb lk jf ll jj lm jn ln lo lp lq bi translated"><strong class="is hj">从GCS桶本地下载模型</strong></li><li id="7d13" class="li lj hi is b it lr ix ls jb lt jf lu jj lv jn ln lo lp lq bi translated"><strong class="is hj">用加载的模型启动Tensorflow服务器</strong></li><li id="fbbf" class="li lj hi is b it lr ix ls jb lt jf lu jj lv jn ln lo lp lq bi translated">对于每个输入文件</li></ul><ol class=""><li id="0996" class="li lj hi is b it iu ix iy jb lk jf ll jj lm jn na lo lp lq bi translated"><strong class="is hj">下载内存中的输入文件</strong></li><li id="a5b4" class="li lj hi is b it lr ix ls jb lt jf lu jj lv jn na lo lp lq bi translated"><strong class="is hj">将输入文件</strong>格式化为Tensorflow服务器期望的JSON格式</li><li id="d533" class="li lj hi is b it lr ix ls jb lt jf lu jj lv jn na lo lp lq bi translated"><strong class="is hj">执行预测</strong>并在主体中设置响应</li><li id="603c" class="li lj hi is b it lr ix ls jb lt jf lu jj lv jn na lo lp lq bi translated"><strong class="is hj">将正文中的响应</strong>格式化为JSON行输出</li><li id="8431" class="li lj hi is b it lr ix ls jb lt jf lu jj lv jn na lo lp lq bi translated"><strong class="is hj">将输出</strong>上传到铲斗/路径输出</li></ol><ul class=""><li id="472d" class="li lj hi is b it iu ix iy jb lk jf ll jj lm jn ln lo lp lq bi translated"><strong class="is hj">关闭Tensorflow服务器</strong>并清理本地数据</li></ul><p id="cc8e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><em class="lh">输出文件层次遵循输入文件层次</em></p><p id="d02c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">您只需将Embedded-tf容器部署到Cloud Run，并使用3个查询参数调用它。这些参数<a class="ae jo" href="https://cloud.google.com/ai-platform/prediction/docs/batch-predict#configuring_a_batch_prediction_job" rel="noopener ugc nofollow" target="_blank">与AI平台批量预测</a>作业预期的参数相同。</p><ul class=""><li id="367c" class="li lj hi is b it iu ix iy jb lk jf ll jj lm jn ln lo lp lq bi translated"><strong class="is hj">模型</strong>:模型的GCS位置。<em class="lh">相当于ModelURI </em></li><li id="15d9" class="li lj hi is b it lr ix ls jb lt jf lu jj lv jn ln lo lp lq bi translated"><strong class="is hj">输入</strong>:带有预测输入数据的文件的GCS位置。<em class="lh">相当于输入路径</em></li><li id="56e7" class="li lj hi is b it lr ix ls jb lt jf lu jj lv jn ln lo lp lq bi translated"><strong class="is hj">输出</strong>:存储带有预测的输出文件的GCS位置。<em class="lh">相当于输出路径</em></li></ul><p id="0cb8" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">输入输出文件也是AI平台批量预测预期的JSON格式</strong>(暂时<em class="lh">只支持JSON</em>)。</p><p id="dd32" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">有了这些参数和内容一致性，<strong class="is hj">对现有项目的影响很小:</strong>只有API调用需要更改，数据和参数都不需要更改。</p><h2 id="9501" class="lw jq hi bd jr lx ly lz jv ma mb mc jz jb md me kd jf mf mg kh jj mh mi kl mj bi translated">权衡和限制</h2><p id="264b" class="pw-post-body-paragraph iq ir hi is b it kn iv iw ix ko iz ja jb kp jd je jf kq jh ji jj kr jl jm jn hb bi translated">然而，使用云运行管理平台带来了一些约束和限制。</p><p id="15ef" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">资源限制<br/> </strong>托管云运行资源有限。你只有<strong class="is hj"> 1或2个vCPU </strong>，没有定制硬件(GPU，TPU)和最大2Gb的内存<strong class="is hj">。</strong></p><p id="30ad" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">因此，<strong class="is hj">内存占用是一个问题</strong>:</p><ul class=""><li id="837b" class="li lj hi is b it iu ix iy jb lk jf ll jj lm jn ln lo lp lq bi translated">模型文件存储在<strong class="is hj"> `/tmp `目录(内存文件系统)</strong>。</li><li id="3331" class="li lj hi is b it lr ix ls jb lt jf lu jj lv jn ln lo lp lq bi translated">输入和输出文件内容<strong class="is hj">在内存</strong>中保持不变。</li><li id="4b28" class="li lj hi is b it lr ix ls jb lt jf lu jj lv jn ln lo lp lq bi translated">应用程序<strong class="is hj">(Go web服务器)和为请求服务的短暂Tensorflow服务器</strong>也会对内存产生影响。</li></ul><p id="c9b2" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">总数<strong class="is hj">不能超过实例</strong>上允许的内存。</p><p id="3fe4" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><em class="lh">我已经为逐个处理输入文件进行了优化，结果是不能同时处理一个以上的输入文件。但是，如果</em> <strong class="is hj"> <em class="lh">您有大型模型或输入，或者如果您的模型使用大量内存和/或GPU，Embedded-tf可能不适合您</em> </strong> <em class="lh">在托管云上运行</em> <strong class="is hj"> <em class="lh">。</em>T48】</strong></p><p id="bedc" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">并发</strong> <br/>从设计上来说，<strong class="is hj"> Embedded-tf是</strong> <strong class="is hj">当时只能处理一个请求(因而是1个模型)</strong>，特别是对于限制内存的问题。</p><p id="a4ad" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><a class="ae jo" href="https://cloud.google.com/run/docs/configuring/concurrency#command-line" rel="noopener ugc nofollow" target="_blank">在Cloud Run上部署服务时，将</a> <code class="du mr ms mt mu b"><a class="ae jo" href="https://cloud.google.com/run/docs/configuring/concurrency#command-line" rel="noopener ugc nofollow" target="_blank">concurrency</a></code> <a class="ae jo" href="https://cloud.google.com/run/docs/configuring/concurrency#command-line" rel="noopener ugc nofollow" target="_blank">参数设置为1 </a>。</p><h1 id="918f" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">不限型号</h1><p id="23b7" class="pw-post-body-paragraph iq ir hi is b it kn iv iw ix ko iz ja jb kp jd je jf kq jh ji jj kr jl jm jn hb bi translated">现在，Embedded-tf允许团队执行<strong class="is hj">批量预测，而无需提供或部署</strong>。模型是在短暂的Tensorflow服务器上即时下载和加载的！</p><p id="2ec0" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">除了这种灵活性，因为我们的数据量是可以接受的，处理时间更短。只有几秒钟<strong class="is hj">而不是平均6分钟</strong>。的确，有了AI平台批处理，所有的环境都必须被创建和破坏。在这里，不再是这种情况，而是一个<strong class="is hj">动态加载，并从云运行的强大功能开始。</strong></p><p id="959c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">总之，<strong class="is hj">处理更平滑，预测更快，因此成本更低</strong>！这一切没有以前的限制，对现有项目影响很小！</p></div><div class="ab cl mk ml gp mm" role="separator"><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp"/></div><div class="hb hc hd he hf"><p id="63df" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">你呢？你的用例符合E <a class="ae jo" href="https://github.com/guillaumeblaquiere/embedded-tf" rel="noopener ugc nofollow" target="_blank"> mbedded-tf </a>吗？如果是这样，请在评论中告诉我。如果没有，打开一个问题，我们将讨论如何最好地解决它！</p></div></div>    
</body>
</html>