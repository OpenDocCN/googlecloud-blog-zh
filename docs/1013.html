<html>
<head>
<title>Upgrading a large cluster on GKE</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">升级GKE上的大型集群</h1>
<blockquote>原文：<a href="https://medium.com/google-cloud/upgrading-a-large-cluster-on-gke-499a7256e7e1?source=collection_archive---------0-----------------------#2019-05-26">https://medium.com/google-cloud/upgrading-a-large-cluster-on-gke-499a7256e7e1?source=collection_archive---------0-----------------------#2019-05-26</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="49f3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在<a class="ae jd" href="https://www.olark.com/" rel="noopener ugc nofollow" target="_blank"> Olark </a>我们从2017年初开始在<a class="ae jd" href="https://cloud.google.com/kubernetes-engine/" rel="noopener ugc nofollow" target="_blank"> GKE </a>的<a class="ae jd" href="https://kubernetes.io/" rel="noopener ugc nofollow" target="_blank"> kubernetes </a>上运行生产工作负载。一开始，我们的集群很小，很容易管理。当我们在节点上升级kubernetes时，这是我们最常见的集群范围管理任务，我们只需在GKE控制台中运行该过程，并关注一段时间。升级涉及一次拆除和更换一个节点，在最好的情况下，每个节点大约需要4-5分钟。当我们有20个节点时，可能需要90-120分钟，这在可容忍的范围内。这是破坏性的，但我们当时所有的k8s服务都可以应对这种情况。这也是不可逆的，但是我们通过在阶段中进行测试来降低这种风险，并保持足够的最新版本，以便在需要时可以用以前的版本替换<a class="ae jd" href="https://cloud.google.com/kubernetes-engine/docs/concepts/node-pools" rel="noopener ugc nofollow" target="_blank">节点池</a>。这种方法在一年多的时间里似乎运行良好。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es je"><img src="../Images/af562cb03ab2383443a9fb1ff08bd341.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bQuttC4wYEhCr79ZDe65xw.png"/></div></div></figure><p id="5dfa" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">随着集群的增长，我们为特定目的创建了额外的节点池，有趣的事情开始发生了:升级开始变得很麻烦。具体来说，这需要很长时间。我们不仅有了更多的节点，而且在这些节点上运行的服务也更加多样化。其中一些实施的东西，如pod中断预算和终止宽限期，会减缓升级速度。由于遗留的连接管理问题，在没有停机时间的情况下，其他服务器无法重新启动。随着升级时间变长，这些计划停机的持续时间也在增长，影响了我们的客户和我们的团队。毫不奇怪，我们开始落后于当前的GKE发布版本。最近，我们收到了一封来自谷歌支持的电子邮件，让我们知道即将到来的所需的主更新将与我们的节点版本不兼容。我们必须升级他们，否则他们会。</p><p id="4d98" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在试运行中使用我们现有的流程来运行升级很快就让我们认识到，我们已经过了就地进行升级的阶段。我们当时生产中最大的节点池有55个节点，完全升级至少需要6个小时。我们总共有105个节点需要升级。我们需要一种不同的方法，并决定通过替换节点池而不是升级它们来前进。在我介绍这个过程是如何工作的之前，我应该澄清一下，对于运行较大的k8s集群的每个人来说，这不一定是一个问题。如果您的所有服务都是无状态的，并且可以安全地重新安排，那么开始升级并让它运行8或10个小时并不是最糟糕的事情。根据我们的经验，这个过程是高度可靠的，如果你不得不退出，有简单的恢复选项。</p><p id="7d9f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">但我怀疑许多人会遇到与我们类似的情况，他们的工作负载多种多样，对中断的容忍度也各不相同。在我们的例子中，集群中有四个节点池，每个节点池都有特定的用途。有些运行无状态的http和rpc服务，非常有弹性。有些运行的服务我们不想在没有通知的情况下重启。另一个运行一个大型的<a class="ae jd" href="https://www.elastic.co/products/elasticsearch" rel="noopener ugc nofollow" target="_blank"> elasticsearch </a>集群，每天接收1 . 5亿到2亿个日志事件。我们决定分别处理其中的每一项，并在不同的时间进行升级，只是为了保持合理和集中的范围，并允许我们根据相关的工作负载定制方法。</p><p id="4198" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们从elasticsearch集群开始，并决定像以前一样就地升级该节点池。运行一个或两个pod的节点相对较少，即使在负载下，elasticsearch本身也能很好地容忍节点故障。每次取出一个节点，中间间隔5分钟，这应该是它可以处理的事情，事实上，这个过程进行得非常顺利。有时集群状态会变成红色，日志传送会有一些短暂的中断，但是正如我的一个同事喜欢指出的那样:“日志记录是一条消防水管。”如果水桶不够大，那就是不够大，我们可以忍受一段时间。</p><p id="924a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们最大的节点池运行无状态http和rpc服务，由超过75个节点组成。这些节点池<a class="ae jd" href="https://cloud.google.com/kubernetes-engine/docs/concepts/cluster-autoscaler" rel="noopener ugc nofollow" target="_blank">自动缩放</a>，其中一些节点池有污点和标签，这些污点和标签对于pod关联性非常重要。为此，我们首先在目标版本上创建一个新的节点池，禁用自动伸缩，使用少量固定的节点。新的节点池复制了现有节点池中的污点和标签。然后，我们在源节点池上禁用了自动扩展。完成后，我们开始通过缩小源节点池和一次扩大10个替换节点来迁移pod。这个过程花了几个小时，非常顺利。我将在下面的结论中谈到我们遇到的一两个问题。完全迁移后，我们在新节点池上启用了自动扩展，并删除了旧节点池。另一个好处是，我们之前注意到，我们在磁盘上为这些节点过度配置了资源，并且能够将引导磁盘大小减半，节省了2500 GB。</p><p id="cb12" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">最后，我们为“无重启”服务的迁移安排了停机时间。我们通过创建新的节点池、复制污点和标签来为此做准备。在这种情况下，我们的目标是迁移pod并尽可能缩短停机时间，因此我们以完整的目标大小创建了新的节点池。然后，我们将现有的节点池缩减一半，等待节点被删除，单元被重新安排并准备就绪。在验证了新节点上的工作负载后，我们删除了剩余的源节点池，并将剩余的节点池强制转移到新节点上。如果新节点上的工作负载出现故障，回退将是备份以前的节点池并删除新的节点池。所有这些升级总共花费了大约三个小时，完成后，我们的105节点集群的所有组件都运行在最新版本的kubernetes上。</p><p id="c11a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我可以把这篇文章的标题定为“我们为什么运行kubernetes”或者“我喜欢节点池”，而且几乎做到了。从我作为一名软件工程师和SRE的角度来看，全身心投入kubernetes生态系统所带来的灵活性仍然是一件近乎神奇的事情。不是说我们没有遇到一点小麻烦。发生的一件神秘的事情是，缩小现有的节点池有两次挂起。好消息是，使用<code class="du jq jr js jt b">kubectl get nodes</code>并检查节点状态可以很容易地识别哪个节点导致了问题。在升级期间，节点从<code class="du jq jr js jt b">Ready/Schedulable</code>移动到<code class="du jq jr js jt b">Ready/NotSchedulable</code>，最后移动到<code class="du jq jr js jt b">NotReady/NotSchedulable</code>，之后它们被移除。每次都有一个节点卡在<code class="du jq jr js jt b">Ready/NotSchedulable</code>。很容易识别和移除妨碍工作的悬挂pod，这两种情况下都是<a class="ae jd" href="https://kubernetes.github.io/ingress-nginx/" rel="noopener ugc nofollow" target="_blank"> nginx入口控制器</a>默认后端。</p><p id="2a70" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我想对我的同事Kyle Owens、Nick Hill、Nick MacInnis和Aaron Wilson表示感谢，感谢他们在集思广益和实施升级方面提供的帮助，并感谢我们的前同事Brandon Dimcheff，感谢他们提供了很好的建议。</p></div></div>    
</body>
</html>